# ARGO Enhanced Prompts V2.0

## ğŸ“‹ æ¦‚è¿°

æœ¬æ¬¡æ›´æ–°å°†é«˜è´¨é‡çš„LLM promptsèå…¥åˆ°ARGOç³»ç»Ÿä¸­ï¼ŒåŸºäº `ARGO_Complete_LLM_Prompts.txt` çš„æœ€ä½³å®è·µï¼Œæ˜¾è‘—æå‡äº†ç³»ç»Ÿå„ä¸ªç»„ä»¶çš„æç¤ºè¯è´¨é‡ã€‚

## ğŸ¯ ä¸»è¦æ”¹è¿›

### 1. **ç»Ÿä¸€çš„Promptsç®¡ç†æ¨¡å—** (`src/prompts.py`)

åˆ›å»ºäº†é›†ä¸­åŒ–çš„æç¤ºè¯ç®¡ç†ç³»ç»Ÿï¼ŒåŒ…å«ï¼š

- **åŸºç¡€æŒ‡ä»¤**: ARGOç³»ç»Ÿçš„æ ¸å¿ƒè§’è‰²å®šä¹‰
- **æŸ¥è¯¢åˆ†è§£**: å¸¦è¿›åº¦è¿½è¸ªçš„åˆ†è§£æ¨¡æ¿ï¼ˆåŒ…å«3ä¸ªå®Œæ•´ç¤ºä¾‹ï¼‰
- **æ£€ç´¢ç­”æ¡ˆç”Ÿæˆ**: åŸºäºæ£€ç´¢æ–‡æ¡£çš„ç­”æ¡ˆæ¨¡æ¿ï¼ˆåŒ…å«4ä¸ªç¤ºä¾‹ï¼‰
- **ä¸­é—´æ¨ç†**: å‚æ•°åŒ–çŸ¥è¯†æ¨ç†æ¨¡æ¿
- **æœ€ç»ˆåˆæˆ**: æ ¼å¼åŒ–è¾“å‡ºæ¨¡æ¿ï¼ˆæ”¯æŒé•¿/çŸ­ç­”æ¡ˆï¼‰

**ç‰¹ç‚¹**:
- Few-shot learningï¼ˆæ¯ä¸ªä»»åŠ¡3-4ä¸ªç¤ºä¾‹ï¼‰
- æ˜ç¡®çš„æŒ‡ä»¤å’Œæ ¼å¼è¦æ±‚
- è¿›åº¦è¿½è¸ªï¼ˆProgress: 0-100%ï¼‰
- O-RANé¢†åŸŸç‰¹å®šæŒ‡å¯¼

### 2. **QueryDecomposer å¢å¼º** (`src/decomposer.py`)

**æ”¹è¿›å†…å®¹**:
```python
# æ—§ç‰ˆæœ¬ï¼šç®€å•çš„æŒ‡ä»¤
"Generate a sub-question to help answer the original question."

# æ–°ç‰ˆæœ¬ï¼šå¸¦è¿›åº¦è¿½è¸ªå’Œç¤ºä¾‹çš„å®Œæ•´æ¨¡æ¿
"""
[Progress: 35%] Follow up: What are the latency requirements for O-RAN fronthaul?
Let's search in O-RAN specifications.
Context: [O-RAN.WG4] One-way latency typically <400us for FR1.
Intermediate answer: The one-way fronthaul latency requirement is typically 
under 400 microseconds for FR1...
"""
```

**ä¼˜åŠ¿**:
- âœ… è‡ªåŠ¨æ·»åŠ è¿›åº¦ç™¾åˆ†æ¯”
- âœ… æ ‡å‡†åŒ–çš„"Follow up:"æ ¼å¼
- âœ… ç¤ºä¾‹å¼•å¯¼ç”Ÿæˆæ›´å‡†ç¡®çš„å­æŸ¥è¯¢
- âœ… é¿å…é‡å¤æŸ¥è¯¢

### 3. **Retriever ç­”æ¡ˆç”Ÿæˆ** (`src/retriever.py`)

**æ–°å¢åŠŸèƒ½**:
```python
# åœºæ™¯1: æ£€ç´¢æˆåŠŸåï¼ŒåŸºäºæ£€ç´¢æ–‡æ¡£ç”Ÿæˆç­”æ¡ˆ
answer = retriever.generate_answer_from_docs(
    question=subquery,
    docs=retrieved_docs,
    model=model,
    tokenizer=tokenizer
)
# ä½¿ç”¨ RETRIEVAL_ANSWER_PROMPTï¼ˆå¸¦Contextï¼‰
```

**æ”¹è¿›å†…å®¹**:
- âœ… åŸºäºæ£€ç´¢æ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆä¸­é—´ç­”æ¡ˆ
- âœ… ä½¿ç”¨ä¸“é—¨çš„æ£€ç´¢ç­”æ¡ˆpromptï¼ˆSection 5ï¼‰
- âœ… æ”¯æŒ"[No information found]"æ£€æµ‹
- âœ… å¼•ç”¨O-RANè§„èŒƒæ¥æº

### 4. **ARGO_System æ¨ç†ä¼˜åŒ–** (`src/argo_system.py`)

**ä¸¤ç§ä¸åŒçš„ç­”æ¡ˆç”Ÿæˆæ¨¡å¼**:

**æ¨¡å¼1: æ£€ç´¢åç­”æ¡ˆç”Ÿæˆ** (RetrieveåŠ¨ä½œ)
```python
# _execute_retrieve() ä¸­
answer = retriever.generate_answer_from_docs(
    question=subquery,
    docs=docs,  # â† ä½¿ç”¨æ£€ç´¢åˆ°çš„æ–‡æ¡£
    model=model,
    tokenizer=tokenizer
)
# ä½¿ç”¨ build_retrieval_answer_prompt()
# æ ¼å¼: Question + Context â†’ Answer
```

**æ¨¡å¼2: å‚æ•°åŒ–çŸ¥è¯†æ¨ç†** (ReasonåŠ¨ä½œ)
```python
# _execute_reason() ä¸­
prompt = ARGOPrompts.build_reasoning_prompt(
    original_question=question,
    history=history  # â† ä½¿ç”¨å†å²ï¼Œä½†ä¸ä¾èµ–æ–°æ–‡æ¡£
)
# ä½¿ç”¨ build_reasoning_prompt()
# æ ¼å¼: Question + Previous context â†’ Intermediate reasoning
# LLMåŸºäºé¢„è®­ç»ƒçŸ¥è¯†æ¨ç†ï¼Œä¸æ£€ç´¢æ–°æ–‡æ¡£
```

**å…³é”®åŒºåˆ«**:

| ç»´åº¦ | æ£€ç´¢ç­”æ¡ˆç”Ÿæˆ | å‚æ•°åŒ–æ¨ç† |
|------|-------------|-----------|
| è§¦å‘æ¡ä»¶ | RetrieveåŠ¨ä½œæˆåŠŸ | ReasonåŠ¨ä½œ |
| è¾“å…¥ | Question + **Retrieved Docs** | Question + **History context** |
| Promptæ¨¡æ¿ | `RETRIEVAL_ANSWER_PROMPT` | `REASONING_PROMPT` |
| Few-shotç¤ºä¾‹ | 4ä¸ªæ£€ç´¢ç¤ºä¾‹ | 3ä¸ªæ¨ç†ç¤ºä¾‹ |
| çŸ¥è¯†æ¥æº | **å¤–éƒ¨æ–‡æ¡£** | **LLMå‚æ•°åŒ–çŸ¥è¯†** |
| è¾“å‡ºæ ¼å¼ | ç›´æ¥ç­”æ¡ˆ | ä¸­é—´æ¨ç† |

**ä¼˜åŠ¿**:
- âœ… æ˜ç¡®åŒºåˆ†ä¸¤ç§çŸ¥è¯†æ¥æº
- âœ… æ£€ç´¢promptå¼ºè°ƒåŸºäºæ–‡æ¡£å›ç­”
- âœ… æ¨ç†promptå¼ºè°ƒåŸºäºå·²çŸ¥ä¿¡æ¯è¿æ¥
- âœ… é¿å…æ··æ·†æ£€ç´¢å’Œæ¨ç†

### 5. **AnswerSynthesizer æ ¼å¼åŒ–è¾“å‡º** (`src/synthesizer.py`)

**æ–°å¢åŠŸèƒ½**:
```python
# æ”¯æŒæ ¼å¼åŒ–è¾“å‡º
<answer long>
The O-RAN fronthaul interface uses three protocol layers: 
Control-Plane (CU-Plane) for control signaling over eCPRI/Ethernet, 
User-Plane (U-Plane) for IQ data transport with eCPRI encapsulation, 
and Synchronization-Plane (S-Plane) for precise timing...
</answer long>

<answer short>
O-RAN fronthaul uses C/U/S-plane protocols with <400us latency, 
eCPRI encapsulation, compression options, requiring low-latency 
transport limited to ~20km.
</answer short>
```

**ä¼˜åŠ¿**:
- âœ… è‡ªåŠ¨æå–é•¿/çŸ­ç­”æ¡ˆ
- âœ… æ•´åˆæ‰€æœ‰æ£€ç´¢æ–‡æ¡£
- âœ… å±•ç¤ºæ¨ç†å†å²æ‘˜è¦
- âœ… æä¾›ç­”æ¡ˆæº¯æº

## ğŸ“ æ–‡ä»¶ç»“æ„

```
ARGO2/ARGO/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ prompts.py           # â­ æ–°å¢ï¼šç»Ÿä¸€çš„Promptsç®¡ç†
â”‚   â”œâ”€â”€ decomposer.py        # âœ¨ æ›´æ–°ï¼šä½¿ç”¨æ–°prompts
â”‚   â”œâ”€â”€ retriever.py         # âœ¨ æ›´æ–°ï¼šæ–°å¢ç­”æ¡ˆç”Ÿæˆ
â”‚   â”œâ”€â”€ argo_system.py       # âœ¨ æ›´æ–°ï¼šä½¿ç”¨æ–°æ¨ç†prompts
â”‚   â””â”€â”€ synthesizer.py       # âœ¨ æ›´æ–°ï¼šæ ¼å¼åŒ–è¾“å‡º
â”œâ”€â”€ test_enhanced_prompts.py # â­ æ–°å¢ï¼šæµ‹è¯•è„šæœ¬
â””â”€â”€ PROMPTS_V2_README.md     # â­ æ–°å¢ï¼šæœ¬æ–‡æ¡£
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### å¿«é€Ÿæµ‹è¯•ï¼ˆæ¨èï¼‰

ä½¿ç”¨Mockæ£€ç´¢å™¨å¿«é€ŸéªŒè¯promptæ•ˆæœï¼š

```bash
cd /data/user/huangxiaolin/ARGO2/ARGO
python test_enhanced_prompts.py --mode quick
```

### å®Œæ•´æµ‹è¯•

ä½¿ç”¨çœŸå®Chromaæ•°æ®åº“ï¼š

```bash
python test_enhanced_prompts.py --mode full \
    --model /path/to/Qwen2.5-1.5B-Instruct \
    --device cuda:0
```

### é›†æˆåˆ°å®éªŒä¸­

åœ¨ä½ çš„å®éªŒè„šæœ¬ä¸­ä½¿ç”¨å¢å¼ºçš„ARGOç³»ç»Ÿï¼š

```python
from src.argo_system import ARGO_System

# åˆå§‹åŒ–ç³»ç»Ÿï¼ˆè‡ªåŠ¨ä½¿ç”¨æ–°promptsï¼‰
argo = ARGO_System(
    model=model,
    tokenizer=tokenizer,
    use_mdp=True,
    retriever_mode="chroma",  # æˆ– "mock"
    chroma_dir="Environments/chroma_store",
    verbose=True
)

# è¿è¡ŒæŸ¥è¯¢ï¼ˆå†…éƒ¨ä½¿ç”¨å¢å¼ºçš„promptsï¼‰
answer, history, metadata = argo.run_episode(
    question="What is the E2 interface latency requirement?",
    return_history=True
)

print(f"Answer: {answer}")
print(f"Steps: {metadata['total_steps']}")
print(f"Retrievals: {metadata['retrieve_count']}")
```

## ğŸ“Š å¯¹æ¯”ç¤ºä¾‹

### æŸ¥è¯¢åˆ†è§£å¯¹æ¯”

**æ—§ç‰ˆæœ¬è¾“å‡º**:
```
What is the E2 interface?
What are the latency requirements?
How does it work?
```

**æ–°ç‰ˆæœ¬è¾“å‡º**:
```
[Progress: 0%] Follow up: What is the E2 interface in O-RAN architecture?
Let's search in O-RAN specifications.

[Progress: 30%] Follow up: What are E2 service models?
Let's search in O-RAN specifications.

[Progress: 55%] Follow up: How do xApps use E2 interface for optimization?
Intermediate answer: xApps running on Near-RT RIC subscribe to E2SM services...
```

### ç­”æ¡ˆè´¨é‡å¯¹æ¯”

**æ—§ç‰ˆæœ¬**:
```
The E2 interface connects RIC to nodes. It has service models like KPM and RC.
```

**æ–°ç‰ˆæœ¬**:
```
<answer long>
The E2 interface enables RAN optimization by connecting the Near-RT RIC to 
E2 nodes (O-CU-CP, O-CU-UP, O-DU) for near-real-time control with 10ms-1s 
latency. It uses standardized E2 Service Models (E2SM) including KPM for 
performance monitoring, RC for RAN control, NI for network interfaces, and 
CCC for mobility control. xApps on the Near-RT RIC subscribe to these services 
to receive real-time RAN metrics, analyze network conditions, and send control 
commands to optimize parameters like handover thresholds, scheduling policies, 
and resource allocation.
</answer long>

<answer short>
E2 interface connects Near-RT RIC to RAN nodes enabling 10ms-1s optimization 
through E2 Service Models (KPM, RC, NI, CCC) that allow xApps to monitor 
metrics and control RAN parameters dynamically.
</answer short>
```

## ğŸ”§ é…ç½®é€‰é¡¹

åœ¨ `src/prompts.py` çš„ `PromptConfig` ç±»ä¸­å¯ä»¥è°ƒæ•´ï¼š

```python
class PromptConfig:
    # Decomposeré…ç½®
    DECOMPOSER_MAX_LENGTH = 128
    DECOMPOSER_TEMPERATURE = 0.7
    DECOMPOSER_TOP_P = 0.9
    
    # Reasoneré…ç½®
    REASONER_MAX_LENGTH = 256
    REASONER_TEMPERATURE = 0.5
    REASONER_TOP_P = 0.95
    
    # Synthesizeré…ç½®
    SYNTHESIZER_MAX_LENGTH = 512
    SYNTHESIZER_TEMPERATURE = 0.3  # è¾ƒä½æ¸©åº¦ä¿è¯å‡†ç¡®æ€§
    SYNTHESIZER_TOP_P = 0.95
    
    # é€šç”¨é…ç½®
    MAX_HISTORY_STEPS = 5      # æç¤ºè¯ä¸­æ˜¾ç¤ºçš„æœ€å¤§å†å²æ­¥æ•°
    MAX_DOCS_PER_STEP = 3      # æ¯æ­¥æ˜¾ç¤ºçš„æœ€å¤§æ–‡æ¡£æ•°
    DOC_TRUNCATE_LENGTH = 300  # æ–‡æ¡£æˆªæ–­é•¿åº¦
```

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

åŸºäºARGO V2.2å®éªŒæ¡†æ¶çš„è®¾è®¡ç›®æ ‡ï¼š

| æŒ‡æ ‡ | æ—§ç‰ˆæœ¬ | æ–°ç‰ˆæœ¬ | æ”¹è¿› |
|------|--------|--------|------|
| ç­”æ¡ˆè´¨é‡ (Q) | ~0.65 | **~0.85** | +31% |
| å­æŸ¥è¯¢ç›¸å…³æ€§ | ä¸­ç­‰ | **é«˜** | æ˜¾è‘—æå‡ |
| æ£€ç´¢æˆåŠŸç‡ | 70% | **85%** | +21% |
| æ ¼å¼ä¸€è‡´æ€§ | ä½ | **é«˜** | æ ‡å‡†åŒ– |
| å¯è¿½æº¯æ€§ | æ—  | **å®Œæ•´** | æ–°å¢æ¥æº |

## ğŸ› å·²çŸ¥é—®é¢˜

1. **é•¿æ–‡æœ¬æˆªæ–­**: å½“å†å²è¾ƒé•¿æ—¶ï¼Œpromptå¯èƒ½è¶…å‡ºæ¨¡å‹ä¸Šä¸‹æ–‡é™åˆ¶
   - **è§£å†³æ–¹æ¡ˆ**: å·²è®¾ç½® `max_length=4096` å¹¶æ™ºèƒ½æˆªæ–­å†å²
   
2. **æ ¼å¼è§£æå¤±è´¥**: å°æ¨¡å‹å¯èƒ½ä¸ä¸¥æ ¼éµå¾ª `<answer long>` æ ¼å¼
   - **è§£å†³æ–¹æ¡ˆ**: `_postprocess_answer` æœ‰å…œåº•é€»è¾‘
   
3. **ä¸­æ–‡promptæ”¯æŒ**: å½“å‰promptsä¸ºè‹±æ–‡
   - **è®¡åˆ’**: æœªæ¥å¯æ·»åŠ ä¸­æ–‡ç‰ˆæœ¬

## ğŸ”„ å‘åå…¼å®¹æ€§

âœ… **å®Œå…¨å…¼å®¹**: ç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹ï¼ŒARGO_Systemè‡ªåŠ¨ä½¿ç”¨æ–°prompts

```python
# æ—§ä»£ç ç»§ç»­å·¥ä½œ
argo = ARGO_System(model, tokenizer)
answer, _, _ = argo.run_episode(question)

# æ–°åŠŸèƒ½å¯é€‰ä½¿ç”¨
from src.prompts import ARGOPrompts
prompt = ARGOPrompts.build_decomposition_prompt(...)
```

## ğŸ“š å‚è€ƒæ–‡æ¡£

- `ARGO_Enhanced_Single_Prompt_V2.2.txt` - å®éªŒæ¡†æ¶è®¾è®¡
- `ARGO_Complete_LLM_Prompts.txt` - å®Œæ•´Promptæ¨¡æ¿
- `ARCHITECTURE_EXPLANATION.md` - ç³»ç»Ÿæ¶æ„è¯´æ˜

## ğŸ“ å¼•ç”¨

å¦‚æœä½ ä½¿ç”¨äº†å¢å¼ºçš„ARGO Promptsï¼Œè¯·å¼•ç”¨ï¼š

```
ARGO (Adaptive RAG for O-RAN) - Enhanced Prompts V2.0
Optimal Policy Implementation with Standardized LLM Prompts
2024
```

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æ”¹è¿›promptsï¼è¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š

1. âœ… ä¿æŒFew-shotç¤ºä¾‹ï¼ˆ3-4ä¸ªï¼‰
2. âœ… æ˜ç¡®çš„ä»»åŠ¡æŒ‡ä»¤
3. âœ… O-RANé¢†åŸŸç‰¹å®š
4. âœ… æ ¼å¼ä¸€è‡´æ€§
5. âœ… æ·»åŠ æµ‹è¯•ç”¨ä¾‹

## ğŸ“§ è”ç³»

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š
- `test_enhanced_prompts.py` çš„æµ‹è¯•è¾“å‡º
- `src/prompts.py` çš„æ–‡æ¡£æ³¨é‡Š
- å®éªŒæ—¥å¿—ä¸­çš„è¯¦ç»†é”™è¯¯ä¿¡æ¯

---

**æœ€åæ›´æ–°**: 2024å¹´11æœˆ
**ç‰ˆæœ¬**: V2.0
**çŠ¶æ€**: âœ… å·²å®Œæˆé›†æˆ
