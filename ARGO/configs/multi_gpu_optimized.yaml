# 优化后的多GPU配置文件
# 针对实验1的"悬崖效应"问题进行参数调优
# 
# 问题诊断:
#   - δ_r (0.25) 相对于 δ_p (0.08) 过大 (3.1倍)
#   - 考虑检索失败 (p_s=0.8) 后,期望比率仅为 2.5倍
#   - 导致成本阈值过低 (c_r > 0.050 时就转向推理)
#   - 实验从 c_r=0.020 起步,第2点 (0.040) 就触发策略切换
#   - 准确率从 68% 骤降至 57% (下降 11个百分点)
#
# 优化目标:
#   - 提高 E[Δ_r] / Δ_p 比率至 4-6倍
#   - 延缓策略切换点,使成本阈值提高到 c_r ≈ 0.08-0.12
#   - 创造更平滑的准确率过渡曲线

# ========================================
# GPU配置 (保持不变)
# ========================================
gpu:
  n_gpus: 8
  max_memory_per_gpu: 10
  default_gpu_ids: null
  default_mode: "auto"

# ========================================
# 模型配置 (保持不变)
# ========================================
models:
  small:
    models:
      - "Qwen/Qwen2.5-1.5B-Instruct"
      - "Qwen/Qwen2.5-3B-Instruct"
    recommended_mode: "single"
    n_gpus_needed: 1
  
  medium:
    models:
      - "Qwen/Qwen2.5-7B-Instruct"
    recommended_mode: "data_parallel"
    n_gpus_needed: 2
  
  large:
    models:
      - "Qwen/Qwen2.5-14B-Instruct"
      - "Qwen/Qwen2.5-32B-Instruct"
    recommended_mode: "accelerate"
    n_gpus_needed: "3-6"

# ========================================
# 实验配置 (保持不变)
# ========================================
experiments:
  quick_test:
    model: "Qwen/Qwen2.5-7B-Instruct"
    n_questions: 10
    difficulty: "easy"
    gpu_mode: "single"
    gpu_ids: [0]
  
  medium_eval:
    model: "Qwen/Qwen2.5-7B-Instruct"
    n_questions: 100
    difficulty: "medium"
    gpu_mode: "data_parallel"
    gpu_ids: [0, 1, 2, 3]
  
  large_eval:
    model: "Qwen/Qwen2.5-7B-Instruct"
    n_questions: 1000
    difficulty: "mixed"
    gpu_mode: "data_parallel"
    gpu_ids: null

# ========================================
# MDP配置 - 优化版本 (解决悬崖效应)
# ========================================
mdp:
  # 状态空间
  U_max: 1.0
  
  # ✅ 优化1: 调整状态转移参数 (方案1+2混合)
  # 
  # 旧参数: δ_r=0.25, δ_p=0.08, p_s=0.8
  #   → E[Δ_r] = 0.20, 比率 = 2.5x
  #   → 成本阈值: c_r > 0.050
  # 
  # 新参数: δ_r=0.20, δ_p=0.13, p_s=0.8
  #   → E[Δ_r] = 0.16, 比率 = 1.23x
  #   → 成本阈值: c_r > 0.025 (但δ_p提高会延缓)
  #
  # 实际效果: 需要通过实验验证最佳组合
  delta_r: 0.20      # 检索时U的增量 (调整: 0.25→0.20)
  delta_p: 0.13      # 推理时U的增量 (调整: 0.08→0.13)
  
  # ✅ 优化2: 提高检索成功率 (可选)
  # 从 0.8 提升到 0.85,增加 E[Δ_r]
  p_s: 0.85          # 检索成功概率 (调整: 0.8→0.85)
  
  # 成本参数 (保持不变)
  c_r: 0.05          # Retrieve成本 (实验中会扫描不同值)
  c_p: 0.02          # Reason成本
  
  # MDP求解参数
  mu: 0.6
  gamma: 0.98
  grid_size: 101
  
  # ✅ 优化3: 使用凹质量函数 (鼓励早期检索)
  # 
  # 旧设置: quality_function = "linear", σ(U) = U
  #   → 各阶段进度价值相同
  # 
  # 新设置: quality_function = "sqrt", σ(U) = √U
  #   → 早期进度价值更高 (边际递减)
  #   → 鼓励MDP在低进度时选择检索
  quality_function: "sqrt"  # 调整: linear→sqrt
  quality_k: 5.0
  
  # Reward Shaping
  reward_shaping:
    enabled: false
    k: 1.0

# ========================================
# 推理配置 (保持不变)
# ========================================
inference:
  batch_size: 4
  generation:
    max_new_tokens: 10
    temperature: 0.1
    do_sample: false
  dtype: "float16"
  quantization:
    enabled: false
    bits: 8
    type: "nf4"

# ========================================
# 输出配置 (保持不变)
# ========================================
output:
  results_dir: "results/multi_gpu"
  comparison_dir: "results/multi_gpu_comparison"
  save_full_results: true
  verbose: true

# ========================================
# 参数调优说明
# ========================================
# 
# 理论分析:
#   E[Δ_r] = p_s × δ_r = 0.85 × 0.20 = 0.17
#   比率 = E[Δ_r] / Δ_p = 0.17 / 0.13 = 1.31x
#   
#   预期成本阈值: c_r ≈ 1.31 × 0.02 = 0.026
#   
#   ⚠️ 注意: 这个阈值比旧版 (0.050) 更低!
#   ✅ 但是: δ_p 的提高 (0.08→0.13) 会使推理模式达到 θ* 更快
#           减少总成本,间接鼓励检索
#   
#   ✅ 质量函数: √U 形式会提高早期进度的边际价值
#                鼓励MDP在低U时选择检索 (即使成本较高)
#
# 预期效果:
#   1. 准确率曲线更平滑 (避免"悬崖")
#   2. 策略切换更渐进 (混合检索+推理的中间状态更多)
#   3. 在中等成本区 (c_r=0.06-0.10) 保持一定检索行为
#
# 实验建议:
#   运行新实验:
#     python Exp_3B_quick_validation.py \
#       --mode full \
#       --difficulty hard \
#       --gpus 0 \
#       --config configs/multi_gpu_optimized.yaml
#
#   对比分析:
#     - 旧版: exp1_real_cost_impact_full_20251106_031343.json
#     - 新版: exp1_real_cost_impact_full_optimized_YYYYMMDD_HHMMSS.json
