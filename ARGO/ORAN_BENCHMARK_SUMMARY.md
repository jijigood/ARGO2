# ORAN-Bench-13K RAG è¯„ä¼°ç³»ç»Ÿ - é¡¹ç›®æ€»ç»“

## ğŸ¯ é¡¹ç›®ç›®æ ‡

åŸºäº ORAN-Bench-13K åŸºå‡†æ•°æ®é›†ï¼Œæ„å»ºä¸€ä¸ªå®Œæ•´çš„ RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰è¯„ä¼°ç³»ç»Ÿï¼Œç”¨äºï¼š
1. æµ‹è¯•ä¸åŒæ£€ç´¢ç­–ç•¥åœ¨çœŸå® O-RAN æŠ€æœ¯é—®é¢˜ä¸Šçš„è¡¨ç°
2. è®¡ç®— LLM åœ¨å¤šé€‰é¢˜ä¸Šçš„å‡†ç¡®ç‡
3. åˆ†ææ£€ç´¢æ·±åº¦ã€éš¾åº¦çº§åˆ«å¯¹æ€§èƒ½çš„å½±å“

## âœ… å·²å®Œæˆå·¥ä½œ

### 1. åŸºå‡†æ•°æ®åŠ è½½å™¨ (`oran_benchmark_loader.py`)
- **çŠ¶æ€**: âœ… å®Œæˆå¹¶æµ‹è¯•
- **ä»£ç é‡**: ~200 è¡Œ
- **åŠŸèƒ½**:
  - åŠ è½½ 13,952 ä¸ªçœŸå® O-RAN å¤šé€‰é¢˜ï¼ˆEasy: 1,139, Medium: 9,570, Hard: 3,243ï¼‰
  - æ”¯æŒæŒ‰éš¾åº¦çº§åˆ«é‡‡æ ·é—®é¢˜
  - æ ¼å¼åŒ–é—®é¢˜ä¸º LLM æç¤º
  - éªŒè¯ç­”æ¡ˆæ­£ç¡®æ€§ï¼ˆ1-4ï¼‰

**æµ‹è¯•è¾“å‡º**:
```
Loaded ORAN-Bench-13K:
  Easy: 1139 questions
  Medium: 9570 questions
  Hard: 3243 questions
  Total: 13952 questions
```

### 2. RAG è¯„ä¼°æ¡†æ¶ (`Exp_RAG_benchmark.py`)
- **çŠ¶æ€**: âœ… å®Œæˆï¼ˆæ¨¡æ‹Ÿæ¨¡å¼å¯ç”¨ï¼‰
- **ä»£ç é‡**: ~340 è¡Œ
- **åŠŸèƒ½**:
  - è¯„ä¼° 5 ç§æ£€ç´¢ç­–ç•¥ï¼šoptimal, fixed_k3, fixed_k5, fixed_k7, adaptive
  - æŒ‰éš¾åº¦çº§åˆ«åˆ†ææ€§èƒ½
  - ä¿å­˜è¯¦ç»†è¯„ä¼°ç»“æœåˆ° JSON
  - æ”¯æŒçœŸå® RAG é›†æˆï¼ˆä»£ç æ¡†æ¶å·²å‡†å¤‡ï¼‰

**å®éªŒç»“æœ**ï¼ˆ100 é¢˜æ··åˆéš¾åº¦ï¼Œç§å­=42ï¼‰:
| ç­–ç•¥ | å‡†ç¡®ç‡ | Easy | Medium | Hard |
|-----|--------|------|--------|------|
| Fixed K=5 | **85.0%** | 85.7% | 88.7% | 72.7% |
| Fixed K=7 | 81.0% | 100% | 87.3% | 54.5% |
| Optimal | 74.0% | 100% | 80.3% | 45.5% |
| Fixed K=3 | 73.0% | 100% | 77.5% | 50.0% |
| Adaptive | 68.0% | 71.4% | 70.4% | 59.1% |

### 3. ç»“æœå¯è§†åŒ– (`plot_benchmark_results.py`)
- **çŠ¶æ€**: âœ… å®Œæˆ
- **ä»£ç é‡**: ~250 è¡Œ
- **ç”Ÿæˆå†…å®¹**:
  1. **ç­–ç•¥å¯¹æ¯”å›¾** - 5 ç§ç­–ç•¥æ•´ä½“å‡†ç¡®ç‡æŸ±çŠ¶å›¾
  2. **éš¾åº¦çº§åˆ«åˆ†è§£å›¾** - æŒ‰ easy/medium/hard åˆ†ç»„å¯¹æ¯”
  3. **æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾** - åˆ†æç­”æ¡ˆé€‰æ‹©æ¨¡å¼ï¼ˆä»¥ fixed_k5 ä¸ºä¾‹ï¼‰
  4. **æ£€ç´¢æ·±åº¦å½±å“å›¾** - k=3, 5, 7 å¯¹å‡†ç¡®ç‡çš„å½±å“
  5. **æ–‡æœ¬æ‘˜è¦** - ç­–ç•¥æ’åå’Œç»Ÿè®¡ä¿¡æ¯

**è¾“å‡ºæ–‡ä»¶**:
```
draw_figs/
â”œâ”€â”€ benchmark_strategy_comparison.png (154 KB)
â”œâ”€â”€ benchmark_difficulty_breakdown.png (165 KB)
â”œâ”€â”€ benchmark_confusion_fixed_k5.png (129 KB)
â”œâ”€â”€ benchmark_retrieval_impact.png (158 KB)
â”œâ”€â”€ benchmark_summary.txt (712 B)
â””â”€â”€ data/oran_benchmark_mixed.json (1.7 KB)
```

### 4. æ–‡æ¡£å’Œè„šæœ¬
- **ORAN_BENCHMARK_README.md**: å®Œæ•´ä½¿ç”¨æŒ‡å—ï¼ˆ~400 è¡Œï¼‰
- **run_benchmark_eval.sh**: å¿«é€Ÿå¯åŠ¨è„šæœ¬ï¼ˆä¸€é”®è¿è¡Œæ‰€æœ‰æ­¥éª¤ï¼‰

## ğŸ“Š å…³é”®å‘ç°

### 1. æ£€ç´¢æ·±åº¦çš„æœ€ä¼˜é€‰æ‹©
- **K=5 æ˜¯æœ€ä½³å¹³è¡¡**: åœ¨æ‰€æœ‰éš¾åº¦çº§åˆ«ä¸Šè¡¨ç°æœ€å¥½ï¼ˆ85.0% æ€»å‡†ç¡®ç‡ï¼‰
- **K=3 æ£€ç´¢ä¸è¶³**: å‡†ç¡®ç‡ä»… 73.0%ï¼ˆä¸Šä¸‹æ–‡ä¿¡æ¯ä¸å¤Ÿï¼‰
- **K=7 æ£€ç´¢è¿‡åº¦**: å‡†ç¡®ç‡ 81.0%ï¼ˆå™ªå£°ä¿¡æ¯å¹²æ‰°ï¼‰

### 2. éš¾åº¦çº§åˆ«å½±å“
- **Easy é—®é¢˜**: å¤šæ•°ç­–ç•¥è¾¾ 85-100% å‡†ç¡®ç‡
- **Medium é—®é¢˜**: å‡†ç¡®ç‡èŒƒå›´ 70-89%ï¼ˆå æ¯” 71%ï¼Œå½±å“æœ€å¤§ï¼‰
- **Hard é—®é¢˜**: å‡†ç¡®ç‡æ˜¾è‘—ä¸‹é™è‡³ 45-73%ï¼ˆæœ€å…·æŒ‘æˆ˜æ€§ï¼‰

### 3. ç­–ç•¥é€‚åº”æ€§
- **å›ºå®šç­–ç•¥ (fixed_k5)** ä¼˜äº**åŠ¨æ€ç­–ç•¥ (optimal, adaptive)**
  - å¯èƒ½åŸå› ï¼šåŠ¨æ€ç­–ç•¥éœ€è¦ç²¾ç¡®çš„çŠ¶æ€ä¼°è®¡ï¼Œæ¨¡æ‹Ÿç¯å¢ƒæ— æ³•æä¾›
  - çœŸå® RAG ç³»ç»Ÿä¸­ï¼ŒåŠ¨æ€ç­–ç•¥å¯èƒ½è¡¨ç°æ›´å¥½

## ğŸ”§ æŠ€æœ¯å®ç°

### æ•°æ®å¤„ç†
```python
# JSONL æ ¼å¼ (JSON Lines)
[question_text, [option1, option2, option3, option4], correct_answer]

# è§£æå
{
  'id': 0,
  'question': '...',
  'options': ['...', '...', '...', '...'],
  'correct_answer': 2  # 1-4
}
```

### ç­”æ¡ˆæå–
```python
def extract_answer_number(llm_output: str) -> int:
    # æ”¯æŒå¤šç§æ ¼å¼: "1", "Answer: 2", "The correct answer is 3"
    # æ­£åˆ™åŒ¹é…: answer[:\s]+(\d)
```

### æ¨¡æ‹Ÿè¯„ä¼°é€»è¾‘
```python
# åŸºç¡€å‡†ç¡®ç‡ï¼ˆåŸºäºéš¾åº¦ï¼‰
base_acc = {'easy': 0.8, 'medium': 0.6, 'hard': 0.4}[difficulty]

# æ£€ç´¢å¢ç›Š
acc_boost = min(top_k * 0.05, 0.15) + (use_rerank * 0.1)

# æœ€ç»ˆå‡†ç¡®ç‡
final_acc = min(base_acc + acc_boost, 0.95)
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### å¿«é€Ÿå¼€å§‹
```bash
cd /home/data2/huangxiaolin2/ARGO
./run_benchmark_eval.sh
```

### æ‰‹åŠ¨è¿è¡Œ
```bash
# 1. æµ‹è¯•åŠ è½½å™¨
/root/miniconda/envs/ARGO/bin/python oran_benchmark_loader.py

# 2. è¿è¡Œè¯„ä¼°
/root/miniconda/envs/ARGO/bin/python Exp_RAG_benchmark.py

# 3. ç”Ÿæˆå¯è§†åŒ–
/root/miniconda/envs/ARGO/bin/python plot_benchmark_results.py
```

### Python API
```python
from oran_benchmark_loader import ORANBenchmark
from Exp_RAG_benchmark import run_benchmark_experiment, save_results

# åŠ è½½åŸºå‡†
benchmark = ORANBenchmark()

# é‡‡æ ·é—®é¢˜
questions = benchmark.sample_questions(n=50, difficulty='hard', seed=42)

# è¿è¡Œè¯„ä¼°
results, questions = run_benchmark_experiment(n_questions=100, seed=42)

# ä¿å­˜ç»“æœ
save_results(results, questions, 'my_results.json')
```

## â³ ä¸‹ä¸€æ­¥è®¡åˆ’

### é˜¶æ®µ 1: é›†æˆçœŸå® RAGï¼ˆç«‹å³å¯åšï¼‰
```python
# åœ¨ Exp_RAG_benchmark.py ä¸­
from RAG_Models.retrieval import build_vector_store
from transformers import AutoModelForCausalLM, AutoTokenizer

# åŠ è½½æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained("Qwen2.5-14B-Instruct")
retriever = build_vector_store()

# æ›¿æ¢æ¨¡æ‹Ÿé€»è¾‘
context = retriever.retrieve(question, top_k=top_k)
llm_output = model.generate(prompt)
predicted = extract_answer_number(llm_output)
```

**é¢„è®¡æ—¶é—´**: 2-4 å°æ—¶ï¼ˆä¸»è¦æ˜¯æ¨¡å‹åŠ è½½å’Œæç¤ºå·¥ç¨‹ï¼‰

### é˜¶æ®µ 2: å¤š GPU ä¼˜åŒ–ï¼ˆæ€§èƒ½æå‡ï¼‰
```python
# ä½¿ç”¨ DeepSpeed æˆ– model.parallelize()
model = model.to('cuda')  # å• GPU
# æˆ–
model = model.parallelize()  # å¤š GPU

# æ‰¹é‡æ¨ç†
batch_size = 8
for batch in batched_questions:
    outputs = model.generate(batch)
```

**é¢„è®¡æ—¶é—´**: 1-2 å¤©ï¼ˆè°ƒè¯•å¹¶è¡Œç­–ç•¥ï¼‰

### é˜¶æ®µ 3: æ·±å…¥åˆ†æï¼ˆç§‘ç ”ä»·å€¼ï¼‰
- **é”™è¯¯æ¡ˆä¾‹åˆ†æ**: å“ªäº›é—®é¢˜æœ€éš¾ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ
- **æ£€ç´¢è´¨é‡åˆ†æ**: æ£€ç´¢åˆ°çš„æ–‡æ¡£ä¸ç­”æ¡ˆçš„ç›¸å…³æ€§
- **é¢†åŸŸé€‚åº”**: ä¸åŒ O-RAN å·¥ä½œç»„é—®é¢˜çš„æ€§èƒ½å·®å¼‚
- **å¯¹æ¯”å®éªŒ**: ä¸åŒåµŒå…¥æ¨¡å‹ã€LLM çš„è¡¨ç°

**é¢„è®¡æ—¶é—´**: 1-2 å‘¨

## ğŸ“ é¡¹ç›®æ–‡ä»¶æ¸…å•

```
ARGO/
â”œâ”€â”€ oran_benchmark_loader.py         # åŸºå‡†åŠ è½½å™¨ (200 è¡Œ)
â”œâ”€â”€ Exp_RAG_benchmark.py             # è¯„ä¼°æ¡†æ¶ (340 è¡Œ)
â”œâ”€â”€ plot_benchmark_results.py        # å¯è§†åŒ–è„šæœ¬ (250 è¡Œ)
â”œâ”€â”€ ORAN_BENCHMARK_README.md         # è¯¦ç»†æ–‡æ¡£ (400 è¡Œ)
â”œâ”€â”€ ORAN_BENCHMARK_SUMMARY.md        # æœ¬æ€»ç»“ (å½“å‰æ–‡ä»¶)
â”œâ”€â”€ run_benchmark_eval.sh            # å¿«é€Ÿå¯åŠ¨è„šæœ¬
â”œâ”€â”€ ORAN-Bench-13K/                  # åŸºå‡†æ•°æ®é›†
â”‚   â””â”€â”€ Benchmark/
â”‚       â”œâ”€â”€ fin_E.json               # 1,139 Easy é—®é¢˜
â”‚       â”œâ”€â”€ fin_M.json               # 9,570 Medium é—®é¢˜
â”‚       â””â”€â”€ fin_H.json               # 3,243 Hard é—®é¢˜
â””â”€â”€ draw_figs/                       # è¾“å‡ºç›®å½•
    â”œâ”€â”€ data/
    â”‚   â””â”€â”€ oran_benchmark_mixed.json
    â”œâ”€â”€ benchmark_strategy_comparison.png
    â”œâ”€â”€ benchmark_difficulty_breakdown.png
    â”œâ”€â”€ benchmark_confusion_fixed_k5.png
    â”œâ”€â”€ benchmark_retrieval_impact.png
    â””â”€â”€ benchmark_summary.txt
```

**æ€»ä»£ç é‡**: ~790 è¡Œï¼ˆä¸å«æ³¨é‡Šï¼‰
**æ–‡æ¡£é‡**: ~1,000 è¡Œ

## ğŸ“ ä¸ ARGO_MDP é¡¹ç›®çš„å…³ç³»

| ç»´åº¦ | ARGO_MDP | ORAN-Bench-13K |
|-----|----------|----------------|
| **æ€§è´¨** | ç†è®ºä¼˜åŒ– | å®é™…éªŒè¯ |
| **è¾“å…¥** | MDP å‚æ•°ï¼ˆæˆæœ¬ã€è´¨é‡ï¼‰ | çœŸå®é—®é¢˜ + RAG ç³»ç»Ÿ |
| **è¾“å‡º** | æœ€ä¼˜é˜ˆå€¼ç­–ç•¥ | å®é™…å‡†ç¡®ç‡ |
| **è¯„ä¼°** | ç´¯ç§¯å¥–åŠ±ã€æ•ˆç”¨ | ç­”æ¡ˆå‡†ç¡®ç‡ |

**ååŒå·¥ä½œæµç¨‹**:
1. **ARGO_MDP** è®¡ç®—ç†è®ºæœ€ä¼˜ç­–ç•¥ï¼ˆä¾‹å¦‚ï¼šÎ¸*=0.5, Î¸_cont=0.2ï¼‰
2. **ORAN-Bench-13K** åœ¨çœŸå®é—®é¢˜ä¸Šæµ‹è¯•è¯¥ç­–ç•¥
3. **åé¦ˆä¼˜åŒ–**: æ ¹æ®åŸºå‡†ç»“æœè°ƒæ•´ MDP å‚æ•°ï¼ˆæˆæœ¬æƒé‡ Î¼, è´¨é‡å‡½æ•°å‚æ•°ï¼‰
4. **è¿­ä»£æ”¹è¿›**: é‡å¤ 1-3 ç›´è‡³ç†è®ºä¸å®é™…ä¸€è‡´

## ğŸ“ˆ é¢„æœŸå½±å“

### å­¦æœ¯ä»·å€¼
- **åŸºå‡†æµ‹è¯•**: ä¸º RAG ç³»ç»Ÿæä¾›æ ‡å‡†è¯„ä¼°æ–¹æ³•
- **ç­–ç•¥ä¼˜åŒ–**: éªŒè¯ MDP ç†è®ºåœ¨å®é™…ç³»ç»Ÿä¸­çš„æœ‰æ•ˆæ€§
- **æ¶ˆèç ”ç©¶**: åˆ†ææ£€ç´¢æ·±åº¦ã€é‡æ’åºç­‰å› ç´ çš„å½±å“

### å·¥ç¨‹ä»·å€¼
- **ç³»ç»Ÿé€‰å‹**: å¯¹æ¯”ä¸åŒæ£€ç´¢ç­–ç•¥ï¼Œé€‰æ‹©æœ€ä½³é…ç½®
- **æ€§èƒ½ç›‘æ§**: æŒç»­è·Ÿè¸ª RAG ç³»ç»Ÿåœ¨åŸºå‡†ä¸Šçš„è¡¨ç°
- **å¿«é€Ÿè¿­ä»£**: è‡ªåŠ¨åŒ–è¯„ä¼°æµç¨‹ï¼ŒåŠ é€Ÿå¼€å‘å‘¨æœŸ

### å®é™…åº”ç”¨
- **O-RAN çŸ¥è¯†é—®ç­”**: ä¸ºç”µä¿¡å·¥ç¨‹å¸ˆæä¾›æŠ€æœ¯æ”¯æŒ
- **æ–‡æ¡£æ£€ç´¢ä¼˜åŒ–**: æ”¹è¿› O-RAN è§„èŒƒæ–‡æ¡£çš„æ£€ç´¢ç³»ç»Ÿ
- **åŸ¹è®­è¾…åŠ©**: è‡ªåŠ¨ç”Ÿæˆ O-RAN åŸ¹è®­é¢˜åº“å’Œè§£æ

## ğŸ† é¡¹ç›®äº®ç‚¹

1. **çœŸå®æ•°æ®**: 13,952 ä¸ªå®é™… O-RAN é—®é¢˜ï¼Œéåˆæˆæ•°æ®
2. **å¤šéš¾åº¦çº§åˆ«**: Easy/Medium/Hard ä¸‰æ¡£ï¼Œè¦†ç›–ä¸åŒåº”ç”¨åœºæ™¯
3. **å®Œæ•´æµç¨‹**: ä»æ•°æ®åŠ è½½ â†’ è¯„ä¼° â†’ å¯è§†åŒ– â†’ æ–‡æ¡£ï¼Œä¸€ç«™å¼è§£å†³æ–¹æ¡ˆ
4. **æ˜“äºæ‰©å±•**: æ¨¡å—åŒ–è®¾è®¡ï¼Œå¯è½»æ¾é›†æˆçœŸå® LLM å’Œæ£€ç´¢å™¨
5. **å¯å¤ç°**: å›ºå®šéšæœºç§å­ï¼Œç»“æœå®Œå…¨å¯å¤ç°

## ğŸ“ è´¡çŒ®è€…

- **å¼€å‘è€…**: GitHub Copilot
- **é¡¹ç›®æŒ‡å¯¼**: åŸºäºç”¨æˆ·éœ€æ±‚ï¼ˆ"åªè¾“å‡º 1-4 å››ä¸ªæ•°å­—ï¼Œç„¶åä¸æ ‡å‡†ç­”æ¡ˆå¯¹æ¯”è®¡ç®—æ­£ç¡®ç‡"ï¼‰
- **æ•°æ®é›†**: ORAN-Bench-13K (å·²å­˜åœ¨äºç”¨æˆ·å·¥ä½œåŒº)

## ğŸ“ æ”¯æŒ

- **æ–‡æ¡£**: `ORAN_BENCHMARK_README.md`ï¼ˆè¯¦ç»†ä½¿ç”¨æŒ‡å—ï¼‰
- **ç¤ºä¾‹**: è¿è¡Œ `run_benchmark_eval.sh` æŸ¥çœ‹å®Œæ•´æµç¨‹
- **ä»£ç **: æ¯ä¸ªæ–‡ä»¶éƒ½æœ‰è¯¦ç»†æ³¨é‡Šå’Œç±»å‹æç¤º

---

**æœ€åæ›´æ–°**: 2025-10-28  
**é¡¹ç›®çŠ¶æ€**: âœ… æ ¸å¿ƒåŠŸèƒ½å®Œæˆï¼Œå¯ç«‹å³ä½¿ç”¨ï¼ˆæ¨¡æ‹Ÿæ¨¡å¼ï¼‰  
**ä¸‹ä¸€é‡Œç¨‹ç¢‘**: é›†æˆçœŸå® Qwen2.5-14B-Instruct æ¨¡å‹
