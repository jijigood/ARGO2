========================================
7B优化实验启动
========================================

GPU状态:
index, name, memory.free [MiB]
0, NVIDIA GeForce RTX 3060, 12016 MiB
1, NVIDIA GeForce RTX 3060, 12026 MiB
2, NVIDIA GeForce RTX 3060, 12026 MiB
3, NVIDIA GeForce RTX 3060, 12026 MiB
4, NVIDIA GeForce RTX 3060, 12026 MiB
5, NVIDIA GeForce RTX 3060, 12026 MiB
6, NVIDIA GeForce RTX 3060, 12026 MiB
7, NVIDIA GeForce RTX 3060, 12026 MiB

运行参数:
  模式: small
  GPU: 0,1
  难度: hard

启动实验...

启动参数:
  模式: small
  难度: hard
  GPU: [0, 1]
  种子: 42


================================================================================
实验1: 检索成本影响 - 7B优化版本
================================================================================
运行模式: 小规模测试模式 (10题, 快速验证逻辑)
LLM模型: Qwen2.5-7B-Instruct (优化版)
嵌入模型: /data/user/huangxiaolin/ARGO/models/all-MiniLM-L6-v2
问题难度: HARD
问题数量: 10
c_r采样点: 5个
================================================================================

GPU配置:
  可用GPU: 2张
  使用GPU: [0, 1] (7B模型需要2张GPU)
    GPU 0: NVIDIA GeForce RTX 3060 (12.6GB)
    GPU 1: NVIDIA GeForce RTX 3060 (12.6GB)
  剩余GPU: [] (可用于其他任务)

加载ORAN-Bench-13K数据集...
Loaded ORAN-Bench-13K:
  Easy: 1139 questions
  Medium: 9570 questions
  Hard: 3243 questions
  Total: 13952 questions
✓ 加载了 10 道 HARD 问题

加载嵌入模型: /data/user/huangxiaolin/ARGO/models/all-MiniLM-L6-v2
✓ 嵌入模型加载成功 (GPU 0)

================================================================================
预计算问题embeddings (优化检索性能)...
================================================================================

✓ 预计算完成!
  - 问题数: 10
  - 耗时: 0.4秒 (0.0分钟)
  - 平均: 37.4ms/问题
  - 内存占用: ~0.01 MB
================================================================================

连接Chroma数据库: /data/user/huangxiaolin/ARGO2/ARGO/Environments/chroma_store
✓ Chroma集合加载成功 (文档数: 436279)

加载LLM模型: /data/user/huangxiaolin/ARGO/RAG_Models/models/Qwen2.5-7B-Instruct
  使用 2 张GPU加载7B模型...
  优化策略: device_map='auto', torch_dtype=bfloat16, 降低GPU通信开销
Traceback (most recent call last):
  File "/data/user/huangxiaolin/.local/lib/python3.11/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
  File "/data/user/huangxiaolin/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
    validate_repo_id(arg_value)
  File "/data/user/huangxiaolin/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
    raise HFValidationError(
huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/data/user/huangxiaolin/ARGO/RAG_Models/models/Qwen2.5-7B-Instruct'. Use `repo_type` argument if needed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/data/user/huangxiaolin/ARGO2/ARGO/Exp_7B_optimized_full.py", line 1088, in <module>
    main()
  File "/data/user/huangxiaolin/ARGO2/ARGO/Exp_7B_optimized_full.py", line 1059, in main
    experiment = Optimized7BExperiment(
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/data/user/huangxiaolin/ARGO2/ARGO/Exp_7B_optimized_full.py", line 233, in __init__
    self._load_llm()
  File "/data/user/huangxiaolin/ARGO2/ARGO/Exp_7B_optimized_full.py", line 244, in _load_llm
    self.tokenizer = AutoTokenizer.from_pretrained(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/user/huangxiaolin/.local/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py", line 1073, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/user/huangxiaolin/.local/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py", line 905, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/data/user/huangxiaolin/.local/lib/python3.11/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/user/huangxiaolin/.local/lib/python3.11/site-packages/transformers/utils/hub.py", line 531, in cached_files
    resolved_files = [
                     ^
  File "/data/user/huangxiaolin/.local/lib/python3.11/site-packages/transformers/utils/hub.py", line 532, in <listcomp>
    _get_cache_file_to_return(path_or_repo_id, filename, cache_dir, revision, repo_type)
  File "/data/user/huangxiaolin/.local/lib/python3.11/site-packages/transformers/utils/hub.py", line 143, in _get_cache_file_to_return
    resolved_file = try_to_load_from_cache(
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/user/huangxiaolin/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
    validate_repo_id(arg_value)
  File "/data/user/huangxiaolin/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
    raise HFValidationError(
huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/data/user/huangxiaolin/ARGO/RAG_Models/models/Qwen2.5-7B-Instruct'. Use `repo_type` argument if needed.
