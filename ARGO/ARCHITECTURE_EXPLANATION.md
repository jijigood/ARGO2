# ARGO RAG ç³»ç»Ÿæ¶æ„è¯´æ˜

## æ‚¨çš„é—®é¢˜

**Q: è¿™äº›æ–‡ä»¶æ˜¯å¦åªæ˜¯ RAG å®ç°å’Œè¯„ä¼°ï¼Œæ²¡æœ‰é›†æˆ MDPã€æœ€ä¼˜é˜ˆå€¼ç­‰æ–¹æ³•ï¼Ÿéœ€è¦é…åˆå…¶ä»–è„šæœ¬ä½¿ç”¨å—ï¼Ÿ**

**A: æ˜¯çš„ï¼Œæ‚¨çš„è§‚å¯Ÿå®Œå…¨æ­£ç¡®ï¼** è®©æˆ‘è¯¦ç»†è¯´æ˜ï¼š

---

## ğŸ”´ å½“å‰é—®é¢˜è¯Šæ–­

### 1. ç°æœ‰æ–‡ä»¶çš„åŠŸèƒ½å®šä½

| æ–‡ä»¶ | åŠŸèƒ½ | æ˜¯å¦ä½¿ç”¨ MDP ç­–ç•¥ | æ˜¯å¦ä½¿ç”¨çœŸå® RAG |
|-----|------|-----------------|----------------|
| `oran_benchmark_loader.py` | æ•°æ®åŠ è½½ | âŒ å¦ | N/A |
| `Exp_RAG_benchmark.py` | è¯„ä¼°æ¡†æ¶ | âš ï¸ **éƒ¨åˆ†ä½¿ç”¨**ï¼ˆä»…ç”¨äºé€‰æ‹© top_kï¼‰ | âŒ æ¨¡æ‹Ÿ |
| `integrate_real_rag.py` | RAG ç¤ºä¾‹ | âŒ **å®Œå…¨ä¸ä½¿ç”¨** | âœ… çœŸå®ï¼ˆä½†æœ‰ CUDA é”™è¯¯ï¼‰ |
| `plot_benchmark_results.py` | å¯è§†åŒ– | âŒ å¦ | N/A |

### 2. æ ¸å¿ƒé—®é¢˜

#### âŒ é—®é¢˜ 1: MDP ç­–ç•¥æœªçœŸæ­£åº”ç”¨

**å½“å‰å®ç°** (`Exp_RAG_benchmark.py`):
```python
# ç¬¬ 210-220 è¡Œ
for q in questions:
    # 1. è°ƒç”¨ MDP ç­–ç•¥è·å– action
    action = strategy_fn(state)  # ä¾‹å¦‚: (top_k=5, use_rerank=1, use_filter=0)
    
    # 2. ä½¿ç”¨ action æ£€ç´¢ä¸€æ¬¡
    retrieval_config = {'top_k': top_k, 'use_rerank': use_rerank, ...}
    
    # 3. ç«‹å³è¯„ä¼°ï¼ˆæ²¡æœ‰è¿­ä»£ï¼ï¼‰
    single_result = evaluate_rag_on_benchmark(benchmark, [q], retrieval_config)
```

**é—®é¢˜**:
- MDP çš„ `action` åº”è¯¥æ˜¯ **Retrieve/Reason/Terminate**ï¼ˆä¸‰ä¸ªåŠ¨ä½œï¼‰
- å½“å‰åªç”¨ MDP å†³å®š **æ£€ç´¢å‚æ•°** (top_k)
- **ç¼ºå°‘è¿­ä»£å¾ªç¯**: æ²¡æœ‰æ ¹æ® uncertainty åŠ¨æ€å†³å®šæ˜¯å¦ç»§ç»­æ£€ç´¢

#### âŒ é—®é¢˜ 2: æ²¡æœ‰ Uncertainty çŠ¶æ€è¿½è¸ª

**MDP çš„æ ¸å¿ƒ**:
```
State: (U, C)  # U=uncertainty, C=cumulative_cost
Actions: {Retrieve, Reason, Terminate}

Retrieve: U' = U - Î´_r,  C' = C + c_r  (é™ä½ä¸ç¡®å®šæ€§ï¼Œå¢åŠ æˆæœ¬)
Reason:   U' = U - Î´_p,  C' = C + c_p
Terminate: ç»“æŸï¼Œè¾“å‡ºç­”æ¡ˆ
```

**å½“å‰ç¼ºå¤±**:
- âŒ æ²¡æœ‰ `U` (uncertainty) å˜é‡
- âŒ æ²¡æœ‰ `C` (cumulative cost) è¿½è¸ª
- âŒ æ²¡æœ‰è¿­ä»£æ›´æ–° `U` å’Œ `C`

#### âŒ é—®é¢˜ 3: æ²¡æœ‰æœ€ä¼˜é˜ˆå€¼çš„å®é™…åº”ç”¨

**ARGO_MDP é¡¹ç›®è®¡ç®—çš„æœ€ä¼˜é˜ˆå€¼**:
- `Î¸*` = 0.5 (termination threshold)
- `Î¸_cont` = 0.2 (continuation threshold)

**åº”è¯¥å¦‚ä½•ä½¿ç”¨**:
```python
if U < Î¸_cont:
    action = Terminate  # ä¸ç¡®å®šæ€§è¶³å¤Ÿä½ï¼Œåœæ­¢
elif U < Î¸*:
    action = Reason     # ä¸­ç­‰ä¸ç¡®å®šæ€§ï¼Œæ¨ç†
else:
    action = Retrieve   # é«˜ä¸ç¡®å®šæ€§ï¼Œæ£€ç´¢æ›´å¤šä¿¡æ¯
```

**å½“å‰**:
- âœ… `ARGO_MDP/` é¡¹ç›®**è®¡ç®—äº†æœ€ä¼˜é˜ˆå€¼**
- âŒ `ARGO/Exp_RAG_benchmark.py` **æ²¡æœ‰ä½¿ç”¨è¿™äº›é˜ˆå€¼**

---

## âœ… æ­£ç¡®çš„é›†æˆæ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: çœŸæ­£çš„ MDP-Guided RAGï¼ˆåˆšåˆšåˆ›å»ºï¼‰

**æ–‡ä»¶**: `mdp_guided_rag.py`

**æ ¸å¿ƒæ”¹è¿›**:
1. âœ… **ä½¿ç”¨ MDP æœ€ä¼˜é˜ˆå€¼** (`Î¸*`, `Î¸_cont`)
2. âœ… **è¿­ä»£æ£€ç´¢-æ¨ç†å¾ªç¯**
3. âœ… **åŠ¨æ€ Uncertainty æ›´æ–°**
4. âœ… **æˆæœ¬è¿½è¸ªå’Œå†³ç­–**

**å·¥ä½œæµç¨‹**:
```
åˆå§‹åŒ–: U = 1.0, C = 0.0, docs = []

Iteration 1:
  - Query MDP: U=1.0 â†’ Action = Retrieve (å› ä¸º U > Î¸*)
  - Retrieve 3 docs â†’ U = 0.85, C = 0.1
  
Iteration 2:
  - Query MDP: U=0.85 â†’ Action = Retrieve
  - Retrieve 3 docs â†’ U = 0.70, C = 0.2
  
Iteration 3:
  - Query MDP: U=0.70 â†’ Action = Retrieve
  - Retrieve 3 docs â†’ U = 0.55, C = 0.3

Iteration 4:
  - Query MDP: U=0.55 â†’ Action = Reason (å› ä¸º Î¸_cont < U < Î¸*)
  - LLM æ¨ç† â†’ U = 0.43, C = 0.35, answer = 2

Iteration 5:
  - Query MDP: U=0.43 â†’ Action = Reason
  - LLM æ¨ç† â†’ U = 0.35, C = 0.40, answer = 2 (ä¸å˜)

Iteration 6:
  - Query MDP: U=0.35 â†’ Action = Reason
  - LLM æ¨ç† â†’ U = 0.27, C = 0.45, answer = 2

Iteration 7:
  - Query MDP: U=0.27 â†’ Action = Reason
  - LLM æ¨ç† â†’ U = 0.19, C = 0.50, answer = 2

Iteration 8:
  - Query MDP: U=0.19 â†’ Action = Terminate (å› ä¸º U < Î¸_cont)
  - è¾“å‡ºæœ€ç»ˆç­”æ¡ˆ: 2
```

### æ–¹æ¡ˆ 2: ç®€åŒ–ç‰ˆï¼ˆåœ¨ç°æœ‰ä»£ç ä¸Šä¿®æ”¹ï¼‰

ä¿®æ”¹ `Exp_RAG_benchmark.py`ï¼Œæ·»åŠ è¿­ä»£é€»è¾‘ï¼š

```python
def evaluate_rag_with_mdp_loop(question, strategy, max_iters=5):
    """ä½¿ç”¨ MDP è¿­ä»£å¾ªç¯è¯„ä¼° RAG"""
    U = 1.0  # åˆå§‹ä¸ç¡®å®šæ€§
    C = 0.0  # ç´¯ç§¯æˆæœ¬
    docs = []
    
    for iteration in range(max_iters):
        # æŸ¥è¯¢ MDP ç­–ç•¥
        action = strategy.get_action(U, C)
        
        if action == 'terminate':
            break
        elif action == 'retrieve':
            new_docs = retriever.retrieve(question, k=3)
            docs.extend(new_docs)
            U -= 0.15  # ä¸ç¡®å®šæ€§å‡å°‘
            C += 0.1   # æ£€ç´¢æˆæœ¬
        elif action == 'reason':
            answer = llm.generate(question, docs)
            U -= 0.12  # æ¨ç†å‡å°‘ä¸ç¡®å®šæ€§
            C += 0.05  # æ¨ç†æˆæœ¬
    
    return answer, C, iteration
```

---

## ğŸ“Š ä¸‰ç§æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | MDP é›†æˆ | è¿­ä»£æ£€ç´¢ | æˆæœ¬ä¼˜åŒ– | å®ç°éš¾åº¦ | ç§‘ç ”ä»·å€¼ |
|-----|---------|---------|---------|---------|---------|
| **å½“å‰ Exp_RAG_benchmark.py** | âš ï¸ éƒ¨åˆ† | âŒ æ—  | âŒ æ—  | ç®€å• | â­ ä½ |
| **æ–° mdp_guided_rag.py** | âœ… å®Œæ•´ | âœ… æœ‰ | âœ… æœ‰ | ä¸­ç­‰ | â­â­â­â­ é«˜ |
| **ä¿®æ”¹ Exp_RAG_benchmark.py** | âœ… å®Œæ•´ | âœ… æœ‰ | âœ… æœ‰ | è¾ƒéš¾ | â­â­â­ ä¸­é«˜ |

---

## ğŸ”„ æ–‡ä»¶ä¾èµ–å…³ç³»

### å½“å‰æ¶æ„ï¼ˆä¸å®Œæ•´ï¼‰

```
ARGO_MDP/                    ARGO/
â”œâ”€â”€ src/                     â”œâ”€â”€ oran_benchmark_loader.py
â”‚   â”œâ”€â”€ mdp_solver.py        â”‚   â””â”€â”€ [åŠ è½½æ•°æ®]
â”‚   â””â”€â”€ env_argo.py          â”‚
â””â”€â”€ configs/base.yaml        â”œâ”€â”€ Exp_RAG_benchmark.py
    â””â”€â”€ [è®¡ç®— Î¸*, Î¸_cont]         â””â”€â”€ [è¯„ä¼°ï¼Œä½†æ²¡ç”¨ Î¸*]
                             â”‚
                [æ–­å±‚ï¼]     â”œâ”€â”€ integrate_real_rag.py
                             â”‚   â””â”€â”€ [RAG ç¤ºä¾‹ï¼Œä¸ç”¨ MDP]
                             â””â”€â”€ plot_benchmark_results.py
```

### æ–°æ¶æ„ï¼ˆå®Œæ•´é›†æˆï¼‰

```
ARGO_MDP/                    ARGO/
â”œâ”€â”€ src/                     â”œâ”€â”€ oran_benchmark_loader.py
â”‚   â”œâ”€â”€ mdp_solver.py â”â”â”â”â”â”â”â”â”â”â”> mdp_guided_rag.py
â”‚   â””â”€â”€ env_argo.py          â”‚   â”œâ”€â”€ å¯¼å…¥ MDPSolver
â””â”€â”€ configs/base.yaml â”â”â”â”â”â”â”â”˜   â”œâ”€â”€ ä½¿ç”¨ Î¸*, Î¸_cont
                             â”‚   â”œâ”€â”€ è¿­ä»£æ£€ç´¢-æ¨ç†
                             â”‚   â””â”€â”€ æˆæœ¬ä¼˜åŒ–
                             â”‚
                             â”œâ”€â”€ RAG_Models/
                             â”‚   â”œâ”€â”€ retrieval.py â”â”> mdp_guided_rag.py
                             â”‚   â””â”€â”€ embeddings.py      (æä¾›æ£€ç´¢å™¨)
                             â”‚
                             â””â”€â”€ integrate_real_rag.py
                                 â””â”€â”€ [è¢« mdp_guided_rag.py æ›¿ä»£]
```

---

## ğŸš€ æ¨èä½¿ç”¨æ–¹å¼

### é€‰é¡¹ A: ä½¿ç”¨æ–°çš„ MDP-Guided RAGï¼ˆæ¨èï¼‰

```bash
cd /home/data2/huangxiaolin2/ARGO

# 1. æµ‹è¯•ï¼ˆæ¨¡æ‹Ÿ LLMï¼Œå¿«é€ŸéªŒè¯é€»è¾‘ï¼‰
python mdp_guided_rag.py

# 2. çœŸå®è¯„ä¼°ï¼ˆä½¿ç”¨ Qwen2.5-14Bï¼‰
python -c "
from mdp_guided_rag import run_mdp_rag_experiment
run_mdp_rag_experiment(
    n_questions=50,
    difficulty='medium',
    use_real_llm=True,  # ä½¿ç”¨çœŸå® LLM
    seed=42
)
"
```

### é€‰é¡¹ B: å¯¹æ¯”å®éªŒï¼ˆMDP vs. é MDPï¼‰

```python
# å®éªŒ 1: ä¼ ç»Ÿ RAGï¼ˆå›ºå®š k=5ï¼Œæ—  MDPï¼‰
from Exp_RAG_benchmark import run_benchmark_experiment
results_baseline = run_benchmark_experiment(n_questions=100, seed=42)

# å®éªŒ 2: MDP-Guided RAG
from mdp_guided_rag import run_mdp_rag_experiment
results_mdp = run_mdp_rag_experiment(n_questions=100, seed=42)

# å¯¹æ¯”:
# - å‡†ç¡®ç‡: MDP vs. Baseline
# - æˆæœ¬: MDP åº”è¯¥æ›´ä½ï¼ˆåŠ¨æ€åœæ­¢æ£€ç´¢ï¼‰
# - æ£€ç´¢æ¬¡æ•°: MDP åº”è¯¥æ›´å°‘ï¼ˆæ ¹æ® U å†³å®šï¼‰
```

---

## ğŸ”§ è§£å†³ CUDA é”™è¯¯ï¼ˆGTX 1080 Tiï¼‰

æ‚¨é‡åˆ°çš„é”™è¯¯ï¼š
```
CUDA error: no kernel image is available for execution on the device
GTX 1080 Ti: CUDA capability 6.1 (ä¸æ”¯æŒ)
PyTorch è¦æ±‚: CUDA capability >= 7.0
```

**è§£å†³æ–¹æ¡ˆ**:

### æ–¹æ¡ˆ 1: é‡è£…å…¼å®¹çš„ PyTorchï¼ˆæ¨èï¼‰

```bash
# å¸è½½å½“å‰ PyTorch
pip uninstall torch torchvision torchaudio

# å®‰è£…æ”¯æŒ CUDA 6.1 çš„æ—§ç‰ˆæœ¬
pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116
```

### æ–¹æ¡ˆ 2: CPU æ¨¡å¼ï¼ˆä»…æµ‹è¯•ç”¨ï¼‰

åœ¨ `mdp_guided_rag.py` ä¸­:
```python
self.model = AutoModelForCausalLM.from_pretrained(
    model_path,
    torch_dtype=torch.float32,  # æ”¹ä¸º float32
    device_map="cpu",           # å¼ºåˆ¶ CPU
    trust_remote_code=True
)
```

### æ–¹æ¡ˆ 3: å…ˆç”¨æ¨¡æ‹Ÿ LLM æµ‹è¯•é€»è¾‘

```python
# æµ‹è¯• MDP é€»è¾‘ï¼Œä¸åŠ è½½çœŸå®æ¨¡å‹
run_mdp_rag_experiment(
    n_questions=10,
    use_real_llm=False,  # ä½¿ç”¨æ¨¡æ‹Ÿ
    seed=42
)
```

---

## ğŸ“ æ€»ç»“

### æ‚¨çš„é—®é¢˜ç­”æ¡ˆ

1. **Q: æ˜¯å¦åªæ˜¯ RAG å®ç°å’Œè¯„ä¼°ï¼Ÿ**
   - **A**: æ˜¯çš„ï¼Œ`integrate_real_rag.py` å’Œ `Exp_RAG_benchmark.py` éƒ½**æ²¡æœ‰çœŸæ­£é›†æˆ MDP ç­–ç•¥**

2. **Q: æ²¡æœ‰é›†æˆ MDPã€æœ€ä¼˜é˜ˆå€¼ï¼Ÿ**
   - **A**: æ­£ç¡®ï¼è™½ç„¶è°ƒç”¨äº† `Env_RAG` çš„ç­–ç•¥ï¼Œä½†ï¼š
     - âŒ æ²¡æœ‰ä½¿ç”¨ `Î¸*` å’Œ `Î¸_cont` é˜ˆå€¼
     - âŒ æ²¡æœ‰ uncertainty çŠ¶æ€è¿½è¸ª
     - âŒ æ²¡æœ‰è¿­ä»£æ£€ç´¢-æ¨ç†å¾ªç¯

3. **Q: éœ€è¦é…åˆå…¶ä»–è„šæœ¬ä½¿ç”¨å—ï¼Ÿ**
   - **A**: æ˜¯çš„ï¼åº”è¯¥ï¼š
     - âœ… **ARGO_MDP/** â†’ è®¡ç®—æœ€ä¼˜é˜ˆå€¼
     - âœ… **mdp_guided_rag.py** â†’ ä½¿ç”¨é˜ˆå€¼ + è¿­ä»£ RAG
     - âœ… **oran_benchmark_loader.py** â†’ æä¾›æµ‹è¯•æ•°æ®
     - âœ… **RAG_Models/** â†’ æä¾›æ£€ç´¢å’ŒåµŒå…¥

### ä¸‹ä¸€æ­¥

1. **ç«‹å³**: æµ‹è¯• `mdp_guided_rag.py`ï¼ˆæ¨¡æ‹Ÿæ¨¡å¼ï¼‰
2. **è§£å†³ CUDA**: é‡è£…å…¼å®¹ PyTorch æˆ–ç”¨ CPU
3. **å®Œæ•´è¯„ä¼°**: è¿è¡Œ MDP vs. Baseline å¯¹æ¯”å®éªŒ
4. **è®ºæ–‡ç»“æœ**: å±•ç¤º MDP é™ä½æˆæœ¬ + æå‡å‡†ç¡®ç‡

è¿™æ‰æ˜¯**çœŸæ­£çš„ MDP-Guided RAG**ï¼ğŸ¯
