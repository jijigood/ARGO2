# ORAN QAæå–å·¥å…· - å¿«é€Ÿå¼€å§‹æŒ‡å—

## ğŸ“‹ ç›®å½•

1. [å·¥å…·æ¦‚è¿°](#å·¥å…·æ¦‚è¿°)
2. [å‡†å¤‡å·¥ä½œ](#å‡†å¤‡å·¥ä½œ)
3. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
4. [å®Œæ•´æå–](#å®Œæ•´æå–)
5. [ç»“æœåˆ†æ](#ç»“æœåˆ†æ)
6. [é«˜çº§é…ç½®](#é«˜çº§é…ç½®)
7. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ğŸ¯ å·¥å…·æ¦‚è¿°

æœ¬å·¥å…·ä»TeleQnAæ•°æ®é›†(106,324ä¸ªç”µä¿¡é¢†åŸŸé—®ç­”)ä¸­æå–**ä»…æ¶‰åŠO-RANçŸ¥è¯†**çš„é—®ç­”å¯¹,ç”Ÿæˆä¸“é—¨çš„O-RANé—®ç­”æ•°æ®é›†ã€‚

**æ ¸å¿ƒæŠ€æœ¯:**
- æ¨¡å‹: Qwen2.5-14B-Instruct
- æ¨ç†å¼•æ“: vLLM (é«˜æ€§èƒ½)
- GPU: 8å¡å¹¶è¡Œ (Tensor Parallelism)
- æ‰¹å¤„ç†: æ¯æ‰¹32ä¸ªé—®é¢˜

---

## âš™ï¸ å‡†å¤‡å·¥ä½œ

### 1. ç¯å¢ƒè¦æ±‚

```bash
# Python 3.8+
python --version

# CUDA 11.8+
nvidia-smi
```

### 2. å®‰è£…ä¾èµ–

```bash
cd /data/user/huangxiaolin/ARGO2/ARGO/TeleQnA

# æ–¹æ³•1: ä½¿ç”¨requirements.txt
pip install -r requirements.txt

# æ–¹æ³•2: æ‰‹åŠ¨å®‰è£…
pip install vllm>=0.2.7 torch>=2.0.0 transformers>=4.36.0 tqdm
```

### 3. éªŒè¯æ¨¡å‹è·¯å¾„

```bash
ls -lh /data/user/huangxiaolin/ARGO/RAG_Models/models/Qwen2.5-14B-Instruct
```

ç¡®è®¤æ¨¡å‹æ–‡ä»¶å­˜åœ¨ä¸”å®Œæ•´ã€‚

### 4. éªŒè¯æ•°æ®é›†

```bash
ls -lh /data/user/huangxiaolin/ARGO2/ARGO/TeleQnA/TeleQnA.txt
wc -l /data/user/huangxiaolin/ARGO2/ARGO/TeleQnA/TeleQnA.txt
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### Step 1: å¿«é€Ÿæµ‹è¯• (æ¨èé¦–æ¬¡ä½¿ç”¨)

åœ¨å¤„ç†å…¨éƒ¨æ•°æ®å‰,å…ˆæµ‹è¯•å‰10ä¸ªé—®é¢˜ä»¥éªŒè¯åŠŸèƒ½:

```bash
cd /data/user/huangxiaolin/ARGO2/ARGO/TeleQnA

# è¿è¡Œå¿«é€Ÿæµ‹è¯•
./run_test.sh
```

**é¢„æœŸè¾“å‡º:**

```
=========================================
Quick Test: ORAN QA Extraction
=========================================

Testing with first 10 questions

Loading sample questions from: ...
âœ“ Loaded 10 sample questions

Initializing vLLM model...
âœ“ vLLM model loaded

Processing 10 questions...

================================================================================

Question ID: question 0
Question: What is the purpose of the Nmfaf_3daDataManagement_Deconfigure service operation? [3GPP Rele...
Category: Standards specifications
Is ORAN: âœ— NO
Reason: This is a general 3GPP specification, not specific to O-RAN.
LLM Response: NO - This is a general 3GPP specification, not specific to O-RAN.
--------------------------------------------------------------------------------

...

================================================================================
Test Summary:
  Total questions: 10
  ORAN questions: 2 (20.0%)
  Non-ORAN questions: 8 (80.0%)
================================================================================

âœ“ Quick test completed!
```

### Step 2: æ£€æŸ¥æµ‹è¯•ç»“æœ

æŸ¥çœ‹æµ‹è¯•è¾“å‡º,ç¡®è®¤:
- âœ… æ¨¡å‹åŠ è½½æˆåŠŸ
- âœ… LLMå“åº”æ ¼å¼æ­£ç¡® (YES/NO + ç†ç”±)
- âœ… åˆ¤æ–­ç»“æœåˆç†

å¦‚æœæµ‹è¯•é€šè¿‡,ç»§ç»­ä¸‹ä¸€æ­¥ã€‚å¦‚æœæœ‰é—®é¢˜,å‚è€ƒ[å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)ã€‚

---

## ğŸƒ å®Œæ•´æå–

### Step 1: è¿è¡Œå®Œæ•´æå–

```bash
cd /data/user/huangxiaolin/ARGO2/ARGO/TeleQnA

# è¿è¡Œå®Œæ•´æå– (é¢„è®¡3-5å°æ—¶)
./run_extraction.sh
```

### Step 2: ç›‘æ§è¿›åº¦

è„šæœ¬ä¼šæ˜¾ç¤ºå®æ—¶è¿›åº¦:

```
============================================================
Starting ORAN extraction with vLLM
Total questions: 106324
Batch size: 32
GPU parallelism: 8
============================================================

Processing batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3323/3323 [2:34:15<00:00, 2.78s/it]
```

### Step 3: ç­‰å¾…å®Œæˆ

**é¢„è®¡æ—¶é—´:** 3-5å°æ—¶ (å–å†³äºGPUæ€§èƒ½)

**GPUä½¿ç”¨æƒ…å†µ:** å¯åœ¨å¦ä¸€ä¸ªç»ˆç«¯ç›‘æ§:

```bash
watch -n 1 nvidia-smi
```

---

## ğŸ“Š ç»“æœåˆ†æ

### 1. æŸ¥çœ‹è¾“å‡ºæ–‡ä»¶

```bash
# ORANé—®é¢˜é›†
cat TeleQnA_ORAN_only.json | jq '.' | head -50

# æå–æ—¥å¿—
head -100 extraction_log.txt

# ç»Ÿè®¡ORANé—®é¢˜æ•°é‡
cat TeleQnA_ORAN_only.json | jq 'length'
```

### 2. è¾“å‡ºæ–‡ä»¶è¯´æ˜

#### `TeleQnA_ORAN_only.json`

ä»…åŒ…å«O-RANç›¸å…³é—®é¢˜çš„JSONæ–‡ä»¶:

```json
{
  "question 156": {
    "question": "Which deployment scenario in O-RAN Town involves vO-CU and vO-DU at the aggregation location?",
    "option 1": "Scenario 1",
    "option 2": "Scenario 2",
    "option 3": "Scenario 3",
    "option 4": "Scenario 4",
    "answer": "option 3: Scenario 3",
    "explanation": "Scenario 3 in O-RAN Town involves vO-CU and vO-DU at the aggregation location...",
    "category": "Standards specifications"
  }
}
```

#### `extraction_log.txt`

è¯¦ç»†çš„æå–æ—¥å¿—,è®°å½•æ¯ä¸ªé—®é¢˜çš„åˆ¤æ–­è¿‡ç¨‹:

```
================================================================================
Question ID: question 156
Question: Which deployment scenario in O-RAN Town involves vO-CU and vO-DU at the aggregation location?
Is ORAN: True
Reason: This question is about O-RAN deployment scenarios and components.
LLM Response: YES - This question is about O-RAN deployment scenarios and components.
================================================================================
```

### 3. ç»Ÿè®¡åˆ†æç¤ºä¾‹

```bash
# æ€»é—®é¢˜æ•°
total=$(cat TeleQnA.txt | grep -c '"question"')
echo "Total questions: $total"

# ORANé—®é¢˜æ•°
oran=$(cat TeleQnA_ORAN_only.json | jq 'length')
echo "ORAN questions: $oran"

# è®¡ç®—ç™¾åˆ†æ¯”
echo "scale=2; $oran * 100 / $total" | bc
```

---

## ğŸ”§ é«˜çº§é…ç½®

### 1. è°ƒæ•´GPUæ•°é‡

å¦‚æœåªæœ‰4å¼ GPU:

```python
# ç¼–è¾‘ extract_oran_qa.py
TENSOR_PARALLEL_SIZE = 4  # æ”¹ä¸º4

# æˆ–ä¿®æ”¹ç¯å¢ƒå˜é‡
export CUDA_VISIBLE_DEVICES=0,1,2,3
```

### 2. è°ƒæ•´æ‰¹å¤„ç†å¤§å°

å¦‚æœé‡åˆ°GPUå†…å­˜ä¸è¶³:

```python
# ç¼–è¾‘ extract_oran_qa.py
BATCH_SIZE = 16  # å‡å°æ‰¹å¤„ç†å¤§å°(é»˜è®¤32)
```

### 3. è°ƒæ•´å†…å­˜ä½¿ç”¨

```python
# ç¼–è¾‘ extract_oran_qa.py
llm = LLM(
    model=MODEL_PATH,
    tensor_parallel_size=TENSOR_PARALLEL_SIZE,
    max_model_len=MAX_MODEL_LEN,
    trust_remote_code=True,
    dtype="float16",
    gpu_memory_utilization=0.85,  # é™ä½åˆ°85%(é»˜è®¤90%)
)
```

### 4. è‡ªå®šä¹‰Prompt

å¦‚éœ€æ›´ä¸¥æ ¼æˆ–æ›´å®½æ¾çš„ORANåˆ¤å®šæ ‡å‡†,ç¼–è¾‘`EXTRACTION_PROMPT`æ¨¡æ¿:

```python
# åœ¨ extract_oran_qa.py ä¸­ä¿®æ”¹ EXTRACTION_PROMPT
```

### 5. åªå¤„ç†éƒ¨åˆ†æ•°æ®

```python
# ç¼–è¾‘ extract_oran_qa.py çš„ load_teleqna_dataset å‡½æ•°
# æ·»åŠ é™åˆ¶æ¡ä»¶
def load_teleqna_dataset(file_path: str, max_questions: int = 1000) -> Dict:
    # ... 
    # åªåŠ è½½å‰max_questionsä¸ªé—®é¢˜
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: `ModuleNotFoundError: No module named 'vllm'`

**è§£å†³:**
```bash
pip install vllm --upgrade
```

### Q2: `CUDA out of memory`

**è§£å†³:**
1. å‡å°æ‰¹å¤„ç†å¤§å°: `BATCH_SIZE = 16`
2. å‡å°åºåˆ—é•¿åº¦: `MAX_MODEL_LEN = 2048`
3. é™ä½GPUå†…å­˜å ç”¨: `gpu_memory_utilization=0.8`
4. å‡å°‘GPUæ•°é‡: `TENSOR_PARALLEL_SIZE = 4`

### Q3: æ¨¡å‹åŠ è½½å¤±è´¥

**è§£å†³:**
```bash
# æ£€æŸ¥æ¨¡å‹è·¯å¾„
ls /data/user/huangxiaolin/ARGO/RAG_Models/models/Qwen2.5-14B-Instruct

# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§
du -sh /data/user/huangxiaolin/ARGO/RAG_Models/models/Qwen2.5-14B-Instruct
```

### Q4: vLLMç‰ˆæœ¬ä¸å…¼å®¹

**è§£å†³:**
```bash
# å¸è½½æ—§ç‰ˆæœ¬
pip uninstall vllm

# å®‰è£…æœ€æ–°ç‰ˆæœ¬
pip install vllm --upgrade
```

### Q5: æå–ç»“æœä¸å‡†ç¡®

**è§£å†³:**
1. æ£€æŸ¥promptè®¾è®¡æ˜¯å¦æ¸…æ™°
2. è°ƒæ•´temperatureå‚æ•°(å½“å‰ä¸º0.0)
3. äººå·¥æŠ½æ ·æ£€æŸ¥å¹¶ä¼˜åŒ–prompt
4. è€ƒè™‘ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹

### Q6: å¤„ç†é€Ÿåº¦å¤ªæ…¢

**ä¼˜åŒ–:**
1. å¢åŠ æ‰¹å¤„ç†å¤§å°: `BATCH_SIZE = 64`
2. ä½¿ç”¨æ›´å¤šGPU: `TENSOR_PARALLEL_SIZE = 16`
3. æ£€æŸ¥GPUåˆ©ç”¨ç‡: `nvidia-smi`

### Q7: JSONè§£æé”™è¯¯

**è§£å†³:**
```bash
# æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ ¼å¼
python -m json.tool TeleQnA.txt > /dev/null

# å¦‚æœæ ¼å¼æœ‰é—®é¢˜,æ‰‹åŠ¨ä¿®å¤
```

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æœ€ä½³GPUé…ç½®

| GPUæ•°é‡ | æ‰¹å¤„ç†å¤§å° | é¢„è®¡é€Ÿåº¦ | æ¨èåœºæ™¯ |
|---------|-----------|---------|---------|
| 8 | 32 | æœ€å¿«(3-4h) | ç”Ÿäº§ç¯å¢ƒ |
| 4 | 16 | ä¸­ç­‰(6-8h) | èµ„æºå—é™ |
| 2 | 8 | è¾ƒæ…¢(12-16h) | æµ‹è¯•ç¯å¢ƒ |

### 2. å†…å­˜ä¼˜åŒ–

```python
# ä½å†…å­˜é…ç½®
gpu_memory_utilization=0.7
BATCH_SIZE = 8
MAX_MODEL_LEN = 2048

# é«˜å†…å­˜é…ç½®
gpu_memory_utilization=0.95
BATCH_SIZE = 64
MAX_MODEL_LEN = 8192
```

---

## ğŸ“ åç»­å¤„ç†

### 1. è´¨é‡æ£€æŸ¥

```bash
# éšæœºæŠ½æ ·10ä¸ªORANé—®é¢˜
cat TeleQnA_ORAN_only.json | jq -r 'to_entries | .[].value.question' | shuf | head -10
```

### 2. æ•°æ®ç»Ÿè®¡

```python
import json

with open('TeleQnA_ORAN_only.json', 'r') as f:
    oran_data = json.load(f)

# æŒ‰ç±»åˆ«ç»Ÿè®¡
categories = {}
for q in oran_data.values():
    cat = q.get('category', 'Unknown')
    categories[cat] = categories.get(cat, 0) + 1

print("ORANé—®é¢˜ç±»åˆ«åˆ†å¸ƒ:")
for cat, count in sorted(categories.items(), key=lambda x: -x[1]):
    print(f"  {cat}: {count}")
```

### 3. æ ¼å¼è½¬æ¢

å¦‚éœ€è½¬æ¢ä¸ºå…¶ä»–æ ¼å¼(å¦‚CSV):

```python
import json
import csv

with open('TeleQnA_ORAN_only.json', 'r') as f:
    oran_data = json.load(f)

with open('TeleQnA_ORAN_only.csv', 'w', newline='', encoding='utf-8') as f:
    writer = csv.writer(f)
    writer.writerow(['ID', 'Question', 'Answer', 'Category'])
    
    for qid, qdata in oran_data.items():
        writer.writerow([
            qid,
            qdata['question'],
            qdata['answer'],
            qdata.get('category', '')
        ])
```

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚é‡åˆ°é—®é¢˜:

1. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶: `extraction_log.txt`
2. å‚è€ƒæœ¬æ–‡æ¡£çš„[å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)éƒ¨åˆ†
3. æ£€æŸ¥GPUçŠ¶æ€: `nvidia-smi`
4. éªŒè¯ç¯å¢ƒé…ç½®

---

## ğŸ“„ è®¸å¯è¯

æœ¬å·¥å…·éµå¾ªé¡¹ç›®ä¸»ä»“åº“çš„è®¸å¯è¯ã€‚

---

**ç¥ä½¿ç”¨æ„‰å¿«! ğŸ‰**
