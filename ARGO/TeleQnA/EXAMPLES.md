# ä½¿ç”¨ç¤ºä¾‹ - ORAN QAæå–å·¥å…·

## ğŸ“ ç¤ºä¾‹1: å¿«é€Ÿæµ‹è¯•

```bash
# è¿›å…¥ç›®å½•
cd /data/user/huangxiaolin/ARGO2/ARGO/TeleQnA

# è¿è¡Œå¿«é€Ÿæµ‹è¯• (æµ‹è¯•å‰10ä¸ªé—®é¢˜)
./run_test.sh
```

**é¢„æœŸè¾“å‡º:**
```
=========================================
Quick Test: ORAN QA Extraction
=========================================

Testing with first 10 questions

Loading sample questions from: /data/user/huangxiaolin/ARGO2/ARGO/TeleQnA/TeleQnA.txt
âœ“ Loaded 10 sample questions

Initializing vLLM model...
âœ“ vLLM model loaded

Processing 10 questions...

================================================================================

Question ID: question 0
Question: What is the purpose of the Nmfaf_3daDataManagement_Deconfigure service operation? [3GPP Rele...
Category: Standards specifications
Is ORAN: âœ— NO
Reason: This is a general 3GPP specification, not specific to O-RAN.
...

================================================================================
Test Summary:
  Total questions: 10
  ORAN questions: 2 (20.0%)
  Non-ORAN questions: 8 (80.0%)
================================================================================

âœ“ Quick test completed!
```

---

## ğŸ“ ç¤ºä¾‹2: ä½¿ç”¨äº¤äº’å¼èœå• (æ¨è)

```bash
cd /data/user/huangxiaolin/ARGO2/ARGO/TeleQnA

# è¿è¡Œäº¤äº’å¼èœå•
./run_menu.sh
```

**èœå•ç•Œé¢:**
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     ORAN QA Extraction Tool - TeleQnA Dataset             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ å½“å‰ç›®å½•: /data/user/huangxiaolin/ARGO2/ARGO/TeleQnA

è¯·é€‰æ‹©æ“ä½œ:

  1) å¿«é€Ÿæµ‹è¯• (å‰10ä¸ªé—®é¢˜)
  2) å®Œæ•´æå– - åŸºç¡€ç‰ˆ
  3) å®Œæ•´æå– - å¢å¼ºç‰ˆ (æ¨è, æ”¯æŒæ–­ç‚¹ç»­ä¼ )
  4) æŸ¥çœ‹æå–è¿›åº¦
  5) æ£€æŸ¥ç»“æœç»Ÿè®¡
  6) å®‰è£…ä¾èµ–
  0) é€€å‡º

è¯·è¾“å…¥é€‰é¡¹ [0-6]: 
```

é€‰æ‹© **3** è¿è¡Œå¢å¼ºç‰ˆæå–ã€‚

---

## ğŸ“ ç¤ºä¾‹3: ç›´æ¥è¿è¡ŒPythonè„šæœ¬

```bash
cd /data/user/huangxiaolin/ARGO2/ARGO/TeleQnA

# è®¾ç½®GPU
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7

# è¿è¡Œå¢å¼ºç‰ˆ (æ¨è)
python extract_oran_qa_enhanced.py
```

**è¾“å‡ºç¤ºä¾‹:**
```
############################################################
# ORAN QA Extraction from TeleQnA Dataset (Enhanced)
# Using: /data/user/huangxiaolin/ARGO/RAG_Models/models/Qwen2.5-14B-Instruct
# GPUs: 8
# Features: Checkpoint, Error Handling, Progress Tracking
############################################################

Loading TeleQnA dataset from: /data/user/huangxiaolin/ARGO2/ARGO/TeleQnA/TeleQnA.txt
âœ“ Loaded 106324 questions

Initializing vLLM model...
  Model: /data/user/huangxiaolin/ARGO/RAG_Models/models/Qwen2.5-14B-Instruct
  Tensor Parallel Size: 8
âœ“ vLLM model loaded successfully

============================================================
Starting ORAN extraction with vLLM
Total questions: 106324
Remaining questions: 106324
Batch size: 32
GPU parallelism: 8
============================================================

Processing batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3323/3323 [2:34:15<00:00, 2.78s/it]

âœ“ Checkpoint saved: 106324/106324 questions processed

Saving 8456 ORAN questions to: /data/user/huangxiaolin/ARGO2/ARGO/TeleQnA/TeleQnA_ORAN_only.json
Saving extraction log to: /data/user/huangxiaolin/ARGO2/ARGO/TeleQnA/extraction_log.txt

============================================================
Extraction Summary:
  Total questions: 106324
  ORAN questions: 8456 (7.95%)
  Non-ORAN questions: 97868 (92.05%)
============================================================
âœ“ Checkpoint file removed (extraction completed)

âœ“ Extraction completed successfully!
```

---

## ğŸ“ ç¤ºä¾‹4: æ–­ç‚¹ç»­ä¼ 

å¦‚æœæå–è¿‡ç¨‹ä¸­ä¸­æ–­äº†,ç›´æ¥é‡æ–°è¿è¡Œå³å¯:

```bash
cd /data/user/huangxiaolin/ARGO2/ARGO/TeleQnA
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7

# é‡æ–°è¿è¡Œ,è‡ªåŠ¨ä»ä¸Šæ¬¡ä¸­æ–­çš„åœ°æ–¹ç»§ç»­
python extract_oran_qa_enhanced.py
```

**è¾“å‡ºç¤ºä¾‹:**
```
Loading TeleQnA dataset from: ...
âœ“ Loaded 106324 questions

âœ“ Loaded checkpoint: 50000 questions processed

Initializing vLLM model...
âœ“ vLLM model loaded successfully

============================================================
Starting ORAN extraction with vLLM
Total questions: 106324
Remaining questions: 56324  # â† ä»ç¬¬50000ä¸ªç»§ç»­
Batch size: 32
GPU parallelism: 8
============================================================

âœ“ Resuming from checkpoint: starting at question 50000

Processing batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1761/1761 [1:28:42<00:00, 3.02s/it]
...
```

---

## ğŸ“ ç¤ºä¾‹5: æŸ¥çœ‹ç»“æœ

### 5.1 æŸ¥çœ‹ORANé—®é¢˜æ•°é‡

```bash
cd /data/user/huangxiaolin/ARGO2/ARGO/TeleQnA

# ä½¿ç”¨jqæŸ¥çœ‹
cat TeleQnA_ORAN_only.json | jq 'length'
```

è¾“å‡º:
```
8456
```

### 5.2 æŸ¥çœ‹éšæœºORANé—®é¢˜

```bash
# éšæœºæŠ½å–5ä¸ªORANé—®é¢˜
cat TeleQnA_ORAN_only.json | jq -r '.[] | .question' | shuf | head -5
```

è¾“å‡ºç¤ºä¾‹:
```
Which deployment scenario in O-RAN Town involves vO-CU and vO-DU at the aggregation location?
Which components are responsible for embedding intelligence in the O-RAN architecture?
How does O-RAN enable interchangeability of components?
Which node controls the O-DUs in the O-RAN architecture?
What does O-RAN define functional blocks that are used in CF (Cell-free) mMIMO networks?
```

### 5.3 æŸ¥çœ‹æŸä¸ªå…·ä½“é—®é¢˜

```bash
# æŸ¥çœ‹ç¬¬ä¸€ä¸ªORANé—®é¢˜
cat TeleQnA_ORAN_only.json | jq 'to_entries | .[0]'
```

è¾“å‡ºç¤ºä¾‹:
```json
{
  "key": "question 156",
  "value": {
    "question": "Which deployment scenario in O-RAN Town involves vO-CU and vO-DU at the aggregation location?",
    "option 1": "Scenario 1",
    "option 2": "Scenario 2",
    "option 3": "Scenario 3",
    "option 4": "Scenario 4",
    "answer": "option 3: Scenario 3",
    "explanation": "Scenario 3 in O-RAN Town involves vO-CU and vO-DU at the aggregation location, with user traffic carried over OFH and encryption not needed between the cell site and aggregation site.",
    "category": "Standards specifications"
  }
}
```

### 5.4 æŸ¥çœ‹æå–æ—¥å¿—

```bash
# æŸ¥çœ‹æ—¥å¿—å‰50è¡Œ
head -50 extraction_log.txt

# æˆ–ä½¿ç”¨lessæµè§ˆ
less extraction_log.txt
```

---

## ğŸ“ ç¤ºä¾‹6: ç»Ÿè®¡åˆ†æ

### 6.1 æŒ‰ç±»åˆ«ç»Ÿè®¡

```python
import json
from collections import Counter

# åŠ è½½æ•°æ®
with open('TeleQnA_ORAN_only.json', 'r') as f:
    oran_data = json.load(f)

# ç»Ÿè®¡ç±»åˆ«
categories = [q.get('category', 'Unknown') for q in oran_data.values()]
category_counts = Counter(categories)

print("ORANé—®é¢˜ç±»åˆ«åˆ†å¸ƒ:")
for cat, count in category_counts.most_common():
    print(f"  {cat}: {count}")
```

**è¾“å‡ºç¤ºä¾‹:**
```
ORANé—®é¢˜ç±»åˆ«åˆ†å¸ƒ:
  Standards specifications: 6234
  Research overview: 1523
  Research publications: 699
```

### 6.2 è®¡ç®—æå–ç‡

```bash
# ä½¿ç”¨äº¤äº’å¼èœå•çš„é€‰é¡¹5
./run_menu.sh
# é€‰æ‹© 5) æ£€æŸ¥ç»“æœç»Ÿè®¡
```

è¾“å‡º:
```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
æ€»é—®é¢˜æ•°:      106324
ORANé—®é¢˜æ•°:    8456
ORANå æ¯”:      7.95%
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## ğŸ“ ç¤ºä¾‹7: è‡ªå®šä¹‰é…ç½®

### 7.1 ä¿®æ”¹GPUæ•°é‡

```python
# ç¼–è¾‘ extract_oran_qa_enhanced.py

# æ”¹ä¸ºä½¿ç”¨4å¼ GPU
TENSOR_PARALLEL_SIZE = 4

# æˆ–åœ¨è¿è¡Œæ—¶è®¾ç½®
export CUDA_VISIBLE_DEVICES=0,1,2,3
python extract_oran_qa_enhanced.py
```

### 7.2 ä¿®æ”¹æ‰¹å¤„ç†å¤§å°

```python
# ç¼–è¾‘ extract_oran_qa_enhanced.py

# å‡å°æ‰¹å¤„ç†å¤§å° (èŠ‚çœå†…å­˜)
BATCH_SIZE = 16
```

### 7.3 ä¿®æ”¹ä¿å­˜é¢‘ç‡

```python
# ç¼–è¾‘ extract_oran_qa_enhanced.py

# æ¯5ä¸ªbatchä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹
SAVE_FREQUENCY = 5
```

---

## ğŸ“ ç¤ºä¾‹8: æ•…éšœæ’æŸ¥

### 8.1 æ£€æŸ¥GPUçŠ¶æ€

```bash
# å®æ—¶ç›‘æ§GPU
watch -n 1 nvidia-smi

# æˆ–åœ¨å¦ä¸€ä¸ªç»ˆç«¯è¿è¡Œ
nvidia-smi
```

### 8.2 æŸ¥çœ‹è¿›åº¦æ–‡ä»¶

```bash
# æŸ¥çœ‹å½“å‰è¿›åº¦
cat progress.json | jq '.'
```

è¾“å‡º:
```json
{
  "current_batch": 1500,
  "total_batches": 3323,
  "progress_percent": 45.14,
  "elapsed_time": 5432.67,
  "estimated_remaining": 6598.33,
  "timestamp": "2025-10-29T14:23:45.123456"
}
```

### 8.3 å†…å­˜ä¸è¶³æ—¶çš„å¤„ç†

```python
# ç¼–è¾‘ extract_oran_qa_enhanced.py

# é™ä½é…ç½®
BATCH_SIZE = 8
MAX_MODEL_LEN = 2048

llm = LLM(
    model=MODEL_PATH,
    tensor_parallel_size=TENSOR_PARALLEL_SIZE,
    max_model_len=MAX_MODEL_LEN,
    trust_remote_code=True,
    dtype="float16",
    gpu_memory_utilization=0.7,  # é™ä½åˆ°70%
)
```

---

## ğŸ“ ç¤ºä¾‹9: æ•°æ®æ ¼å¼è½¬æ¢

### 9.1 è½¬æ¢ä¸ºCSV

```python
import json
import csv

with open('TeleQnA_ORAN_only.json', 'r') as f:
    oran_data = json.load(f)

with open('TeleQnA_ORAN_only.csv', 'w', newline='', encoding='utf-8') as f:
    writer = csv.writer(f)
    writer.writerow(['ID', 'Question', 'Options', 'Answer', 'Explanation', 'Category'])
    
    for qid, qdata in oran_data.items():
        options = ', '.join([v for k, v in qdata.items() if k.startswith('option')])
        writer.writerow([
            qid,
            qdata['question'],
            options,
            qdata['answer'],
            qdata.get('explanation', ''),
            qdata.get('category', '')
        ])

print("âœ“ å·²è½¬æ¢ä¸ºCSVæ ¼å¼")
```

### 9.2 æå–é—®ç­”å¯¹

```python
import json

with open('TeleQnA_ORAN_only.json', 'r') as f:
    oran_data = json.load(f)

qa_pairs = []
for qid, qdata in oran_data.items():
    qa_pairs.append({
        'id': qid,
        'question': qdata['question'],
        'answer': qdata['answer']
    })

with open('ORAN_QA_pairs.json', 'w', encoding='utf-8') as f:
    json.dump(qa_pairs, f, ensure_ascii=False, indent=2)

print(f"âœ“ æå–äº† {len(qa_pairs)} ä¸ªé—®ç­”å¯¹")
```

---

## ğŸ¯ æœ€ä½³å®è·µå»ºè®®

1. **é¦–æ¬¡ä½¿ç”¨**: å…ˆè¿è¡Œ `./run_test.sh` æµ‹è¯•
2. **å®Œæ•´æå–**: ä½¿ç”¨å¢å¼ºç‰ˆ `python extract_oran_qa_enhanced.py`
3. **ç›‘æ§è¿›åº¦**: åœ¨å¦ä¸€ç»ˆç«¯è¿è¡Œ `watch -n 10 "cat progress.json | jq '.'"`
4. **è´¨é‡æ£€æŸ¥**: æå–å®ŒæˆåéšæœºæŠ½æ ·éªŒè¯
5. **ä¿å­˜å¤‡ä»½**: å®šæœŸå¤‡ä»½ `TeleQnA_ORAN_only.json`

---

**ç¥ä½¿ç”¨é¡ºåˆ©! ğŸ‰**
