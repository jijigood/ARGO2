Table of Contents
Table of Figures
Figure 2-1:  Relationship of this Document to Scenario Documents and O-RAN Management Documents	8
Figure 2-2:  O-RAN Architecture and Management Interfaces	9
Figure 3-1: O-Cloud Pre-Deployment Processing	13
Figure 3-2: Platform Software Installation	16
Figure 3-3: O-Cloud Deployment Processing	18
Figure 3-4: O-Cloud Inventory Update	20
Figure 3-5: Hardware Infrastructure Scaling	21
Figure 3-6: O-Cloud Platform Software Update	23
Figure 3-7: O-Cloud Functional Status Query	25
Figure 3-8: O-Cloud Functional Status Update	27
Figure 3-9: IMS Software Update	30
Figure 3-10: Instantiate Network Function	34
Figure 3-11: Scale Out of Network Function	36
Figure 3-12: Scale In of Network Function	38
Figure 3-13: SW Upgrade of Network Function	42
Figure 3-14: Terminate Network Function	43
Figure 3-15: Configure O-Cloud for Near-RT RIC	45
Figure 3-16: Deploy xAPP	48
Figure 3-17: Reconfiguration	52
Figure 3-18: Remote System Reset of legacy xNB by OSS	53
Figure 3-19:NF Deployment level recovery	55
Figure 3-20: O-Cloud Node level recovery	57
Figure 3-21: Alarm Subscription	59
Figure 3-22: Alarm Notification	62
Figure 3-23: Alarm Query	65
Figure 3-24: IMS Alarm Subscription	67
Figure 3-25: IMS Alarm Subscription Deletion	70
Figure 3-26: Alarm Synchronization	73
Figure 3-27: Alarm Acknowledge/Clear	75
Figure 3-28: Log Query	81
Figure 3-29: Alarm Dictionary Discovery	84
Figure 3-30: Logging Management	87
Figure 3-31: Alarm List Management	90
Figure 3-32: PM Job Creation	92
Figure 3-33: PM Data and PM Subscription	93
Figure 3-34: PM Subscription	96
Figure 3-35: PM Notification Reporting	100
Figure 3-36: PM Streaming Reporting	106
Figure 3-37: PM File Reporting	111
Figure 3-38: PM Job Query	113
Figure 3-39: PM Job Delete	117
Figure 3-40: PM  Job Update	121
Figure 3-41: PM Job Suspend	125
Figure 3-42: PM Job Resume	129
Figure 3-43: VLAN Allocation	131
Figure 3-44: VLAN Deallocation	133
Figure 3-45: Network Slice Creation	137
Figure 3-46: Network Slice Deletion	138
Figure 3-47: Network Resource Provisioning for Underlay Network	140
Figure 3-48: Create Kubernetes (K8s) Cluster	146
Figure 3-49: Delete Kubernetes (K8s) Cluster	148
Foreword
This Technical Specification (TS) has been produced by O-RAN Alliance.
Modal verbs terminology
In the present document "shall", "shall not", "should", "should not", "may", "need not", "will", "will not", "can" and "cannot" are to be interpreted as described in clause 3.2 of the O-RAN Drafting Rules (Verbal forms for the expression of provisions).
"must" and "must not" are NOT allowed in O-RAN deliverables except when used in direct citation.
Scope
The contents of the present document are subject to continuing work within O-RAN and may change following formal O-RAN approval. Should the O-RAN Alliance modify the contents of the present document, it will be re-released by O-RAN with an identifying change of version date and an increase in version number as follows:
Version xx.yy.zz
where:
xx	the first digit-group is incremented for all changes of substance, i.e., technical enhancements, corrections, updates, etc. (the initial approved document will have xx=01).  Always 2 digits with leading zero if needed.
yy	the second digit-group is incremented when editorial only changes have been incorporated in the document. Always 2 digits with leading zero if needed.
zz	the third digit-group included only in working versions of the document indicating incremental changes during the editing process.  External versions never include the third digit-group. Always 2 digits with leading zero if needed.
The present document specifics cloudification and orchestration use cases and requirements for O-RAN.
References
References are either specific (identified by date of publication and/or edition number or version number) or non-specific. For specific references, only the cited version applies.  For non-specific references, the latest version of the referenced document (including any amendments) applies.
NOTE:	While any hyperlinks included in this clause were valid at the time of publication, O-RAN cannot guarantee their long term validity.
-	For a non-specific reference, the latest version applies. In the case of a reference to a 3GPP document (including a GSM document), a non-specific reference implicitly refers to the latest version of that document in Release 16.
The following documents contain provisions which, through reference in this text, constitute provisions of this specification.
3GPP TR 21.905: "Vocabulary for 3GPP Specifications".
ETSI GS NFV 003 V1.4.1, “Terminology for Main Concepts in NFV”
O-RAN-WG1-O-RAN-Architecture-Description, “O-RAN Architecture Description”
O-RAN White Paper: “O-RAN: Towards an Open and Smart RAN”, October 2018.
O-RAN.WG10.OAM-Architecture: “O-RAN Operations and Maintenance Architecture”.
O-RAN.WG10.O1-Interface: “O-RAN Operations and Maintenance Interface Specification”.
O-RAN-WG6.CAD: “Cloud Architecture and Deployment Scenarios for O-RAN Virtualized RAN”.
O-RAN-WG2.UCR, “Use Case and Requirements Specification”
O-RAN-WG6.O2-GA&P: “O2 General Aspects and Principles”
O-RAN.WG3.RICARCH: “Near-RT RIC Architecture”
O-RAN-WG6.AAL-GAnP: “O-RAN O-Cloud Acceleration Abstraction Layer”
ETSI GS NFV-SOL 015 V1.2.1 (2020-12): “Specification of Patterns and Conventions for RESTful NFV-MANO APIs”
ETSI 3GPP TS 29.501 V16.5.0 (2020-09): “Principles and Guidelines for Services Definition; Stage 3”
O-RAN.WG1.Slicing-Architecture: “O-RAN Working Group 1 Slicing Architecture”
ITU-T Recommendation X.731, “Information technology - Open Systems Interconnection - Systems management: State management function”, January 1992
ETSI GS NFV-IFA 013 V4.2.2 (2021-06): “ Network Functions Virtualisation (NFV) Release 4; Management and Orchestration; Os-Ma-Nfvo reference point – Interface and Information Model Specification”
O-RAN.WG6.O2IMS-INTERFACE: “O-RAN O2ims Interface Specification”
O-RAN.SFG.O-RAN-Security-Requirements-Specifications: “O-RAN Security Requirements Specification”
ETSI GS NFV-IFA 032 V4.3.1 (2022-06): “Network Functions Virtualisation (NFV) Release 4; Management and Orchestration; Interface and Information Model Specification for Multi-Site Connectivity Services”
Definition of Terms, Symbols and Abbreviations
Terms
For the purposes of the present document, the terms and definitions given in 3GPP TR 21.905 [1] and the following apply. A term defined in the present document takes precedence over the definition of the same term, if any, in 3GPP TR 21.905 [1].
Managed Function 	Term used in O-RAN OAM to refer to a distinct logical function that is managed.  Examples include Near-RT RIC, O-CU-CP, O-CU-UP, O-DU, and O-RU.    
From the OAM Framework document:  3GPP TS 28.622 states that a Managed Function (MF) can represent a telecommunication function either realized by software running on dedicated hardware or realized by software running on NFVI. Each managed function instance communicates with a manager (directly or indirectly) over one or more management interfaces exposed via its containing managed element instance.
Managed Element 	Term used in O-RAN OAM to refer to a distinct physical or virtual element that is managed.  The ME will expose its contained MFs and their information models to the SMO through its management interfaces.
From the OAM Framework document:  3GPP TS 28.622 states that a Managed Element (ME) communicates with a manager (directly or indirectly) over one or more management interfaces for the purpose of being monitored and/or controlled. Managed elements may or may not additionally perform element management functionality.
Abbreviations
For the purposes of this document, the abbreviations given in 3GPP TR 21.905 [1] and the following apply. 
An abbreviation defined in the present document takes precedence over the definition of the same abbreviation, if any, in 3GPP TR 21.905 [1].
3GPP	Third Generation Partnership Project
5G	Fifth-Generation Mobile Communications
CNF	Containerized Network Function
DMS	O-Cloud Deployment Management Services
FOCOM	Federated O-Cloud Orchestration & Management
IM	Information Model
IMS	O-Cloud Infrastructure Management Services
LCM	Life Cycle Management
NF	Network Function
NFO	Network Function Orchestration
NFVI	Network Function Virtualization Infrastructure
O-CU	O-RAN Central Unit as defined by O-RAN ALLIANCE
O-CU-CP	O-CU Control Plane
O-CU-UP	O-CU User Plane
O-DU	O-RAN Distributed Unit (uses Lower-level Split)
O-RU	O-RAN Radio Unit
PNF	Physical Network Function
RAN	Radio Access Network
SMO	Service Management and Orchestration Framework
VIM	Virtual Infrastructure Manager
VNF	Virtual Network Function
WG	Working Group
Objectives
Context and Relationship to other WG6 and O-RAN Work
This document introduces different use cases for O-RAN orchestration of virtualized RAN and the interfaces used for management and orchestration, in particular the O1 interface between the service management and orchestration framework and the RAN managed functions and the O2 interface between the service management and orchestration framework and the O-Cloud Infrastructure Management Services/Deployment Management Services that controls resource assignment for Virtualized Network Functions.
This document relies on WG1 architecture documents for the overall architecture.  WG6 focuses on end-to-end orchestration in O-RAN and virtualization/cloudification of O-RAN functions.
The following documents are used as input on high level O-RAN OAM architecture and functions:
WG1 O-RAN architecture [3]
WG10 OAM architecture [5]
WG10 OAM interface specification (O1) [6]
In addition, the WG6 CADS specification [7] is referenced for input on cloud architecture and terminology, and the WG6 O2 General Aspects and Principles [9] is referenced for details of the O2 interface and its usage
The details of implementing orchestration interfaces and models are covered in follow on documents, such as are shown in purple in Figure 2-1.
NOTE:	Work on AAL[11] may lead to additional use cases in future.
Figure 2-1:  Relationship of this Document to Scenario Documents and O-RAN Management Documents
This document also draws on work from other O-RAN working groups such as WG2 for Non-RT RIC details and WG3 for Near-RT RIC and xAPP details, as well as sources from other industry bodies.
Objectives of this Document
The O-RAN ALLIANCE seeks to improve RAN flexibility and deployment velocity, while at the same time reducing the capital and operating costs through the adoption of cloud-based architectures.
A key principle is the decoupling of RAN hardware and software for all components including O-CU, O-DU, and O-RU, and the deployment of software components on commodity server architectures supplemented with programmable accelerators where necessary.
Given that the RAN environment will consist of a range of different components that can be realized by either PNFs or VNFs/CNFs it is critical to understand the coordination of RAN components done by the Service Management and Orchestration Framework to deploy and operate RAN services in an O-RAN architecture.
This document defines end-to-end use cases in clause 3 and specifies OAM-related general and interface requirements in clause 4 to support the O-RAN architecture.
Relationship to O-RAN OAM Architecture
This document follows the high-level O-RAN OAM Architecture defined in O-RAN WG10.  The high-level OAM Architecture is given below in Figure 2-2 as taken from [3] but focusing on OAM interfaces O1 and O2 only.
Figure 2-2:  O-RAN Architecture and Management Interfaces
The Use Cases in this document describe the use of the O1 and O2 interfaces for orchestration within an O-RAN.
Functional Description of O-RAN Cloud Infrastructure
This document uses terminology for O-Cloud components taken from the Cloud Architecture and Deployment Scenarios for O-RAN virtualized RAN Specification [7], and O2 General Aspects and Principles [9], including the O-Cloud Node, IMS and DMS.
Orchestration Use Cases
These Use Cases focus on the private cloud case where the cloud is managed by the operator.  Applicability to the public cloud case is for further study.
The present document provides Use Cases related to Network Function, O-Cloud, SMO and Near-RT RIC.  At a high level, the use cases cover similar functionality/scope applicable to O-Cloud and O-Cloud-based Network Functions, such as:
Instantiation and deployment of O-Cloud and Network Functions
Updating of O-Cloud and Network Functions
Scaling of O-Cloud and Network Functions
Instantiation and deployment of O-Cloud in the O-RAN is triggered by the “Service Request” from SMO and a sequential process involving the use cases described in clauses 3.1.1, 3.1.2, 3.1.3. The instantiation of Network Function is described in clause 3.2.1.
Updating of O-Cloud and Network Function can be performed independently and be triggered by the SMO as described in clauses 3.1.6 and 3.2.4, respectively.
Scaling of Network Function is triggered by the SMO as described in clause 3.2.2 (for the scaling out) and clause 3.2.3 (for the scaling in). Scaling of O-Cloud is described in clause 3.1.5.
The roles and actors described in Table 3-1 are used in the use case descriptions.
Table 3-1: Description of actors and roles used in the use cases.
Note: The UML® Sequence Diagrams in the use cases follow the template defined in the OAM Architecture [5] Appendix B.  An arrow with dashed lines is used to indicate a synchronous return message.
Note: UML® is a registered trademark of the Object Management Group, in the United States and other countries. O-RAN is not affiliated with, endorsed or sponsored by the Object Management Group.
There might be various situations where the IMS software or its data store itself has become corrupt. In this situation, the IMS as a producer entity might not be able to perform its functions over the O2ims interface. This problem applies to all the following use cases. Ways or strategies of how to recover or react to a non-functional IMS will be covered in the Loss of O2ims of Management Link Use Case [Note: use case to be added in future].
For all the following use cases, there are common messaging framework errors and exceptions that can occur. For example, if a response message is never received because of a network outage, it is expected that eventually the system will time out. These standard code responses will apply to all the following use cases and are not mentioned explicitly as separate exceptions within the use cases.
O-Cloud Basic Use Cases
Cloud Platforms must be identified for the SMO to take advantage of them. In traditional data center clouds these have been manually or externally added to the SMO for homing of NF deployments since the numbers are typically low from hundreds of cloud regions to even several thousand. However, in the case of edge clouds the number of deployments scale into the 10K to 100K range, in which case this process needs to more closely resemble the way RAN elements are “discovered”. Even in this latter case, the rationale for edge clouds is for specific performance requirements, therefore not all edge clouds are equivalent. This Use Case describes how the SMO discovers and manages a cloud implementation that meets the O-RAN specifications as described in the Cloud Architecture and Deployment Scenarios for O-RAN virtualized RAN [7]. Such a cloud instance is generally referred to as an O-Cloud which is comprised of O-Cloud Nodes (Compute, Storage, and Network), dedicated resources for the O-Cloud.
This group of Use Cases includes the following:
Pre-processing where before the O-Cloud is activated the SMO is configured with the identity of the O-Cloud so that registration can be done
Basic platform software installation by the SMO and IMS
O-Cloud deployment processing where the O-Cloud registers with SMO and has its identity and software version checked
Capabilities Exchange where the SMO either queries for O-Cloud capabilities or is notified autonomously that there has been a change in O-Cloud capabilities
O-Cloud hardware upgrade where a new O-Cloud Node is added
O-Cloud software update where the platform software version is upgraded or downgraded in the O-Cloud
The end result of the group of use cases is an active O-Cloud registered with SMO and ready for the deployment of Network Functions.
NOTE:	Where Personnel are shown as part of the Use Case, the roles and terminology used are given for purposes of illustration only.
NOTE: 	Regarding security and authentication of an entity that interacts with the IMS, which typically the FOCOM in the SMO, the topic of security and authentication will be addressed by the O-RAN security focus group (SFG). A common solution which affects all the following use cases will be studied and specified by the SFG. This is currently FFS. When these are better understood, each of the following use cases will be updated to reflect the security & authentication requirements.
O-Cloud Pre-Deployment Processing Use Case
High Level Description
This Use Case describes the SMO being configured to add an O-Cloud into its inventory prior to the O-Cloud itself being activated and attempting to register with the SMO.
The Use Case assumes that this will be part of a sequence of “Service Requests” to the SMO, one for the deployment of the O-Cloud and one for the Network Function(s) that will run on that O-Cloud instance.  In the latter request, information is assumed to be present on the NF Service Requests to identify the O-Cloud instance, as described in a later Use Case.
NOTE:	In some cases, there could potentially be a single “Service Request” to SMO containing information about both the O-Cloud and Network Function(s) that will run on that O-Cloud instance, but this is not covered in the Use Case.
Sequence Description
UML sequence diagram
Figure 3-1: O-Cloud Pre-Deployment Processing
O-Cloud Platform Software Installation Use Case
High Level Description
The Use Case describes the deployment of the O-Cloud and installation of O-Cloud Platform Software on an O-Cloud Node.  The Cloud Installer begins the installation by installing the hardware for the O-Cloud Nodes and notifying SMO to begin Cloud Build.  SMO then loads O-Cloud Platform Software on a first O-Cloud Node in the O-Cloud, which then brings up any additional O-Cloud Nodes in the O-Cloud.
During activation of other O-Cloud Nodes, the O-Cloud Management Plane activates IMS, which then notifies the SMO of its availability.  The SMO then sends IMS the required set of O-Cloud Node Roles and Personalities to support.  The IMS loads necessary basic software for O-Cloud onto the other O-Cloud Nodes and also configures and activates one or more DMSs.
It is assumed that hardware to deploy O-Cloud Management Software is pre-configured and ready. Network connectivity between O-Cloud network gateways(s) and SMO is assumed to be ready, as per the “O-Cloud Pre-Deployment Processing Use Case” described in clause 3.1.1.
Sequence Description
UML sequence diagram
Figure 3-2: Platform Software Installation
O-Cloud Registration and Initialization Use Case
High Level Description
This Use Case describes the sequence for registration and initialization of the newly deployed O-Cloud.  The SMO queries the O-Cloud for its SW inventory, checks to see if this requires any updates, configures the O-Cloud and queries the O-Cloud for available DMS.  Following this sequence, the O-Cloud is available for NF deployments to be instantiated.
Sequence Description
UML sequence diagram
Figure 3-3: O-Cloud Deployment Processing
O-Cloud Inventory Update Use Case (DMS Example)
High Level Description
This Use Case describes the procedure for the SMO and O-Cloud to update inventory information about its type and current capabilities using O2 Infrastructure Inventory Services [9], including resource build configurations (aka “flavors”), capacity, utilization and availability.  This procedure is invoked initially at deployment of the O-Cloud and can be invoked at later times to identify changes in the capabilities of the O-Cloud. Two patterns are possible, one using query/response from the SMO in order to get current inventory, e.g., before instantiating a new NF deployment and one triggered by autonomous indications from the O-Cloud when there has been a change in inventory status.
This example shows inventory update being used by SMO to update its inventory of DMS capabilities.
Sequence Description
UML sequence diagram
Figure 3-4: O-Cloud Inventory Update
Hardware Infrastructure Scaling of O-Cloud Post Deployment
High Level Description
After the initial deployment of an O-Cloud, it may be necessary to scale up resources. In this use case, we examine how the SMO will discover and manage a new O-Cloud Node that has been cabled and powered up to be part of an existing O-Cloud.
Sequence Description
UML sequence diagram
Figure 3-5: Hardware Infrastructure Scaling
O-Cloud Platform Software Update Use Case
High Level Description
Edge clouds deployments can range in the 10K to 100K range across an operator network. Rolling O-Cloud software updates (upgrades and downgrades) need to be performed without service disruption for both VM and container-based workloads. Across a region, it may be necessary to update all edge O-Clouds in a serial fashion in order to minimize potential disruptions or in a parallel fashion where a set amount of edge O-Clouds in a region are simultaneously updated. Compute and storage nodes of individual edge O-Clouds can also be updated in a serial or parallel hitless fashion. Within an individual O-Cloud, the IMS migrates Network Function deployments from the affected O-Cloud Nodes before the software update in order to avoid service disruption (in this use case, it is assumed that IMS does this autonomously).  From an SMO perspective, offloading the update strategy of an edge O-Cloud to a regional and local controller substantially reduces the update complexity.
Fault handling of an O-Cloud update is critical. Individual nodes can fail during the update process and may need to be replaced. Rolling back of the update prior to a successful completion must also be supported.
In this use case, we examine how the SMO will update a single O-Cloud.  It is assumed that the software update does not affect the IMS itself, and that the IMS is capable of performing the software update and migrating NF deployments from the affected O-Cloud Nodes without affecting active services.
Sequence Description
UML sequence diagram
Figure 3-6: O-Cloud Platform Software Update
Functional Status Query Use Case
High Level Description
The purpose of the functional status query use case is to allow for the request of state and status information from the O-Cloud. Standardized state and status information can be found in ITU-T X.731 (see reference [15]). While X.731 concepts originate in a wireless RAN context, they are useful and applicable to the management and reporting of O-Cloud resources.
Note: For an operator to indicate something is in maintenance, the Administrative State Attribute (from X.731) values of “locked” and “shutting down” could be used.
Note: For an operator to indicate something is undergoing test, the Availability Status attribute (X.731) “in test” and the Control Status Attribute (X.731) “subject to test” and “reserved for test” could be used.
For example, an operator wants to see that things are “healthy” and operating with no faults. They could issue a functional status query on the O-Cloud; and the query would return an operational state of “enabled” with no alarm status of “alarm outstanding” for all resources.
Sequence Description
UML Sequence Diagram
Figure 3-7: O-Cloud Functional Status Query
Functional Status Update Use Case
High Level Description
The purpose of the functional status update use case is to update the state and status of the O-Cloud Resources.
Sequence Description
UML Sequence Diagram
Figure 3-8: O-Cloud Functional Status Update
IMS Software Update Use Case
High Level Description
This use case focuses on the update of IMS software. For the O-Cloud Platform Software update, please see 3.1.6.
Sequence Description
UML Sequence Diagram
Figure 3-9: IMS Software Update
Network Function Basic Use Cases
Instantiate Network Function on O-Cloud
High Level Description
This Use Case describes the instantiation of a Cloud-Native Network Function as a new deployment on an O-Cloud, and notification to the SMO once the instantiation of resources for the Network Function deployment has been completed.
The following Use Case adopts terms from the high-level model described in Clause 4 of the OAM Architecture [5]. For definition purposes the terms adopted are defined below. However, if the definition is in conflict with the OAM Architecture, then the OAM Architecture will supersede these definitions.
DeploymentDescriptor:	The Deployment Descriptor describes a deployment option that has been validated by the Solution Provider of the application.
DeploymentItem:	The Deployment Item describes a complete deployment of an application or part of an application. A Deployment Descriptor can include one or more Deployment Items. Each Deployment Item describes the Cloud Requirements (Capabilities and Capacities) that are needed for the deployment to be successful. It may include references to Executable Images and Cloud Native Descriptor Files which are sent to the Cloud where the deployment is expected to occur.
CloudNativeDescriptorFile:	The Cloud Native Descriptor File is an artifact which is intended to be opaque to the SMO and sent via the O2dms that meets the specified cloud capabilities identified in the DeploymentItem.
ExecutableImage:	The Executable Image is an artifact which is intended to be deployed into the O-Cloud, this could be a docker image, or any other binary image such as a bitstream used to configure an accelerator.
NOTE: The instantiation on the O-Cloud Node may be part of a larger procedure instantiating multiple connected Network Functions, in which case the SMO will coordinate the timing of instantiation across O-Clouds and O-Cloud Nodes, the configuration of transport needed between O-Cloud Nodes and other requirements such as addressing and security used for connecting the Network Functions as below. Instantiation of multiple connected NFs is not addressed in the use case.
Sequence Description
UML sequence diagram
Figure 3-10: Instantiate Network Function
Scale Out of NF
High Level Description
This Use Case describes how to instantiate additional resources for NF deployments in order to expand the capacity of an NF. This results in horizontal elasticity and allows the NF to consume the resources it needs based on the level of demand based on network traffic.
NOTE:	In this use case, scaling is managed by the SMO.  Self-management of scaling by the NF is for future study.
Sequence Description
UML sequence diagram
Figure 3-11: Scale Out of Network Function
Scale In of NF
High Level Description
This Use Case describes how to delete NF deployments to reduce the capacity of an O-Cloud-based ME realizing an O-RAN NF, to improve efficiency. This supports horizontal elasticity and allows the NF to consume only the resources it needs based on the level of demand based on network traffic.
Sequence Description
UML sequence diagram
Figure 3-12: Scale In of Network Function
Software Upgrade of NF
High Level Description
This Use Case describes SMO-managed upgrade to the software of the Network Function. This covers the software deployment and its activation.  Once activated the NF is configured by SMO similar to the NF deployment use case.
This use case illustrates the build-and-replace NF software upgrade approach.  This approach utilizes a graceful or soft upgrade where the old NF is not deleted until this can be done without disrupting existing traffic it supports. Other approaches could be developed specific to containerization such as break-fix, or the PNF form of Upgrade-in-place.  More complex scenarios such as support of zero traffic loss may be explored in future versions.
Sequence Description
UML sequence diagram
Figure 3-13: SW Upgrade of Network Function
3.2.5	Terminate Network Function on O-Cloud
3.2.5.1 High Level Description
This Use Case describes the termination of a Network Function on an O-Cloud, and notification to the SMO once the termination of resources for the Network Function deployment has been completed.
3.2.5.2	Sequence description
3.2.5.3 UML sequence diagram
Figure 3-14: Terminate Network Function
Near-RT RIC/xAPP Use Cases
Configure O-Cloud for Near-RT RIC
High Level Description
This Use Case defines an optional procedure using Custom Resources to configure a Kubernetes O-Cloud to support the Near-RT RIC function by using, as an example, the Kubernetes® Custom Resource Definitions (CRD).
NOTE:	Similar procedure may be used for O-Cloud configuration for other functions as well.
NOTE: Kubernetes® and K8s® are registered trademarks of the Linux Foundation, in the United States and other countries. O-RAN is not affiliated with, endorsed or sponsored by the Linux Foundation.
The Near-RT RIC may require a Custom Resource to ensure proper lifecycle management of the near-RT RIC and its xAPPs. This capability has to be added to the O-Cloud prior to a near-RT RIC service deployment. There are multiple ways to add a custom resource. For example, Custom Resource Definitions (CRD) is easier and requires no programming. Another possibility is to use API Aggregation which requires programming but is more flexible in terms of API behaviors. Both options require a "service" in Kubernetes to be deployed. The following example illustrates the CRD initial installation.
Sequence Description
UML Sequence Diagram
Figure 3-15: Configure O-Cloud for Near-RT RIC
Deploy xAPP in Near-RT RIC
High Level Description
xAPPs are developed independent of the near-RT RIC in which they execute. This Use Case describes how an xAPP is instantiated and associated with a near-RT RIC.
Sequence Description
NOTE:	Information could be, for example, RIC namespace, IP address or ports needed to access RIC services, as determined by WG3
UML Sequence Diagram
Figure 3-16: Deploy xAPP
Multi-vendor network provisioning in a mixed PNF/VNF environment
A Use Case description of multi-vendor provisioning of an O-RAN service can be found in the O-RAN OAM Architecture specification [5].
Reconfiguration of O-RAN Virtual Network Function(s)
High Level Description
A common orchestration request is the reconfiguration of one or a set of cloud-based O-RAN Virtual Network Functions in order to affect the behavior of the RAN.  The action taken could be, for example, to re-optimize network traffic patterns or update the load balancing of traffic across the RAN network.  The trigger for this action could be any number of events such as non-real time traffic analysis by the Non-RT RIC, or input from non-RAN sources such as upcoming natural events or scheduled human events.
In such cases the SMO will either be told or determine by its own analysis which Virtual Network Functions need reconfiguration and in which order this is done if multiple Virtual Network Functions are involved.  If a problem develops during reconfiguration then SMO may optionally invoke a fallback procedure to revert the Virtual Network Functions to their original configuration.  As in reconfiguration of PNFs, O1 Interface [6] Provisioning Management is used.
NOTE:	There may be a need for SMO to initially reroute traffic away from the affected Virtual Network Functions and subsequently revert traffic to the original patterns.  This could be done by using Network Function Reconfiguration on adjacent Network Functions that send or receive information from the affected Network Functions.
Sequence Description
UML sequence diagram
Figure 3-17: Reconfiguration
Recovery Use Cases
Introduction
When an operator experiences problems with an O-Cloud NF Deployment(s), O-Cloud Node(s), or O-Cloud instance, it is possible for the operator to initiate a recovery at different levels of the O-Cloud.
These can include the following:
Application-level healing
This causes an application within an NF on the O-Cloud to be healed on operator request, and is accomplished through the O1 interface between SMO and the associated NF. Typically, the network operator tries to execute the Application level healing as part of recovering from NF’s application failures via O1.
The Application level healing is out of scope of the present document since it is foreseen that the interactions are only on the O1 interface.
NF Deployment level healing (refer to clause 3.6.2)
Another level of healing is by acting upon the NF Deployments (e.g., workloads in Kubernetes case) that realize an NF instance, where either the network operator can execute the NF Deployment level healing  via O2dms, or the O-Cloud internal deployment management functions can execute built-in or configured procedures for auto-healing of the NF Deployment, e.g., based on workload monitoring in O-Cloud.
When the healing of an NF Deployment within an O-Cloud is triggered via an operator request, it is accomplished through the O2dms interface between SMO and the DMS responsible for the deployment management services of the NF Deployment of concern.
In the case of auto-healing, the DMS may automatically trigger healing of the NF Deployment, where no operator request over O2dms interface is necessary.
O-Cloud Node level healing (refer to clause 3.6.3)
This causes one or more O-Cloud Nodes within an O-Cloud to be healed on operator request, and is accomplished through the O2ims interface between SMO and the IMS responsible for infrastructure management services for that O-Cloud Node. This can be used as part of recovery of the resources within the O-Cloud, i.e., the O-Cloud Node level healing. It is also possible that IMS executes built-in or configured procedures for auto-healing of the O-Cloud Node.  This level of healing needs extra trigger considerations because it can affect multiple NFs running on the O-Cloud Node(s). For instance, "draining" the O-Cloud Node (i.e., migrating the NF deployments out from the affected O-Cloud Node) and/or setting the O-Cloud Node into maintenance mode can be done before requesting the O-Cloud Node healing. Related NF deployment requirements from the NF deployment descriptor and cloud native descriptors that are available to the O-Cloud DMS are taken into consideration as part of the O-Cloud Node healing (e.g., graceful evacuation of Pods based on Pod disruption budgets set for that NF).
In the case of auto-healing, the IMS may automatically trigger healing of the O-Cloud Node, where no operator requires over O2ims interface is necessary.
O-Cloud instance level healing
This causes an O-Cloud instance to be healed on operator request.  This last level of healing, i.e., O-Cloud instance level healing, can be seen as a last resort action and it needs extra trigger considerations because it can affect multiple NFs and O-Cloud Nodes residing in the O-Cloud instance.
Editor’s Note: It is for further study whether this can be accomplished through the O2 interface.
The ordering or which one of the healings to use or execute is up to network operator policies, e.g., in some cases a cascading might be tried, while in other cases the operator might decide to activate a specific healing without cascading among them.
For illustrative purposes, the following is explanation about typical system reset cases in legacy deployments. In legacy deployment cases, when the xNB experiences some issue at the software level, e.g., the software on the xNB is not responding to the operations of the remote management tool due to possible software failures, “physical hardware” level reset is performed to re-gain software level control. For performing this action, typically an OSS sends a “system reset” signal to the target xNB. This procedure is necessary to reset the system (CU and DU) in xNB without performing a “manual intervention” at the radio antenna site, e.g., “personnel pushing power button”. Figure 3-16 illustrates an example of remote system reset in the legacy deployment case.  System reset does not apply in exactly the same way for recovery of NF and O-Cloud systems but healing at different levels can be supported using O2 as described above.
Figure 3-18: Remote System Reset of legacy xNB by OSS
Network Function Deployment Level Healing Use Case
High Level Description
Depending on the O-Cloud technology, in some cases the capability of auto-healing of the NF deployments is available intrinsically in the O-Cloud platform. In that case, the NF deployment requirements from the NF deployment descriptors and cloud native descriptors are taken into account together with the runtime state of the NF Deployment in O-Cloud, to activate the NF Deployment auto-healing process.
When such O-Cloud DMS capability is not available or there is a need for an operator triggered recovery as one or more O-RAN NF(s) is (are) experimenting some failure, and the error could not be fixed by using the O1 interface services, then as a possible step, the network operator could trigger SMO to request the DMS to perform an NF Deployment level healing to attempt to fix the problem.
The healing of an NF Deployment may be performed via different means depending on the type of resources required for the NF Deployment (e.g., VM or container). For instance, both in VM-based and container-based NF Deployments, the capability to restart the VM or OS Container/Pod can be leveraged. The NF Deployment could be restarted (stop and start), or its associated resources be reallocated/replaced on the same or different O-Cloud Nodes.
NOTE:	Alternatively, if the O-Cloud cannot perform the healing, new NF Deployment instances can be created on O-Cloud Nodes with resources of equivalent characteristics and profile as defined in that NF deployment descriptors and cloud native descriptors. This can be performed in the context of service recovery, not a healing of a specific NF Deployment.
This use case describes the procedure to attempt to heal specific NF Deployments using the O2dms interface services.
3.6.2.2 Sequence description
3.6.2.3 UML sequence diagram
Figure 3-19:NF Deployment level recovery
O-Cloud Node Level Healing Use Case
High Level Description
Depending on the O-Cloud technology, in some cases the capability of auto-healing of the O-Cloud Nodes is available intrinsically in the O-Cloud platform.
When such O-Cloud IMS capability is not available or there is a need for an operator triggered recovery as one or more O-RAN NF(s) is (are) experiencing some failure, and the error could not be fixed by using the O1 or O2dms interface services, then as a possible step, the network operator could trigger SMO to request the IMS to perform an O-Cloud Node level healing to attempt to fix the problem. In addition, certain events received by SMO about malfunctioning O-Cloud Node resources could indicate or trigger the need to heal those resources, even in the case that such resource is not actually being allocated for running the whole or part of an O-RAN NF.
The healing of an O-Cloud Node may be performed via different means. For instance, the O-Cloud Node could be restarted (stop and start the node) or reallocated to use other O-Cloud Resources or O-Cloud Infrastructure resources.
This use case describes the procedure to attempt to heal specific O-Cloud Nodes using the O2ims interface services. This procedure can be invoked when some faults are identified that could be resolved by healing O-Cloud Nodes.
3.6.3.2 Sequence description
3.6.3.3 UML sequence diagram
Figure 3-20: O-Cloud Node level recovery
Fault Use Cases
Alarm Subscription Use Case
High Level Description
This Use Case supports IMS Alarm Event Subscription as described in ETSI Sol15 Clause 5.9 [12] as a pattern, 3GPP TS29.501-G50 [13].
An alarm subscription allows for one or more consumers to receive alarm event notifications. This is accomplished by the potential subscriber(s) issuing a subscription to the publisher of alarm events.
Sequence Description
UML sequence diagram
Figure 3-21: Alarm Subscription
Alarm Notification Use Case
High Level Description
This Use Case supports Alarm Notification(s) by the alarm publisher (IMS).  A condition occurs on an O-Cloud resource which causes the current alarm list to change. This triggers an evaluation of the alarm subscription criteria by the publisher (IMS). If deemed relevant by the subscription criteria, the alarm is sent to the subscription endpoint. The alarm is sent in an alarm notification which is an event that carries the details of these relevant alarms. Alarm notifications are sent from a publisher to subscriber(s). See the Alarm subscription use case for more details on Alarm subscriptions.
Sequence Description
UML sequence diagram
Figure 3-22: Alarm Notification
Alarm Query Use Case
High Level Description
This Use Case supports Alarm Query (Alarm History) for O2ims. Alarm query allows for the SMO to query for specific kinds of alarms or groups of alarms based on the alarm query criteria. This is useful for an operator to investigate, track, or debug a system.
Sequence Description
UML sequence diagram
Figure 3-23: Alarm Query
IMS Alarm Subscription Query Use Case
High Level Description
This use case is about the Management of Alarm Subscriptions; in particular, the query service operation. The create and delete of an Alarm Subscription is documented in separate use cases. This use case only concerns the query of an Alarm Subscription. Query (cf. query-response) and Read (cf. CRUD operations) are synonymous in this situation.
The query of an Alarm Subscription is the ability of an authorized entity to get the details of an Alarm Subscription including its criteria. An entity here would usually be the SMO or O-Cloud Operator; however, it could also be another authorized user/technician, or machine (e.g., software, script, etc.). Typically, an entity would perform a subscription query to cross-check their alarm subscription. Though, it could also be utilized for management purposes as well.
Sequence Description
UML Sequence Diagram
Figure 3-24: IMS Alarm Subscription
IMS Alarm Subscription Delete Use Case
High Level Description
This use case is about the Management of Alarm Subscriptions; in particular, the delete service operation. The create and query of an Alarm Subscription is documented in separate use cases. This use case only concerns the delete of an Alarm Subscription.
The delete of an Alarm Subscription is the ability of an authorized entity to delete an Alarm Subscription at the IMS. It is also possible to delete all alarm subscriptions associated with the consumer subscription identifier.  An entity here would usually be the SMO; however, it could also be another authorized user/technician, or machine (e.g., software, script, etc.).
There is no update operation for an Alarm Subscription. To accomplish an update, an entity would need to first delete a subscription and then create a subscription with the desired subscription criteria.
Any subscription operations that change a subscription must be logged. Therefore, the delete and create of an alarm subscription must be logged. The logging occurs at the O-Cloud IMS.
Sequence Description
UML Sequence Diagram
Figure 3-25: IMS Alarm Subscription Deletion
Alarm Synchronization Use Case
High Level Description
This use case is for Alarm Synchronization. This is a special case, though commonly employed situation, for Alarm Query.
Alarm Synchronization is an Alarm Query on all the alarms of interest. Synchronization is just an alarm query operation with a specific query for all alarm changes within a specific time frame.
The Alarm Synchronization result is the same as a “Get Alarm List” with the entire list requested.
Alarm synchronization may be performed on demand left up to the consumer when to issue the operation.
One example of where alarm synchronization would be used is a situation where the communication link between the client (such as the SMO) and source of truth (such as the O-Cloud) might become disconnected or disrupted. In this case, the client will want to synchronize with the source of truth after a connect is re-established.
A situation might arise such that during the time of disconnection between the O-Cloud and the management layer (FOCOM/SMO), an alarm appeared and was cleared. From the Alarm Query Use case: to get historical alarms, the cloud operator would just perform an alarm query with the appropriate criteria. For example, an alarm query with the criteria to request for all alarms with cleared status would return the historical alarms based on the retention policy of the alarm list. Thus, to perform an Alarm Synchronization for alarm with a long communication outage time an operator could perform this type of operation to synchronize historical alarm lists as well.
Sequence Description
UML Sequence Diagram
Figure 3-26: Alarm Synchronization
Alarm Acknowledge/Clear Use Case
High Level Description
This Use Case relates to Alarm Supervision. It is expected that some O-Cloud infrastructure resources can experience alarm conditions that need to be managed or cleared.
This use case is used for a management entity to acknowledge or request for alarm(s) to be cleared. It is expected that some resources could have some alarms that can be manually cleared while other alarms would be automatically cleared.
Acknowledgement of alarms means that a resource type has defined alarms that may require further human intervention; and that the acknowledge function allows an entity to recognize that the condition exists, and that further action might need to be taken.
Some alarms, based on the resource type, may have alarms that can be manually cleared after they have been raised.
Sequence Description
UML Sequence Diagram
Figure 3-27: Alarm Acknowledge/Clear
Log Query
High Level Description
This use case describes log query. Logs could be queried by the SMO to the IMS via O2. A user, application, or entity can query for logs that are available in the Cloud: both O-Cloud (exposed /IMS) and Cloud Infrastructure. Any log kept in the Cloud infrastructure might be queried through a user interface client or file transfer client such as CLI, SSH2, SFTP; this would be implementation specific.
There are three basic kinds of logs that might be kept within the Cloud (both exposed O-Cloud and Cloud infrastructure):
ALARM LOGS – Alarm logs are a record of the alarms that have been raised by the IMS. The IMS keeps and produces an Alarm Log. It is expected that the IMS logs every alarm that it sends to the FOCOM (SMO). Faults are transformed into Alarms by the IMS. Alarm Logs are exposed in an O-Cloud to northbound entities.
FAULT LOGS – Faults are kept in the Cloud infrastructure. Faults are raised by a Cloud Infrastructure Resource. Faults are transformed into alarms by the IMS. Thus, not every fault is an alarm. Not all faults are necessarily logged, and the Cloud Infrastructure Resource may keep fault log(s). The creation and operation of Fault Logs is up to implementation. Disclaimer: some implementations could combine Fault and Debug logs together. Fault logs are not necessarily exposed to northbound entities.
DEBUG LOGS – The creation and operation of Debug Logs is up to implementation. They might be able to be turned off. The log level would typically be configurable (at the source, middle, and end user level). For example, a typical implementation may use syslog (defined in RFC5424) which defines a “log level” to show informational (most detail), trace, warnings, errors, to critical (least detail) messages. Disclaimer: some implementations could combine Fault logs and Debug logs together. Debug logs are not necessarily exposed to northbound entities.
OTHER LOGS – There may be other logs besides Alarm, Fault and Debug logs that might be kept in the O-Cloud. This would be left to implementation.
The conclusion of this use case may provide either:
Pull Ca–e - A consumer retrieve the log(s) after being given an endpoint, or
Push Case – The producer gives a consumer log(s)that match input criteria.
Because this is left to implementation, this use case will address both types as alternate flows. For example, an endpoint might be an IP address, where a user, application, or entity could then use a file transfer client to get logs from. When it is an endpoint, it can have data related to the endpoint not just an IP address.
Note: the SMO will likely need to be able to inter-operate with different and sometimes legacy IMS implementations. It is expected that the SMO would need to be able to support both paradigms: one where the IMS returns Log Files from a Log Query request and another where the IMS returns an endpoint and then for the SMO to later fetch Log Files.
Sequence Description
UML Sequence Diagram
Figure 3-28: Log Query
Alarm Dictionary Discovery Use Case
High Level Description
When a new O-Cloud Resource Type is discovered in the O-Cloud infrastructure either on O-Cloud genesis or during run-time, the IMS would inform FOCOM (SMO) about that new Resource Type so that the appropriate corresponding alarm dictionary can be identified.
It is expected that the SMO would have already onboarded the associated Resource Type before it is discovered by the O-Cloud infrastructure, as described in O2 IMS Specification [17]. The four situations where an alarm dictionary could be discovered are:
SOFTWARE UPDATE – A software update creates a new resource type with its attendant alarm dictionary in inventory. Existing resources can either remain pointing to the existing Resource Type or be software updated to the newly loaded Resource Type. Each Resource Type has its own unique alarm dictionary associated with it at the SMO.
QUERY & SYNCHRONIZATION – A query service may also result in the discovery of new Resource Types in the O-Cloud infrastructure. Additionally, the initial synchronization of the model between the O-Cloud and management system (SMO) may result in the discovery of Resource Types to be managed. Each Resource Type has its own unique alarm dictionary associated with it.
NEW RESOURCES ADDED – New objects have been added to the O-Cloud infrastructure. Subsequently, new Resource Types corresponding to those new objects may be added which then may result in a notification event being generated to a consumer (FOCOM/SMO) or subscriber. Each Resource Type has its own unique alarm dictionary associated with it.
IMS LIFE CYCLE SOFTWARE UPDATE – When the software of the O-Cloud is updated new Resource Types can be discovered.
Sequence Description
UML Sequence Diagram
Figure 3-29: Alarm Dictionary Discovery
Logging Management Use Case
High Level Description
The Logging Management use case defines how IMS administrates, provisions, and configures logging management for logs that reside in the O-Cloud generated by O-Cloud Resources. It is related to the Log Query (IMS) Use Case [see Clause 3.7.8 above] because it sets the behavior how IMS handles the management of logging that underpins the Log Query use case. This Use case will cover logging management. Some examples of logging management: the configuration of the retention period, the activation of logging, logging rotation of older logs (FIFO), and setting log levels.
Logging management can apply to all the various types of logs kept in the O-Cloud including Alarm, Fault and Debug logs. The direct logging management toward specific types of logs are implementation specific.
There are Cloud native implementations for storing logs produced from O-Cloud Infrastructure resources. O-Cloud Resources could be physical or logical (see [9]). The Logging management use case should apply to O-Cloud Resources in a uniform way but should also account for those Cloud specific implementations. For example, the use of logging level by the IMS may not have a perfect “mapping” to a log level from a O-Cloud Infrastructure resource’s log.
Sequence Description
UML Sequence Diagram
Figure 3-30: Logging Management
Alarm List Management Use Case
High Level Description
This use case describes the Alarm List Management operations. The SMO, or an entity can request for updates to Alarm List Management behavior at the IMS.
Faults are errors that an O-Cloud infrastructure resource detects (and stores). The fault is sent to the IMS. The IMS performs the task of sending alarm notifications to an end user (SMO or subscribing entity) and mapping the incoming faults to alarms. The IMS keeps all the current alarms in an alarm list. The request for Alarm List Management is sent from the FOCOM towards the IMS. The request has attributes which describe the things to be adjusted. Principally, the Retention period of alarms can be changed per resource-type by the Alarm List Management operation. After the retention period expires, alarms in the alarm list for that resource types would be purged or archived based on alarm policy.
For example, the Alarm List Management request could have an attribute to specify to retention period by the IMS of Compute Node alarms (resource types) for 72 hours.
Additional extensions attributes in the Alarm List Management request could change other aspects of Alarm List Management. This would allow for implementation specific behavior. For example, an extension attribute might cause certain types of alarms from a certain Compute Node resource to be purged or archived after a certain period of time or based on triggers.
Sequence Description
UML Sequence Diagram
Figure 3-31: Alarm List Management
Performance Use Cases
Performance Management Job Creation Use Case
High Level Description
A Performance Management (PM) Job is a task for collecting measurements and metrics related to O-Cloud Resources. It is the central entity for coordinating performance management activities. The IMS collects metrics and measurements from O-Cloud Resource(s). The PM Job is created in the IMS.
Note: The term “PM Job” is a widely used telecommunications industry term. See the GA&P for more details.
This use case describes:
(1) The creation of PM Job(s)
(2) The collection and processing of measurement data from O-Cloud Resource(s) tasked by the PM job. Note: processing entails operations such as the conversion of counters from one form to another, storage of data, scraping data from one format to another.
Sequence Description
UML Sequence Diagram
Figure 3-32: PM Job Creation
Performance Measurement Subscription Use Case
High Level Description
This use case describes the flow for an entity to subscribe to Performance measurements data from an O-Cloud. PM jobs collect and compose measurements. The subscription determines when and how those are reported. The subscription allows a subscriber to get data that has been collected in the O-Cloud. Once subscribed, the Performance Measurement data is sent to a performance measurement subscriber, an entity north-bound of the O-Cloud. In the O-RAN context, it is the SMO; however, it could be another other subscribing entity.
Figure 3-33: PM Data and PM Subscription
Figure 3-28 shows the basic flow of Performance Data collection and subscription. Measurement and telemetry data is collected within the O-Cloud and gathered by PM Job(s) and stored locally. The Performance Subscription Manager within the IMS can retrieve the data to be sent to the SMO. There is a publisher and subscriber notification end point that is used to send the performance data to that is defined in the subscription. Measurement reports are composed at the SMO and can then be used to perform analysis on within the SMO.
Performance measurements in an O-Cloud might use event notification reporting, stream-based reporting, or file-based reporting ) to a subscriber . For performance measurements to be sent, a subscription needs to be created. The subscription  indicates an end point for where the performance measurements should be sent to. The subscription filter qualifies what data from the PM jobs should be sent.
The subscription will indicate the interval. A capabilities exchange could occur between the SMO and the O-Cloud indicating the mechanism and formats supported by the O-Cloud. The SMO can then subscribe to the mechanisms and formats within the subscription filter. In the capabilities exchange, the IMS would report the jobs and their collection intervals.
Sequence Description
UML Sequence Diagram
Figure 3-34: PM Subscription
Performance Notification Reporting Use Case
High Level Description
In the context of O-RAN Cloud managed systems, performance measurements can be transmitted by one of three mechanisms: event notification(s), streaming based reporting, or file-based reporting. The performance measurement subscription use case defined the service connection end point where the events are sent to in the subscription filter.
EVENT NOTIFICATIONS – Event based reporting would send individual events to a subscriber and a connection is opened each time a notification is to be sent. Non-real time performance measurements could use event-notification reporting mechanisms.
STREAMING BASED REPORTING – Streaming is typically used for a continuous session to send performance measurement data. For streaming, the connection is opened and kept open without having to renegotiate.
FILE REPORTING – Off-line, or non-real time performance measurements could use file-based or event-notification reporting mechanisms.
The SMO is expected to support all three of the above mechanisms. However, any given IMS (O-Cloud) implementation may not support all three.
This use case will cover performance event notification reporting to send performance data. An entity that subscribes to these performance event notifications will get an event or callback invoked for each reporting message.
Notification reports are based on a subscription. The performance subscription determines three things:
REPORTING FREQUENCY – The subscription filter indicates the reporting frequency when data is included in a report. The subscription filter establishes the trigger mechanism during the subscription which that trigger when the callback would be invoked.
METHOD & FORMAT – The method & format are specified in the subscription filter. The method of delivery is event notifications, streaming based reporting, or file reporting mechanisms. The format being the encoding scheme used for the payload. Formats will be defined in the data model.
ITEMS TO REPORT - It is expected each criterion define: a list of PM jobs and their lists of measures that are of interest to report.
Event based notification would be utilized for low frequency and low volume of reporting since a session is re-established with the sending of each event. At higher data volumes a continuous session would be more efficient. See the streaming reporting use case for more details.
There are three basic exception cases:
CONNECTION LOST – If connectivity between the subscriber and the publisher (IMS) is lost, a connection would not be able to be opened. There are implementation considerations such as: how long data is held for, recovery of the connection, backing up data, preventing data storms upon recovery, and management after recovery.
DATA UNAVAILABLE – This exception occurs when the performance measurement data is not available in the O-Cloud on the IMS when it should be reported. This results in a missed timing window when data was expected, but it was not available. In the interface, it would be expected a response would indicate data was unavailable. For example, in a RESTful interface an “404#@#” would indicate this exception. There are implementation considerations such as: O-Cloud failures, IMS failures, data recovery, and data synchronization.
PM JOB FAILURES & ISSUES – If the PM Job is unable to perform its function. If there are failures or issues with the PM Job(s) which might result in data being unavailable it is expected that there would alarms that would be raised by the IMS. This results in data being unavailable.
Sequence Description
UML Sequence Diagram
Figure 3-35: PM Notification Reporting
Performance Measurement Streaming Reporting Use Case
High Level Description
In the context of O-RAN Cloud managed systems, performance measurements can be transmitted by one of three mechanisms: active collection by a consumer, active push by a producer (e.g. streaming-based reporting), and/or file-based reporting. The performance measurement subscription use case defines the service connection end point where the events are sent to in the subscription filter. Both active push and active collection have similar purposes, but the active control is with either the producer or consumer.
ACTIVE PUSH BY A PRODUCER – A producer (IMS) could send performance data through pushing data to a consumer. At least two options may be identified:
STREAMING – First is where a connection between consumer & producer persists between the data reports which is like 3GPP streaming reporting (3GPP TS28.532 Clause 11.5). For streaming, the connection is typically opened and kept open without having to renegotiate. Streaming is used to send a flow of performance measurement data bursts. Once the WebSocket is opened, the meta-data about the streams is exchanged, the consumer can then receive the serialized data. The point is that meta-data does not need to be exchanged with every data burst.
EVENT NOTIFICATIONS – The second option is by event notifications, where a new connection is reestablished between a consumer and producer for each data reporting. This is like how 5GC SBA works (3GPP TS23.501, TS23.502 services). The data is sent as a payload of a notification. The major difference is in the overhead associated with the notification because even to report a small amount data requires the header and establishing a connection.
ACTIVE COLLECTION BY A CONSUMER – The consumer could also actively collect data from a producer.
CONFIGURATION MANAGEMENT READ ONLY ATTRIBUTES – Reuse of configuration management approach where attribute conveying the value of performance data is read by the consumer like any other configuration management attribute.
DATA SCRAPING – Use of data scraping common to cloud native implementations where a collector reads the data from a pre-defined URI.
FILE BASED REPORTING – File based reporting is not used for real-time, historically it is used for low-priority or background collection for large amounts of performance data. The file-based reporting has potential options: file upload by the producer and file download by the consumer following a file ready notification.
FILE UPLOAD BY PRODUCER – There is not an artificial delay, the data is reported whenever it is available. The shortfall is that it involves action by the producer.
FILE DOWNLOAD BY CONSUMER – It removes the burden from the producer, but may rely upon either periodic polling, or notification from the producer about the data being ready for download. The latter case is how 3GPP file-based reporting working in 3GPP TS28.532 Clause 11.6; and ETSI ISG NFV specifications (IFA008, IFA013).
The SMO is expected to support all three of the above mechanisms. However, any given IMS (O-Cloud) implementation may not support all three.
To stream performance measurements, a connection session is established between the IMS as a publisher and a subscriber (FOCOM at the SMO).  While the connection persists, performance data would be transmitted while it matches the subscription filter.
Performance Data is sent to the subscriber endpoint based on the subscription filter. The PM jobs collect performance data and store it locally. When the subscription indicates when data would be sent, the Performance Subscription Manager (PSM) within the IMS retrieves data. Then, the PSM formats it and sends it in a notification event in a stream. Thus, streaming-based reporting sends performance data to a subscriber endpoint based on a subscription. The subscription filter may give an interval or specify a trigger. Each element may have a criterion that determines when it is sent.
Sequence Description
UML Sequence Diagram
Figure 3-36: PM Streaming Reporting
Performance Measurement File Reporting Use Case
High Level Description
In the context of O-RAN Cloud managed systems, performance measurements can be transmitted by one of three mechanisms: active collection by a consumer, active push by a producer (e.g. streaming-based reporting), and/or file-based reporting.
The SMO is expected to support all three of the above mechanisms. However, any given IMS (O-Cloud) implementation may not support all three.
File based reporting has two cases:
File Upload by Producer (Push) – In a file upload case, the Performance Subscription Manager (PSM) within the IMS determines that data would be sent. Then, the PSM fetches the data, bundles it into a file, and sends the performance data as a file to a subscription end point.
File download by Consumer (Pull) – In a file download by consumer case, the subscription indicates that the data should be made available. When this event occurs, the PSM retrieves the data and sends a file ready notification to the SMO. Later, the SMO will retrieve the file.
Sequence Description
UML Sequence Diagram
Figure 3-37: PM File Reporting
Performance Measurement Job Query Use Case
High Level Description
PM Jobs collect performance data on O-Cloud infrastructure resources. Default Performance Measurement Jobs (PM Jobs) are created on O-Cloud genesis. Additionally, PM Jobs can be created through a request from a consumer (see the PM Job Creation use case).
This use case describes a flow where a consumer can query for PM Jobs in the O-Cloud.
In the query request, a consumer can specify a query filter for the state of a PM Job(s) of interest. Supported PM Job states include active, suspended, and deprecated defined as follows:
ACTIVE STATE – A PM Job that has been created and is currently running is defined to be in the Active state.
SUSPENDED STATE – A PM Job that has been created, and through a request to stop measurement collection is defined to be in the suspended state. See the PM Job Suspend use case for more details [Note: for future addition].
DEPRECATED STATE – As a result of a PM job deletion request, the PM job is defined to be in the deprecated state. See the PM Job Delete use case (3.8.7).
Sequence Description
UML Sequence Diagram
Figure 3-38: PM Job Query
Performance Measurement Job Delete Use Case
High Level Description
PM Jobs collect performance data on O-Cloud infrastructure resources. Default Performance Measurement Jobs (PM Jobs) are created on O-Cloud genesis. Additionally, PM Jobs can be created through a request from a consumer (see the PM Job Creation use case).
This use case describes a flow where a consumer requests for PM Job(s) to be deleted. A consumer can specify the PM Job(s) to be deleted by the associated PM Job Identifiers (IDs) which can be obtained through a PM Job query or PM Job create.
DEPRECATED STATE – As a result of a PM Job deletion request, the PM Job(s) go into the deprecated state. Deprecated PM Job(s) records are held for a retention period after which they are purged from the system. It is expected that the retention period can be configured. PM Job(s) stay in the deprecated state until they are purged; thus, PM Job(s) cannot be “resurrected” once they are in the deprecated state.
SUSPEND BEFORE DELETE – Only suspended PM Jobs can be deleted. A consumer or owner needs to first suspend the PM Job(s) before they can be deleted. Default PM Jobs cannot be suspended by a typical consumer request. See the PM Job suspend use case for more details [Note: use case to be added in future].
DEFAULT PM JOBS – Default PM Jobs are unlike normal PM Jobs. Rather, default PM Jobs may be deleted by IMS software update, or by privilege settings.
PM JOB OWNERSHIP – It is expected that a PM Job has one owner though it might have more than one consumer. A User (Operator or Entity) has a Role, and that Role has Privilege/Permissions associated with. Thus, the role may have the permissions to affect the state or delete a PM Job. Default PM Jobs also have owners. Note: Security considerations and analysis from the O-RAN Security Requirements specification [18] is FFS.
NOTIFICATION AFTER DELETION – The PM Job deletion operation may affect subscriber(s) that were getting data from the deleted PM Job(s). One of the consequences of this use case is that the subscriber(s) are notified if they had been subscribing to data collected by those PM Job(s) that were deleted. They choose to subscribe to job change notification, or they may take action after getting a report that indicates that those affected measurements were deleted.
Note: A Cloud operator may wish to minimize the computational overhead within the O-Cloud and thus may delete lower priority PM Job(s).
Sequence Description
UML Sequence Diagram
Figure 3-39: PM Job Delete
Performance Measurement Job Update Use Case
High Level Description
PM Jobs collect performance data on O-Cloud infrastructure resources. Default Performance Measurement Jobs (PM Jobs) are created on O-Cloud genesis. Additionally, PM Jobs can be created through a request from a consumer (see the PM Job Creation use case).
This use case describes Performance Measurement Job (PM Job) updates that can occur from one of two reasons as described:
RESOURCE CHANGES – Resource changes can cause PM Job(s) to update. PM Job(s) collect data from O-Cloud infrastructure resources. When O-Cloud resources are updated, added, or deleted that a PM Job depends on, the PM Job update use case may be invoked. Resources changes can impact the PM Job measure criteria which include the measured Resources, collected Measures, qualified Resource Types, and/or Resource scope criteria which may trigger a PM Job update. It is possible that the result of the evaluation may not alter the PM Job(s).
UPDATE BY REQUEST – A consumer (operator or entity) may also request for an update to PM Job(s) through a request operation. A consumer may request for data collection updates for PM Job(s). For example, different data to be collected from O-Cloud infrastructure resources. This may occur autonomously from a consumer, for example through a policy trigger. Only a consumer with the proper permissions that own the PM Job(s) can update the PM Job.
Sequence Description
UML Sequence Diagram
Figure 3-40: PM  Job Update
Performance Measurement Job Suspend Use Case
High Level Description
PM Jobs collect performance data on O-Cloud infrastructure resources. Default Performance Measurement Jobs (PM Jobs) are created on O-Cloud genesis. Additionally, PM Jobs can be created through a request from a consumer (see the PM Job Creation use case).
This use case describes a flow where a Performance Measurement Job (PM jobs) is suspended. Suspending a PM Job might be done to improve system performance because PM Jobs come at the cost of system overhead and computational cycles. Suspending a PM Job will cause it to be inactive when its report timer is triggered where it would normally collect data.
DORMANCY PERIODS – PM Job(s) can be suspended for a specified time period (dormancy period). A consumer may specify when PM Job(s) can be returned to normal operation. The request can either specify a dormancy filter or suspend the PM Job indefinitely (“PM Job Stop”). PM Jobs indefinitely suspended need a consumer request to resume operations. See the PM Job Resume use case.
RELATION TO PM JOB DELETE OPERATION – Only suspended PM Jobs can be deleted. A consumer or owner must first suspend PM Job(s) before they can be deleted. Default PM Jobs cannot be suspended by a typical consumer request. See the PM Job delete use case for more details.
PM JOB OWNERSHIP – It is expected that a PM Job has one owner, though it might have more than one consumer. The role has the permissions to suspend a PM Job. A User (Operator or Entity) has a Role, and that Role has Privilege/Permissions associated with. Thus, a user (operator or entity) has permissions based on their role. Default PM Jobs also have owners. Relationship to the Security specification is FFS.
Sequence Description
UML Sequence Diagram
Figure 3-41: PM Job Suspend
Performance Measurement Job Resume Use Case
High Level Description
PM Jobs collect performance data on O-Cloud infrastructure resources. Default Performance Measurement Jobs (PM Jobs) are created on O-Cloud genesis. Additionally, PM Jobs can be created through a request from a consumer (see the PM Job Creation use case).
This use case describes resuming one Performance Measurement Job (PM Job) that has previously been suspended. See the PM Job Suspend Use case for more details.
RESUMING OPERATIONS – PM Job(s) in the suspend state have had their measurement collection activity halted. The PM Job Resume operation will request that the PM Job start operations again. The PM Job will transition to the active state. The PM Job will begin measurement collection at their next scheduled collection interval period. The PM Job will continue to collect measurements based on their criteria. To change the interval times or collection behavior, a PM Job update would need to be performed.
PM JOB OWNERSHIP – It is expected that a PM Job has one owner, though it might have more than one consumer. The role has the permissions to resume a PM Job. A User (Operator or Entity) has a Role, and that Role has Privilege/Permissions associated with. Thus, a user (operator or entity) has permissions based on their role. Default PM Jobs also have owners. Relationship to the Security specification is FFS.
Sequence Description
UML Sequence Diagram
Figure 3-42: PM Job Resume
VLAN Management Use Cases
VLAN Allocation Use Case
High Level Description
This Use Case supports allocation of a VLAN ID to support various deployment use cases such a network slice.
As an example, one of the consumers is RAN NSSMF (Network Slice Subnet Management Function) that needs to associate a RAN slice to a VLAN ID during slice subnet provisioning procedures. Within a given O-Cloud, RAN NSSMF uses this VLAN ID as handover between O-Cloud and transport network so that the slice could be carried through the transport network across multiple O-Clouds.  If a slice spans multiple O-Clouds, this handover is necessary for each segment of the transport connecting these O-Clouds. See Annex A in the O-RAN.WG1.Slicing-Architecture-v05.00 [14] as to how this VLAN ID is used in various deployments.
The scope of this use case is simply to allocate/reserve a VLAN ID within O-Cloud. As a part of this use case, no configuration is pushed in the O-Cloud.
Since VLANs have a local significance, each O-Cloud manages a pool of VLAN IDs, and returns a VLAN ID upon a query/request from SMO (FOCOM). To avoid using the same VLAN ID multiple times, O-Cloud may take the VLAN ID out of the “available” pool after it allocates it. O-Cloud may choose any mechanism to ensure that same VLAN IDs is not used multiple times.
NOTE: There are other viable identifiers to associate a slice with (such as VLANs, VNIs, VRFs, etc.), In the initial version of O-RAN network slicing, VLAN IDs are used for this purpose. Additional identifiers, or an abstract identifier may be introduced in future. This does not impose any networking constrains within O-Cloud.
Sequence Description
UML sequence diagram
Figure 3-43: VLAN Allocation
VLAN Deallocation Use Case
High Level Description
This use case supports deallocation of a VLAN ID when a given VLAN ID not needed anymore, such as at the time of deletion of a network slice. A given VLAN IDs is a returned back to “available” pool of VLAN IDs in each O-Cloud.
VLAN IDs are a limited/finite set of pool. Therefore, it is important to recycle the VLAN IDs as they are not needed anymore. As an example, when a network slice is deleted, RAN NSSMF sends a deallocate VLAN ID request to O-Cloud. O-Cloud moves the VLAN ID into the pool of available VLAN IDs.
Sequence Description
UML sequence diagram
Figure 3-44: VLAN Deallocation
Network Slicing Use Cases
Network slices may span across multiple domains such as RAN, Core, and Transport. The slice is divided into multiple subnets; one subnet per domain, i.e., RAN Slice Subnet, Transport Slice Subnet, and Core Slice Subnet. This section only covers the RAN Slice Subnet.
Network slice creation requires creation of O-RAN Network Slice Subnet Instance (O-NSSI). RAN Network Slice Subnet Management Function (NSSMF) manages the creation and deletion of O-NSSI. For details, please see O-RAN.WG1.Slicing-Architecture-v06.00 [14].
RAN NSSMF also manages disaggregated RAN deployment use cases where Network Functions (such as O-DU and O-CU) are deployed in different O-Clouds or in different locations in each O-Cloud. RAN NSSMF manages creation of O-NSSI and relevant Network Functions (NFs) across multiple O-Clouds. RAN NSSMF triggers the Network Functions management operation via NFO. RAN NSSMF also coordinates with the constituent Transport NSSMF to achieve the slice connectivity across multiple O-Clouds.
Network Slice Creation Use Case
3.10.1.1 High Level Description
This use case supports creation of RAN slice subnet.
RAN NSSMF coordinates with its constituent Transport NSSMF through NSMF to stitch the connectivity across multiple O-Clouds or multiple sites in a distributed O-Cloud (for disaggregated RAN deployments). In such deployments, the network connectivity for the slice may require multiple network connections, herein referred to as network segments. For example, a slice spanning across two O-Clouds connected by transport may have up to 5 network segments. Two network segments within each O-Cloud, two segments between the O-Clouds and their respective Transport attachment points and a fifth network segment in the transport network.
In multi-vendor O-RAN deployments, many flavors of NFs may co-exist. Some may require trunked interfaces whereas others may require access interfaces. Similarly, multiple forms for NFs may exist such as CNFs, VNFs, or PNFs.
The End-2-End slice must be associated with a network segment unique identifier per network segment, here in called a tag. While a choice of various viable identifiers (such as VLANs, VNIs, VRFs, etc.) is available, in this Use Case a VLAN ID is one of the example identifier/tags for network slicing. In that case, VLAN IDs are chosen for both within O-Cloud as well as for handover to the transport network.
NOTE: The use case further elaborates on the scenario of using VLAN IDs, but other network segmentation solutions are also possible.
The packets marked with this unique tag/VLAN ID traverse the network segments within O-Cloud and are of local significance within a given network segment. This tag/VLAN ID may be stitched/mapped to a different tag by the O-Cloud Gateway to handover to the transport network attachment point. As an example, say VLAN ID 100 was chosen to mark an EMBB slice. This VLAN ID 100 may map to a VRF_X at O-Cloud Gateway and a VLAN ID 200 may be used to carry the same packets in the transport network. This mapping allows the transport network to carry the packets associated with each slice.
Depending upon the slice SLAs and deployment scenario of a slice, RAN NSSMF makes the decisions such as:
If additional NF instances need to be deployed (e.g., one O-DU instance per slice), or
Use the existing NF for the new slice (e.g., shared resources for a slice)
RAN NSSMF/SMO makes an NF placement decision taking all relevant information into account.
Etc.
Note: The actual details of such decisions by RAN NSSMF are out of the scope for this use case. See O-RAN.WG1.Slicing-Architecture-v06.00 for details.
Sequence Description
UML sequence diagram
Figure 3-45: Network Slice Creation
Network Slice Deletion Use Case
High Level Description
This use case supports the deletion of the network slice.
When RAN NSSMF deletes a slice subnet, the Network Function instances associated with the slice may need to be terminated as well. Depending upon the deployment scenario (e.g., shared network functions vs. non shared), RAN NSSMF makes decision if NF needs to be terminated or not.  RAN NSSMF sends request to NFO to terminate appropriate NFs.
A VLAN ID associated with the slice is deallocated (both at O-Cloud Site Network Fabric as well as O-Cloud Node Cluster Network level) so that O-Cloud could reuse the VLAN ID for further use.
Sequence Description
UML sequence diagram
Figure 3-46: Network Slice Deletion
Provisioning Use Cases
Network Resource Provisioning for Underlay Network Use Case
High level description
This use case describes the procedure for SMO to provision network resource for the Underlay Network (infrastructure-level network) enabling O-Cloud Nodes to communicate with each other and with the O-Cloud Gateway connected to networks outside of the O-Cloud site. This procedure can be invoked independently to the existing O-Cloud Basic Use Case specified in clause 3.1.
Sequence description
UML sequence diagram
Figure 3-47: Network Resource Provisioning for Underlay Network
Create Kubernetes (K8s) Cluster Use Case
High level description
This use case describes the processing of a request to create a single Kubernetes (K8s) Cluster from the FOCOM towards the IMS at the O-Cloud. The use case aims to assign a suitable set of computer systems, storage resources and network connectivity as a basis for a K8s Cluster, to establish a K8s Cluster in the O-Cloud and to inform the requesting entity what has been created. Before this use case is started it is expected that SMO has concluded that a new K8s Cluster shall be created in a specific O-Cloud. When the use case is concluded, any modified O-Cloud (exposed) Resources are updated in the O-Cloud Inventory model.
Note: A Kubernetes (K8s) cluster is a type of container infrastructure cluster.
Sequence description
UML sequence diagram
Figure 3-48: Create Kubernetes (K8s) Cluster
Delete Kubernetes (K8s) Cluster Use Case
High Level Description
This use case describes the processing of a request to delete a single Kubernetes (K8s) Cluster from the FOCOM towards the IMS at the O-Cloud. The objective of the operation is to delete a previously created Kubernetes Cluster. This is part of a family of O2 IMS Provisioning operations related to Kubernetes Clusters.
When the use case is concluded, the specified cluster in the O-Cloud should be deleted. Typically, the associated (exposed) O-Cloud Resources are released and updated in the O-Cloud Inventory model. Depending on implementation the O-Cloud Resources may not immediately be released.
Sequence Description
UML Sequence Diagram
Figure 3-49: Delete Kubernetes (K8s) Cluster
Orchestration Requirements
The following section contains requirements on the O-Cloud, SMO, O1 and O2 based on the Orchestration Use Cases above.
General Requirements
Orchestration Requirements Relating to O1
Defines requirements for O-RAN managed function IM elements and FM/PM elements needed for orchestration using the O1 interface.
NOTE:	These requirements may overlap with those in [5] and may be moved to [5] in future.
Orchestration Requirements Relating to O2
Annex A (Informative): Terminology Used in O-Cloud Requirements
The following terms and definitions are used in the O-Cloud requirements.
History