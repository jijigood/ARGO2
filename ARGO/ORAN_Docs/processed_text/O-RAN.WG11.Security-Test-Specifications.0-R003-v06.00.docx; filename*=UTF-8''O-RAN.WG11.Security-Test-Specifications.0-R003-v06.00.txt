O-RAN.WG11.SecTestSpecs.0-R003-v06.00

   O-RAN.WG11.SecTestSpecs.0-R003-v06.00

Technical Specification

O-RAN Work Group 11 (Security Work Group)

O-RAN Security Test Specifications

Copyright © 2024 by the O-RAN ALLIANCE e.V.

The copying or incorporation into any other work of part or all of the material available in this specification in any form without the prior written permission of O-RAN ALLIANCE e.V.  is prohibited, save that you may print or download extracts of the material of this specification for your personal use, or copy the material of this specification for the purpose of sending to individual third parties for their information provided that you acknowledge O-RAN ALLIANCE as the source of the material and that you inform the third party that these conditions apply to them and that they must comply with them.

O-RAN ALLIANCE e.V., Buschkauler Weg 27, 53347 Alfter, Germany

Register of Associations, Bonn VR 11238, VAT ID DE321720189

Contents

List of figures	8

List of tables	8

Foreword	9

Modal verbs terminology	9

1 Scope	10

2 References	11

2.1 Normative references	11

2.2 Informative references	12

3 Definition of terms, symbols and abbreviations	13

3.1 Terms	13

3.2 Abbreviations	13

4 Objectives and scope	16

5 Testing methodology and configuration	17

5.1 DUT / SUT	17

5.2 Test Setup	18

5.3 Test and measurement equipment and tools	18

5.4 Test report	20

5.5 Assumptions	20

5.6 Testing tools	20

6 Security Protocol & APIs Validation	23

6.1 Overview	23

6.2 STC-6-001: SSH Server & Client	23

6.2.1 Test description and applicability	23

6.2.2 Test setup and configuration	23

6.2.3 Test procedure	24

6.2.4 Expected results	24

6.3 STC-6-002: TLS	24

6.3.1 Test description and applicability	24

6.3.2 Test setup and configuration	25

6.3.3 Test procedure	25

6.3.4 Expected results	26

6.4 STC-6-003: DTLS	26

6.4.1 Test description and applicability	26

6.4.2 Test setup and configuration	26

6.4.3 Test procedure	27

6.4.4 Expected results	27

6.5 IPSec	27

6.5.1 STC-6-004-01: IPSec security	27

6.5.2 STC-6-004-02: IKE Header Flags Fuzzing	29

6.5.3 STC-6-004-03: IKE Key Exchange Payload Fuzzing	30

6.5.4 STC-6-004-04: IKE Malformed Certificate Payload	31

6.6 STC-6-005: OAuth 2.0	33

6.6.1 Test description and applicability	33

6.6.2 Test setup and configuration	33

6.6.3 Test procedure	34

6.6.4 Expected results	35

6.7 NACM	36

6.7.1 STC-6-006-01: NACM RBAC Configuration	36

6.7.2 STC-6-006-02: NACM Logging Monitoring	37

6.7.3 STC-6-006-03: NACM Hardening Configuration	39

6.8 802.1x	40

6.8.1 STC-6-007-01: 802.1X Cryptographic Algorithms Key Strength	40

6.9 X.509	42

6.9.1 STC-6-009-01: X.509 Certificate Structure Verification	42

6.9.2 STC-6-009-02: X.509 Certificate Validity Period Verification	43

6.9.3 STC-6-009-03: X.509 Certificate Key Usage Verification	44

6.9.4 STC-6-009-04: X.509 Certificate Chain Validation	45

6.10 eCPRI	46

6.10.1 STC-6-010-01: eCPRI Session Management	46

6.10.2 STC-6-010-02: eCPRI Input Validation	47

6.10.3 STC-6-010-03: eCPRI Error Handling	48

6.10.4 STC-6-010-04: eCPRI Access Control	49

6.10.5 STC-6-010-05: eCPRI Logging and Auditing	50

6.10.6 STC-6-010-06: eCPRI Timeout Error Handling	51

6.11 SCTP	52

6.11.1 STC-6-011-01: SCTP Association Establishment	52

6.11.2 STC-6-011-02: SCTP Data Transfer	53

6.11.3 STC-6-011-03: SCTP Association Termination	54

6.11.4 STC-6-011-04: SCTP Authentication	55

6.11.5 STC-6-011-05: SCTP DoS Prevention Rate Limiting	56

6.11.6 STC-6-011-06: SCTP Input Validation	57

6.11.7 STC-6-011-07: SCTP Authorization	58

6.11.8 STC-6-011-08: SCTP Data Exposure	59

6.12 RESTful	60

6.12.1 STC-6-012-01: REST API Authentication	60

6.12.2 STC-6-012-02: REST Authorization and Access Control	62

6.12.3 STC-6-012-03: REST Input Validation and Sanitization	63

6.12.4 STC-6-012-04: REST Security Logging and Monitoring	64

7 Common Network Security Tests for O-RAN components	66

7.1 Overview	66

7.2 Network Protocol and Service Enumeration	66

7.2.1 STC-7-7.2-001: Network Protocol and Service Enumeration	66

7.3 Password-Based Authentication	68

7.3.1 STC-7-7.3-001: Password guessing	68

7.3.2 STC-7-7.3-002: Unauthorized Password Reset	70

7.3.3 STC-7-7.3-003: Password Policy Enforcement	71

7.4 Network Protocol Fuzzing	72

7.5 Denial of Service/Message Flooding	74

7.5.1 STC-7-7.5-001: Protocol, Application and Volumetric Based DDoS Attacks	74

7.5.2 STC-7-7.5-002: O-CU DoS protection and recovery	75

7.5.3 STC-7-7.5-003: O-DU DoS protection and recovery	76

7.5.4 STC-7-7.5-004: O-RU DoS protection and recovery	77

7.5.5 STC-7-7.5-005: Near-RT RIC DoS protection and recovery	78

7.6 Input validation and error handling	79

7.6.1 STC-7-7.6-001: O-CU input validation and error handling	79

7.6.2 STC-7-7.6-002: O-DU input validation and error handling	80

7.6.3 STC-7-7.6-003: Near-RT RIC input validation and error handling	82

7.7 Secure configuration verification	83

7.7.1 STC-7-7.7-001: O-CU secure configuration verification	84

7.7.2 STC-7-7.7-002: O-DU secure configuration verification	85

7.7.3 STC-7-7.7-003: O-RU secure configuration verification	86

7.7.4 STC-7-7.7-004: Near-RT RIC secure configuration verification	87

7.8 Logging and monitoring	88

7.8.1 STC-7-7.8-001: O-CU logging and monitoring	88

7.8.2 STC-7-7.8-002: O-DU logging and monitoring	89

7.8.3 STC-7-7.8-003: O-RU logging and monitoring	91

7.8.4 STC-7-7.8-004: Near-RT RIC logging and monitoring	92

8 System security evaluation for O-RAN component	93

8.1 Overview	93

8.2 System Vulnerability Scanning	93

8.2.1 STC-8-8.2-001: System Vulnerability Scanning	93

8.3 Data and Information Protection	94

8.4 System logging	94

8.4.1 Introduction	94

8.4.2 STC-8-8.4-001: Security log format and related log fields	94

8.4.3 STC-8-8.4-002: Authenticated Time Stamping	96

8.4.4 STC-8-8.4-003: Network Security and System Security Events	97

8.4.5 STC-8-8.4-004: Application Security Events	100

8.4.6 STC-8-8.4-005: Data Access Security Events	100

8.4.7 STC-8-8.4-006: Account and Identity Security Events	103

8.4.8 STC-8-8.4-007: General Security Events	105

8.4.9 STC-8-8.4-008: Storage	106

9 Software security evaluation for O-RAN components	108

9.1 Overview	108

9.2 Open-Source Software Component Analysis	108

9.3 Binary Static Analysis	108

9.4 Software Bill of Materials (SBOM)	109

9.4.1 STC-9-9.4-001: SBOM Signature	109

9.4.2 STC-9-9.4-002: SBOM Data Fields	110

9.4.3  STC-9-9.4-003: SBOM Format	112

9.4.4  STC-9-9.4-004: SBOM Depth	113

9.4.5 STC-9-9.4-005: SBOM completeness check	114

9.4.6 STC-9-9.4-006: SBOM version verification	115

9.4.7 STC-9-9.4-007: SBOM vulnerability cross check	115

9.4.8 STC-9-9.4-008: SBOM Delivery	116

9.4.9 STC-9-9.4-009 SBOM Vulnerabilities Field	117

9.4.10 STC-9-9.4-010: SBOM OSC Components	118

9.5 Software Image Signing and Verification	119

9.5.1 STC-9-9.5-001: Software Image/Application Package Signing	119

9.5.2 STC-9-9.5-002: Software Signature Verification	120

10 ML security validation for O-RAN system	121

10.1 Overview	121

10.2 ML Data Poisoning	121

11 Security tests of O-RAN interfaces	121

11.1 FH	121

11.1.1 Overview	121

11.1.2 Open Fronthaul Point-to-Point LAN Segment	121

11.1.3 M-Plane	125

11.1.4 U-Plane	140

11.1.5 S-Plane	142

11.2 Y1	152

11.2.1 STC-11-11.2-001: Y1 Authenticity	152

11.2.2 Y1 Confidentiality, integrity, and replay	153

11.2.3 STC-11-11.2-005: Y1 Authorization	158

11.3 O1	160

11.3.1 STC-11-11.3-001: O1 Authenticity	160

11.3.2 O1 Confidentiality, integrity and replay	161

11.3.3 O1 Interface Network Configuration Access Control Model (NACM) Validation	166

11.4 O2	168

11.4.1 STC-11-11.4-001: O2 Authenticity	168

11.4.2 STC-11-11.4-002: O2 Confidentiality	169

11.4.3 STC-11-11.4-003: O2 Integrity	170

11.4.4 STC-11-11.4-004: O2 Replay	171

11.4.5 STC-11-11.4-005: O2 Authorization	172

11.5 E2	173

11.5.1 STC-11-11.5-001: E2 Confidentiality	173

11.5.2 STC-11-11.5-002: E2 Integrity	175

11.5.3 STC-11-11.5-003: E2 Replay	177

11.5.4 E2 Authenticity	179

12 Security test of O-RU	182

12.1 Overview	182

12.2 STC-12-12.2-001: SSH on M-Plane interface	182

12.2.1 Introduction	182

12.2.2 Test Description	182

12.2.3 Test setup and configuration	182

12.2.4 Test procedure	182

12.2.5 Expected results	182

12.3 STC-12-12.3-001: TLS on M-Plane interface	183

12.3.1 Introduction	183

12.3.2 Test Description	183

12.3.3 Test setup and configuration	183

12.3.4 Test procedure	183

12.3.5 Expected results	183

12.4 Security functional requirements and test cases	183

13 Security test of Near-RT RIC	184

13.1 Overview	184

13.2 Void	184

13.3 Transactional APIs	184

13.3.1 Introduction	184

13.3.2 STC-13-13.3-001: TLS for transactional APIs	184

13.3.3 STC-13-13.3-002: mTLS for transactional APIs	185

13.3.4 STC-13-13.3-003: OAuth 2.0 for transactional APIs	185

14 Security test of xApps	186

14.1 Overview	186

14.2 xApp Signing and Verification	186

15 Security test of Non-RT RIC	186

15.1 Overview	186

15.2 Non-RT RIC	187

15.2.1 STC-15-15.2-001: Non-RT RIC OAuth 2.0 Resource Owner/Server	187

15.2.2 STC-15-15.2-002: Non-RT RIC OAuth 2.0 Client	187

15.2.3 STC-15-15.2-003: Non-RT RIC Framework OAuth 2.0	188

15.3 R1 interface	189

15.3.1 STC-15-15.3-001: TLS on R1 Interface	189

15.3.2 STC-15-15.3-002: mTLS on R1 Interface	189

15.3.3 STC-15-15.3-003: OAuth 2.0 on R1 Interface	190

15.4 A1 interface	191

15.4.1 STC-15-15.4-001: TLS on A1 Interface	191

15.4.2 STC-15-15.4-002: mTLS on A1 Interface	191

15.4.3 STC-15-15.4-003: OAuth 2.0 on A1 interface	192

16 Security test of rApps	193

16.1 Overview	193

16.2 rApp Signing and Verification	193

16.3 rApp Authorization	193

16.3.1 STC-16-16.3-001: rApp OAuth 2.0 Client	193

17 Security test of SMO	194

17.1 Overview	194

17.2 Void	194

17.3 SMO	194

17.3.1 STC-17-17.3-001: SMO OAuth 2.0 Resource Owner/Server	194

17.3.2 STC-17-17.3-002: SMO OAuth 2.0 Client	195

17.3.3 STC-17-17.3-003: SMO mTLS for mutual authentication	196

17.4 SMO Internal Communications	196

17.4.1 STC-17-17.4-001: TLS for SMO Internal Communications	196

17.4.2 STC-17-17.4-002: mTLS for SMO Internal Communications – SMO Functions	197

17.5 SMO External Interfaces	198

17.5.1 STC-17-17.5-001: TLS for SMO External Interfaces	198

17.5.2 STC-17-17.5-002: mTLS for SMO External Interfaces	198

17.5.3 STC-17-17.5-003: SMO Framework OAuth 2.0 Resource Owner/Server for External Interface	199

17.5.4 STC-17-17.5-004: SMO Functions OAuth 2.0 Client	200

17.6 SMO Logging	200

17.6.1 STC-17-17.6-001: TLS for SMO Logging Export	200

17.6.2 STC-17-17.6-002: mTLS for SMO Logging Export	201

18 Security test of O-Cloud	202

18.1 Overview	202

18.2 Void	202

18.3 O-Cloud virtualization layer	202

18.3.1 STC-18-18.3-001: Secure authentication (positive case)	202

18.3.2 STC-18-18.3-002: Secure authentication (negative case)	203

18.3.3 STC-18-18.3-003: Secure authorization (positive case)	204

18.3.4 STC-18-18.3-004: Secure authorization (negative case)	205

18.3.5 STC-18-18.3-005: Validate network connections allowed by network policies	206

18.3.6 STC-18-18.3-006: Validate network connections not allowed by network policies	207

18.3.7 STC-18-18.3-007: Validate network connections from outside the allowed network ranges	207

18.3.8 STC-18-18.3-008: Exploitation of O-Cloud component vulnerabilities	208

18.3.9 STC-18-18.3-009: Identification and remediation of insecure configuration settings	209

18.3.10 STC-18-18.3-010: Validation of logging and monitoring for security incidents	210

18.3.11 STC-18-18.3-011: O-Cloud Privilege Escalation Prevention	211

18.4 Application instantiation by O-Cloud	212

18.4.1 STC-18-18.4-001: Verification of Application with valid signature by O-Cloud during Instantiation	212

18.4.2 STC-18-18.4-002: Verification of Application with incorrect signature by O-Cloud during Instantiation	213

18.5 Resource Management and enforcement in O-Cloud	214

18.5.1 STC-18-18.5-001: O-Cloud Resource Consumption Limit Enforcement	214

18.5.2 STC-18-18.5-002: O-Cloud Storage Volume Limit Enforcement	215

18.5.3 STC-18-18.5-003: O-Cloud CPU Overcommit Prevention	217

18.5.4 STC-18-18.5-004: O-Cloud Memory Overcommit Prevention	218

18.5.5 STC-18-18.5-005: O-Cloud Network Overcommit Prevention	219

18.5.6 STC-18-18.5-006: O-Cloud Storage Overcommit Prevention	220

18.6 Secure Update	222

18.6.1 STC-18-18.6-001: O-Cloud Infrastructure Software Package Integrity - Positive	222

18.6.2 STC-18-18.6-002: O-Cloud Infrastructure Software Package Integrity Failure– Negative	223

18.6.3 STC-18-18.6-003: Secure Update procedure for O-Cloud Platform -Positive	224

18.6.4 STC-18-18.6-004: Secure Update failure for O-Cloud Platform-Negative	225

19 Security test of VNF/CNF	227

19.1 Overview	227

19.2 STC-19-19.2-001: Executive environment protection	227

19.3 STC-19-19.3-001: Signature validation during App image onboarding	228

19.4 STC-19-19.4-001: Application image deployment security	229

20 Security tests of Common Application Lifecycle Management	230

20.1 Overview	230

20.2 Application package	231

20.2.1 STC-20-20.2-001: Application package signature verification	231

21 Security test of O-CU-CP	232

21.1 Overview	232

21.2 3GPP specific security functional requirements and test cases	232

21.3 O-RAN specific security functional requirements and test cases	232

22 Security test of O-CU-UP	232

22.1 Overview	232

22.2 3GPP specific security functional requirements and test cases	232

22.3 O-RAN specific security functional requirements and test cases	233

23 Security test of O-DU	233

23.1 Overview	233

23.2 3GPP specific security functional requirements and test cases	233

23.3 O-RAN specific security functional requirements and test cases	233

24 End-to-End security test cases	234

24.1 3GPP Security Assurance Specification (SCAS)	234

25 Security test of Shared O-RU	244

25.1 Overview	244

25.2 Shared O-RU test cases	244

25.2.1 STC-25-25.2-001: mTLS for mutual authentication	244

25.2.2 STC-25-25.2-002: NACM Authorization	245

25.2.3 STC-25-25.2-003: TLS across Open Fronthaul	246

25.2.4 STC-25-25.2-004: Reject Password-based authentication	247

	Annex A (informative): 	Example of Security Testing Tools / Toolset	248

	Annex B (informative): 	Template of test report	249

Revision history	252

Annex (informative): Change History	254

List of figures

	Figure 51: Logical Architecture of O-RAN system	17

	Figure 61: Access Token request	34

	Figure 62: Service request	35

List of tables

	Table 51 Test and measurement equipment list	20

	Table 91: Minimum set of data fields for SPDX [12]	110

	Table 92: Minimum set of data fields for CycloneDX [13]	111

	Table 93: Minimum set of data fields for SWID [13]	112

	Table 111: Scenarios to be executed	122

	Table 112: Expected results	123

	Table 113: Scenarios to be executed	124

	Table 114: Expected results	124

	Table 241: List of SCAS Test Cases for NR and applicable technology from Clause 4.2.2 of 3GPP TS 33.511	234

	Table 242: List of SCAS Test Cases for LTE and applicable technology from Clause 4.2.2 of 3GPP TS 33.216	239

	Table Annex A1 List of sample open source security testing tools/toolset	248

Foreword

This Technical Specification (TS) has been produced by O-RAN Alliance.

Modal verbs terminology

In the present document "shall", "shall not", "should", "should not", "may", "need not", "will", "will not", "can" and "cannot" are to be interpreted as described in clause 3.2 of the O-RAN Drafting Rules (Verbal forms for the expression of provisions).

"must" and "must not" are NOT allowed in O-RAN deliverables except when used in direct citation.

	Scope

The present document provides description of the Security Tests, which validate security functions and configurations per security and security protocols requirements and are based on the priority of the risk analysis for O-RAN systems.

	References

References are either specific (identified by date of publication and/or edition number or version number) or non-specific. For specific references, only the cited version applies. For non-specific references, the latest version of the referenced document (including any amendments) applies.

NOTE:	While any hyperlinks included in this clause were valid at the time of publication, O-RAN cannot guarantee their long-term validity.

	Normative references

References are either specific (identified by date of publication and/or edition number or version number) or nonspecific. For specific references, only the cited version applies. For non-specific references, the latest version of the referenced document (including any amendments) applies.

NOTE:	While any hyperlinks included in this clause were valid at the time of publication, O-RAN cannot guarantee their long term validity.

The following referenced documents are necessary for the application of the present document.

	O-RAN ALLIANCE TS: “O-RAN Architecture Description”

	O-RAN ALLIANCE TS: “O-RAN Security Protocols Specification”

	O-RAN ALLIANCE TS: “O-RAN Security Threat Modeling and Risk Assessment”

	O-RAN ALLIANCE TS: “O-RAN End-to-End Test Specification”

	O-RAN ALLIANCE TS: “O-RAN Security Requirements and Controls Specification”

	3GPP TR 21.905: “Vocabulary for 3GPP Specifications” (Release 16), December 2020

	3GPP TS 33.117: “Catalogue of General Security Assurance Requirements” (Release 16), December 2020

	3GPP TS 33.511: “Security Assurance Specification (SCAS) for the next generation Node B (gNodeB) network product class”

	3GPP TS 33.216: “Security Assurance Specification (SCAS) for the Evolved Node B (eNodeB) network product class”

	Openssh Security Vulnerabilities: https://www.cvedetails.com/vulnerability-list/vendor_id-97/product_id-585/Openbsd-Openssh.html

	"IEEE Standard for Local and Metropolitan Area Networks--Port-Based Network Access Control," in IEEE Std 802.1X-2020 (Revision of IEEE Std 802.1X-2010 Incorporating IEEE Std 802.1Xbx-2014 and IEEE Std 802.1Xck-2018), vol., no., pp.1-289, 28 Feb. 2020, doi: 10.1109/IEEESTD.2020.9018454

	Microsoft: “Generating Software Bills of Materials (SBOMs) with SPDX at Microsoft”, https://devblogs.microsoft.com/engineering-at-microsoft/generating-software-bills-of-materials-sboms-with-spdx-at-microsoft/, October 2021

	The United States Department of Commerce: “The Minimum Elements For a Software Bill of Materials (SBOM)”, July 2021

	Network Configuration Access Control Model, RFC 8341, https://tools.ietf.org/html/rfc8341

	O-RAN ALLIANCE TR: “O-RAN O-Cloud Security Analysis Report”

	O-RAN ALLIANCE TR: “O-RAN Near-RT RIC and xApp Security Analysis Report”

	O-RAN ALLIANCE TR: “O-RAN Non-RT RIC Security Analysis Report”

	RFC 6749: The OAuth 2.0 Authorization framework. https://datatracker.ietf.org/doc/html/rfc6749

	RFC 7519: JSON Web Token (JWT). https://datatracker.ietf.org/doc/html/rfc7519

	RFC 7515: JSON Web Signature (JWS). https://datatracker.ietf.org/doc/html/rfc7515

	O-RAN ALLIANCE TS: “O-RAN Fronthaul Working Group Management Plane Specification”

	O-RAN ALLIANCE TS: “O-RAN Use Cases Detailed Specification”

	3GPP TS 33.523: “5G Security Assurance Specification (SCAS); Split gNB product classes”

	O-RAN ALLIANCE TS: “O-RAN WG4 Management Plane Specification”

	3GPP TS 33.501: “Security architecture and procedures for 5G system”

 Informative references

References are either specific (identified by date of publication and/or edition number or version number) or nonspecific. For specific references, only the cited version applies. For non-specific references, the latest version of the referenced document (including any amendments) applies.

NOTE:	While any hyperlinks included in this clause were valid at the time of publication, ETSI cannot guarantee their long-term validity.

The following referenced documents are not necessary for the application of the present document, but they assist the user with regard to a particular subject area.

Service Name and Transport Protocol Port Number Registry. https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml

SPDX, https://spdx.dev/

CycloneDX, https://cyclonedx.org/

Guidelines for the Creation of Interoperable Software Identification (SWID) Tags, NISTIR 8060, David Waltermire et al., U.S. NIST, 2016, http://dx.doi.org/10.6028/NIST.IR.8060

	Definition of terms, symbols and abbreviations

	Terms

For the purposes of the present document, the terms and definitions given in 3GPP TR21.905 [6], O-RAN Architecture Description [1], and the following in this clause apply. A term defined in the present document takes precedence over the definition of the same term, if any, in 3GPP TR21.905 [6] and O-RAN Architecture Description [1].

A1: Interface between non-RT RIC and Near-RT RIC to enable policy-driven guidance of Near-RT RIC applications/functions, and support AI/ML workflow.

E2:  Interface connecting the Near-RT RIC and one or more O-CU-CPs, one or more O-CU-UPs, and one or more O-DUs.

RAN: Generally referred as Radio Access Network. In terms of this document, any component below Near-RT RIC per O-RAN architecture, including O-CU/O-DU/O-RU.

Overcommitting resources: It refers to the practice of allocating or promising more resources than are physically available on a system. This concept is commonly used in virtualized and cloud environments. The idea behind overcommitment is to optimize resource utilization based on the observation that not all applications will use their allocated resources to the maximum at the same time. Here's a breakdown of overcommitment for different resources:

CPU Overcommitment: More virtual CPUs (vCPUs) are allocated to VMs or Containers than there are physical CPU cores available on the host.

Memory Overcommitment: The total memory allocated to VMs or Containers exceeds the physical RAM available on the host.

Storage Overcommitment: More storage space is allocated to VMs or Containers than the actual available capacity on the storage device.

Network Overcommitment: More bandwidth is promised to VMs or Containers than the physical network can provide.

Overcommit ratios: It defines the extent to which resources can be overallocated compared to the actual available physical resources.

CPU Overcommit Ratio:

If you have a CPU overcommit ratio of 2:1, it means you can allocate twice the number of virtual CPUs (vCPUs) as there are physical CPU cores on the host. For instance, if a server has 8 physical CPU cores, you could allocate 16 vCPUs across various VMs or Containers.

Memory Overcommit Ratio:

If you have a memory overcommit ratio of 1.5:1, it means you can allocate 1.5 times the amount of virtual RAM as there is physical RAM on the host. For a server with 64GB of physical RAM, you could allocate a total of 96GB of RAM across various VMs or Containers.

	Abbreviations

For the purposes of the present document, the abbreviations given 3GPP TR21.905[6], O-RAN Architecture Description[1], and the following in this clause apply. A abbreviation defined in the present document takes precedence over the definition of the same abbreviation, if any, in 3GPP TR21.905[6] and O-RAN Architecture Description[1].

AI/ML	Artificial Intelligence / Machine Learning

CMS/PKCS#7/CAdES	Cryptographic Message Syntax/Public-Key Cryptography Standards/CMS Advanced Electronic Signatures

CNF	Cloud Native Function

CSI	Channel State Information

DTLS	Datagram Transport Layer Security

DUT	Device Under Test

eCPRI	Enhanced Common Public Radio Interface

FTP	File Transfer Protocol

FTPS	File Transfer Protocol Secure

gRPC	a cross-platform remote procedure call (RPC) framework

IPSEC	Internet Protocol Security

JSF	JSON Signature Format

JSON	JavaScript Object Notation

JWT	JSON Web Token

JWS	JSON Web Signature

KPI	Key Performance Indicator

mTLS	Mutual Trasport Layer Security

NACM	Network Configuration Access Control Model

NETCONF	Network Configuration Protocol

NTIA	National Telecommunications and Information Administration - United States Department of Commerce

OAuth	Open Authentication

PDCP	Packet Data Convergence Protocol

PNF	Physical Network Function

PTP	Precision Timing Protocol

RBAC	Role-based Access Control

REST	Representational state transfer

RDF	Resource Description Format

RIC	O-RAN RAN Intelligent Controller

SBOM	Software Bill of Materials

SDLC	Software Development Lifecycle

SSH	Secure Shell

SUT	System Under Test

TLS	Transport Layer Security

VNF	Virtualized Network Function

WAS	Web Application Security

XML	Extensible Markup Language

YAML	YAML Ain’t Markup Language

	Objectives and scope

This security test specification is focused on:

Validating the implementation of security requirements and security protocols specified in [5] and [2].

Emulating security attacks against the O-RAN component(s), interfaces, and the system to measure the robustness of the O-RAN system and the service impact(s).

Validating the effectiveness of the security mitigation method(s) to protect the O-RAN system and the services it offers.

This security test specification is based on the priority of the risk assessment of the O-RAN security threats and security requirements of the O-RAN system.

	Testing methodology and configuration

This chapter describes the common testing methods and configurations used in the subsequent chapters. To ensure fair and comparable test results among various test campaigns, consistent test setups shall be utilized. This security test specification describes the test conditions, methodologies, and procedures, so that the test can be reproduced if needed, and the test results can be used for comparison or reference purposes.

	DUT / SUT

Figure 51: Logical Architecture of O-RAN system

Figure 51 illustrates the O-RAN components, interfaces, and overall system.

As specified in [1], the following O-RAN components and interfaces shall be the DUT or SUT addressed in this security test specification.

O-RAN components:

Network functions and applications

Service Management and Orchestration (SMO)

Non-RT RIC and rApps

Near-RT RIC and xApps

O-CU-CP/UP

O-DU

O-RU

O-eNB

Cloud computing platform

O-Cloud comprising a collection of physical infrastructure nodes that meet O-RAN requirements to host the relevant O-RAN functions (such as Near-RT RIC, O-CU-CP, O-CU-UP, and O-DU), the supporting software components (such as Operating System, Virtual Machine Monitor, Container Runtime, etc.) and the appropriate management and orchestration functions.

Maintained interfaces by O-RAN:

A1 Interface between Non-RT RIC and Near-RT RIC to enable policy-driven guidance of Near-RT RIC applications/functions, and support AI/ML workflow.

O1 Interface connecting the SMO to the Near-RT RIC, one or more O-CU-CPs, one or more O-CU-UPs, and one or more O-DUs.

O2 Interface between the SMO and the O-Cloud

E2 Interface connecting the Near-RT RIC and one or more O-CU-CPs, one or more O-CU-UPs, one or more O-DUs, and one or more O-eNBs.

Open Fronthaul CUS-Plane Interface between O-RU and O-DU

Open Fronthaul M-Plane Interface between O-RU and O-DU as well as between O-RU and SMO

During the test execution, only one DUT or SUT shall be tested at the same time. The rest of elements involved in the test setup should be simulated or real, according to the test preconditions, but only the DUT or SUT shall be considered under evaluation.

	Test Setup

Please refer to the security test cases listed in the following chapters for their specific test setups.

	Test and measurement equipment and tools

 The following table lists test and measurement equipment required for the security tests in this document.

Test tool

Description

Commercial UE and/or UE emulator

A commercial UE or UE emulator shall be used to establish stateful end-to-end connection and to generate or receive data traffic.

The commercial UE used in this context as a test tool is typically a UE which is designed for commercial or testing applications with certain test and diagnostic functions enabled for test and measurements purposes. Such test and diagnostic functions should not affect the performance.

This commercial UE requires an (emulated) SIM card which is pre-provisioned with subscriber profiles. A UE emulator or multiple commercial UEs can be used in multi-UE test scenarios requiring multiple UEs sessions. The UE shall connect to the SUT either via RF cables or via an over the air (OTA) connection. In a lab environment, the UE shall be placed inside an RF shielded box/room to avoid interference from external signals.

A logging tool connected to the UE shall be used to capture measurements and KPI logs for test validation and reporting.

4G/5G Core or Core emulator

A 4G/5G core or core emulator shall be used to terminate 4G/5G NAS sessions, and to support core network procedures required for RAN (SUT) testing. 4G/5G core or core emulator shall support end-to-end connection and data transfer between Application server and commercial UE/UE emulator.

Application (traffic) server

An application (traffic) server shall be used as an endpoint for generation and/or termination of data traffic streams to/from commercial UE(s)/UE emulator. The application server shall be capable of generating data traffic for the services under test.

Network impairment emulator

A network impairment emulator shall be used for tests which require insertion of impairment (packet delay and/or jitter) at the network interface (e.g. OpenFH).

Packet generation tool / DoS emulator

A packet generation tool / Denial of Service (DoS) emulator shall be used for DoS traffic generation of security tests. The tool shall support crafting network traffic over the following network protocols: Ethernet, IP, UDP, TCP, PTP, eCPRI, TLS, HTTP/HTTPS.

Packet capture tool

A packet capture tool shall be used to capture samples of data traffic for validation, analysis, and troubleshooting. It may be used to capture samples of legitimate traffic, which then may be used as templates for fuzzing attacks. The tool shall support capturing network traffic over the following network protocols: Ethernet, IP, UDP, TCP, PTP, eCPRI, TLS, QUIC, HTTP/HTTPS.

Network tap

A network tap shall be a hardware or software device which provides access and visibility to the data flowing across a computer network.

Port scanner

A protocol scanner shall be used for probing network protocols and services. It shall be able to detect open ports. It shall be able to detect what service is exposed as active on the open port.

Port scanners commonly come with built-in database of services. Service detection can use numerous built-in probes for querying various services. In practice, port scanners are often used for service detection.

Fuzzing tool

A protocol fuzzing tool shall be used for unexpected protocol input generation of security tests. The tool shall support mutating and replaying of captured network traffic over the following network protocols: Ethernet, IP, UDP, TCP, PTP, eCPRI, TLS, HTTP/HTTPS.

Vulnerability scanning tool

A vulnerability scanning tool shall be used for blind exploitation of well-known vulnerabilities during security tests. The tool may rely on cyclically updated database of known vulnerabilities based on Common Vulnerabilities and Exposures (CVE) and should support scanning network services running on TCP/IP stack of protocols.

NFV benchmarking and resource exhaustion tool

A Network Function Virtualization (NFV) tool shall be used for O-Cloud system performance measurement and resource exhaustion type of DoS attack generation. This tool shall be capable of supporting any types of O-Cloud environment (public or private) with testing VNF(s) and/or CNF(s).

SSH audit tool

An SSH audit tool shall be used to verify the following properties: version of protocol, cipher suites, and known vulnerabilities in server and client SSH software.

TLS scanning tool

A TLS scanning tool shall be used to verify the following properties: version of protocol, cipher suites, and known vulnerabilities in server TLS software.

DTLS scanning tool

A DTLS scanning tool shall be used to verify the following properties: version of protocol, cipher suites, and known vulnerabilities in server DTLS software.

IKE scanning tool

An IKE scanning tool shall be used to verify the following properties: version of protocol, cipher suites, and known vulnerabilities in server IPsec software.

Software image signing tool

A Software image signing tool shall be used to digitally sign and verify the software image, e.g. xApps or O-RAN component delivered by a software producer/provider.

Table 51 Test and measurement equipment list

	Test report

Tests should be described in the test report with sufficient detail to allow the tests to be reproducible by different parties and to enable comparison. A template for a complete test report is found in Annex B and may be used. Photos and screenshots should also be taken as part of the test report to illustrate the test environment. Additional parameters are specified in the description of each test in the subsequent chapters.

	Assumptions

void

 Testing tools

The tools outlined in this chapter represent a selection of commonly used resources for testing processes. It's important to emphasize that this list is not exhaustive. Testers are encouraged to use additional tools as needed for comprehensive and effective testing, ensuring they meet the standards and requirements set forth in this test plan.

Packet capture and traffic analysis tools:

Wireshark: Wireshark is a widely used open-source network protocol analyser that can capture and analyse network traffic. It enables you to inspect packets for confidentiality, integrity, and replay-related issues. You can also verify authentication mechanisms and analyse access control measures.

tcpdump: tcpdump is a command-line packet analyser available on various operating systems. It captures network traffic and can save it to a file for later analysis. tcpdump offers powerful filtering capabilities to capture specific traffic based on criteria such as source/destination IP addresses, protocols, or ports.

Netscout Sniffer: Netscout Sniffer is a commercial network analysis tool that offers real-time packet capture and analysis capabilities. It provides comprehensive visibility into network traffic and offers advanced features for troubleshooting and performance analysis.

Colasoft Capsa: Colasoft Capsa is a network analyser designed for network monitoring and troubleshooting. It captures and analyses network traffic, providing insights into protocols, applications, and potential secusrity issues. Capsa offers both real-time and post-capture analysis.

Tcpreplay: Tcpreplay is an open-source tool used for replaying captured network traffic. It allows you to replay network packets from a previously captured pcap file, simulating real-world traffic scenarios. While its primary purpose is not security testing, tcpreplay can be utilized as a tool in security testing efforts, particularly for testing the replay and handling of network packets.

Traffic Generation Tools:

Scapy: Scapy is a powerful Python-based tool that can create, manipulate, and send custom network packets. It allows to generate and replay packets on an interface to test for replay vulnerabilities.

Hping: Hping is a command-line tool that can send custom packets and perform various network-related activities. It can be used to generate replayed packets on an interface for testing purposes.

Scripting and Automation Tools to develop custom test scripts:

Python: Python scripting language provides libraries (e.g., socket, scapy) that allow you to write custom scripts to generate and replay packets on an interface.

Bash scripting: Bash scripting can be utilized to automate the process of capturing packets and replaying them on an interface.

Network Emulation Tools:

GNS3: GNS3 is a network emulation tool that allows you to simulate complex network topologies. It can be used to create a virtual environment with RAN E1 interfaces, generate traffic, and simulate replay attacks for testing purposes.

Network performance tools:

iperf3: iPerf3 is an open-source tool for network performance testing and measurement. While it is primarily focused on network performance evaluation, it can also be utilized as a tool to indirectly assess certain aspects of security, such as bandwidth availability and network congestion.

Traffic Manipulation Tools:

Burp Suite: Burp Suite is a web application security testing tool that can intercept, modify, and replay network traffic. While it is primarily designed for web applications, it allows to test the integrity, confidentiality, and authenticity of data transmitted over an interface.

Vulnerability assessment tools

Nessus: Nessus is a popular vulnerability assessment tool that can scan an interface for known security vulnerabilities and misconfigurations. It can help identify potential weaknesses related to confidentiality, integrity, replay attacks, and access control.

OpenVAS: OpenVAS (Open Vulnerability Assessment System) is an open-source vulnerability scanner that can perform security audits on security protocols implementations. It can detect vulnerabilities, misconfigurations, and compliance issues, helping ensure that an interface adheres to security best practices and standards.

Security Information and Event Management (SIEM) Tools:

SIEM tools like Splunk or ELK (Elasticsearch, Logstash, Kibana) can help collect and analyse security events and logs related to the O-RAN components and interfaces. They can assist in identifying potential security incidents, monitoring access control, and detecting anomalies.

IPsec tool

OpenSwan is an open-source implementation of the IPsec (Internet Protocol Security) protocols suite. It provides tools and libraries for setting up and managing IPsec connections, which can be used to test the confidentiality, integrity, replay, authenticity, and access control of an interface. Here's how OpenSwan can be used for testing:

Confidentiality and Integrity:

OpenSwan allows to configure IPsec tunnels with encryption algorithms (e.g., AES) and integrity algorithms (e.g., HMAC-SHA256). By setting up IPsec connections using OpenSwan, it is possible to verify the confidentiality and integrity of data transmitted over an interface.

Replay Attack:

OpenSwan supports anti-replay mechanisms, which protect against replay attacks by assigning sequence numbers to IPsec packets. These mechanisms can be tested to ensure that replayed packets are detected and rejected.

Authenticity:

OpenSwan supports authentication mechanisms such as pre-shared keys or digital certificates, which ensure the authenticity of IPsec connections. Testing can be performed to verify the proper authentication of an interface.

Access Control:

OpenSwan allows to configure IPsec security policies, including source/destination IP address filtering, protocol filtering, and port filtering. These policies can be tested to ensure that only authorized traffic is allowed through an interface.

StrongSwan: Another open-source IPsec-based VPN solution that includes testing capabilities. It allows you to configure and simulate IPsec connections, test authentication methods, and perform security checks.

Cryptographic operations testing tools

Hashing Tools: Hashing tools such as sha256sum, can be used to calculate hash values of transmitted data. By comparing the computed hash values at the source and destination, you can verify the integrity of the data.

Cryptographic Libraries: Cryptographic libraries, such as Bouncy Castle, provide APIs and tools for implementing and testing integrity protection mechanisms. These libraries offer functions to generate integrity checks (e.g., MAC) and validate the integrity of received data.

	Security Protocol & APIs Validation

	Overview

This chapter contains test cases to validate implementation of security protocols against O-RAN security requirements in [2] and [5].

	STC-6-001: SSH Server & Client

Test Name: SSH_Server_and_Client_Protocol

Requirement Name: Network Security Protocol - SSH

Requirement Reference:  Clause 4.1, O-RAN Security Protocols and Controls Specification [2]

Requirement Description: Robust protocol implementation with adequately strong cipher suites is being required for SSH

Threat References: T-O-RAN-05

DUT/s: O-DU, O-RU

	Test description and applicability

Purpose: To verify implementation of the secure communication protocol SSH as specified in [2].

The following properties shall be validated on both: server and client side:

Supported version of SSH protocol (v2)

Robustness of cryptographic algorithms used for/as:

Host key algorithms (also known as public key signature algorithms)

Symmetric algorithms for encrypting data (also known as symmetric ciphers)

Key exchange algorithms

Message authentication codes (MACs)

Lack of existence of well-known vulnerabilities in leveraged SSH client and server-side implementations (e.g. OpenSSH) according to Common Vulnerabilities and Exposures (CVE) listed at [10].

	Test setup and configuration

This test shall be executed against both server and client endpoints of communication.

Test prerequisites:

 SSH audit tool with capabilities as defined in Chapter 5.3

Network access to SSH server services from tester’s PC (Used for server-side testing)

OS level (shell) access to hosts acting as SSH clients (Used for client-side testing)

	Test procedure

Server-side testing:

Run SSH audit tool in server audit mode against each SSH server service from tester’s PC

Compare the tool’s output with the list of approved SSH protocols and algorithms (for host key, symmetric encryption, key exchange, and MACs) as defined by Security Protocols Specifications

Review the tool’s output for reported vulnerabilities.

Client-side testing:

Run SSH audit tool on each SSH clients in client audit mode

Compare the tool’s output with the list of approved SSH protocols and algorithms (for host key, symmetric encryption, key exchange, and MACs) as defined by Security Protocols Specifications

Review the tool’s output for reported vulnerabilities.

	Expected results

SSH version (v2) support with no older versions enabled.

All supported SSH algorithms (for host key, symmetric encryption, key exchange, and MACs) are explicitly allowed by [2].

No well-known SSH vulnerabilities found.

Expected format of evidence: Log files, traffic captures and/or screenshots

	STC-6-002: TLS

Test Name: TLS_Protocol

Requirement Name: Network Security Protocol - TLS

Requirement Reference: Clause 4.2, O-RAN Security Protocols and Controls Specification [2]

Requirement Description: Support TLS v1.2 and/or TLS v1.3 with protocol profiles

Threat References: T-O-RAN-05, T-SMO-01

DUT/s: SMO, Non-RT RIC, Near-RT RIC, O-CU-CP, O-CU-UP, O-DU, O-RU, O-Cloud

	Test description and applicability

Purpose: To verify implementation of the secure communication protocol TLS as specified in [2].

The following properties shall be validated for the TLS service on O-RAN component(s):

Supported version of TLS v1.2 or TLS v1.3

Support of mutual authentication

TLS protocol profiles required and/or recommended in Clause 4.2.2 of [2]

Lack of existence of TLS well-known vulnerabilities in TLS implementations (e.g. OpenSSL) according to Common Vulnerabilities and Exposures (CVE) listed [10]

	Test setup and configuration

This test shall be executed against O-RAN component with TLS service enabled as the DUT.

Test prerequisites:

TLS scanning tool with client certificate(s) installed;

DUT with CA cert signing the client certificate(s)

Network access to DUT

	Test procedure

Protocol scanning

Run TLS scanning tool against DUT for detection of:

TLS version

Cipher suites

Elliptic curves

Certificate type

Diffie-Hellman groups

Compression methods

TLS vulnerability scan (i.e. compression, CCS injection, Heartbleed, ROBOT, …) Compare the test result/report with the list of approved TLS versions and profiles as defined by Security Protocols Specification

Review the test result/report for vulnerabilities

Mutual Authentication

Run TLS scanning tool with TLS v1.2 and valid client certificate against DUT with mutual authentication enabled to verify the establishment of the TLS session after successful authentication

Run TLS scanning tool with TLS v1.2 and invalid client certificate (including but not limited to expired certificate, missing field certificate, untrusted CA signed certificate, …) against DUT with mutual authentication enabled to verify the failed attempt of the TLS session establishment due to certificate validation

Run TLS scanning tool with TLS v1.3 and valid client certificate against DUT with mutual authentication enabled to verify the establishment of the TLS session after successful authentication

Run TLS scanning tool with TLS v1.3 and invalid client certificate (including but not limited to expired certificate, missing field certificate, untrusted CA signed certificate, …) against DUT with mutual authentication enabled to verify the failed attempt of the TLS session establishment due to certificate validation

	Expected results

TLS versions (1.2 and 1.3) support with no older version(s) enabled.

TLS protocol profiles support without default cryptographically insecure ciphers support

No well-known TLS vulnerabilities found

Mutual authentication support for TLS versions (1.2 and 1.3)

Expected format of evidence: Log files, traffic captures and/or screenshots

	STC-6-003: DTLS

Test Name: DTLS_Protocol

Requirement Name: Network Security Protocol - DTLS

Requirement Reference: Clause 4.4, O-RAN Security Protocols and Controls Specification [2]

Requirement Description: Support DTLS v1.2

Threat References: T-O-RAN-01

DUT/s: Near-RT RIC, O-CU-CP, O-CU-UP, O-DU

	Test description and applicability

Purpose: To verify implementation of the secure communication protocol DTLS as specified in [2].

The following properties shall be validated for the DTLS service on O-RAN component(s):

Supported version of DTLS v1.2

DTLS protocol profiles specs listed in Clause 4.4.2 of [2]

Lack of existence of TLS well-known vulnerability

	Test setup and configuration

This test shall be executed against O-RAN component with DTLS service enabled as the DUT.

Test prerequisites:

DTLS scanning tool

Network access to DUT

	Test procedure

Run DTLS scanning tool against DUT for detection of:

DTLS version

Cipher suites

Elliptic curves

Certificate type

Diffie-Hellman groups

Compression methods

DTLS vulnerability scan (i.e. compression, CCS injection, Heartbleed, ROBOT, …) Compare the test result/report with the list of approved DTLS versions and profiles as defined by Security Protocols Specifications

Review the test result/report for vulnerabilities.

	Expected results

DTLS version (1.2) support with no older version(s) enabled.

DTLS protocol profiles support without default cryptographically insecure ciphers support

No well-known DTLS vulnerabilities found.

Expected format of evidence: Log files, traffic captures and/or screenshots.

	IPSec

This clause introduces a series of tests centered around ensuring the security and stability of communication within an O-RAN network using the IKEv2 server and IPSec security protocols. These tests, spanning from evaluating secure communication implementations to meticulously probing for potential vulnerabilities in handling certificates and key exchanges, serve to affirm the robustness of the IKEv2 server.

STC-6-004-01: IPSec security

Test Name: TC_IPSec_Security

Requirement Name: Network Security Protocol - IPSec

Requirement Reference: Clause 4.5, O-RAN Security Protocols Specification [2], ‘REQ-SEC-E2-1’ clause 5.2.4.1 in O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: Support IPSec tunnel mode with confidentiality, integrity, authentication, and anti-replay protection.

Threat References: T-O-RAN-01 clause 7.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: Near-RT RIC, O-CU-CP, O-CU-UP, O-DU

Test description and applicability

Purpose: To verify implementation of the secure communication protocol IPsec.

The following properties shall be validated for the IPsec service on O-RAN component(s):

ESP in tunnel mode

Supported version of IKE v2

IPsec capabilities listed in Clause 4.5.1.1 of [2]

Test setup and configuration

This test shall be executed against O-RAN component with IPsec service enabled as the DUT.

Test prerequisites:

IKE scanning tool

Network access to DUT

Test procedure

Run IKE scanning tool against DUT for detection of:

ESP Encryption Transforms

ESP Authentication Transforms

Diffie-Hellman groups

Certificate type

Review the test result/report for vulnerabilities

Expected results

IKE version (v2) support with no older version(s) enabled.

Supported ESP Encryption Transforms shall include:

ENCR_NULL

ENCR_AES_CBC

ENCR_AES_GCM_16

Supported ESP Authentication Transforms shall include:

AUTH_AES_128_GMAC

AUTH_HMAC_SHA2_256_128

Supported Diffie-Hellman groups shall include:

DH group 19 (256-bit ECP group)

If certificates are used, their format shall be X.509v3

Expected format of evidence:

The following evidence, in one or more formats as applicable, should be provided:

.pcap files capturing the IKE negotiations between the tool and the DUT.

Server logs from the DUT detailing the handling of IKE negotiations.

Report or output from the IKE scanning tool, specifically highlighting:

Detected ESP Encryption Transforms.

Detected ESP Authentication Transforms.

Detected Diffie-Hellman groups.

Detected Certificate type.

Screenshots from the IKE scanning tool showing scan results, especially the supported IKE version and any vulnerabilities detected.

If certificates are used, a sample or screenshot verifying the X.509v3 format.

STC-6-004-02: IKE Header Flags Fuzzing

Requirement Name: Network Security Protocol - IPSec

Requirement Reference & Description: O-RAN Security Protocols Specification clause 4.5  [2], ‘REQ-SEC-E2-1’ clause 5.2.4.1 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-01’ clause 7.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: Near-RT RIC, O-CU-CP, O-CU-UP, O-DU

Test Name: TC_IKE_HEADER_FLAGS_FUZZING

Test Description and Applicability

Purpose: The purpose of this test is to verify the robustness of the IKEv2 server when faced with malformed IKE headers. Flags within the IKE header are intended to provide specific instructions or information about the message. By fuzzing these flags, we can identify potential vulnerabilities or flaws in the server's processing logic.

Test Setup and Configuration

A controlled environment with an IKEv2 server and a test client.

Packet capture tool (e.g., Wireshark) for monitoring the traffic.

Fuzzing tool or script to generate malformed IKE header flags.

Test Procedure

Begin by starting the packet capture tool to record the test session.

Use the fuzzing tool or script to generate IKEv2 messages with the following malformed flags in the IKE header:

Initiator flag: Flip this flag to see if the server can identify a message that shouldn't be from an initiator.

Version flag: Introduce an unsupported version.

Response flag: Send messages that have this flag inappropriately set.

Combination of multiple flags: Mix flags to generate completely unexpected combinations.

Send each of these malformed messages to the IKEv2 server individually, waiting for a response before sending the next.

Observe server reactions, looking specifically for any unhandled exceptions, crashes, or irregular behaviours.

Expected Results

The IKEv2 server handles the malformed flags gracefully, either by rejecting the message or by ignoring the unexpected flag values.

There is no crashes, hangs, or undefined behaviours.

Expected format of evidence

Packet capture files (.pcap) showing the malformed flags sent and the server's responses.

Server logs indicating the handling (or rejection) of the malformed messages.

STC-6-004-03: IKE Key Exchange Payload Fuzzing

Requirement Name: Network Security Protocol - IPSec

Requirement Reference & Description: O-RAN Security Protocols Specification clause 4.5 [2], ‘REQ-SEC-E2-1’ clause 5.2.4.1 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-01’ clause 7.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: Near-RT RIC, O-CU-CP, O-CU-UP, O-DU

Test Name: TC_IKE_KEY_EXCHANGE_PAYLOAD_FUZZING

Test Description and Applicability

Purpose: The purpose of this test is to examine the IKEv2 server's ability to manage corrupted or unexpected data within the Key Exchange (KE) payload. The KE payload carries the Diffie-Hellman public value. If the server is unable to handle malformed KE payloads, it might be susceptible to attacks or crashes.

Test Setup and Configuration

A controlled environment with an IKEv2 server and a test client.

Packet capture tool (e.g., Wireshark) for monitoring the traffic.

Fuzzing tool or script capable of generating malformed KE payloads.

Test Procedure

Start the packet capture tool to ensure you record every detail of the test session.

Use your fuzzing tool or script to generate IKEv2 messages with the following specific manipulations in the KE payloads:

Unexpected length: Prepare 10 distinct messages where the KE payload's declared length is longer or shorter than the actual payload.

Corrupted data: Generate 10 messages introducing random bytes into the KE payload to see how the server handles non-standard values.

Unsupported Diffie-Hellman groups: Create 5 messages attempting to initiate a key exchange using a DH group that is either deprecated or not supported by the server.

Empty KE payload: Formulate 5 messages with an empty KE payload.

Sequentially send these 30 malformed messages to the IKEv2 server. After sending each message, wait for the server's response to avoid overloading it. Ensure the following sequence:

Send the 10 "Unexpected Length" messages.

Follow with the 10 "Corrupted Data" messages.

Continue with the 5 "Unsupported Diffie-Hellman Groups" messages.

Conclude with the 5 "Empty KE Payload" messages.

NOTE: Monitor the server's reactions closely. The server should ideally handle errors gracefully, either ignoring them or responding with an appropriate error message, without any crashes or hangs.

Expected Results

The IKEv2 server gracefully handles the malformed KE payloads, either by ignoring them, responding with an error, or requesting a valid KE payload.

No crashes, hangs, or undefined behaviours occur.

Expected format of evidence

Packet capture files (.pcap) highlighting the malformed KE payloads and the server's corresponding responses.

Server logs detailing the handling (or rejection) of the malformed KE payloads.

STC-6-004-04: IKE Malformed Certificate Payload

Requirement Name: Network Security Protocol - IPSec

Requirement Reference & Description: O-RAN Security Protocols Specification clause 4.5  [2], ‘REQ-SEC-E2-1’ clause 5.2.4.1 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-01’ clause 7.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: Near-RT RIC, O-CU-CP, O-CU-UP, O-DU

Test Name: TC_IKE_MALFORMED_CERTIFICATE_PAYLOAD

Test Description and Applicability

Purpose: This test aims to verify the IKEv2 server's capability to properly validate certificate payloads. Certificate payloads are essential in the IKEv2 authentication phase. A server vulnerable to malformed certificate payloads could be susceptible to impersonation or man-in-the-middle attacks.

Test Setup and Configuration

A controlled environment with an IKEv2 server and a test client.

Packet capture tool (e.g., Wireshark) to monitor and capture traffic.

A set of both valid and deliberately malformed certificates.

Test Procedure

Valid Certificate Test:

Initiate an IKEv2 session using a valid certificate to ensure baseline functionality.

Confirm successful authentication and session establishment.

Expired Certificate:

Use a previously valid certificate that has now expired.

Attempt to initiate an IKEv2 session.

Observe the server's rejection of this certificate.

Certificate with Invalid Signature:

Modify a valid certificate's content slightly (e.g., change an attribute) without re-signing it. This will invalidate its signature.

Attempt to initiate an IKEv2 session using this certificate.

The server should detect the invalid signature and reject the connection.

Certificate from Untrusted Authority:

Generate a new certificate signed by a Certificate Authority (CA) that the IKEv2 server doesn't trust or recognize.

Attempt to initiate a connection using this certificate.

Observe the server rejecting the certificate due to the untrusted CA.

Certificate with Modified Subject/Issuer Fields:

Modify the subject or issuer fields of a certificate to contain irregular or unexpected values (e.g., overly long strings, special characters).

Use this certificate to initiate an IKEv2 session.

The server should validate these fields, notice the irregularities, and potentially reject the connection.

Certificate with Invalid Key Usage:

Use a certificate that doesn't have "key encipherment" or "digital signature" as its key usage, which are typically needed for IKEv2 operations.

Attempt to initiate a session.

The server should detect the inappropriate key usage and decline the connection.

Expected Results:

For the valid certificate, the IKEv2 server authenticates successfully and establish a session.

For all other scenarios, the IKEv2 server detects the certificate anomalies and rejects the connection attempts. Specific error messages or logs relating to certificate validation failure are generated.

Expected format of evidence:

Packet capture files (.pcap) capturing the entire exchange, showing the certificate exchange and the server's response.

Server logs detailing the acceptance or rejection of each certificate, with corresponding reasons or error messages for rejections.

	STC-6-005: OAuth 2.0

Test Name: OAuth2.0_Protocol

Requirement Name: Authorization based on OAuth 2.0 shall be enforced for O-RAN application’s API service request to O-RAN resource provider.

Requirement Reference: Clause 4.7, O-RAN Security Protocol and Controls Specifications [2]

Requirement Description: O-RAN OAuth 2.0 based authorization including resource registration, application access token request and token based service access request

Threat References: T-O-RAN-05, T-NEAR-RT-04, T-rAPP-04

DUT/s: Non-RT RIC, Near-RT RIC, xApps, rApps

	Test description and applicability

Purpose: To verify implementation of the authorization of O-RAN application’s (e.g. xApps) API service request to O-RAN resource provider (e.g. Near-RT RIC) based on OAuth 2.0 as specified in [2]

 The following properties shall be validated:

Supported version of OAuth 2.0

Application access token request process

Mutual TLS authentication is required

Token based service access request process

Mutual TLS authentication is required

	Test setup and configuration

This test shall be executed against O-RAN component(s)/application(s) requesting or providing service(s) via API call.

Test prerequisites:

OAuth client – Client/Application as DUT

Resource server – Resource owner/provider as DUT

OAuth server – OAuth 2.0 Authorization Server (real or emulated)

OAuth client registration can be a manual process with client profile pre-provisioned on the OAuth server based on client certificate’s subject alternative name field

Resource server registered with the OAuth server for its supported API service(s)

This process can be a manual or automatic process preceding with resource server authentication

The API service profile(s) should follow the definition of O-RAN specifications

TLS service enabled on the OAuth client, Resource server and OAuth server with all the required keys, root and/or immediate (if necessary) CA certificates required for mutual TLS authentication procedure

IP connectivity in btw Authorization Server, Resource provider and Client/Application

Network access to Authorization Server, Resource provider and Client/Application by the tester

	Test procedure

The following test steps and test scenarios shall be followed for the validation:

Application access token request process validation

Application access token request process with valid client certificate and parameters

O-RAN application as OAuth client makes the access token request towards OAuth server over secured TLS communication session with mutual TLS authentication;

Figure 61: Access Token request

Verify the session is established between the OAuth client and OAuth server, and the access token request is processed with a successful response with digitally signed JSON Web Signature (JWS) as described in RFC 7515 [20] by the OAuth server.

Application access token request process with wrong client certificate

O-RAN application as OAuth client shall send the access token request towards OAuth server over secured TLS communication session with mutual TLS authentication;

Verify the session establishment in between the OAuth client and server is not possible.

Application access token request process with incorrect parameters

O-RAN application as OAuth client shall send the access token request with incorrect parameters towards OAuth server over secured TLS communication session with mutual TLS authentication;

Verify the session is established between the OAuth client and OAuth server, and the access token request is processed with a failed response by the OAuth server with error code defined in RFC 6749 7 [18].

Token based service request process validation

Token based service access request process with valid access token

O-RAN application as OAuth client shall send an API service request towards O-RAN resource provider using the access token obtained as a response to access token request over a secured TLS communication session with mutual TLS authentication;

Figure 62: Service request

Verify the session is established between the application and resource provider, and the service request is processed with a response by the resource provider.

Token based service access request process with incorrect access token

O-RAN application as OAuth client shall send an API service request towards O-RAN resource provider using an incorrect access token over a secured TLS communication session with mutual TLS authentication;

Verify the session is established between the application and resource provider, and the service request is processed with a failed response (401) by the resource provider.

	Expected results

The O-RAN component/application shall be able to execute API service(s) call with OAuth 2.0 based authorization.

Expected format of evidence: Log files, traffic captures and/or screenshots.

NACM

In this clause, we explore a series of test cases, each meticulously designed to scrutinize and bolster the security and functionality of the Network Access Control Management (NACM) within an O-RAN environment. Encompassing aspects such as Role-Based Access Control (RBAC) Configuration, Logging and Monitoring, and Hardening Configuration, these tests aim to validate and fortify the NACM’s ability to adeptly manage access, log and monitor activities, and robustly safeguard against a spectrum of cybersecurity threats.

STC-6-006-01: NACM RBAC Configuration

Requirement Name: NACM security

Requirement Reference & Description: ‘REQ-NAC-FUN-1 to REQ-NAC-FUN-10’ clause 5.2.2.1.3 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-03, T-O-RAN-05, T-O-RAN-06’ clause 7.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: Near-RT RIC, O-CU-CP, O-CU-UP, O-DU

Test Name: TC_NACM_RBAC_CONFIGURATION

Test description and applicability

Purpose: The purpose of this test is to verify the RBAC configuration for secure access control on the TLS-based NACM with NETCONF.

Test setup and configuration

The NACM and NETCONF services are properly configured and operational.

The RBAC feature is supported and enabled in the NACM system.

RBAC roles, access control rules, and denied resources or operations are properly defined.

Test procedure

Verify RBAC role definitions.

Check that RBAC roles are properly defined for access control.

	Review the RBAC role definitions.

EXAMPLE: Command “show nacm rbac roles”

	Validate that the defined roles match the intended access control requirements.

Verify RBAC role assignment.

Test the assignment of RBAC roles to users or user groups.

	Assign roles to users or user groups.

EXAMPLE: “Command: configure nacm rbac role-assignment”

	Verify that the assigned roles are reflected in the configuration.

Verify unauthorized access denial.

Test access to resources or operations that are not permitted for a specific RBAC role.

	Identify a resource or operation that is denied for a specific role.

EXAMPLE: “Command show nacm rbac role-permissions <role_name>”

	Attempt to access the denied resource or operation with a user assigned to the role.

EXAMPLE: “Command: execute netconf operation <operation_name>”

Expected Results

For step 1), Roles are defined with their associated permissions and restrictions.

For step 2), Roles are assigned to the appropriate users or user groups.

For step 3)-a, The denied resource or operation is listed for the specified role.

For step 3)-b, Access to the denied resource or operation is denied, and an appropriate error message is displayed.

Expected format of evidence

For step 1), The output of the show nacm rbac roles command, showing the defined roles and their associated permissions and restrictions.

For step 2), Confirmation that the roles have been successfully assigned to the appropriate users or user groups, as reflected in the configuration.

For step 3), An appropriate error message indicating access denial when attempting to access a denied resource or operation with a user assigned to a specific role.

STC-6-006-02: NACM Logging Monitoring

Requirement Name: NACM security

Requirement Reference & Description: ‘REQ-NAC-FUN-1 to REQ-NAC-FUN-10’ clause 5.2.2.1.3 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-03, T-O-RAN-05, T-O-RAN-06’ clause 7.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: Near-RT RIC, O-CU-CP, O-CU-UP, O-DU

Test Name: TC_NACM_LOGGING_MONITORING

Test description and applicability

Purpose: The purpose of this test is to verify the logging and monitoring configuration for the TLS-based NACM with NETCONF.

Test setup and configuration

The NACM and NETCONF services are properly configured and operational.

Logging and monitoring systems are in place, integrated and configured with the NACM system.

Test procedure

Verify logging configuration.

Check that logging is properly configured to capture relevant security-related events.

	Review the logging configuration settings.

EXAMPLE: “Command: show nacm logging configuration”

	Trigger security-related events (e.g., access violations, failed authentication attempts) and validate that the events are logged.

Verify monitoring configuration.

Test the monitoring configuration to ensure that security-related events and performance metrics are monitored.

	Review the monitoring configuration settings.

EXAMPLE: “Command: show nacm monitoring configuration”

	Trigger security-related events or exceed performance thresholds and verify that the monitoring system captures and reports these events or metrics.

Verify audit log review.

Test the ability to review audit logs for security-related events.

	Retrieve the audit logs.

EXAMPLE: “Command: show nacm audit-logs”

	Review the audit logs to ensure that they contain the expected information and provide a detailed record of security-related activities.

Expected Results

For step 1), Logging is enabled with appropriate log levels, log destinations, and log retention policies.

For step 2), Monitoring is enabled with appropriate metrics, thresholds, and alerting mechanisms.

For step 3), Audit logs containing security-related events are available.

Expected format of evidence

Confirmation that logging is enabled with the expected log levels, log destinations, and log retention policies. Additionally, evidence of captured security-related events in the logs.

Confirmation that monitoring is enabled with the configured metrics, thresholds, and alerting mechanisms. Evidence of captured security-related events or performance metrics exceeding thresholds.

The audit logs containing security-related events, demonstrating that they contain the expected information and provide a detailed record of security-related activities.

STC-6-006-03: NACM Hardening Configuration

Requirement Name: NACM security

Requirement Reference & Description: ‘REQ-NAC-FUN-1 to REQ-NAC-FUN-10’ clause 5.2.2.1.3 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-03, T-O-RAN-05, T-O-RAN-06’ clause 7.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: Near-RT RIC, O-CU-CP, O-CU-UP, O-DU

Test Name: TC_NACM_HARDENING_CONFIGURATION

Test description and applicability

Purpose: The purpose of this test is to verify the hardening configuration for the TLS-based NACM with NETCONF.

Test setup and configuration

The NACM and NETCONF services are properly configured and operational.

TLS is properly implemented and configured. The tester executes the tests on the TLS protocol as defined in Clause 6.3.

Secure key management practices are implemented.

Test procedure

Verify secure cryptographic protocols and algorithms.

Ensure that the cryptographic protocols and algorithms used in the TLS-based NACM with NETCONF are secure and compliant with clause 4.3 of O-RAN security protocols specification [2].

	Review the TLS configuration settings.

EXAMPLE “Command: show nacm tls configuration”

	Validate that the TLS configuration aligns with clause 4.3 of O-RAN security protocols specification [2].

Verify secure key management.

Test the key management practices to ensure secure generation, storage, and distribution of cryptographic keys.

	Review the key management configuration settings.

EXAMPLE: “Command: show nacm key-management configuration”

	Validate that the key management configuration complies with industry best practices and organizational policies.

Verify secure session termination.

Test the termination of TLS sessions to ensure that connections are properly closed and resources are released securely.

	Initiate multiple TLS sessions with the NACM system.

EXAMPLE: “Command: execute nacm connect <component>”

	Terminate the TLS sessions.

EXAMPLE: “Command: execute nacm disconnect <component>”

Expected Results

For step 1), Secure cryptographic protocols (e.g., TLS 1.2, TLS 1.3) and strong encryption algorithms (e.g., AES-256) are used.

For step 2), Secure practices such as key generation, secure key storage, and key distribution mechanisms are implemented [2] Clause 5.

For step 3)-a, Successful establishment of TLS sessions.

For step 3)-b, Sessions are terminated correctly, and resources are released securely.

Expected format of evidence

Confirmation (logs or screenshots) that the TLS configuration is utilizing secure cryptographic protocols (e.g., TLS 1.2, TLS 1.3) and strong encryption algorithms (e.g., AES-256).

Confirmation (logs or screenshots) that secure key management practices, such as key rotation, secure storage, and distribution mechanisms, are implemented.

Confirmation (logs or screenshots) that TLS sessions are terminated correctly and securely, with appropriate evidence demonstrating the release of resources.

802.1x

This clause conducts a detailed investigation into the security and consistency of network communication by scrutinizing the 802.1X authentication protocol. This collection of tests focuses on verifying the sturdiness of the handshake protocol, assuring the steadfast power and dependability of the certificate validation chain of trust, and carefully confirming the effectiveness of cryptographic algorithms and key strengths.

STC-6-007-01: 802.1X Cryptographic Algorithms Key Strength

Requirement Name: 802.1x security

Requirement Reference & Description: ‘REQ-SEC-OFHPLS-1 to REQ-SEC-OFHPLS-3’ clause 5.2.5.5.1 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-FRHAUL-01, T-FRHAUL-02, T-CPLANE-01, T-CPLANE-02’ clause 7.4.1.2 in O-RAN Security Threat Modeling and Risk Assessment [3].

DUT/s: O-RU, O-DU

Test Name: TC_802.1X_CRYPTOGRAPHIC_ALGORITHMS_KEY_STRENGTH

Test description and applicability

Purpose: The purpose of this test case is to verify the cryptographic algorithms and key strength used in the 802.1x authentication process. It ensures that secure cryptographic algorithms are employed with appropriate key strengths, while avoiding the use of deprecated or insecure algorithms.

Test setup and configuration

802.1x protocol is configured on the O-RAN NFs O-DU and O-RU.

Supplicant (O-RU) and authenticator (O-DU) are configured to use the desired cryptographic algorithms and key strengths.

Test procedure

Obtain the certificate used by the supplicant or authenticator.

Command (Supplicant or Authenticator): This step depends on the specific supplicant software being used.

EXAMPLE: if OpenSSL is used, the following command to extract the certificate can be used: openssl x509 -in <certificate_file> -text

Examine the certificate to identify the cryptographic algorithms and key strengths used.

Cryptographic Algorithms: Look for the algorithm used for digital signatures (e.g., RSA, ECDSA) and encryption (e.g., AES). Avoid the use of deprecated algorithms such as TDES.

Key Strength: Determine the key length used for cryptographic operations, such as RSA, TDES key length or ECC curve strength.

Verify that secure cryptographic algorithms and appropriate key strengths are employed, while avoiding deprecated or insecure options.

Cryptographic Algorithm Verification: Ensure that the cryptographic algorithms used are considered secure and recommended by trusted sources. Avoid the use of deprecated algorithms such as MD5 or SHA-1 for digital signatures.

Key Strength Verification: Verify that the key lengths or curve strengths meet the recommended security requirements. Avoid weak key sizes, such as RSA keys shorter than 2048 bits, AES shorter than 256 bits or ECC curves shorter than 256 bits.

Expected Results

Positive Case: Secure cryptographic algorithms are used with appropriate key strengths, meeting industry standards and best practices. Deprecated or insecure algorithms and weak key sizes are not used [2] Clause 5.

Negative Case: Deprecated or insecure cryptographic algorithms are used, or the key strengths do not meet the recommended security requirements.

Expected format of evidence

For positive cases, provide information about the cryptographic algorithms used, ensuring they are secure, and highlight the appropriate key strengths while avoiding deprecated algorithms or weak key sizes.

For negative cases, provide information about the use of deprecated or insecure cryptographic algorithms or inadequate key strengths, emphasizing the security vulnerabilities.

X.509

This clause aims to robustly validate various aspects of X.509 certificate usage within the O-RAN system, ensuring secure and reliable certificate-based authentication and communication across all applicable network entities.

STC-6-009-01: X.509 Certificate Structure Verification

Requirement Name: X.509 security

Requirement Reference & Description: ‘REQ-TLS-FUN-1’ clause 5.2.2.1.2 [5], ‘REQ-SEC-O2-1’ clause 5.2.3.1 [5], ‘REQ-SEC-OCLOUD-O2dms-1 to REQ-SEC-OCLOUD-O2dms-3’ clause 5.1.8.9.1.1 [5], ‘REQ-SEC-OCLOUD-O2ims-1 to REQ-SEC-OCLOUD-O2ims-3’ clause 5.1.8.9.1.2 [5], ‘REQ-SEC-O-CLOUD-NotifAPI-1 to REQ-SEC-O-CLOUD-NotifAPI-2’ clause 5.1.8.9.1.3 [5], ‘REQ-SEC-A1-1,REQ-SEC-A1-2’ clause 5.2.1.1 [5], ‘REQ-SEC-E2-1’ clause 5.2.4.1 [5], ‘REQ-SEC-R1-1, REQ-SEC-R1-2’ clause 5.2.6.1 [5], ‘REQ-SEC-Y1-1 to REQ-SEC-Y1-3’ clause 5.2.7.2 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-03, T-O-RAN-05, T-O-RAN-06’ clause 7.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU, O-CU, Near-RT RIC, xApp, rApp, Non-RT RIC, SMO, O-Cloud

Test Name: TC_X509_CERT_STRUCTURE_VERIFICATION

Test description and applicability

Purpose: The purpose of this test is to ensure that the X.509 certificate follows the correct structure and format. This test is applicable to all X.509 certificates used in the O-RAN system.

Test setup and configuration:

Obtain a sample valid X.509 certificate.

Test Procedure

Certificate Fields Examination:

Validate the certificate's version field. The version number should match the intended version (typically 3 for X.509 version 3).

Examine the Subject field to ensure it contains relevant information about the certificate holder.

Check the Issuer field to confirm it identifies the certificate authority that issued the certificate.

Verify the Validity field to ensure the "Not Before" date is earlier than the "Not After" date, indicating a valid time range for the certificate's use.

Key Usage and Extended Key Usage Extension Check:

Validate the presence of the Key Usage extension. Verify that it specifies the allowed usages of the public key, such as digital signatures, key encipherment, etc.

Confirm the presence of the Extended Key Usage extension if needed. This extension defines additional purposes for the key pair, like client authentication or server authentication.

ASN.1 DER Encoding:

Use ASN.1 decoding libraries to parse the certificate data.

Ensure the decoding process succeeds without errors, indicating the certificate adheres to the DER encoding rules.

Expected Results

The certificate adheres to the X.509 standard structure, contains accurate information, and follows the ASN.1 DER encoding rules.

Expected format of evidence

Log or report indicating successful certificate structure validation.

STC-6-009-02: X.509 Certificate Validity Period Verification

Requirement Name: X.509 security

Requirement Reference & Description: ‘REQ-TLS-FUN-1’ clause 5.2.2.1.2 [5], ‘REQ-SEC-O2-1’ clause 5.2.3.1 [5], ‘REQ-SEC-OCLOUD-O2dms-1 to REQ-SEC-OCLOUD-O2dms-3’ clause 5.1.8.9.1.1 [5], ‘REQ-SEC-OCLOUD-O2ims-1 to REQ-SEC-OCLOUD-O2ims-3’ clause 5.1.8.9.1.2 [5], ‘REQ-SEC-O-CLOUD-NotifAPI-1 to REQ-SEC-O-CLOUD-NotifAPI-2’ clause 5.1.8.9.1.3 [5], ‘REQ-SEC-A1-1,REQ-SEC-A1-2’ clause 5.2.1.1 [5], ‘REQ-SEC-E2-1’ clause 5.2.4.1 [5], ‘REQ-SEC-R1-1, REQ-SEC-R1-2’ clause 5.2.6.1 [5], ‘REQ-SEC-Y1-1 to REQ-SEC-Y1-3’ clause 5.2.7.2 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-03, T-O-RAN-05, T-O-RAN-06’ clause 7.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU, O-CU, Near-RT RIC, xApp, rApp, Non-RT RIC, SMO, O-Cloud

Test Name: TC_X509_CERT_VALIDITY_PERIOD_VERIFICATION

Test description and applicability

Purpose: The purpose of this test is to ensure that the certificate's validity dates are accurate and within an acceptable range. This test is relevant for all X.509 certificates within the O-RAN system.

Test setup and configuration

Prepare certificates with different validity periods (valid, expired, not yet valid).

Test Procedure

Verify a Valid Certificate:

Set up a valid certificate with appropriate "Not Before" and "Not After" dates.

Verify that the certificate is accepted when used for its intended purpose.

Verify an Expired Certificate:

Set up a certificate with a past expiration date.

Attempt to use the expired certificate for its intended purpose.

Verify that the certificate is rejected due to expiration.

Verify a Not Yet Valid Certificate:

Set up a certificate with a "Not Before" date in the future.

Attempt to use the certificate before the valid start date.

Verify that the certificate is rejected due to being not yet valid.

Expected Results

Valid certificates are accepted, while expired and not-yet-valid certificates are rejected.

Expected format of evidence

Log or report showing successful validation and rejection for different validity periods.

STC-6-009-03: X.509 Certificate Key Usage Verification

Requirement Name: X.509 security

Requirement Reference & Description: ‘REQ-TLS-FUN-1’ clause 5.2.2.1.2 [5], ‘REQ-SEC-O2-1’ clause 5.2.3.1 [5], ‘REQ-SEC-OCLOUD-O2dms-1 to REQ-SEC-OCLOUD-O2dms-3’ clause 5.1.8.9.1.1 [5], ‘REQ-SEC-OCLOUD-O2ims-1 to REQ-SEC-OCLOUD-O2ims-3’ clause 5.1.8.9.1.2 [5], ‘REQ-SEC-O-CLOUD-NotifAPI-1 to REQ-SEC-O-CLOUD-NotifAPI-2’ clause 5.1.8.9.1.3 [5], ‘REQ-SEC-A1-1,REQ-SEC-A1-2’ clause 5.2.1.1 [5], ‘REQ-SEC-E2-1’ clause 5.2.4.1 [5], ‘REQ-SEC-R1-1, REQ-SEC-R1-2’ clause 5.2.6.1 [5], ‘REQ-SEC-Y1-1 to REQ-SEC-Y1-3’ clause 5.2.7.2 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-03, T-O-RAN-05, T-O-RAN-06’ clause 7.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU, O-CU, Near-RT RIC, xApp, rApp, Non-RT RIC, SMO, O-Cloud

Test Name: TC_X509_CERT_KEY_USAGE_VERIFICATION

Test description and applicability

Purpose: The purpose of this test is to confirm that the certificate's key usage and extended key usage extensions are correctly defined.

Test setup and configuration

Prepare certificates with different key usage and extended key usage extensions.

Test Procedure

Verify a Certificate with Correct Usage Extensions:

Set up a certificate with proper key usage and extended key usage extensions matching its intended purpose (e.g., server authentication).

Attempt to use the certificate for its designated purpose.

Verify that the certificate is accepted.

Verify a Certificate with Incorrect or Missing Usage Extensions:

Set up a certificate with incorrect or missing key usage or extended key usage extensions.

Attempt to use the certificate for its intended purpose.

Verify that the certificate is rejected.

Expected Results

Certificates with correct usage extensions are accepted, while those with incorrect or missing extensions are rejected.

Expected format of evidence

Log or report indicating successful validation and rejection for different key usage scenarios.

STC-6-009-04: X.509 Certificate Chain Validation

Requirement Name: X.509 security

Requirement Reference & Description: ‘REQ-TLS-FUN-1’ clause 5.2.2.1.2 [5], ‘REQ-SEC-O2-1’ clause 5.2.3.1 [5], ‘REQ-SEC-OCLOUD-O2dms-1 to REQ-SEC-OCLOUD-O2dms-3’ clause 5.1.8.9.1.1 [5], ‘REQ-SEC-OCLOUD-O2ims-1 to REQ-SEC-OCLOUD-O2ims-3’ clause 5.1.8.9.1.2 [5], ‘REQ-SEC-O-CLOUD-NotifAPI-1 to REQ-SEC-O-CLOUD-NotifAPI-2’ clause 5.1.8.9.1.3 [5], ‘REQ-SEC-A1-1,REQ-SEC-A1-2’ clause 5.2.1.1 [5], ‘REQ-SEC-E2-1’ clause 5.2.4.1 [5], ‘REQ-SEC-R1-1, REQ-SEC-R1-2’ clause 5.2.6.1 [5], ‘REQ-SEC-Y1-1 to REQ-SEC-Y1-3’ clause 5.2.7.2 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-03, T-O-RAN-05, T-O-RAN-06’ clause 7.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU, O-CU, Near-RT RIC, xApp, rApp, Non-RT RIC, SMO, O-Cloud

Test Name: TC_X509_CERT_CHAIN_VALIDATION

Test Description and applicability

Purpose: The purpose of this test is to validate the certificate chain's integrity and trustworthiness. This test is applicable to scenarios where certificates are part of a chain (e.g., intermediate and root certificates).

Test setup and configuration

Prepare a certificate chain with correct and incorrect configurations.

Test Procedure

Verify a Certificate Chain with Correct Order and Valid Signatures:

Set up a valid certificate chain with proper order and valid signatures.

Attempt to use the certificate chain for its intended purpose.

Verify that the certificate chain is accepted.

Verify a Certificate Chain with Incorrect Order or Invalid Signatures:

Set up a certificate chain with incorrect order or invalid signatures.

Attempt to use the certificate chain for its intended purpose.

Verify that the certificate chain is rejected.

Expected Results

A valid certificate chain is accepted, while an invalid chain is rejected.

Expected format of evidence

Log or report indicating successful validation and rejection for different certificate chain scenarios.

eCPRI

This clause emphasizes the importance of securing the eCPRI protocol to ensure secure, robust, and reliable communication within the O-RAN system. The tests target multiple dimensions of eCPRI’s security framework, from session management to auditing capabilities.

STC-6-010-01: eCPRI Session Management

Requirement Name: eCPRI security

Requirement Reference & Description: ‘REQ-SEC-TRAN-1’ clause 5.3.4.1 in O-RAN Security and Controls Requirements Specifications [5].

Threat References: ‘T-FRHAUL-01, T-FRHAUL-02’ clause 7.4.1.2 in O-RAN Security Threat Modeling and Risk Assessment [3].

DUT/s: O-RU, O-DU

Test Name: TC_eCPRI_SESSION_MANAGEMENT

Test description and applicability

Purpose: The purpose of this test is to verify that the eCPRI protocol properly manages sessions and prevents session-related vulnerabilities.

Test setup and configuration

eCPRI API is accessible.

Authentication credentials are available.

Test procedure

Positive Case:

Authenticate with the eCPRI API and establish a session.

Perform valid API requests within the session.

Verify that the session remains active and valid for a reasonable duration.

Perform subsequent API requests using the same session.

Verify that the API responds with the expected results without re-authentication.

Negative Case:

Authenticate with the eCPRI API and establish a session.

Wait for the session to expire or become inactive.

Attempt to perform API requests using the expired or inactive session.

Verify that the API responds with an appropriate error message.

Expected Result: The eCPRI protocol manages sessions effectively, allowing authorized requests to be performed within valid sessions while preventing unauthorized access to expired or inactive sessions.

Expected format of evidence

Test log: A log file documenting the steps performed during the test, including session establishment, API requests, and responses.

Screenshots: Screenshots of the API responses showing successful session establishment and subsequent API interactions.

STC-6-010-02: eCPRI Input Validation

Requirement Name: eCPRI security

Requirement Reference & Description: ‘REQ-SEC-TRAN-1’ clause 5.3.4.1 in O-RAN Security Requirements and Controls Specifications [5].

Threat References: ‘T-FRHAUL-01, T-FRHAUL-02’ clause 7.4.1.2 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU

Test Name: TC_eCPRI_INPUT_VALIDATION

Test description and applicability

Purpose: The purpose of this test is to ensure that the eCPRI protocol properly validates and sanitizes user input to prevent common security vulnerabilities such as injection attacks.

Test setup and configuration

eCPRI API is accessible.

Input fields requiring validation are identified.

Test procedure

Positive Case:

Send API requests with valid and expected input values.

Verify that the API processes the requests successfully and provides the expected responses.

Negative Case:

Generate API requests by systematically applying fuzzing techniques to introduce deliberately malicious input values containing potential security threats.

Verify that the eCPRI API detects and rejects the malicious input, responding with appropriate error messages or status codes.

NOTE: Ensuring comprehensive coverage against malicious inputs is challenging due to the boundless variety of potential inputs. A more pragmatic approach is to adopt a risk-focused testing strategy. This method emphasizes inputs that pose significant threats to security. Such inputs commonly fall under categories like data breaches (inputs that might unveil confidential information, encryption keys, or credentials), unauthorized entry (inputs that could circumvent authentication or exploit privileges to gain unauthorized access), and system infiltration (inputs that might activate code execution vulnerabilities). It's worth noting that fuzzing tools play a pivotal role in generating malicious inputs for APIs to pinpoint potential vulnerabilities. The importance of the fuzzing methodology has been accentuated in this context, and it's relevant to all O-RAN APIs (e.g., SCTP, eCPRI and RESTful APIs).

Expected Result: The eCPRI protocol validates and sanitizes user input to prevent security vulnerabilities related to improper input handling.

Expected format of evidence

Test log: A log file documenting the requests sent to the API, including valid and malicious inputs.

Screenshots: Screenshots of the API responses showing the handling of valid inputs and appropriate error messages for malicious inputs.

STC-6-010-03: eCPRI Error Handling

Requirement Name: eCPRI security

Requirement Reference & Description: ‘REQ-SEC-TRAN-1’ clause 5.3.4.1  in O-RAN Security Requirements and Controls Specifications [5].

Threat References: ‘T-FRHAUL-01, T-FRHAUL-02’ clause 7.4.1.2 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU

Test Name: TC_eCPRI_ERROR_HANDLING

Test description and applicability

Purpose: The purpose of this test is to ensure that the eCPRI protocol handles errors securely and does not disclose sensitive information.

Test setup and configuration

eCPRI API is accessible.

Various error scenarios are identified.

Test procedure

Attempt to force error conditions by sending unexpected or malicious requests, by simulating a high-latency or slow network connection between the client and the eCPRI API server.

Verify that the eCPRI API detects and handles the errors appropriately, responding with informative error messages without revealing sensitive information.

Validate that the error messages provide helpful and actionable information for troubleshooting.

Restore normal connectivity.

Resend a normal request to the eCPRI API.

Verify that the API processes the request successfully and provides the expected response.

Expected Result: The eCPRI protocol handles errors securely, providing meaningful error messages without disclosing sensitive information and recovering seamlessly when the connection is restored.

Expected format of evidence

Screenshots: Screenshots of the error messages or status codes received from the API in response to triggered errors.

Test log: A log file documenting the requests and responses during error scenarios.

STC-6-010-04: eCPRI Access Control

Requirement Name: eCPRI security

Requirement Reference & Description: ‘REQ-SEC-TRAN-1’ clause 5.3.4.1  in O-RAN Security Requirements and Controls Specifications [5].

Threat References: ‘T-FRHAUL-01, T-FRHAUL-02’ clause 7.4.1.2 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU

Test Name: TC_eCPRI_ACCESS_CONTROL

Test description and applicability

Purpose: The purpose of this test is to verify that the eCPRI protocol enforces access controls consistently across all relevant resources and endpoints.

Test setup and configuration

eCPRI API is accessible.

User roles and permissions are defined.

Test procedure

Positive Case:

Authenticate with different roles.

Send requests to various API endpoints associated with different levels of access rights.

Verify that the API allows access to authorized resources and returns the expected results.

Repeat the test with different authenticated user roles and ensure consistent access control enforcement.

Negative Case:

Attempt to access resources or perform actions that require higher access privileges than the authenticated user possesses.

Verify that the eCPRI API responds with appropriate access control-related error messages or status codes.

Repeat the test with different scenarios and confirm consistent behaviour.

Expected Result: The eCPRI protocol enforces access controls consistently, granting access only to authorized users based on their assigned roles and permissions.

Expected format of evidence

Test log: A log file documenting the user authentication process, access requests, and the responses received from the API.

Screenshots: Screenshots of successful access to authorized resources and error messages for unauthorized access attempts.

STC-6-010-05: eCPRI Logging and Auditing

Requirement Name: eCPRI security

Requirement Reference & Description: ‘REQ-SEC-TRAN-1’ clause 5.3.4.1 in O-RAN Security Requirements and Controls Specifications [5].

Threat References: ‘T-FRHAUL-01, T-FRHAUL-02’ clause 7.4.1.2 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU

Test Name: TC_eCPRI_LOGGING_AUDITING

Test description and applicability

Purpose: The purpose of this test is to validate that the eCPRI protocol logs relevant security events and activities and supports auditing capabilities.

Test setup and configuration

eCPRI API is accessible.

Logging and auditing mechanisms are enabled and configured.

Test procedure

Perform various API actions (e.g., authentication, access control, data retrieval, configuration changes).

Verify that the eCPRI API generates appropriate log entries for each action, capturing relevant security-related information.

Access and review the generated logs to ensure they contain the necessary details for security auditing purposes.

Expected Result: The eCPRI protocol generates accurate and tamper-resistant logs, recording security-related events and activities for auditing and forensic analysis.

Expected format of evidence

Log files: The generated log files containing recorded security events and activities during the testing process.

Screenshots: Screenshots of log entries highlighting relevant security events and timestamps.

STC-6-010-06: eCPRI Timeout Error Handling

Requirement Name: eCPRI security

Requirement Reference & Description: ‘REQ-SEC-TRAN-1’ clause 5.3.4.1  in O-RAN Security Requirements and Controls Specifications [5].

Threat References: ‘T-FRHAUL-01, T-FRHAUL-02’ clause 7.4.1.2 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU

Test Name: TC_eCPRI_TIMEOUT_ERROR_HANDLING

Test description and applicability

Purpose: The purpose of this test is to verify that the eCPRI protocol handles timeout errors gracefully and provides appropriate error messages.

Test setup and configuration

eCPRI API is running and accessible.

A request with a long processing time or a simulated delay is prepared.

Test procedure

Positive Case:

Send a request to the eCPRI API with a normal processing time.

Verify that the API responds within a reasonable time frame and provides the expected response.

Negative Case:

Send a request to the eCPRI API that triggers a timeout condition (e.g., requesting a resource that requires a long processing time).

Verify that the API responds with an appropriate error message or status code indicating the timeout condition.

Adjust the timeout settings or optimize the processing time.

Resend the request to the eCPRI API.

Verify that the API processes the request successfully and provides the expected response within the adjusted timeout duration.

Expected Result: The eCPRI protocol handles timeout errors gracefully, providing meaningful error messages or status codes when a request exceeds the configured or reasonable processing time. Once the timeout issue is addressed, the API processes requests within the specified time limits.

Expected format of evidence

Test log: A log file documenting the requests sent to the eCPRI API and their corresponding responses, including timestamps.

Screenshots or videos: Screenshots or video recordings showing the requests being sent to the eCPRI API and the received error messages or status codes indicating the timeout error.

SCTP

The SCTP is pivotal in ensuring reliable, secure, and efficient communication within O-RAN networks, particularly between various endpoints such as O-CU, O-DU, and Near-RT RIC. To validate its operational and security robustness, the following test cases are designed, emphasizing diverse facets of SCTP, namely, association management, data transfer, authentication, authorization, and resilience against potential threats and attacks.

STC-6-011-01: SCTP Association Establishment

Requirement Name: SCTP security

Requirement Reference & Description: ‘REQ-SEC-TRAN-1’ clause 5.3.4.1 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-E2-01, T-E2-02, T-E2-03’ clause 7.4.1.12 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-CU, O-DU, Near-RT RIC

Test Name: TC_SCTP_ASSOCIATION_ESTABLISHMENT

Test description and applicability

Purpose: The purpose of this test is to ensure that the SCTP protocol can establish an association between two endpoints.

Test setup and configuration

The SCTP protocol is up and running, and two endpoints are available for testing.

Test procedure

Use the sctp_bindx() function to bind the local endpoint to a specific IP address and port.

Use the sctp_connectx() function to establish an association with the remote endpoint.

Verify that the association has been established by checking the return value of the sctp_connectx() function.

Expected Results

The SCTP protocol is able to establish an association between the two endpoints.

Expected format of evidence

The following evidence, in one or more formats as applicable, should be provided:

Version or build of the SCTP protocol tested.

Details of the two endpoints used (IP addresses, port numbers).

Logs from sctp_bindx() function execution.

Logs from sctp_connectx() function execution.

Return value of the sctp_connectx() function indicating association status.

(Optional) Network packet captures showing SCTP handshake.

STC-6-011-02: SCTP Data Transfer

Requirement Name: SCTP security

Requirement Reference & Description: ‘REQ-SEC-TRAN-1’, clause 5.3.10.2 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-E2-01, T-E2-02, T-E2-03’ clause 7.4.1.12 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-CU, O-DU, Near-RT RIC

Test Name: TC_SCTP_DATA_TRANSFER

Test description and applicability

Purpose: The purpose of this test is to ensure that the SCTP protocol can transfer data between two endpoints.

Test setup and configuration

An SCTP association has been established between two endpoints.

Test procedure

Use the sctp_sendmsg() function to send data from one endpoint to the other.

Use the sctp_recvmsg() function to receive the data on the other endpoint.

Verify that the data has been transferred correctly by comparing the sent and received data.

Expected Results The SCTP protocol is able to transfer data between the two endpoints.

Expected format of evidence

The following evidence, in one or more formats as applicable, should be provided:

Details of the established SCTP association (e.g., IP addresses, port numbers).

Logs from sctp_sendmsg() function execution, including data sent.

Logs from sctp_recvmsg() function execution, showing received data.

Comparison of sent and received data to verify integrity.

(Optional) Network packet captures showing SCTP data transfer.

STC-6-011-03: SCTP Association Termination

Requirement Name: SCTP security

Requirement Reference & Description: ‘REQ-SEC-TRAN-1’, clause 5.3.10.2 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-E2-01, T-E2-02, T-E2-03’ clause 7.4.1.12 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-CU, O-DU, Near-RT RIC

Test Name: TC_SCTP_ASSOCIATION_TERMINATION

Test description and applicability

Purpose: The purpose of this test is to ensure that the SCTP protocol can terminate an association between two endpoints.

Test setup and configuration

An SCTP association has been established between two endpoints.

Test procedure

Use the sctp_shutdown() function to initiate the shutdown of the association.

Use the sctp_recvmsg() function to receive the SHUTDOWN COMPLETE chunk on the other endpoint.

Verify that the association has been terminated by checking the return value of the sctp_recvmsg() function.

Expected Results The SCTP protocol is able to terminate an association between the two endpoints.

Expected format of evidence

The following evidence, in one or more formats as applicable, should be provided:

Details of the established SCTP association (e.g., IP addresses, port numbers).

Logs from sctp_shutdown() function execution.

Logs from sctp_recvmsg() function execution, showing the SHUTDOWN COMPLETE chunk.

Return value of the sctp_recvmsg() function indicating association termination status.

(Optional) Network packet captures showing SCTP association termination process.

STC-6-011-04: SCTP Authentication

Requirement Name: SCTP security

Requirement Reference & Description: ‘REQ-SEC-TRAN-1’, clause 5.3.4.1  in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-E2-01, T-E2-02, T-E2-03’ clause 7.4.1.12 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-CU, O-DU, Near-RT RIC

Test Name: TC_SCTP_AUTHENTICATION (Positive Case)

Test description and applicability

Purpose: To validate that SCTP associations can be successfully established and authenticated over an IPsec-secured connection.

Test setup and configuration

Enable IPsec on the network interface.

Configure IPsec with valid security policies and keys.

Ensure that the SCTP library and the system network stack are configured to support IPsec.

Use SCTP library.

EXAMPLE: the sctplib library in the C programming language

Test procedure

Establish a SCTP association:

Create SCTP socket: EXAMPLE: Sample SCTP command: sctp_socket = sctp_socket(AF_INET, SOCK_STREAM, IPPROTO_SCTP);

During this step, the SCTP state cookie is created and needs to be authenticated.

Ensure that the SCTP association is established over the IPsec-secured connection

Authenticate the connection:

EXAMPLE: Sample SCTP command: sctp_setsockopt(sctp_socket, IPPROTO_SCTP, SCTP_AUTH_CHUNK, &auth_params, sizeof(auth_params))

Verify that the IPsec layer is authenticating the SCTP packets

Ensure that the SCTP state cookie is authenticated

Send and receive data over the authenticated connection.

EXAMPLE: Sample SCTP commands:

Transmit data over the SCTP association: sctp_sendmsg(sctp_socket, send_buffer, send_length, NULL, 0, 0, 0, stream_id, 0, 0);

Receive data over the SCTP association: sctp_recvmsg(sctp_socket, receive_buffer, receive_length, NULL, NULL, NULL);

Expected Results

Successful establishment of the SCTP association over an IPsec-secured connection.

All SCTP packets are authenticated by IPsec.

Successful data transmission over the SCTP association

Expected format of evidence

Test logs demonstrating the establishment of the SCTP association.

STC-6-011-05: SCTP DoS Prevention Rate Limiting

Requirement Name: SCTP security

Requirement Reference & Description: ‘REQ-SEC-TRAN-1’, clause 5.3.4.1 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-E2-01, T-E2-02, T-E2-03’ clause 7.4.1.12 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-CU, O-DU, Near-RT RIC

Test Name: TC_SCTP_ DOS_PREVENTION_RATE_LIMITING

Test description and applicability

Purpose: The purpose of this test is to verify that the SCTP protocol effectively handles DoS attacks and prevents resource exhaustion.

Test setup and configuration

Enable DoS prevention mechanisms.

The rate limiting parameters, such as the maximum number of connections or allowed data transfer rate, are properly defined.

Use SCTP library.

EXAMPLE: the sctplib library in the C programming language

Test procedure

Simulate a DoS attack by overwhelming the SCTP protocol with a large number of connection requests (send data at a rate that exceeds the defined rate limiting parameters).

EXAMPLE: Sample SCTP commands:

for (int i = 0; i < num_connections; i++) {

sctp_socket = sctp_socket(AF_INET, SOCK_STREAM, IPPROTO_SCTP);

// Establish connections rapidly beyond system limits

}

Monitor the SCTP protocol's response and behaviour during the excessive connection and data transfer attempts.

Expected Results

The SCTP protocol detects the excessive usage and applies rate limiting measures to restrict or reject connections or data transfers that exceed the defined limits.

The system handles the rate limiting effectively, ensuring that resources are not exhausted or overwhelmed.

Expected format of evidence

Test logs showing successful handling of the DoS attack, such as connection limits or rejection messages.

System performance metrics or logs indicating the proper handling of excessive connection requests.

STC-6-011-06: SCTP Input Validation

Requirement Name: SCTP security

Requirement Reference & Description: ‘REQ-SEC-TRAN-1’, clause 5.3.4.1 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-E2-01, T-E2-02, T-E2-03’ clause 7.4.1.12 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-CU, O-DU, Near-RT RIC

Test Name: TC_SCTP_INPUT_VALIDATION

Test description and applicability

Purpose: To verify that the SCTP protocol performs proper input validation to prevent security vulnerabilities such as buffer overflows or injection attacks.

Test setup and configuration

The SCTP protocol is configured with input validation enabled.

Use SCTP library.

EXAMPLE: the sctplib library in the C programming language

Test procedure

Attempt to establish a connection using the SCTP protocol and provide invalid or malicious input.

EXAMPLE: Sample SCTP command: sctp_socket = sctp_socket(AF_INET, SOCK_STREAM, IPPROTO_SCTP);

Send data containing invalid or malicious content over the connection.

EXAMPLE: Sample SCTP command: sctp_sendmsg(sctp_socket, malicious_data_buffer, data_length, NULL, 0, 0, 0, stream_id, 0, 0);

Expected Results

The SCTP protocol performs input validation and rejects or sanitizes the invalid or malicious input.

The connection is not established, or the malicious data is handled safely.

Expected format of evidence

Test logs showing the rejection or sanitization of invalid or malicious input.

Output from the application indicating the successful validation and rejection of malicious data.

STC-6-011-07: SCTP Authorization

Requirement Name: SCTP security

Requirement Reference & Description: ‘REQ-SEC-TRAN-1’, clause 5.3.4.1 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-E2-01, T-E2-02, T-E2-03’ clause 7.4.1.12 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-CU, O-DU, Near-RT RIC

Test Name: TC_SCTP_AUTHORIZATION

Test description and applicability

Purpose: The purpose of this test is to verify that the SCTP protocol enforces proper authorization mechanisms, allowing only authorized clients to establish connections or access specific resources.

Test setup and configuration

The SCTP protocol is configured with authorization enabled.

The server has a defined set of authorized clients or roles.

Use SCTP library.

EXAMPLE: the sctplib library in the C programming language

Test procedure

Attempt to establish a connection using the SCTP protocol with an unauthorized client or without providing proper authorization credentials.

EXAMPLE: Sample SCTP command: sctp_socket = sctp_socket(AF_INET, SOCK_STREAM, IPPROTO_SCTP);

Send authorization credentials or attempt to access protected resources over the connection.

EXAMPLE: Sample SCTP command: sctp_sendmsg(sctp_socket, authorization_request, request_length, NULL, 0, 0, 0, stream_id, 0, 0);

Expected Results

The SCTP protocol verifies the provided authorization credentials and rejects the connection or denies access to protected resources for unauthorized clients.

Authorized clients is able to establish connections and access protected resources without any issues.

Expected format of evidence

Test logs showing the rejection of unauthorized clients or denial of access to protected resources.

Output from the application indicating the successful verification of authorization credentials.

STC-6-011-08: SCTP Data Exposure

Requirement Name: SCTP security

Requirement Reference & Description: ‘REQ-SEC-TRAN-1’, clause 5.3.10.2  in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-E2-01, T-E2-02, T-E2-03’ clause 7.4.1.12 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-CU, O-DU, Near-RT RIC

Test Name: TC_SCTP_DATA_EXPOSURE

Test description and applicability

Purpose: The purpose of this test is to ensure that the SCTP protocol does not leak any sensitive data.

Test setup and configuration

The SCTP protocol is up and running.

Use SCTP library.

EXAMPLE: the sctplib library in the C programming language

	Test procedure

	Establish a connection using the SCTP protocol.

EXAMPLE: Sample SCTP command: sctp_socket = sctp_socket(AF_INET, SOCK_STREAM, IPPROTO_SCTP);

	Monitor the network traffic or analyse the transmitted data to detect any potential leakage or exposure of sensitive information.

Test for data leakage in responses, logs, and error messages.

	Expected Results

	The SCTP protocol does not expose any sensitive data.

Expected format of evidence

Verification that no sensitive information is accessible from the intercepted network traffic or data analysis.

RESTful

This clause emphasizes the necessity of robust security controls to safeguard these APIs within the O-RAN NFs against various threats and vulnerabilities. The outlined test cases aim to validate the security mechanisms deployed in RESTful API implementations, ensuring authentication, authorization, input validation, and secure logging and monitoring are upheld to the highest standards, thereby securing the NFs from malicious actors and potential breaches.

STC-6-012-01: REST API Authentication

Requirement Name: RESTful API protection

Requirement Reference & Description: ‘REQ-SEC-O-CLOUD-NotifAPI-1, REQ-SEC-O-CLOUD-NotifAPI-2’ clause 5.1.8.9.1.3 [5], ‘REQ-SEC-API-1, REQ-SEC-API-2, REQ-SEC-API-3, REQ-SEC-API-4, REQ-SEC-API-5, REQ-SEC-API-6, REQ-SEC-API-8, REQ-SEC-API-9, REQ-SEC-API-10, REQ-SEC-API-13, REQ-SEC-API-15’ clause 5.3.10.2 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-01, T-O-RAN-02, T-O-RAN-03, T-O-RAN-05, T-O-RAN-06’ clause 7.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU, O-CU, Near-RT RIC, xApp, rApp, Non-RT RIC, SMO, O-Cloud

Test Name: TC_REST_API_AUTHENTICATION

Test description and applicability

Purpose: The purpose of this test is to verify the authentication mechanism of an O-RAN NF supporting RESTful API.

Test setup and configuration

An O-RAN NF supporting the RESTful API is provisioned and running.

Access to the O-RAN NF management system or command-line interface.

Test procedure

Positive Case:

Authenticate using valid credentials or API tokens:

EXAMPLE: curl -X POST -H "Content-Type: application/json" -d '{"username":"<username>", "password":"<password>"}' http://<ORAN_IP>/auth

Capture the authentication token from the response.

Execute an authenticated request against an O-RAN NF resource (e.g., get cell status).

Verify that the request is successful and returns the expected response.

Negative Case:

Attempt to access the O-RAN RESTful API without providing valid authentication credentials:

curl http://<ORAN_IP>/cell-status

Verify that the request fails and returns an unauthorized response.

Expected Results

Positive Case:

Authentication using valid credentials or API tokens is successful.

Authorized requests to O-RAN NF resources return the expected responses.

Negative Case:

Requests without valid authentication credentials are rejected with an unauthorized response.

Expected format of evidence

Screenshots or logs showing the successful authentication and authorized requests.

Screenshots or logs showing the failed authentication attempts.

STC-6-012-02: REST Authorization and Access Control

Requirement Name: RESTful API protection

Requirement Reference & Description: ‘REQ-SEC-O-CLOUD-NotifAPI-1, REQ-SEC-O-CLOUD-NotifAPI-2’ clause 5.1.8.9.1.3 [5], ‘REQ-SEC-API-1, REQ-SEC-API-2, REQ-SEC-API-3, REQ-SEC-API-4, REQ-SEC-API-5, REQ-SEC-API-6, REQ-SEC-API-8, REQ-SEC-API-9, REQ-SEC-API-10, REQ-SEC-API-13, REQ-SEC-API-15’ clause 5.3.10.2 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-01, T-O-RAN-02, T-O-RAN-03, T-O-RAN-05, T-O-RAN-06’ clause 7.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU, O-CU, Near-RT RIC, xApp, rApp, Non-RT RIC, SMO, O-Cloud

Test Name: TC_REST_AUTHORIZATION_ACCESS_CONTROL

Test description and applicability

Purpose: The purpose of this test is to ensure that the RESTful API enforces proper authorization and access control mechanisms.

Test setup and configuration

An O-RAN NF supporting the RESTful API is provisioned and running.

Access to the O-RAN NF management system or command-line interface.

User roles and permissions are defined and configured.

Test procedure

Positive Case:

Authenticate using credentials associated with a user assigned to a role with necessary permissions:

EXAMPLE: curl -X POST -H "Content-Type: application/json" -d '{"username":"<username>", "password":"<password>"}' http://<ORAN_IP>/auth

Capture the authentication token from the response.

Execute a request that requires the permissions granted by the user's role (e.g., update configuration).

Verify that the request is successful and returns the expected response.

Negative Case:

Authenticate using credentials associated with a user not assigned to a role with necessary permissions:

EXAMPLE: curl -X POST -H "Content-Type: application/json" -d '{"username":"<username>", "password":"<password>"}' http://<ORAN_IP>/auth

Capture the authentication token from the response.

Execute a request that requires the permissions beyond the user's role (e.g., perform a restricted operation).

Verify that the request fails and returns a forbidden response.

Expected Results

Positive Case:

Users with appropriate roles and permissions can perform authorized actions.

Requests requiring specific permissions return the expected responses.

Negative Case:

Users without necessary roles or permissions are restricted from performing unauthorized actions.

Requests requiring permissions beyond the user's role return a forbidden response.

Expected format of evidence

Screenshots or logs showing the successful authorization and access control enforcement.

Screenshots or logs showing the failed authorization attempts.

STC-6-012-03: REST Input Validation and Sanitization

Requirement Name: RESTful API protection

Requirement Reference & Description: ‘REQ-SEC-O-CLOUD-NotifAPI-1, REQ-SEC-O-CLOUD-NotifAPI-2’ clause 5.1.8.9.1.3 [5], ‘REQ-SEC-API-1, REQ-SEC-API-2, REQ-SEC-API-3, REQ-SEC-API-4, REQ-SEC-API-5, REQ-SEC-API-6, REQ-SEC-API-8, REQ-SEC-API-9, REQ-SEC-API-10, REQ-SEC-API-13, REQ-SEC-API-15’ clause 5.3.10.2 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-01, T-O-RAN-02, T-O-RAN-03, T-O-RAN-05, T-O-RAN-06’ clause 7.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU, O-CU, Near-RT RIC, xApp, rApp, Non-RT RIC, SMO, O-Cloud

Test Name: TC_REST_INPUT_VALIDATION_SANITIZATION

Test description and applicability

Purpose: The purpose of this test is to validate that the RESTful API properly validates and sanitizes input data to prevent common security vulnerabilities.

Test setup and configuration

An O-RAN NF supporting the RESTful API is provisioned and running.

Access to the O-RAN NF management system or command-line interface.

Test procedure

Positive Case:

Construct a valid request with appropriate input data:

EXAMPLE: curl -X POST -H "Content-Type: application/json" -d '{"parameter1":"value1", "parameter2":"value2"}' http://<ORAN_IP>/api-endpoint

Verify that the request is successful and returns the expected response.

Negative Case:

Construct a request with invalid or malicious input data:

EXAMPLE: curl -X POST -H "Content-Type: application/json" -d '{"parameter1":"<script>alert(1)</script>", "parameter2":"value2"}' http://<ORAN_IP>/api-endpoint

Verify that the request fails and returns an error response or rejects the malicious input.

Expected Results

Positive Case:

Requests with valid and appropriate input data are successfully processed.

Responses from the O-RAN NF RESTful API are as expected.

Negative Case:

Requests with invalid or malicious input data are rejected or handled properly to prevent security vulnerabilities.

Expected format of evidence

Screenshots or logs showing the successful input validation and sanitization.

Screenshots or logs showing failed input validation or sanitization attempts.

STC-6-012-04: REST Security Logging and Monitoring

Requirement Name: RESTful API protection

Requirement Reference & Description: ‘REQ-SEC-O-CLOUD-NotifAPI-1, REQ-SEC-O-CLOUD-NotifAPI-2’ clause 5.1.8.9.1.3 [5], ‘REQ-SEC-API-1, REQ-SEC-API-2, REQ-SEC-API-3, REQ-SEC-API-4, REQ-SEC-API-5, REQ-SEC-API-6, REQ-SEC-API-8, REQ-SEC-API-9, REQ-SEC-API-10, REQ-SEC-API-13, REQ-SEC-API-15’ clause 5.3.10.2 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-01, T-O-RAN-02, T-O-RAN-03, T-O-RAN-05, T-O-RAN-06’ clause 7.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU, O-CU, Near-RT RIC, xApp, rApp, Non-RT RIC, SMO, O-Cloud

Test Name: TC_REST_SECURITY_LOGGING_MONITORING

Test description and applicability

Purpose: The purpose of this test is to verify that the O-RAN NF logs and monitors API activities for security and compliance purposes.

Test setup and configuration

An O-RAN NF supporting the RESTful API is provisioned and running.

Access to the O-RAN NF management system or command-line interface.

Test procedure

Positive Case:

Enable API logging and monitoring for the O-RAN NF.

Generate a series of API requests and actions.

Review the logs or monitoring system for the recorded activities.

Negative Case:

Attempt unauthorized API actions or exploit security vulnerabilities.

Verify that the logs or monitoring system captures and raises alerts for these activities.

Expected Results

Positive Case:

API activities are logged and monitored by the O-RAN NF.

Logs or monitoring system records the expected API requests and actions.

Negative Case:

Unauthorized or malicious API actions trigger alerts in the logs or monitoring system.

Logs or monitoring system captures and records failed security attempts.

Expected format of evidence

Screenshots or logs from the O-RAN NF management system showing the successful or failed API logging and monitoring settings.

	Common Network Security Tests for O-RAN components

	Overview

This chapter contains a set of security evaluations that are performed from outside and inside of the network function in a network capacity. It is used to measure the external exposure and risk(s) of the function in place and leverages common techniques used in cyber security to evaluate the risk(s) device under test faces or has.

The objects in scope of these network-based security tests are SMO, Non-RT RIC, Near-RT RIC, O-CU-CP, O-CU-UP, O-DU, O-RU, O-eNB and O-Cloud.

Network Protocol and Service Enumeration

	STC-7-7.2-001: Network Protocol and Service Enumeration

Test name: TC_Network_Procotol_And_Enumeration

Requirement Name: Network protocol and service enumeration

Requirement Reference: REQ-SEC-NET-1, clause 5.3.3.1, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: “A list of network protocols and services supported on the O-RAN component shall be clearly documented by its vendor. Unused protocols shall be disabled.”

Threat References: T-O-RAN-01, T-O-RAN-02

DUT/s: SMO, Non-RT RIC, Near-RT RIC, O-CU-CP, O-CU-UP, O-DU, O-RU, O-Cloud

	Test description and applicability

Purpose: To verify that the list of active network protocols and services on running O-RAN component is in line with vendor-provided list of network protocols and services supported by the O-RAN component. Probing of network protocols and services on running O-RAN component provides the information whether the service is active or not.

NOTE 1: In practice, such probing is often referred to as network scanning or port scanning.

This test case probes all possible TCP and SCTP ports in range 0-65535 using port scanner for presence of the active services.

This test case probes all documented UDP ports from vendor-provided list using port scanner for presence of the active services. Optionally, additional UDP ports may be scanned as well.

Result of probing the running O-RAN component is a list of active network protocols and services. Each item contains network protocol (TCP, UDP, SCTP), port number (from range 0-65535) and service name. If service type cannot be determined during probing, service name is "unknown".

Service name is in line with Service Name and Transport Protocol Port Number Registry defined by IANA [i.1] . If service name is not defined in [i.1], vendor provided service name should be used.

NOTE 2: In practice, services may also run on ports different from ports defined in [i.1].

O-RAN component configuration influences what network protocols and services are exposed as active. Service that is supported by O-RAN component may be disabled and therefore can be detected during probing as not active.

Comparison between the vendor-provided list of all supported network protocols and services and the list or active network protocols and services found by port scanner are performed.

	Test setup and configuration

This test is executed against running O-RAN component as the DUT.

Test prerequisites:

Port scanner with capabilities as defined in clause 5.3 of present document

Network access to DUT

Vendor-provided list of network protocols and services supported by DUT

	Test procedure

List of open ports are determined as follows:

Port scanner scans all TCP ports in range 0-65535 on the IP interface of DUT. TCP SYN/ACK response by DUT are interpreted as open port.

Port scanner scans all SCTP ports in range 0-65535 on the IP interface of DUT. SCTP INIT-ACK response by DUT are interpreted as open port.

All UDP ports documented in vendor-provided list are interpreted as open ports. Other UDP ports may be considered as open for the purpose of service detection.

NOTE 3: Due to the nature of UDP protocol, there is no simple method of open port detection similar to TCP/SCTP methods based on analysis of response message type (TCP: SYN/ACK, SCTP: INIT-ACK). In case of UDP, open port detection inevitably relies on service detection which is discussed in step 2 of this test procedure. In practice, port scans of entire UDP port range 0-65535 are impractical and time consuming. Typically, service detection is performed only for subset of UDP ports. UDP port subset selection is arbitrary and not standardized. Service detection in this test procedure is required for UDP ports from vendor-provided list and is optional for other UDP ports.

For each open port from previous step, port scanner performs service detection by sending service probe(s) as follows:

If open port is listed in vendor-provided list, port scanner uses service probe from its built-in database that exactly matches service documented in vendor-provided list.

If open port is not listed in vendor-provided list, port scanner should use service probe from its built-in database that exactly matches service defined in [i.1] for the that open port. If such service is not defined in [i.1], port scanner may report service as "unknown". Alternatively, port scanner may perform further service detection attempts based on other service probes from its built-in database.

NOTE 4: Service detection for open ports that are also listed in vendor-provided list requires only one probe. Finding any open ports that are not listed in vendor-provided list means this test case fails. However, service information can be helpful in discussion with DUT vendor. This test procedure therefore accommodates optional service detection based on one probe or multiple probes.

Port scanner shall produce list of detected active network protocols, ports and services on DUT.

	Expected results

All services found by port scanner are documented in vendor-provided list. This test case ends with success if:

both lists match exactly

list of network protocols and services found by port scanner has fewer items than vendor-provided list; all items found by port scanner exactly match items from vendor-provided list.

If any service is found by port scanner and it is not documented in vendor-provided list, this test case shall fail. It means that vendor-provided list is incorrect and undocumented attack surface exists.

Expected format of evidence: Report file, log files and/or screenshots.

	Password-Based Authentication

	STC-7-7.3-001: Password guessing

Test name: TC_Password_Guessing

Requirement Name: Password-Based Authentication

Requirement Reference: REQ-SEC-PASS-1, clause 5.3.7.1, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: Password guessing protection mechanism is present on the DUT

Threat References: T-O-RAN-02, T-O-RAN-03, T-O-RAN-05, T-O-RAN-06

DUT/s: SMO, Non-RT RIC, Near-RT RIC, O-CU-CP, O-CU-UP, O-DU, O-RU, O-Cloud

	Test description and applicability

Purpose: To verify that running O-RAN component has protection mechanism(s) implemented to prevent password guessing attacks against services using password-based authentication.

NOTE 1: In practice, brute-forcing and dictionary attacks are the most common classes of password guessing attacks. Traditional approach to brute-forcing and dictionary attacks uses fixed username with various candidate passwords. Password spraying is another approach that can be combined with brute-forcing and dictionary attacks; fixed password is tested with various candidate usernames. Example of protection mechanism is enforcing delay before next authentication attempt(s) by the same client. This test case cannot list all possible techniques that protection mechanisms can use. However, following list provides overview of the most common approaches:

Increase the delay after each unsuccessful authentication attempt.

Implement challenge-response authentication (example of such measure: CAPTCHA)

In order to prevent more attempts, impose temporary lock out on the client when threshold of consecutive failed authentication attempts is reached. During defined period of time all authentication attempts by locked-out client shall be rejected.

Simulation of password guessing attacks against services on running O-RAN component provides the information whether any protection mechanism is present.

This test case is run against all services on running O-RAN component that use password-based authentication. Vendor-provided list of all supported network protocols and services are used as a source.

NOTE 2: Vendor-provided list of all supported network protocols and services may not include the specific information about presence of password-based authentication as it is including network protocol, port and service name. In practice, only subset of services from vendor-provided list will use password-based authentication.

This test case does not mandate any specific list of passwords to be used for testing.

	Test setup and configuration

This test is executed against running O-RAN component as the DUT.

Test prerequisites:

Valid username for each tested service

Network access to DUT

Physical access to DUT (applicable if the DUT is in physical form)

Vendor-provided list of network protocols and services supported by DUT

	Test procedure

List of services using password-based authentication is determined by analyzing the vendor-provided list as well as by analyzing local services that are not remotely accessible.

For services identified in the previous step, presence of protection mechanism is tested as follows:

combination of valid username and invalid password (or various invalid passwords) are used for authentication repeatedly.

after certain number of authentication attempts, protection mechanism of DUT are detected.

minimum number of authentication attempts are 11.

protection mechanism(s) detects after 10 authentication attempts or fewer.

EXAMPLE: If DUT uses protection mechanism based on delaying authentication attempts, such delay is observed at the latest when DUT receives 11th consecutive invalid authentication attempt.

	Expected results

In context of each of the services using password-based authentication, protection mechanism(s) is present. Applicable to local services and to remotely accessible services.

This test case fails if one or more services using password-based authentication have no protection mechanism present.

Expected format of evidence: Report file, log files and/or screenshots.

	STC-7-7.3-002: Unauthorized Password Reset

Test name: TC_Unauthorized_Password_Reset

Requirement Name: Password-Based Authentication

Requirement Reference: REQ-SEC-PASS-1, clause 5.3.7.1, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: Out-of-band password recovery mechanism absent or deactivated on DUT

Threat References: T-O-RAN-02, T-O-RAN-03, T-O-RAN-05, T-O-RAN-06

DUT/s: SMO, Non-RT RIC, Near-RT RIC, O-CU-CP, O-CU-UP, O-DU, O-RU, O-Cloud

	Test description and applicability

Purpose: To verify that password reset mechanism of running O-RAN component cannot be circumvented, disabled, or misused to gain access to O-RAN component, its configuration, and data.

Test covers services using password-based authentication and out-of-band mechanisms of password reset present in O-RAN components in physical form.

If password reset is required, factory reset of O-RAN component is performed. Factory reset wipes O-RAN component, its configuration and data.

	Test setup and configuration

This test is executed against running O-RAN component as the DUT.

Test prerequisites:

Network access to DUT

Physical access to DUT (applicable if the DUT is in physical form)

Vendor-provided list of network protocols and services supported by DUT

	Test procedure

List of services using password-based authentication are determined by analyzing the vendor-provided list as well as by analyzing local services that are not remotely accessible.

For services identified in the previous step, presence of password reset is tested.

For DUT that has physical form, it verifies that use of hardware factory reset switch or switches results in factory reset. Using any out-of-band mechanism, it is not possible to reset password only.

	Expected results

In context of each of the services using password-based authentication, no password change mechanism is present. Applicable to local services and to remotely accessible services.

This test case fails if one or more services using password-based authentication have password reset mechanism exposed.

This test case fails if DUT in physical form has hardware switch or switches that can be used to reset password without triggering factory reset of DUT.

Expected format of evidence: Report file, log files and/or screenshots.

	STC-7-7.3-003: Password Policy Enforcement

Test name: TC_Password_Policy_Enforcement

Requirement Name: Password-Based Authentication

Requirement Reference: REQ-SEC-PASS-1, clause 5.3.7.1, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: Secure password policy is supported and enforced on the DUT

Threat References: T-O-RAN-02, T-O-RAN-03, T-O-RAN-05, T-O-RAN-06

DUT/s: SMO, Non-RT RIC, Near-RT RIC, O-CU-CP, O-CU-UP, O-DU, O-RU, O-Cloud

	Test description and applicability

Purpose: To verify that password policy applied for services using password-based authentication is effectively enforced by running O-RAN component.

	Test setup and configuration

This test is executed against running O-RAN component as the DUT.

Test prerequisites:

Set of valid username and valid password for each tested service

Network access to DUT

Physical access to DUT (applicable if the DUT is in physical form)

Vendor-provided list of network protocols and services supported by DUT

	Test procedure

List of services using password-based authentication is determined by analyzing the vendor-provided list as well as by analyzing local services that are not remotely accessible.

For services identified in the previous step, effectiveness of password policy enforcement is verified as follows:

combination of valid username and valid password are used to authenticate

password change is performed using password that does not conform to applied password policy

EXAMPLE: DUT uses password policy to set rules for password length, type of characters used (allowed and disallowed characters), complexity (character groups), and denied passwords (deny-list of passwords that cannot be set). Candidate password that does not conform to rules are chosen for this test. As password policy may be complex set of rules, multiple candidate password should be tested to fully cover possible password policy violations.

	Expected results

In context of each of the services using password-based authentication, applied password policy are effectively enforced and non-compliant passwords are rejected by DUT during password change. Applicable to local services and to remotely accessible services.

Expected format of evidence: Report file, log files and/or screenshots.

	Network Protocol Fuzzing

Fuzzing is an automated process of sending invalid or random inputs to a SUT to cause it to malfunction or crash.

Fuzzing is effective for finding vulnerabilities because while most modern programs have extensive input fields, the test coverage of these areas is relatively small. Even though this process can be a powerful capability to ensure robustness, it needs to be sufficiently defined and implemented throughout the system development lifecycle to be helpful and achieve the required results in a multi-vendor environment.

While traditional fuzzing techniques involve fuzzing piece(s) of software and generating inputs through command line or input files, fuzzing telecommunication network protocols tends to be different, requiring sending information via network ports. Furthermore, the complex nature of network protocols in the SUT resulting from how they are layered over each other adds to the challenges of fuzzing such SUTs.

In the case of O-RAN SUT, fuzzing cover protocols rather than application-specific (web applications and services, etc.). The following are examples of the protocols that fuzzing will cover;

General Transport Protocols

SCTP

IP

TCP

UDP

SSH

HTTP

HTTP/2

and

O-RAN Specific Protocols

NETCONF

E1AP

E2AP

A1

CTI

eCPRI

PTP

It is anticipated that many O-RAN components utilize common software frameworks used for the lower-level general communication. In this case it should be evaluated if these General Transport Protocols are being tested in extensive Fuzzing tests in other activities and can therefore be considered to have lower risk profiles compared to the O-RAN Specific Protocols with less testing in the general industry.

Many of the O-RAN specific protocols are state- machine based protocols that can have multiple end points served at the same time, e.g. the protocol needs to be tested in scale to understand if possible memory leaks or other similar aspects is available that could lead to buffer overflows (opening up for possible code execution) or software crashes of the O-RAN specific software.

Fuzzing on the M-Plane protocol inside the Configuration of the O-RAN Fronthaul can be a possible significant area as this is combining multiple technologies from many domains into a single solution. In order for the Fuzzing to be time and resource efficient, it is important that this Fuzzing is protocol and state machine aware so that the Fuzzing can focus on the relevant aspects of the SUT representing the most significant risk exposure. Further effectiveness can be achieved if the Fuzzing capability is able to intelligently respond to the SUT behavior. The Fuzzing tool should be able to both perform test with and without access to relevant credentials. Many possible vulnerabilities would be present on the inside of the authenticated session of the management protocols and would lead to escalation of privileges.

In order to identify the possible risk for memory leaks, Denial of Service (DoS) or other similar aspects a robust logging of the underlying platform (hardware and software), the virtualization or container platform and the O-RAN function, the logging needs to be detailed enough to evaluate the trends early but not intrusive to degrade the performance of the platform and lead to inaccurate results.

As general guidance, vendors and operators running fuzzing tests aim to document the list of all of the protocols of the SUTs reachable externally on an IP-based interface, together with indications of whether adequate available robustness and fuzz testing tools have been used against them. The tool's name, their unambiguous version (also for plug-ins if applicable), user settings, and the relevant output evidenced and should be documented. Additionally, any input causing unspecified, undocumented, or unexpected behavior and a description of this behavior should be highlighted in the testing documentation.

Since fuzzing test cases are not exhaustive and difficult to define and replicate, it's likely that test results even from testing the same set of protocols by different vendors may end up resulting in different outputs. So further effort and time needs to be invested in fuzzing activities until a satisfactory approach based on the vendor's or/and operators adopted risk-based model is satisfied.

	Denial of Service/Message Flooding

	STC-7-7.5-001: Protocol, Application and Volumetric Based DDoS Attacks

Test name: TC_Robustness_DDoS

Requirement Name:  Robustness against Volumetric DDoS Attack

Requirement Reference: REQ-SEC-DOS-1, clause 5.3.5.1, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: “An O-RAN component with external network interface shall be able to withstand network transport protocol based volumetric DDoS attack without system crash and returning to normal service level after the attack”

Threat References: T-O-RAN-04, T-O-RAN-09, T-SMO-03

DUT/s: Components implementing O-RAN interfaces defined in clause 5.1 of this document.

	Test description and applicability

Purpose: To verify the DUT is able to recover from a DDoS attack.

Each component interface is tested to validate how handling of large amounts of requests is done, similar to what is seen from denial of service (DoS) or/and distributed denial of service (DDoS) attempts. DoS/DDoS scenario can be occurred as a result of malicious attack or because of network/operator error. DoS/DDoS attacks may come in these forms: Protocol layer attacks (e.g. SYN Floods, UDP Floods, TCP Floods), Volume based attacks (e.g. ICMP floods, Smurf DDoS) and Application layer attacks (e.g. GET/POST floods, low-and-slow attacks, attacks that target specific software – application with exposed network services or operating system network services).

	Test setup and configuration

This test is executed against running O-RAN component or O-RAN system as the DUT.

Test prerequisites:

Network access to DUT

Vendor-provided list of network protocols and services supported by DUT

	Test procedure

In case the call flow needs authentication:

Set up a call flow that will send repeated requests after the authentication at an increasing rate over time. Mark the failure point of receiving rejection or response messages.

Stop the attack.

Set up a call flow that will send repeated requests before the authentication at an increasing rate over time. Mark the failure point of receiving acceptance or response messages.

Stop the attack.

In case the call flow does not need authentication:

Set up a call flow that will send repeated requests at an increasing rate over time. Mark the failure point of receiving response messages.

Stop the attack.

	Expected results

It is expected the component fails to serve requests after step 1.1, 1.3 and/or step 2.1.

After the attack/test stops, the DUT returns to a functional state, being able to respond to service requests again.

This test case fails if DUT does not return to a functional state after the test stops.

	Expected format of evidence: Report file, log files and/or screenshots.

 STC-7-7.5-002: O-CU DoS protection and recovery

Requirement Name: O-CU DoS protection and recovery

Requirement Reference & Description: ‘REQ-SEC-OCU-1’ clause 5.1.4, ‘REQ-SEC-DOS-1’ clause 5.3.5 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-04, T-O-RAN-09’ clause 5.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-CU

Test Name: TC_DoS_RECOV_OCU

Test description and applicability

Purpose: The purpose of this test is to evaluate the resilience of the O-CU against Denial-of-Service attacks and the recovery process from those attacks.

Test setup and configuration

The O-CU is powered on and operational.

DoS protection mechanisms are implemented on the O-CU.

The testing environment is isolated and does not impact production systems.

Test procedure

Refer to STC-7-7.5-001 for the detailed test procedure.

Expected Results

O-CU detects and demonstrates robustness against the DoS attack, maintaining normal operations with acceptable performance and rejecting requests, regardless of whether they are malicious or not.

O-CU successfully recovers from the DoS attack and resumes normal operation within a reasonable recovery time.

Expected format of evidence:

Observation logs during the DoS attack, including any triggered countermeasures or rate limiting mechanisms, and validate that the O-CU effectively defends against the attack.

Observation logs of the recovery process, including the time taken for the O-CU to regain stable operation, and validate that the recovery is timely and effective.

NOTE: Recovery time specifies the maximum acceptable recovery time after the attack ceases (e.g., "O-CU recovers and returns to normal operation within 5 minutes after the attack stops").

	STC-7-7.5-003: O-DU DoS protection and recovery

Requirement Name: O-DU DoS protection and recovery

Requirement Reference & Description: ‘REQ-SEC-ODU-1’ clause 5.1.5, ‘REQ-SEC-DOS-1’ clause 5.3.5 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-04, T-O-RAN-09’ clause 5.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-DU

Test Name: TC_FH_U-Plane_DoS

Test description and applicability

Purpose: The purpose of this test is to verify the resilience of the user plane to bandwidth exhaustion and packet flooding DoS attacks.

Test setup and configuration

A valid eCPRI connection between the O-RU and O-DU.

Test environment capable of generating high bandwidth traffic (e.g., high volume of packets).

Test procedure

Refer to STC-7-7.5-001 for the detailed test procedure.

Expected Results

The O-DU maintains acceptable performance levels despite increased traffic.

It handles the excess traffic without experiencing significant degradation or failure.

Once the load is reduced, the O-DU recovers and returns to normal operation.

Expected Format of evidence:

Steps performed with detailed execution logs

Metrics and performance measurements (e.g., recovery time, packet loss, CPU utilization) during the DoS attack

 STC-7-7.5-004: O-RU DoS protection and recovery

Requirement Name: O-RU DoS protection and recovery

Requirement Reference & Description: ‘REQ-SEC-ORU-1, REQ-SEC-ORU-2’ clause 5.1.6, ‘REQ-SEC-DOS-1’ clause 5.3.5 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-04, T-O-RAN-09’ clause 5.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU

Test Name: TC_DoS_RECOV_ORU

Test description and applicability

Purpose: The purpose of this test is to evaluate the resilience of the O-RU against Denial-of-Service attacks and the recovery process from those attacks.

Test setup and configuration

The O-RU is powered on and operational.

DoS protection mechanisms are implemented.

The testing environment is isolated and does not impact production systems.

Test procedure

Refer to STC-7-7.5-001 for the detailed test procedure.

Expected Results

O-RU detects and demonstrates robustness against the DoS attack, maintaining normal operations with acceptable performance and rejecting requests, regardless of whether they are malicious or not.

O-RU successfully recovers from the DoS attack and resumes normal operation within a reasonable recovery time.

Expected format of evidence:

Observation logs during the DoS attack, including any triggered countermeasures or rate limiting mechanisms, and validate that the O-RU effectively defends against the attack.

Observation logs of the recovery process, including the time taken for the O-RU to regain stable operation, and validate that the recovery is timely and effective.

NOTE: Recovery time specifies the maximum acceptable recovery time after the attack ceases (e.g., "O-RU recovers and returns to normal operation within 5 minutes after the attack stops").

 STC-7-7.5-005: Near-RT RIC DoS protection and recovery

Requirement Name: Near-RT RIC DoS protection and recovery

Requirement Reference & Description: ‘REQ-SEC-NEAR-RT-6, REQ-SEC-NEAR-RT-7’ clause 5.1.3, ‘REQ-SEC-DOS-1’ clause 5.3.5 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-04, T-O-RAN-09’ clause 5.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: Near-RT RIC

Test Name: TC_DoS_RECOV_NEAR_RT_RIC

Test description and applicability

Purpose: The purpose of this test is to evaluate the resilience of the Near-RT RIC against Denial-of-Service attacks and the recovery process from those attacks.

Test setup and configuration

The Near-RT RIC is powered on and operational.

DoS protection mechanisms are implemented on the Near-RT RIC.

The testing environment is isolated and does not impact production systems.

Test procedure

Refer to STC-7-7.5-001 for the detailed test procedure.

Expected Results

Near-RT RIC detects and demonstrates robustness against the DoS attack, maintaining normal operations with acceptable performance and rejecting requests, regardless of whether they are malicious or not.

Near-RT RIC successfully recovers from the DoS attack and resumes normal operation within a reasonable recovery time.

Expected format of evidence:

Observation logs during the DoS attack, including any triggered countermeasures or rate limiting mechanisms, and validate that the Near-RT RIC effectively defends against the attack.

Observation logs of the recovery process, including the time taken for the Near-RT RIC to regain stable operation, and validate that the recovery is timely and effective.

NOTE: Recovery time specifies the maximum acceptable recovery time after the attack ceases (e.g., "Near-RT RIC recovers and returns to normal operation within 5 minutes after the attack stops").

 Input validation and error handling

Input validation and error handling are pivotal security practices that guard against malformed or malicious data inputs, ensuring that systems behave predictably and securely. This clause elucidates a series of tests designed to validate the efficacy of the input validation and error handling mechanisms implemented in various O-RAN network functions (O-CU, O-DU, Near-RT RIC), safeguarding them from a myriad of potential vulnerabilities and ensuring robust, secure, and stable operations.

 STC-7-7.6-001: O-CU input validation and error handling

Requirement Name: Input validation and error handling on data provided through O1 and E2 interfaces.

Requirement Reference & Description: ‘REQ-SEC-OCU-1’ clause 5.1.4 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-05’ clause 7.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-CU

Test Name: TC_INPUT_VALIDATION_ERR_HANDL_OCU

Test description and applicability

Purpose: The purpose of this test is to verify that the O-CU performs proper input validation on provided data via E2/O1 interfaces and rejects invalid or malicious inputs. It verifies that the O-CU correctly handles errors and responds appropriately.

Test setup and configuration

The O-CU is powered on and operational.

Test environment is set up with E2 and O1 interfaces configured.

Input validation mechanisms are implemented on O-CU.

Error handling mechanisms (e.g., error codes, error messages) are implemented by O-CU.

Test procedure

Case of malformed input data

The tester provides invalid or malformed input data to the O-CU via E2/O1 interfaces, violating the specified format or containing unexpected values.

The tester captures and analyses the response from the E2/O1 interfaces.

The tester verifies that the O-CU detects the invalid input and rejects it appropriately, returning an error message or taking necessary actions to mitigate the impact.

EXAMPLE: actions could be rejecting the message, sending an error indication, etc.

Case of malicious input data

The tester provides malicious input data to the O-CU, aiming to exploit known vulnerabilities (e.g., CVE database, OWASP Top Ten, NIST National Vulnerability Database (NVD), vendor-specific vulnerability database) or perform unauthorized actions.

The tester verifies that the O-CU identifies the malicious input and implements security measures to prevent exploitation, such as input sanitization, access controls, or anomaly detection.

Boundary case

Provide input data at the boundaries of the allowed range or limits defined for specific inputs.

Verify that the O-CU handles the boundary cases correctly, without encountering any unexpected behaviour or errors due to boundary conditions.

Expected Results

For case ‘malformed input data’, the O-CU properly validates incoming inputs form O1/E2 interfaces and rejects those with invalid or malformed data, returning an appropriate error response and preventing any potential security risks or system failures.

For case ‘malicious input data’, the O-CU detects and mitigates the malicious input, preventing any potential security breaches or unauthorized operations.

For case ‘boundary’, the O-CU properly handles the boundary cases, ensuring that inputs at the limits are processed accurately without causing any system instability or vulnerabilities.

Expected format of evidence:

Logs detailing the invalid or malformed input data provided to the O-CU via O1/E2 interfaces, alongside system logs capturing the O-CU's error messages or indications in response to the invalid input.

Logs documenting the malicious input data sent to the O-CU and the targeted vulnerabilities, complemented by system logs highlighting the O-CU 's detection and mitigation actions upon receiving the malicious input.

Logs of the boundary input data values provided to the O-CU, paired with system logs capturing the O-CU 's messages or behaviors in response to the boundary inputs.

 STC-7-7.6-002: O-DU input validation and error handling

Requirement Name: Input validation and error handling on data provided through O1/E2/FH interfaces.

Requirement Reference & Description ‘REQ-SEC-ODU-1’ clause 5.1.5 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-05’ clause 7.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-DU

Test Name: TC_INPUT_VALIDATION_ERR_HANDL_ODU

Test description and applicability

Purpose: The purpose of this test is to verify that the O-DU performs proper input validation on provided data via E2/O1/FH interfaces and rejects invalid or malicious inputs. It verifies that the O-DU correctly handles errors and responds appropriately.

Test setup and configuration

The O-DU is powered on and operational.

Test environment is set up with E2/O1/FH interfaces configured.

Input validation mechanisms are implemented on O-DU.

Error handling mechanisms (e.g., error codes, error messages) are implemented by O-DU.

Test procedure

Case of malformed input data

The tester provides invalid or malformed input data to the O-DU via E2/O1/FH interfaces, violating the specified format or containing unexpected values.

The tester captures and analyses the response from the E2/O1/FH interfaces.

The tester verifies that the O-DU detects the invalid input and rejects it appropriately, returning an error message or taking necessary actions to mitigate the impact.

EXAMPLE: actions could be rejecting the message, sending an error indication, etc.

Case of malicious input data

The tester provides malicious input data to the O-DU, aiming to exploit known vulnerabilities (e.g., CVE database, OWASP Top Ten, NIST National Vulnerability Database (NVD), vendor-specific vulnerability database) or perform unauthorized actions.

The tester verifies that the O-DU identifies the malicious input and implements security measures to prevent exploitation, such as input sanitization, access controls, or anomaly detection.

Boundary case

Provide input data at the boundaries of the allowed range or limits defined for specific inputs.

Verify that the O-DU handles the boundary cases correctly, without encountering any unexpected behaviour or errors due to boundary conditions.

Expected Results

For case ‘malformed input data’, the O-DU properly validates incoming inputs form O1/E2/FH interfaces and rejects those with invalid or malformed data, returning an appropriate error response and preventing any potential security risks or system failures.

For case ‘malicious input data’, the O-DU detects and mitigates the malicious input, preventing any potential security breaches or unauthorized operations.

For case ‘boundary’, the O-DU properly handles the boundary cases, ensuring that inputs at the limits are processed accurately without causing any system instability or vulnerabilities.

Expected format of evidence:

Logs detailing the invalid or malformed input data provided to the O-DU via E2/O1/FH interfaces, alongside system logs capturing the O-DU's error messages or indications in response to the invalid input.

Logs documenting the malicious input data sent to the O-DU and the targeted vulnerabilities, complemented by system logs highlighting the O-DU's detection and mitigation actions upon receiving the malicious input.

Logs of the boundary input data values provided to the O-DU, paired with system logs capturing the O-DU's messages or behaviors in response to the boundary inputs.

 STC-7-7.6-003: Near-RT RIC input validation and error handling

Requirement Name: Error handling by Near-RT RIC

Requirement Reference & Description: ‘REQ-SEC-NEAR-RT-6, REQ-SEC-NEAR-RT-7’ clause 5.1.3 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-NEAR-RT-03, T-NEAR-RT-04’ clause 7.4.1.4 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: NEAR-RT RIC

Test Name: TC_INPUT_VALIDATION_ERR_HANDL_NEAR_RT_RIC

Test description and applicability

Purpose: The purpose of this test is to verify that the Near-RT RIC performs proper input validation on provided data via O1/E2/A1/Y1 interfaces and rejects invalid or malicious inputs. It verifies that the Near-RT RIC correctly handles errors and responds appropriately.

Test setup and configuration

Near-RT RIC is powered and operational.

Test environment is set up with O1/E2/A1/Y1 interfaces configured.

Input validation mechanisms are implemented on Near-RT RIC.

Error handling mechanisms (e.g., error codes, error messages) are implemented by Near-RT RIC.

Test procedure

Case of malformed input data

The tester provides invalid or malformed input data to the Near-RT RIC via O1/E2/A1/Y1interfaces, violating the specified format or containing unexpected values.

The tester captures and analyses the response from the O1/E2/A1/Y1interfaces.

The tester verifies that the Near-RT RIC detects the invalid input and rejects it appropriately, returning an error message or taking necessary actions to mitigate the impact.

EXAMPLE: actions could be rejecting the message, sending an error indication, etc.

Case of malicious input data

The tester provides malicious input data to the Near-RT RIC, aiming to exploit known vulnerabilities (e.g., CVE database, OWASP Top Ten, NIST National Vulnerability Database (NVD), vendor-specific vulnerability database) or perform unauthorized actions.

The tester verifies that the Near-RT RIC identifies the malicious input and implements security measures to prevent exploitation, such as input sanitization, access controls, or anomaly detection.

Boundary case

Provide input data at the boundaries of the allowed range or limits defined for specific inputs.

Verify that the Near-RT RIC handles the boundary cases correctly, without encountering any unexpected behaviour or errors due to boundary conditions.

Expected Results

For case ‘malformed input data’, the Near-RT RIC properly validates incoming inputs form O1/E2/A1/Y1interfaces and rejects those with invalid or malformed data, returning an appropriate error response and preventing any potential security risks or system failures.

For case ‘malicious input data’, the Near-RT RIC detects and mitigates the malicious input, preventing any potential security breaches or unauthorized operations.

For case ‘boundary’, the Near-RT RIC properly handles the boundary cases, ensuring that inputs at the limits are processed accurately without causing any system instability or vulnerabilities.

Expected format of evidence:

Logs detailing the invalid or malformed input data provided to the Near-RT RIC via O1/E2/A1/Y1 interfaces, alongside system logs capturing the Near-RT RIC's error messages or indications in response to the invalid input.

Logs documenting the malicious input data sent to the Near-RT RIC and the targeted vulnerabilities, complemented by system logs highlighting the Near-RT RIC 's detection and mitigation actions upon receiving the malicious input.

Logs of the boundary input data values provided to the Near-RT RIC, paired with system logs capturing the Near-RT RIC 's messages or behaviors in response to the boundary inputs.

Secure configuration verification

The tests outlined in this clause aim to verify the resilience of the configuration of the O-RAN NFs against unauthorized access and modifications, emphasizing the importance of stringent security measures in the face of potential threats.

STC-7-7.7-001: O-CU secure configuration verification

Requirement Name: Secure configuration verification by O-CU

Requirement Reference & Description: ‘REQ-SEC-OCU-1’ clause 5.1.4 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-02’ clause 5.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-CU

Test Name: TC_CONF_VER_OCU

Test description and applicability

Purpose: The purpose of this test is to verify that the O-CU enforces secure configuration settings and protects against unauthorized configuration changes.

Test setup and configuration

The O-CU is powered on and operational.

Secure configuration settings are defined and applied on the O-CU.

Test procedure

Access the O-CU configuration settings

Attempt to access the O-CU configuration settings without proper authorization or credentials.

Verify that the O-CU denies access to the configuration settings and prompts for valid credentials.

Ensure that only authorized users or devices with appropriate credentials can access and modify the configuration settings.

Modification or tampering with the secure configuration settings on the O-CU

Attempt unauthorized access: Try to access and modify the secure configuration settings on the O-CU without proper authorization. This includes sending unauthorized access messages or commands to the O-CU.

Tamper with settings: If access is granted, attempt to modify, delete, or add new configuration settings that deviate from the secure baseline.

Verify that the O-CU detects any unauthorized modification or tampering attempts and rejects the modified configuration.

Ensure that the O-CU maintains the integrity and validity of the configuration settings, reverting any unauthorized changes.

Expected Results

The O-CU denies unauthorized access to the configuration settings and requests valid credentials.

The O-CU detects any unauthorized modification or tampering attempts and rejects the modified configuration, maintaining its secure configuration.

Expected format of evidence:

Document the access denial and verify the system logs or audit logs capturing the unauthorized access attempt.

Document the configuration rejection and verify the system logs or audit logs indicating the detection of unauthorized modification.

STC-7-7.7-002: O-DU secure configuration verification

Requirement Name: Secure configuration verification by O-DU

Requirement Reference & Description: ‘REQ-SEC-ODU-1’ clause 5.1.5 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-02’ clause 5.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-DU

Test Name: TC_CONF_VER_ODU

Test description and applicability

Purpose: The purpose of this test is to verify that the O-DU enforces secure configuration settings and protects against unauthorized configuration changes.

Test setup and configuration

The O-DU is powered on and operational.

Secure configuration settings are defined and applied on the O-DU.

Test procedure

Access the O-DU configuration settings

Attempt to access the O-DU configuration settings without proper authorization or credentials.

Verify that the O-DU denies access to the configuration settings and prompts for valid credentials.

Ensure that only authorized users or devices with appropriate credentials can access and modify the configuration settings.

Modification or tampering with the secure configuration settings on the O-DU

Attempt unauthorized access: Try to access and modify the secure configuration settings on the O-DU without proper authorization. This includes sending unauthorized access messages or commands to the O-DU.

Tamper with settings: If access is granted, attempt to modify, delete, or add new configuration settings that deviate from the secure baseline.

Verify that the O-DU detects any unauthorized modification or tampering attempts and rejects the modified configuration.

Ensure that the O-DU maintains the integrity and validity of the configuration settings, reverting any unauthorized changes.

Expected Results

The O-DU denies unauthorized access to the configuration settings and requests valid credentials.

The O-DU detects any unauthorized modification or tampering attempts and rejects the modified configuration, maintaining its secure configuration.

Expected format of evidence:

Document the access denial and verify the system logs or audit logs capturing the unauthorized access attempt.

Document the configuration rejection and verify the system logs or audit logs indicating the detection of unauthorized modification.

STC-7-7.7-003: O-RU secure configuration verification

Requirement Name: Secure configuration verification by O-RU

Requirement Reference & Description: ‘REQ-SEC-ORU-1, REQ-SEC-ORU-2’ clause 5.1.6 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-02’ clause 5.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU

Test Name: TC_CONF_VER_ORU

Test description and applicability

Purpose: The purpose of this test is to verify that the O-RU enforces secure configuration settings and protects against unauthorized configuration changes.

Test setup and configuration

The O-RU is powered on and operational.

Secure configuration settings are defined and applied on the O-RU.

Test procedure

Access the O-RU configuration settings

Attempt to access the O-RU configuration settings without proper authorization or credentials.

Verify that the O-RU denies access to the configuration settings and prompts for valid credentials.

Ensure that only authorized users or devices with appropriate credentials can access and modify the configuration settings.

Modification or tampering with the secure configuration settings on the O-RU

Attempt unauthorized access: Try to access and modify the secure configuration settings on the O-RU without proper authorization. This includes sending unauthorized access messages or commands to the O-RU.

Tamper with settings: If access is granted, attempt to modify, delete, or add new configuration settings that deviate from the secure baseline.

Verify that the O-RU detects any unauthorized modification or tampering attempts and rejects the modified configuration.

Ensure that the O-RU maintains the integrity and validity of the configuration settings, reverting any unauthorized changes.

Expected Results

The O-RU denies unauthorized access to the configuration settings and requests valid credentials.

The O-RU detects any unauthorized modification or tampering attempts and rejects the modified configuration, maintaining its secure configuration.

Expected format of evidence:

Document the access denial and verify the system logs or audit logs capturing the unauthorized access attempt.

Document the configuration rejection and verify the system logs or audit logs indicating the detection of unauthorized modification.

STC-7-7.7-004: Near-RT RIC secure configuration verification

Requirement Name: Secure configuration verification by Near-RT RIC

Requirement Reference & Description: ‘REQ-SEC-NEAR-RT-6, REQ-SEC-NEAR-RT-7’ clause 5.1.3 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-02’ clause 5.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: NEAR-RT RIC

Test Name: TC_CONF_VER_NEAR_RT_RIC

Test description and applicability

Purpose: The purpose of this test is to verify that the Near-RT RIC enforces secure configuration settings and protects against unauthorized configuration changes.

Test setup and configuration

The Near-RT RIC is powered on and operational.

Secure configuration settings are defined and applied on the Near-RT RIC.

Test procedure

Access the Near-RT RIC configuration settings

Attempt to access the Near-RT RIC configuration settings without proper authorization or credentials.

Verify that the Near-RT RIC denies access to the configuration settings and prompts for valid credentials.

Ensure that only authorized users or devices with appropriate credentials can access and modify the configuration settings.

Modification or tampering with the secure configuration settings on the Near-RT RIC

Attempt unauthorized access: Try to access and modify the secure configuration settings on the Near-RT RIC without proper authorization. This includes sending unauthorized access messages or commands to the Near-RT RIC.

Tamper with settings: If access is granted, attempt to modify, delete, or add new configuration settings that deviate from the secure baseline.

Verify that the Near-RT RIC detects any unauthorized modification or tampering attempts and rejects the modified configuration.

Ensure that the Near-RT RIC maintains the integrity and validity of the configuration settings, reverting any unauthorized changes.

Expected Results

The Near-RT RIC denies unauthorized access to the configuration settings and requests valid credentials.

The Near-RT RIC detects any unauthorized modification or tampering attempts and rejects the modified configuration, maintaining its secure configuration.

Expected format of evidence:

Document the access denial and verify the system logs or audit logs capturing the unauthorized access attempt.

Document the configuration rejection and verify the system logs or audit logs indicating the detection of unauthorized modification.

 Logging and monitoring

The tests outlined here aim to scrutinize the logging and monitoring capabilities of various O-RAN components, ensuring they are up to the mark and can effectively detect, log, and alert any anomalies.

STC-7-7.8-001: O-CU logging and monitoring

Requirement Name: O-CU logging and monitoring

Requirement Reference & Description: ‘REQ-SEC-OCU-1’ clause 5.1.4 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-07’ clause 5.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-CU

Test Name: TC_LOG_OCU

Test description and applicability

Purpose: The purpose of this test is to verify that the O-CU correctly logs and monitors security-related events effectively.

Test setup and configuration

The O-CU is powered on and operational.

Logging and monitoring configurations are properly set up on the O-CU.

Test procedure

Logging

The tester triggers an error or failure condition in the O-CU, such as connection attempts with invalid credentials, unauthorized access and a dropped connection.

The tester verifies that the O-CU logs the error by capturing the relevant log entry.

Monitoring

The tester monitors the key performance indicators (KPIs) of the O-CU, such as throughput, latency, or signal quality.

The tester verifies that the monitoring system accurately collects and displays the KPI values in real-time.

The tester introduces a simulated degradation or overload scenario on the O-CU, such as increasing network traffic or reducing available resources.

The tester monitors the O-CU performance under the simulated scenario.

The tester verifies that the monitoring system detects and raises alerts for the degraded performance or overload condition.

Expected Results

O-CU logs and generates alerts for security-related events, providing necessary information and timestamps for incident investigation and analysis.

The monitoring system provides accurate and real-time KPI values for the O-CU. The monitoring system detects and raises appropriate alerts for the degraded performance or overload condition.

Expected format of evidence:

Capture and analyse the logged error in the O-CU logs or logging system and document the presence of the log entry.

Document the monitored KPI values and the raised alerts, validate them against the expected values, and ensure they are triggered accurately in the monitoring system.

STC-7-7.8-002: O-DU logging and monitoring

Requirement Name: O-DU logging and monitoring

Requirement Reference & Description: ‘REQ-SEC-ODU-1’ clause 5.1.5 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-07’ clause 5.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-DU

Test Name: TC_LOG_ODU

Test description and applicability

Purpose: The purpose of this test is to ensure that the O-DU correctly logs and monitors security-related events effectively.

Test setup and configuration

The O-DU is powered on and operational.

Logging and monitoring configurations are properly set up on the O-DU.

Test procedure

Logging

The tester triggers an error or failure condition in the O-DU, such as connection attempts with invalid credentials, unauthorized access and a dropped connection.

The tester verifies that the O-DU logs the error by capturing the relevant log entry.

Monitoring

The tester monitors the key performance indicators (KPIs) of the O-DU, such as throughput, latency, or signal quality.

The tester verifies that the monitoring system accurately collects and displays the KPI values in real-time.

The tester introduces a simulated degradation or overload scenario on the O-DU, such as increasing network traffic or reducing available resources.

Th tester monitors the O-DU performance under the simulated scenario.

The tester verifies that the monitoring system detects and raises alerts for the degraded performance or overload condition.

Expected Results

O-DU logs and generates alerts for security-related events, providing necessary information and timestamps for incident investigation and analysis.

The monitoring system provides accurate and real-time KPI values for the O-DU. The monitoring system detects and raises appropriate alerts for the degraded performance or overload condition.

Expected format of evidence:

Capture and analyse the logged error in the O-DU logs or logging system and document the presence of the log entry.

Document the monitored KPI values and the raised alerts, validate them against the expected values, and ensure they are triggered accurately in the monitoring system.

STC-7-7.8-003: O-RU logging and monitoring

Requirement Name: O-RU logging and monitoring

Requirement Reference & Description: ‘REQ-SEC-ORU-1, REQ-SEC-ORU-2’ clause 5.1.6 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-07’ clause 5.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU

Test Name: TC_LOG_ORU

Test description and applicability

Purpose: The purpose of this test is to ensure that the O-RU correctly logs and monitors security-related events effectively.

Test setup and configuration

The O-RU is powered on and operational.

Logging and monitoring configurations are properly set up on the O-RU.

Test procedure

Logging

The tester triggers an error or failure condition in the O-RU, such as connection attempts with invalid credentials, unauthorized access and a dropped connection.

The tester verifies that the O-RU logs the error by capturing the relevant log entry.

Monitoring

The tester monitors the key performance indicators (KPIs) of the O-RU, such as throughput, latency, or signal quality.

The tester verifies that the monitoring system accurately collects and displays the KPI values in real-time.

The tester introduces a simulated degradation or overload scenario on the O-RU, such as increasing network traffic or reducing available resources.

Th tester monitors the O-RU performance under the simulated scenario.

The tester verifies that the monitoring system detects and raises alerts for the degraded performance or overload condition.

Expected Results

O-RU logs and generates alerts for security-related events, providing necessary information and timestamps for incident investigation and analysis.

The monitoring system provides accurate and real-time KPI values for the O-RU. The monitoring system detects and raises appropriate alerts for the degraded performance or overload condition.

Expected format of evidence:

Capture and analyse the logged error in the O-RU logs or logging system and document the presence of the log entry.

Document the monitored KPI values and the raised alerts, validate them against the expected values, and ensure they are triggered accurately in the monitoring system.

STC-7-7.8-004: Near-RT RIC logging and monitoring

Requirement Name: Near-RT RIC logging and monitoring

Requirement Reference & Description: ‘REQ-SEC-NEAR-RT-4’ clause 5.1.3 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-04’ clause 5.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: NEAR-RT RIC

Test Name: TC_LOG_NEAR_RT_RIC

Test description and applicability

Purpose: The purpose of this test is to ensure that the Near-RT RIC correctly logs and monitors security-related events effectively.

Test setup and configuration

The Near-RT RIC is powered on and operational.

Logging and monitoring configurations are properly set up on the Near-RT RIC.

Test procedure

Logging

The tester triggers an error or failure condition in the Near-RT RIC, such as connection attempts with invalid credentials, unauthorized access, or a dropped connection.

The tester verifies that the Near-RT RIC logs the error by capturing the relevant log entry.

Monitoring

The tester monitors the key performance indicators (KPIs) of the Near-RT RIC, such as throughput, latency, or signal quality.

The tester verifies that the monitoring system accurately collects and displays the KPI values in real-time.

The tester introduces a simulated degradation or overload scenario on the Near-RT RIC, such as increasing network traffic or reducing available resources.

Th tester monitors the Near-RT RIC performance under the simulated scenario.

The tester verifies that the monitoring system detects and raises alerts for the degraded performance or overload condition.

Expected Results

Near-RT RIC logs and generates alerts for security-related events, providing necessary information and timestamps for incident investigation and analysis.

The monitoring system provides accurate and real-time KPI values for the Near-RT RIC. The monitoring system detects and raises appropriate alerts for degraded performance or overload conditions.

Expected format of evidence:

Capture and analyse the logged error in the Near-RT RIC logs or logging system and document the presence of the log entry.

Document the monitored KPI values and the raised alerts, validate them against the expected values, and ensure they are triggered accurately in the monitoring system.

	System security evaluation for O-RAN component

	Overview

This chapter contains security evaluations to be performed at the system level of an O-RAN component, covering vulnerability scanning, data and information protection and system logging.

The objects in scope of these system security evaluation are SMO, Near-RT RIC, O-CU-CP, O-CU-UP, O-DU and O-RU.

	System Vulnerability Scanning

	STC-8-8.2-001: System Vulnerability Scanning

Test name: TC_Vulnerability_Scanning

Requirement Name: Robustness of OS and Applications

Requirement Reference: REQ-SEC-SYS-1 from clause 5.3.6, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: Operating System (OS) and applications vulnerability scan of O-RAN component

Threat References: T-O-RAN-01

DUT/s: SMO, Near-RT RIC, O-CU-CP, O-CU-UP, O-DU, O-RU

	Test description and applicability

Purpose: To verify the O-RAN element under test does not contain known vulnerabilities in the OS and applications.

Perform vulnerability scanning to ensure that there are no known vulnerabilities on the O-RAN component, both in the Operating System(OS) and the applications (e.g. web app from third-parties software) installed, that can be detected by means of automatic testing tools via the IP enabled network interfaces, or to identify the know vulnerabilities on the O-RAN component and have a clear mitigation plan for the ones of high severity.

Known vulnerabilities are considered those which are publicly disclosed, found by users or reported by security researchers. Those vulnerabilities are widely detected by commercial, or open-source tools designed for this purpose.

	Test setup and configuration

DUT is the O-RAN component with IP enabled network interfaces.

	Test procedure

Run the vulnerability scanning tool and check the potential known vulnerabilities existing on the O-RAN component OS and applications levels.

The severity level of the existing vulnerabilities is evaluated.

	Expected results

The O-RAN component is free from known vulnerabilities or there are security controls in place to mitigate the exploits associated with the vulnerabilities of high severity.

Expected format of evidence: Report files, log files and/or screenshots.

Data and Information Protection

void

	System logging

 Introduction

This clause contains test cases related to security log management.

 STC-8-8.4-001: Security log format and related log fields

Test Name: Validation_of_security_logs_for_date_time_and_location_field_IP_address

Requirement Name: Security logs check for date, time and location field IP address.

Requirement Reference:  SEC-CTL-SLM-FLD-1, SEC-CTL-SLM-FLD-2; [5], Clause 5.3.8.8

Requirement Description: Support for security logs containing date, time and location field IP address.

Threat References: T-O-RAN-07

DUT/s: SMO, Non-RT RIC, Near-RT RIC, O-CU-CP, O-CU-UP, O-DU, O-RU, O-Cloud

Test Description

Purpose: To verify the log fields of security log data from an O-RAN component as per clause 5.3.8.8 of Security requirement and protocol specifications [5] . The security log should have the recommended date and time in ISO 8601 format and mandatorily log the location field IP address (IP address of the host from which security events are generated).

Test setup and configuration

DUT is any O-RAN component that creates/generates security event logs which acts as server. DUT also offers one or more services through which it can be accessed.

Client is the test system equipped to communicate securely with O-RAN component and able to perform security related operations on DUT.

Test procedure

: Scenarios to be executed

Scenario ID

Configuration

1

Login to the DUT via test system with authorized credentials.

2

Execute valid operations on the DUT which triggers/generates the security logs.

Expected results

: Expected results

Scenario ID

Expected result

Reason

1

Connection established.

Authentication successful.

2

All the security logs generated by the DUT have:

1] Date and time format as per ISO 8601 format as recommended by clause 5.3.8.8 of [5]

2] Location field IP address (IP address of the DUT) as mandated by clause 5.3.8.8 of [5]

Security log generation is successful.

Expected format of evidence: Log files

 STC-8-8.4-002: Authenticated Time Stamping

Test Name: Authenticated_Time_Stamping

Requirement Name: Authenticated Time-Stamping

Requirement Reference: Clause 5.3.8.9.2.1, O-RAN Security Requirements and Controls Specification [5]

Requirement Description: Optional support NTPv4

Threat References: T-O-RAN-07

DUT/s: any element defined by O-RAN specification.

Test description and applicability

Purpose: To verify that the element fulfills the optional requirement of supporting Network Time Protocol (NTP) version 4 as specified by RFC5905 for authenticated time stamping in the client role only.

Test setup and configuration

Test prerequisites:

The element is powered on and operational.

The NTP server specified for testing is reachable and properly configured to support authenticated time stamping.

Test procedure

Verify NTP Client Version:

Access the elements configuration settings related to NTP.

Confirm that the element specifies NTP version 4 as the selected protocol.

Authentication Setup

Configure the element to use the necessary authentication methods and -credentials (AES-CMAC/RFC4493, certificates for Autokey/RFC5906) required by RFC5905 for authenticated time stamping.

Provide valid authentication credentials (certificates) for NTP communication.

Time Synchronization

Initiate an NTP time synchronization process from the element to the specified NTP server.

Monitor the communication between the element and the NTP server to ensure that the NTP packets are properly constructed with the required authentication parameters.

Verify that the element successfully receives the authenticated time stamps from the NTP server.

Time Accuracy Check

After synchronization, record the element's internal clock time.

Obtain the time from the NTP server's authenticated time stamp.

Calculate the time difference between the element's internal clock time and the received authenticated time stamp.

Ensure that the time difference is within an acceptable tolerance, considering network latency and authentication processing.

Expected results

The element fulfills the requirement of supporting Network Time Protocol (NTP) version 4 for authenticated time stamping, as specified by RFC5905. The NTP communication successfully employs the configured authentication methods, and the time synchronization process ensures accurate timekeeping within the specified tolerance. An accuracy below 1 second should be measured to pass.

Expected format of evidence: Log files, traffic captures and/or screenshots.

 STC-8-8.4-003: Network Security and System Security Events

Test Name: Network_Security_and_System_Security_Events_Logged

Requirement Name: Network Security Events to be Logged and System Security Events to be Logged.

Requirement Reference: REQ-SEC-SLM-NET-EVT-1, REQ-SEC-SLM-GEN-EVT-1, REQ-SEC-SLM-GEN-EVT-2, REQ-SEC-SLM-GEN-EVT-3, REQ-SEC-SLM-HYP-EVT-1, REQ-SEC-SLM-HYP-EVT-2, REQ-SEC-SLM-HYP-EVT-3, REQ-SEC-SLM-CON-EVT-1, REQ-SEC-SLM-CON-EVT-2, REQ-SEC-SLM-CON-EVT-3.

Requirement Description: Logging of network and system security events in O-Cloud

Threat References: T-O-RAN-01, T-O-RAN-02, T-O-RAN-03, T-O-RAN-09, T-VM-C-01, T-VM-C-02, T-VM-C-03, T-VM-C-04, T-VM-C-05, T-VM-C-06, T-IMG-01, T-IMG-02, T-ADMIN-02.

DUT/s: O-Cloud

Test Description

The security log contains log messages pertaining to network and system events that have security utility.

Purpose: The purpose of the test is to verify the logging of security events from O-Cloud as per the Security Requirements and Controls Specifications [5].

Test setup and configuration

DUT is the O-Cloud. A tester will have access to testing equipment that can connect to the O-Cloud with administrative privileges to the operating system, hypervisor, and container engine.

Test procedure

Login to the DUT via testing equipment with administrative credentials.

Execute the following operations on the DUT.

Create a new network configuration.

Modify an existing network configuration.

Disable a port.

Enable a port.

Generate packets that exceed configured firewall limits.

Generate at least one network connection.

Reboot a virtual machine and then reboot the host operating system.

Shutdown a virtual machine then shutdown the host operating system.

Create a scheduled job within the host operating systems, hypervisor, and container engine.

Make a configuration change to the host operating system and hypervisor.

Attach and detach a virtual disk to a virtual machine.

Create a virtual machine.

Start a virtual machine.

Stop a virtual machine.

Delete a virtual machine.

Add an image to the container repository.

Modify an image to the container repository.

Remove an image to the container repository.

Create a container.

Start a container.

Stop a container.

Restart a container.

Delete a container.

Create a container volume.

Mount a container volume.

Delete a container volume.

Expected results

All the security logs produced by O-Cloud contain log messages that describe the actions taken in the test procedure steps.

For test procedure step 2.1 the log message indicates the creation of a new network configuration.

For test procedure step 2.2 the log message indicates the modification of an existing network configuration.

For test procedure step 2.3 the log message indicates the disabling of a port.

For test procedure step 2.4 the log message indicates the enabling a port.

For test procedure step 2.5 the log message indicates that packets have exceeded configured firewall limits.

For test procedure step 2.6 the log message indicates a network connection has been attempted along with details about that network connection including source and destination IP addresses.

For test procedure step 2.7 the log message indicates that a virtual machine was rebooted, and a subsequent log message indicates that a host operating system has been rebooted.

For test procedure step 2.8 the log message indicates that a virtual machine has been shut down and a subsequent log message indicates that the host operating system has been shut down.

For test procedure step 2.9 the log message indicates that a scheduled job was created within the host operating system, a subsequent log message indicates that a scheduled job was created in the hypervisor, and a subsequent log message indicates that a scheduled job was created in the container engine.

For test procedure step 2.10 the log message indicates that a configuration change was made to the host operating system and a subsequent log message indicates that a configuration change was made to the hypervisor.

For test procedure step 2.11 the log message indicates that a virtual disk was attached to a virtual machine, and a subsequent log message indicates that a virtual disk was detached from a virtual machine.

For test procedure step 2.12 the log message indicates that a virtual machine was created.

For test procedure step 2.13 the log message indicates that a virtual machine was started.

For test procedure step 2.14 the log message indicates that a virtual machine was stopped.

For test procedure step 2.15 the log message indicates that a virtual machine was deleted.

For test procedure step 2.16 the log message indicates that an image was added to the container repository.

For test procedure step 2.17 the log message indicates that an image was modified in the container repository.

For test procedure steps 2.18 the log message indicates that an image was removed from the container repository.

For test procedure step 2.19 the log message indicates a container was created.

For test procedure step 2.20 the log message indicates that a container was started.

For test procedure step 2.21 the log message indicates that a container was stopped.

For test procedure step 2.22 the log message indicated that a container was restarted.

For test procedure step 2.23 the log message indicates that a container was deleted.

For test procedure step 2.24 the log message indicates that a container volume was created.

For test procedure step 2.25 the log message indicates that a container volume was mounted.

For test procedure step 2.26 the log message indicates that a container volume was deleted.

Expected format of evidence: Generated Log Files from DUT/s.

 STC-8-8.4-004: Application Security Events

Test Name: Application_Security_Events_Logged

Requirement Name: Application Security Events to be Logged.

Requirement Reference: REQ-SEC-SLM-APP-EVT-1, REQ-SEC-SLM-APP-EVT-2.

Requirement Description: Support for the logging of security events in network functions

Threat References: T-OPENSRC-01, T-xAPP-01, T-xAPP-02, T-xAPP-03, T-xAPP-04, T-rAPP-01, T-rAPP-02, T-rAPP-03, T-rAPP-04, T-rAPP-05, T-rAPP-06, T-rAPP-07, T-PNF-01.

DUT/s: Near-RT RIC, O-CU-CP, O-CU-UP, O-DU, O-RU.

Test Description

The security log contains log messages pertaining to application events that have security utility.

Purpose: The purpose of the test is to verify the logging of security event data from O-RAN Network Functions as per the Security Requirements and Controls Specifications [5].

Test setup and configuration

DUT is any O-RAN network function, i.e., Near-RT RIC, O-CU-CP, O-CU-UP, O-DU, O-RU. A tester will have access to testing equipment that can connect to any O-RAN network function.

Test procedure

	NOTE 1: Test procedure steps not applicable to the DUT may be skipped.

	Login to the DUT via test equipment with authorized credentials.

	Conduct an operation on the DUT that is known to generate an error.

	Conduct an operation on the DUT that is known to load a dynamic library.

Expected results

All the security logs produced by O-RAN Network Functions contain log messages that pertain to the actions taken in the test procedure steps.

For test procedure step 2 the log message contains an error message.

For test procedure step 3 the log message contains a message indicating that a dynamic library loaded and details about that library.

Expected format of evidence: Generated Log Files from DUT/s.

 STC-8-8.4-005: Data Access Security Events

Test Name: Data_Access_Security_Events_Logged

Requirement Name: Data Access Security Events to be Logged.

Requirement Reference: REQ-SEC-SLM-DAT-EVT-1, REQ-SEC-SLM-DAT-EVT-2, REQ-SEC-SLM-DAT-EVT-3, REQ-SEC-SLM-DAT-EVT-4, REQ-SEC-SLM-DAT-EVT-5, REQ-SEC-SLM-DAT-EVT-6, REQ-SEC-SLM-DAT-EVT-7, REQ-SEC-SLM-DAT-EVT-8.

Requirement Description: Logging of data access security events in O-RAN elements.

Threat References: T-VM-C-01, T-NEAR-RT-03, T-O-RAN-07, T-O-RAN-08, T-GEN-05

DUT/s: SMO, Non-RT RIC, Near-RT RIC, O-CU-CP, O-CU-UP, O-DU, O-RU, O-Cloud

Test Description

The security log contains log messages pertaining to data access that have security utility.

Purpose: The purpose of the test is to verify the logging of data access security events from O-RAN elements as per the Security Requirements and Controls Specifications [5].

Test setup and configuration

A tester will have access to testing equipment that can communicate securely with the DUT and is able to perform security and administrative related operations.

Test procedure

NOTE 1: Test procedure steps not applicable to the DUT may be skipped.

Login to the DUT via testing equipment with authorized credentials.

Execute the following operations on the DUT.

Add a new file.

Delete an existing file.

Attempt to add a file where you are not authorized to do so.

Attempt to delete a file where you are not authorized to do so.

Read an existing file.

Write to an existing file.

Attempt to read to a file where you are not authorized to do so.

Attempt to write to a file where you are not authorized to do so.

Create a new directory.

Delete an existing directory.

Attempt to create a directory where you are not authorized to do so.

Attempt to delete a directory where you are not authorized to do so.

Add data to a datastore or database.

Delete data from a datastore or database.

Attempt to add data to a datastore or database where you are not authorized to do so.

Attempt to delete data from a datastore or database where you are not authorized to do so.

Read data from a datastore or database.

Write data from a datastore or database.

Attempt to read data from a datastore or database where you are not authorized to do so.

Attempt to write data to a datastore or database where you are not authorized to do so.

Make a permissions change to a file.

Make a permissions change to a directory.

Make a permissions change to a datastore or database.

Expected results

All the security logs produced by O-RAN elements contain log messages that document appropriately the actions taken in the test procedure steps.

For test procedure step 2.1 the log message indicates that a new file was added.

For test procedure step 2.2 the log message indicates an existing file was deleted.

For test procedure step 2.3 the log message indicates an unauthorized attempt to add a file.

For test procedure step 2.4 the log message indicates an unauthorized attempt to delete a file.

For test procedure step 2.5 the log message indicates an existing file was read.

For test procedure step 2.6 the log message indicates an existing file was written.

For test procedure step 2.7 the log message indicates an unauthorized attempt to read to a file.

For test procedure step 2.8 the log message indicates an unauthorized attempt to write to a file.

For test procedure step 2.9 the log message indicates a new directory was created.

For test procedure step 2.10 the log message indicates an existing directory was deleted.

For test procedure step 2.11 the log message indicates an unauthorized attempt to create a directory.

For test procedure step 2.12 the log message indicates an unauthorized attempt to delete a directory.

For test procedure step 2.13 the log message indicates data was added to a datastore or database.

For test procedure step 2.14 the log message indicates data was deleted from a datastore or database.

For test procedure step 2.15 the log message indicates an unauthorized attempt to add data to a datastore or database.

For test procedure step 2.16 the log message indicates an unauthorized attempt to delete data from a datastore or database.

For test procedure step 2.17 the log message indicates that data was read from a datastore or database.

For test procedure step 2.18 the log message indicates that data was written to a datastore or database.

For test procedure step 2.19 the log message indicates an unauthorized attempt to read data from a datastore or database.

For test procedure step 2.20 the log message indicates an unauthorized attempt to write data to a datastore or database.

For test procedure step 2.21 the log message indicates a permissions change to a file.

For test procedure step 2.22 the log message indicates a permissions change to a directory.

For test procedure step 2.23 the log message indicates a permissions change to a datastore or database.

Expected format of evidence: Generated Log Files from DUT.

 STC-8-8.4-006: Account and Identity Security Events

Test Name: Account_and_Identity_Security_Events_Logged

Requirement Name: Account and Identity Security Events to be Logged.

Requirement Reference: REQ-SEC-SLM-AAI-EVT-1, REQ-SEC-SLM-AAI-EVT-2, REQ-SEC-SLM-AAI-EVT-3, REQ-SEC-SLM-AAI-EVT-4, REQ-SEC-SLM-AAI-EVT-5, REQ-SEC-SLM-AAI-EVT-6, REQ-SEC-SLM-AAI-EVT-7, REQ-SEC-SLM-AAI-EVT-8, REQ-SEC-SLM-AAI-EVT-9, REQ-SEC-SLM-AAI-EVT-10.

Requirement Description: Logging of account and identity security events in O-RAN elements.

Threat References: T-GEN-02, T-O-RAN-02, T-O-RAN-06, T-O-RAN-07, T-ProtocolStack-02, T-SMO-02, T-SMO-05, T-SMO-08, T-SMO-25, T-SMO-30, T-NEAR-RT-03.

DUT/s: SMO, Non-RT RIC, Near-RT RIC, O-CU-CP, O-CU-UP, O-DU, O-RU, O-Cloud

Test Description

The security log contains log messages pertaining to account and identity events that have security utility.

Purpose: The purpose of the test is to verify the logging of account and identity access security events from O-RAN elements as per Security Requirements and Controls Specifications [5]

Test setup and configuration

A tester will have access to testing equipment that can communicate securely with the DUT and is able to perform security and administrative related operations.

Test procedure

NOTE 1: Test procedure steps not applicable to the DUT may be skipped.

Login to the DUT via testing equipment with authorized credentials.

Execute the following operations on the DUT.

Create an account.

Modify an existing account.

Delete an existing account.

Attempt to create an account where you are not authorized to do so.

Change the privilege level of an existing account from a lower privilege to a higher privilege.

Attempt to change the privilege level of an existing account where you are not authorized to do so.

Change the group membership of an existing account.

Attempt to change the group membership of an existing account where you are not authorized to do so.

Use a function in the DUT that requires a specific authorization that you have been assigned.

Attempt to use a function in the DUT that requires a specific authorization that you have not been assigned.

Authenticate an account to the DUT that has been configured to access that DUT.

Attempt to authenticate an account to the DUT that has not been configured to access that DUT.

Change the privilege level of an existing account from a higher privilege to a lower privilege.

Access the DUT with an account the does not require authentication.

End a session with the DUT.

Expected results

All the security logs produced by O-RAN elements contain log messages that document appropriately the actions taken in the test procedure steps.

For test procedure step 2.1 the log message indicates that an account was created.

For test procedure step 2.2 the log message indicates that an existing account was modified.

For test procedure step 2.3 the log message indicates that an existing account was deleted.

For test procedure step 2.4 the log message indicates an unauthorized attempt to create an account.

For test procedure step 2.5 the log message indicates a privilege level change of an existing account from a lower privilege to a higher privilege.

For test procedure step 2.6 the log message indicates an unauthorized attempt to change the privilege level of an existing account.

For test procedure step 2.7 the log message indicates that the group membership had changed for an existing account.

For test procedure step 2.8 the log message indicates an unauthorized attempt to change the group membership of an existing account.

For test procedure step 2.9 the log message indicates the use of a restricted function.

For test procedure step 2.10 the log message indicates an unauthorized attempt to use a restricted function.

For test procedure step 2.11 the log message indicates the successful authentication of an account.

For test procedure step 2.12 the log message indicates the unsuccessful attempt to authenticate an account.

For test procedure step 2.13 the log message indicates a privilege level change of an existing account from a higher privilege to a lower privilege.

For test procedure step 2.14 the log message indicates access with an account the does not require authentication.

For test procedure step 2.15 the log message indicates the end of a session.

Expected format of evidence: Generated Log Files from DUT.

 STC-8-8.4-007: General Security Events

Test Name: General_Security_Events_Logged

Requirement Name: General Security Events to be Logged.

Requirement Reference: REQ-SEC-SLM-GEN-EVT-1, REQ-SEC-SLM-GEN-EVT-2, REQ-SEC-SLM-GEN-EVT-3, REQ-SEC-SLM-GEN-EVT-4, REQ-SEC-SLM-GEN-EVT-5, REQ-SEC-SLM-GEN-EVT-6.

Requirement Description: Logging of general security events in O-RAN elements.

Threat References: T-ORAN-01, T-O-RAN-02, T-O-RAN-03, T-O-RAN-08, T-GEN-02, T-VM-C-01, T-VM-C-04, T-VM-C-06, T-IMG-01, T-IMG-04, T-VL-01, T-VL-02, T-xAPP-01, T-rAPP-03, T-HW-02.

DUT/s: SMO, Non-RT RIC, Near-RT RIC, O-CU-CP, O-CU-UP, O-DU, O-RU, O-Cloud

Test Description

The security log contains log messages pertaining to general security events.

Purpose: The purpose of the test is to verify the logging of general security events from O-RAN elements as per the Security Requirements and Controls Specifications [5]

Test setup and configuration

A tester will have access to testing equipment that can communicate securely with the DUT and is able to perform security and administrative related operations.

Test procedure

NOTE 1: Test procedure steps not applicable to the DUT may be skipped.

Login to the DUT via testing equipment with authorized credentials.

Execute the following operations on the DUT.

Enable security software such as firewalls, malware protection, data loss prevention or intrusion detection systems.

Disable security software such as firewalls, malware protection, data loss prevention or intrusion detection systems.

Log into DUT using an account with administrative privileges and perform a function that requires those privileges.

Make a change to the security configuration of the DUT.

View a certificate or key on the DUT.

Export a certificate or key from the DUT.

Renew a certificate or key on the DUT.

Import a certificate or key from the DUT.

Modify a certificate or key on the DUT.

Delete a certificate or key from the DUT.

Perform a cryptographic operation on the DUT that involves signatures, encryption, hashing, key generation or key destruction.

Submit a security patch to the DUT but do not apply it.

Expected results

All the security logs produced by O-RAN elements contain log messages that document appropriately the actions taken in the test procedure steps.

For test procedure steps 2.1 and 2.2 the log message indicates that the security software has been enabled or disabled.

For test procedure step 2.3 the log message indicates the use of administrative privileges.

For test procedure step 2.4 the log message indicates that a change to the security configuration has occurred and the nature of the change.

For test procedures 2.5 through 2.11 the log message is absent of any sensitive information related to the certificate or key.

For test procedure 2.12 the log message indicates that a security patch was submitted but not applied.

Expected format of evidence: Generated Log Files from DUT.

 STC-8-8.4-008: Storage

Test Name: Validation_of_secure_storage_of_security_log_data

Requirement Name: Secure storage of security log data

Requirement Reference:  SEC-CTL-SLM-SST-1, SEC-CTL-SLM-SST-2, O-RAN.WG11.Security Requirements and Controls Specification [5], Clause 5.3.8.5

Requirement Description: Support for secure storage of security log data

Threat References: T-O-RAN-07, T-O-RAN-08

DUT/s: Centralized log server

Test Description

Purpose:  To verify whether the storage of security logs is tamper-proof in centralized log servers as per clause 5.3.8.5 of [5]. These storages can be centralized logging servers or cloud-based services.

Test setup and configuration

DUT is the centralized log server where security log data from the O-RAN components are stored. Client is the test system equipped to communicate securely with the DUT.

Preconditions:

The log storage system (Centralized log server) is implemented and operational.

User accounts with appropriate access levels have been provisioned on the DUT.

A list of authorized personnel who should have access to the log system have been identified and documented.

Test procedure

: Scenarios to be executed

Scenario ID

Configuration

1

Login to the DUT via test system with authorized credentials.

2

Create a test account with unauthorized/Invalid credentials and attempt login access to the DUT.

3

Create a test account with insufficient privileges and attempt login access to the DUT.

4

Create a test account with the revoked account (if any earlier account got revoked on DUT) and attempt login access to the DUT.

5

Attempt login access to the DUT with authorized credentials after attempting with revoked account.

Expected results

: Expected results

Scenario ID

Expected result

Reason

1

Connection established.

Success event is logged by the DUT, and the log fields are as per clause 5.3.8.8 of [5]

Authentication successful.

2

Connection not established.

Failure event is logged by the DUT, and the log fields are as per clause 5.3.8.8 of [5]

Authentication failure due to invalid credentials.

3

Connection not established.

Failure event is logged by the DUT, and the log fields are as per clause 5.3.8.8 of [5]

Authentication failure due to insufficient privileges

4

Connection not established.

Failure event is logged by the DUT, and the log fields are as per clause 5.3.8.8 of [5]

Authentication failure due to invalid credentials

5

Connection established.

Success event is logged by the DUT, and the log fields are as per clause 5.3.8.8 of [5]

Authentication successful

Expected format of evidence: Log files

	Software security evaluation for O-RAN components

	Overview

This chapter contains a set of software security evaluations of an O-RAN component, covering Software Lifecycle Management.

The objects in scope of these software security evaluation are SMO, Near-RT RIC, O-CU-CP, O-CU-UP, O-DU and O-RU.

	Open-Source Software Component Analysis

void

	Binary Static Analysis

void

	Software Bill of Materials (SBOM)

	STC-9-9.4-001: SBOM Signature

Test name: TC_SBOM_Signature

Requirement Name: A digital signature is provided for the SBOM.

Requirement Reference: REQ-SBOM-007, REQ-SBOM-011, clause 6.3.1, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: SBOM is authenticity, integrity protected and provided in a standard format.

Threat References: T-O-RAN-09

DUT/s: SMO, Near-RT RIC, O-CU-CP, O-CU-UP, O-DU, O-RU, rApp, xApp

	Test description and applicability

Open RAN software producers shall provide the SBOM for every O-RAN software delivery, including patches, to the network operator. SBOM shall be digitally signed.

Purpose: To verify the SBOM is provided with a digital signature

	Test setup and configuration

SBOM is provided. Tools to verify the SBOM are available.

	Test procedure

Introduction

Ensure the SBOM is provided with a digital signature in the format as described below. Verify SBOM digital signature is valid using the software provider’s public key or certificate. Depending on the format of the SBOM, there are various ways how to include and verify the digital signature of the SBOM. Below, the digital signature methods are detailed.

SPDX

YAML, RDF and tag data: The signature is in a separate file from the SPDX file (Example: foo.spdx has foo.spdx.sig containing it's signature). Digital signature format shall be CMS/PKCS#7/CAdES.

XML: XML Signature 2.0

JSON: JSON Web Signature (JWS), and JSON Signature Format (JSF).

CycloneDX

XML: XML Signature 2.0

JSON: JSON Web Signature (JWS), and JSON Signature Format (JSF).

SWID

XML: XML Signature 2.0

	Expected results

Digital signature of the SBOM shall be valid.

Expected format of evidence: Log file, screenshot, or report file.

	STC-9-9.4-002: SBOM Data Fields

Test name: TC_SBOM_Data_Fields

Requirement Name: Data fields are according to NTIA guidance [13]

Requirement Reference: REQ-SBOM-002, REQ-SBOM-011, clause 6.3.1, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: A minimum set of data fields are included in the SBOM and it is in an standard format.

Threat References: T-O-RAN-09

DUT/s: SMO, Near-RT RIC, O-CU-CP, O-CU-UP, O-DU, O-RU, rApp, xApp

	Test description and applicability

Open RAN software producers shall provide the SBOM for every O-RAN software delivery to the network operator, including patches. Minimum set of the data fields shall be present. Purpose of the test is to verify that the minimum set of the data fields are present in SBOM.

Purpose: To verify the minimum set of data fields are included in the SBOM

	Test setup and configuration

SBOM file is provided. Tools to verify the data fields are available.

	Test procedure

Run the SBOM check tool and verify that there is minimum set of data fields present in SBOM depending on the SBOM format used.

Table 91: Minimum set of data fields for SPDX [12]

NTIA field

NTIA description

SPDX 2.2.1 field

Supplier Name

The name of an entity that creates, defines, and identifies components

PackageSupplier

Component Name

Designation assigned to a unit of software defined by the original supplier

PackageName

Version of the Component

Identifier used by the supplier to specify a change in software from a previously identified version

PackageVersion

Other Unique Identifiers

Other identifiers that are used to identify a component, or serve as a look-up key for relevant databases

SPDXID (Package SPDX Identifier)

Dependency Relationship

Characterizing the relationship that an upstream component X is included in software Y

Relationship: CONTAINS

Author of SBOM Data

The name of the entity that creates the SBOM data for this component

Creator

Timestamp

Record of the date and time of the SBOM data assembly

Created

Table 92: Minimum set of data fields for CycloneDX [13]

NTIA field

NTIA description

CycloneDX field

Supplier Name

The name of an entity that creates, defines, and identifies components

publisher

Component Name

Designation assigned to a unit of software defined by the original supplier

name

Version of the Component

Identifier used by the supplier to specify a change in software from a previously identified version

version

Other Unique Identifiers

Other identifiers that are used to identify a component, or serve as a look-up key for relevant databases

bom/serialNumber and component/bom-ref

Dependency Relationship

Characterizing the relationship that an upstream component X is included in software Y

(Nested assembly/subassembly and/or dependency graphs)

Author of SBOM Data

The name of the entity that creates the SBOM data for this component

bom-descriptor:metadata/
manufacture/contact

Timestamp

Record of the date and time of the SBOM data assembly

timestamp

Table 93: Minimum set of data fields for SWID [13]

NTIA field

NTIA description

SWID tag

Supplier Name

The name of an entity that creates, defines, and identifies components

<Entity> @role
(softwareCreator/publisher),
@name

Component Name

Designation assigned to a unit of software defined by the original supplier

<softwareIdentity> @name

Version of the Component

Identifier used by the supplier to specify a change in software from a previously identified version

<softwareIdentity> @version

Other Unique Identifiers

Other identifiers that are used to identify a component, or serve as a look-up key for relevant databases

<softwareIdentity> @tagID

Dependency Relationship

Characterizing the relationship that an upstream component X is included in software Y

<Link> @rel, @href

Author of SBOM Data

The name of the entity that creates the SBOM data for this component

<Entity> @role (tagCreator), @name

Timestamp

Record of the date and time of the SBOM data assembly

-

This test is part of the O-RAN software producer’s Software Development Lifecycle (SDLC).

	Expected results

Minimum set of data fields are present.

Expected format of evidence: Log file, screenshot, or report file.

9.4.3  STC-9-9.4-003: SBOM Format

Test name: TC_SBOM_Format

Requirement Name: SBOM is provided in one of the accepted formats: SPDX, CycloneDX, or SWID.

Requirement Reference: REQ-SBOM-11, clause 6.3.1, O-RAN Security Requirements and Controls Specification [5]

Requirement Description: SBOM is provided in a standard format.

Threat References: T-O-RAN-09

DUT/s: SMO, Near-RT RIC, O-CU-CP, O-CU-UP, O-DU, O-RU, rApp, xApp

9.4.3.1 Test description and applicability

Open RAN software producers shall provide the SBOM for every O-RAN software delivery in one of three accepted formats: Software Package Data eXchange (SPDX) [i.2], CycloneDX [i.3], or Software Identification (SWID) [i.4] formats.

Purpose: To verify that the SBOM is provided in one of these formats.

9.4.3.2 Test setup and configuration

SBOM file provided for the O-RAN software delivery, and the SBOM check tool is available.

9.4.3.3 Test procedure

 Run the SBOM check tool to verify the SBOM format.

9.4.3.4 Expected results

SBOM format is SDPX, CycloneDX, or SWID.

Expected format of evidence: Screenshots and/or report file.

9.4.4  STC-9-9.4-004: SBOM Depth

Test name: TC_SBOM_Depth

Requirement Name: SBOM Depth is in the required level.

Requirement Reference: REQ-SBOM-004, REQ-SBOM-005, REQ-SBOM-006, clause 6.3.1, O-RAN Security Requirements and Controls Specification [5]

Requirement Description: The SBOM Depth is the required for the different types of software.

Threat References: T-O-RAN-09

DUT/s: SMO, Near-RT RIC, O-CU-CP, O-CU-UP, O-DU, O-RU, rApp, xApp

9.4.4.1 Test description and applicability

Open RAN software producers provide the SBOM for every O-RAN software delivery, including patches, to the network operator. SBOM depth is provided at top-level for every O-RAN software delivery, and SBOM depth is provided to a second-level for any O-RAN Software Community or open source software.

Purpose: To verify that the SBOM depth is provided to the level specified.

9.4.4.2 Test setup and configuration

SBOM file provided for the O-RAN software delivery, and the SBOM check tool is available.

9.4.4.3 Test procedure

Run the SBOM check tool to verify the SBOM depth provided.

At a minimum, all top-level dependencies are listed.

9.4.4.4 Expected results

SBOM depth is as specified in the requirements:

top-level for every O-RAN software delivery

second level for any O-RAN Software Community or open-source software.

Expected format of evidence: Log file, screenshot, or report file.

 STC-9-9.4-005: SBOM completeness check

Requirement Name: The SBOM for each O-RAN NF shall comprehensively and accurately list all sub-components, libraries, and dependencies to ensure a complete representation of the software composition.

Requirement Reference & Description: ‘REQ-SBOM-002’ clause 6.3 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-08, T-O-RAN-09’ clause 7.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU, O-CU, Near-RT RIC, xApp, rApp, Non-RT RIC, SMO, O-Cloud

Test Name: TC_SBOM_COMPLETENESS_CHECK

Test Description and Applicability

Purpose: The purpose of this test is to validate that the SBOM for each component comprehensively lists all sub-components, libraries, and dependencies.

Test Setup and Configuration

Tools: SBOM validation tools, manual review tools.

Data: Access to each component's SBOM.

Test Procedure

Open and review each SBOM.

Ensure that all sub-components, libraries, and dependencies are listed.

Cross-reference the SBOM with the actual component to verify no elements are omitted.

Document any discrepancies or missing elements.

Expected Results:

The SBOM for each component is complete, with no omissions.

Expected format of evidence:

A report detailing:

Each component and its SBOM.

Any discrepancies or missing elements.

Recommendations for SBOM completion.

 STC-9-9.4-006: SBOM version verification

Requirement Name: The version in the SBOM shall accurately match the actual O-RAN NF version.

Requirement Reference & Description: ‘REQ-SBOM-002’ clause 6.3 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-08, T-O-RAN-09’ clause 7.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU, O-CU, Near-RT RIC, xApp, rApp, Non-RT RIC, SMO, O-Cloud

Test Name: TC_SBOM_VERSION_VERIFICATION

Test Description and Applicability

Purpose: The purpose of this test is to ensure the SBOM reflects the current version of the component.

Test Setup and Configuration

Tools: Version control systems, manual review tools.

Data: Inventory of all O-RAN components, their versions, and their SBOMs.

Test Procedure:

For each component, compare the version listed in the SBOM with the actual component version.

Ensure that the SBOM's version matches the component's version.

Document any discrepancies.

Expected Results:

The version specified in the SBOM aligns with the actual version of the component.

Expected format of evidence:

A report detailing:

Each component, its version, and its SBOM version.

Any discrepancies between the two versions.

Recommendations for version alignment.

 STC-9-9.4-007: SBOM vulnerability cross check

Requirement Name: All components listed in the SBOM shall be checked against known vulnerability databases to identify and document any associated security risks.

Requirement Reference & Description: ‘REQ-SBOM-003’ clause 6.3 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-08, T-O-RAN-09’ clause 7.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU, O-CU, Near-RT RIC, xApp, rApp, Non-RT RIC, SMO, O-Cloud

Test Name: TC_SBOM_VULN_CROSS_CHECK

Test Description and Applicability

Purpose: The purpose of this test is to cross-reference the components listed in the SBOM with known vulnerability databases.

Test Setup and Configuration:

Tools: Vulnerability scanning tools like NVD, Snyk, or OWASP Dependency-Check.

Data: Access to each component's SBOM.

Test Procedure:

Extract a list of components and their versions from the SBOM.

Use the vulnerability scanning tool to check for known vulnerabilities associated with each component/version.

Document any vulnerabilities found, noting their severity and potential impact.

Expected Results:

A list of vulnerabilities, if any, associated with the components listed in the SBOM.

Expected format of evidence:

A comprehensive report detailing:

Each component and its version from the SBOM.

Vulnerabilities found.

Severity and potential impact of each vulnerability.

Recommendations for mitigation or patching.

 STC-9-9.4-008: SBOM Delivery

Test Name: SBOM_Delivery_with_O-RAN_Software

Requirement Name: SBOM provided with all O-RAN Software.

Requirement Reference: REQ-SBOM-001, Clause 6.3, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: The O-RAN vendor shall provide the SBOM with every O-RAN software delivery package, including patches.

Threat References: T-O-RAN-09

DUT/s: O-RU, O-DU, O-CU, Near-RT RIC, xApp, rApp, Non-RT RIC, SMO, O-Cloud

Test description and applicability

Purpose: The purpose of this test is to ensure that every O-RAN component is accompanied by an SBOM. This is applicable to all components within the O-RAN system.

Test setup and configuration

Tools: File explorer, documentation access tools, or automated SBOM detection tools.

Environment: A repository or directory containing all O-RAN components and their associated documentation or metadata.

Data: Inventory of all O-RAN components.

Test procedure

Navigate to the directory or repository of each O-RAN component.

Look for associated files or documentation indicating the presence of an SBOM.

Validate the SBOM's content to ensure it's not just a placeholder.

Document any components that lack a genuine SBOM.

Expected Results

Every O-RAN component has a genuine SBOM associated with it.

Expected Format of Evidence:

A spreadsheet or report detailing:

Each component.

Status of its SBOM (Present/Absent).

Notes on any discrepancies or issues found.

 STC-9-9.4-009 SBOM Vulnerabilities Field

Test Name: SBOM_Vulnerabilities_Fields

Requirement Name: Vulnerabilities field omission in SBOMs.

Requirement Reference: REQ-SBOM-003, Clause 6.3, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: Vulnerabilities shall not be included as an additional data field because it would represent a static view from a specific point in time, while vulnerabilities are constantly evolving.

Threat References: T-O-RAN-09

DUT/s: O-RU, O-DU, O-CU, Near-RT RIC, xApp, rApp, Non-RT RIC, SMO, O-Cloud

Test description and applicability

Vulnerabilities fields in an SBOM represent a snapshot of vulnerabilities present in the SBOM at a particular moment in time. Therefore, the vulnerabilities field in SBOM for O-RAN software should not be relied upon to determine the SBOM vulnerabilities by the operator. Operators should perform their own vulnerability assessment.

Purpose: Verify that vulnerabilities fields is not included as an additional field to the SBOM.

Test setup and configuration

SBOM file shall be provided for the O-RAN software delivery, and the SBOM check tool shall be available.

Test procedure

1.  Access the SBOM file provided by the Solution Provider.

2. Verify that no vulnerabilities fields exist within the SBOM.

Expected Results

There are no vulnerabilities field(s) present in the SBOM.

Expected Format of Evidence: screenshot(s)

 STC-9-9.4-010: SBOM OSC Components

Test Name: SBOM_OSC_Components

Requirement Name: Verify OSC components included in SBOM for commercial software which uses O-RAN OSC components.

Requirement Reference: REQ-SBOM-008, Clause 6.3, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: Commercial software vendors using software from the O-RAN Software Community (OSC) shall provide an SBOM that includes the components used from the OSC.

Threat References: T-O-RAN-09

DUT/s: O-RU, O-DU, O-CU, Near-RT RIC, xApp, rApp, Non-RT RIC, SMO, O-Cloud

Test description and applicability

Purpose: Verify that commercial software containing O-RAN OSC components is associated with an SBOM with O-RAN OSC components listed.

Test setup and configuration

Commercial Software with OSC component(s) SBOM file shall be provided for the O-RAN software delivery, and the SBOM check tool shall be available.

Test procedure

1. Access the SBOM file provided by the Solution Provider.

2. Verify the SBOM is for the commercial software.

3. Verify O-RAN Software Community component(s) are listed in the SBOM.

Expected Results

OSC components present in the SBOM.

Expected Format of Evidence: screenshot(s)

	Software Image Signing and Verification

	STC-9-9.5-001: Software Image/Application Package Signing

Test Name: SW_Img_Pkg_Signing

Requirement Name: Any software image(s) of O-RAN components and/or apps shall be digitally signed by its provider for distribution and by the Service Provider for internal publishing.

Requirement Reference: REQ-SEC-ALM-PKG-2, REQ-SEC-ALM-PKG-4, Clause 5.3.2, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: Application package shall be signed and verified for integrity and authenticity protection.

Threat References: T-IMG-01, T-VM-C-02, T-Near-RT-01, T-Near-RT-02, T-xAPP-02, T-rAPP-05

DUT/s: O-RU, O-DU, O-CU, Near-RT RIC, xApp, rApp, Non-RT RIC, SMO, O-Cloud

	Test description and applicability

Open RAN software producer/provider shall provide digitally signed image or Application package for its delivery, including new version and/or patches, to the Service Provider. Service Provider shall digitally sign the verified image or Application package delivered by the software producer for publishing into its catalog visible to SMO.

Purpose: Ensure O-RAN software image or application package is digitally signed.

	Test setup and configuration

Software image or Application package ready for signing.

	Test procedure

Manually or using a software signing service, sign the image or Application package for distribution by software producer or internally published by the Service Provider. The following steps are to be followed:

Generate key-pair: ephemeral key pair (prime256v1) is preferred

private key (and public key if certificate is used) deletion asap

Request for Signing Certificate: Optional, preferred short-lived certificate

Image or Application package hash and signing: SHA256 or stronger

Upload image or Application package and its digital signature(s) for distribution or publish.

	Expected results

The provider’s digital signature of the software image or Application package shall be present in the image repository for distribution from software producer; and Service Provider digital signature of the software image or Application package shall be present in the catalogue published by the O-RAN operator.

Expected Format of Evidence: screenshot(s)

	STC-9-9.5-002: Software Signature Verification

Test Name: SW_Img_Pkg_Verification

Requirement Name: Any software image(s) of O-RAN component(s) and/or app(s) shall be verified for its signature(s) by the operator for onboarding and/or instantiation process.

Requirement Reference: REQ-SEC-ALM-PKG-5, REQ-SEC-ALM-PKG-6, Clause 5.3.2, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: Application package shall be signed and verified for integrity and authenticity protection.

Threat References: T-IMG-01, T-VM-C-02, T-Near-RT-01, T-Near-RT-02, T-xAPP-02

DUT/s: O-RU, O-DU, O-CU, Near-RT RIC, xApp, rApp, Non-RT RIC, SMO, O-Cloud

	Test description and applicability

O-RAN software image(s) or Application package distributed by the software producer/provider shall be authenticated by the Service Provider during the onboarding process with its signature verified. Both provider and Service Provider signatures of the O-RAN software image(s) or Application package shall be verified during the instantiation process.

Purpose: Ensure signatures on O-RAN software image or application package are verified.

	Test setup and configuration

Digitally signed software image or Application package with shared necessary digital certificates or public key shall be validated.

EXAMPLE: Root CA certificate, any intermediate or RA certificates.

	Test procedure

The signature of the software image or Application package shall be verified manually or using a software signing service. The software used to verify the signature(s) could be provided by software producer or internally published by the Service Provider.

For image or Application package instantiation, Service Provider signature of the software image or Application package verification shall be executed first, followed by provider signature verification.

	Expected results

The provider signature verification for software image or Application package during onboarding shall be successful. The Service Provider and provider signatures verification for image or Application instantiation shall be successful.

Expected Format of Evidence: screenshot(s)

	ML security validation for O-RAN system

	Overview

AI/ML technologies and models are adopted at the O-RAN system Non-RT RIC and Near-RT RIC to enable O-RAN use cases: traffic steering, massive MIMO optimization, radio resource allocation for UAV applications, position accuracy enhancement, beam management, and enhance CSI feedback. Other uses cases could be checked in document O-RAN Use Cases Detailed Specification [22].

	ML Data Poisoning

Void

	Security tests of O-RAN interfaces

FH

	Overview

This chapter contains security tests to validate the security protection mechanism of the O-RAN open fronthaul interface.

	Open Fronthaul Point-to-Point LAN Segment

IEEE 802.1X-2020 Port-based Network Access Control [11] provides the means to control network access in point-to-point LAN segments within the Open Fronthaul network. Port-based network access control in the O-RAN Alliance Open Fronthaul comprises supplicant, authenticator, and authentication of server entities described in IEEE 802.1X-2020 [11].

The security test cases in this clause cover the validation of the authenticator and supplicant functionalities of the 802.1X, affecting to all the elements acting as an O-RAN Open Fronthaul network elements, including but not limited to, O-DU, O-RU, switches, FHM, FHGW, TNE and PRTC-T/GM as defined in clause 5.2.5.5 of Security Requirements and Controls Specifications [5].

	STC-11-11.1-001: Authenticator Validation

Test name: TC_Authenticator_Validation

Requirement Name: Authenticator function of O-RAN component

Requirement Reference: REQ-SEC-OFHPLS-1, REQ-SEC-OFHPLS-2 and REQ-SEC-OFHPLS-3 from clause 5.2.5.5.1, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: Requirements of Authenticators in the open fronthaul network and its interface to an Authentication Server

Threat References: T-FRHAUL-02

DUT/s: All the functions with Open Fronthaul functionalities, including but not limited to: O-RU, O-DU, switches, FHM, FHGW, TNE and PRTC/T-GM.

	Test description and applicability

Purpose: To verify and validates the authenticator requirements of the network component to serve the request from supplicant(s) using EAP TLS authentication per 802.1X-2020 [11]

Open fronthaul network component could serve as the authenticator role of the 802.1X for port-based network access control.

	Test setup and configuration

The DUT shall be the O-RAN component with IP enabled network interface reachable to the authentication server and 802.1X enabled for its open fronthaul interface.

First, set up an authentication RADIUS server (e.g. free radius on Linux) with root, server and client certificates configured with .cnf files and eap configuration (eap.conf). Then start the authentication RADIUS server.

	Test procedure

First set up the 802.1X test tool host/device with EAP authentication for 802.1X protocol.

Run the 802.1X test tool emulating the request(s) from the supplicant(s) towards the DUT, which is the authenticator and ensure the 802.1X authentication process runs to completion.

The following test scenarios are executed:

Table 111: Scenarios to be executed

Scenario ID

Configuration

1

Test tool (as supplicant) setting for 802.1X with EAPoL, correct Identity (Certificate DN) and Client Certificate (provisioned on the Radius server)

2

Test tool (as supplicant) setting for 802.1X with EAPoL, correct Identity (Certificate DN) and incorrect Client Certificate (not provisioned on the Radius server)

3

Test tool (as supplicant) setting for 802.1X with EAPoL and incorrect Identity (Certificate DN)

4

Test tool (as supplicant) setting for 802.1X with EAP non-TLS (e.g. MD5) authentication

	Expected results

The O-RAN component successfully complete the procedure for the emulated supplicant validation (being granted or denied), for each test scenario:

Table 112: Expected results

Scenario ID

Expected result

Reason

1

Connection established

Authentication successfully

2

Connection not established

Fail Authentication because the certificate is wrong

3

Connection not established

Fail Authentication because the Identity is wrong

4

Connection not established

Fail Authentication because the authentication type is wrong

Expected format of evidence: log files and/or traffic captures.

	STC-11-11.1-002: Supplicant Validation

Test name: TC_Supplicant_Validation

Requirement Name: Supplicant function of O-RAN component

Requirement Reference: REQ-SEC-OFHPLS-1, REQ-SEC-OFHPLS-2 and REQ-SEC-OFHPLS-3 from clause 5.2.5.5.1, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: Requirements of Supplicant in the open fronthaul network

Threat References: T-FRHAUL-02

DUT/s: All the functions with Open Fronthaul functionalities, including but not limited to, O-RU, O-DU, switches, FHM, FHGW, TNE and PRTC/T-GM.

	Test description and applicability

Purpose: To verify the supplicant requirement of the network component for port connection request using EAP TLS authentication per 802.1X-2020 [11].

Open fronthaul network component shall support supplicant role of the 802.1X for port-based network access control.

	Test setup and configuration

First set up an authentication RADIUS2 server (e.g. free radius on Linux) with root, server and client certificates configured with .cnf files and eap configuration (eap.conf), then start the authentication RADIUS server.

	Test procedure

First, set up the 802.1X test tool host/device as the authenticator with EAP TLS authentication for 802.1X protocol and configure the preset RADIUS server as its authentication server. Then start the test run as an emulated authenticator waiting for the supplicant request.

Configure and enable the O-RAN component of the open fronthaul interface to start the port connection request as a supplicant towards the 802.1X test tool, which is the authenticator and verify the 802.1X authentication process runs to completion.

The following test scenarios are executed:

Table 113: Scenarios to be executed

Scenario ID

Configuration

1

O-RAN component (as supplicant) setting for 802.1X with EAPoL, correct Identity (Certificate DN) and Client Certificate (provisioned on the Radius server)

2

O-RAN component (as supplicant) setting for 802.1X with EAPoL, correct Identity (Certificate DN) and incorrect Client Certificate (un-provisioned on the Radius server)

3

O-RAN component (as supplicant) setting for 802.1X with EAPoL and incorrect Identity (Certificate DN)

4

O-RAN component (as supplicant) setting for 802.1X with EAP non-TLS (e.g. MD5) authentication (optional)

	Expected results

The O-RAN component successfully complete the procedure for the supplicant validation (being granted or denied), for each test scenario:

Table 114: Expected results

Scenario ID

Expected result

Reason

1

Connection established

Authentication successfully

2

Connection not established

Fail Authentication because the certificate is wrong

3

Connection not established

Fail Authentication because the Identity is wrong

4

Connection not established

Fail Authentication because the authentication type is wrong

Expected format of evidence: log files and/or traffic captures.

M-Plane

SSH-based M-Plane authentication, authorization and access control protection

The test cases outlined in this clause verify M-Plane authenticity, authorization, and access control protection over the FH interface using SSH.

STC-11-11.1-001: Secure Password-Based Authentication and Authorization in FH_MPLANE Using SSH

Requirement Name: M-Plane authenticity protection over FH interface using SSH

Requirement Reference & Description: clause 5.4 in O-RAN Fronthaul Working Group Management Plane Specification [21]

Threat References: ‘T-O-RAN-05’ clause 5.4.1, ‘T-FRHAUL-01, T-FRHAUL-02, T-MPLANE-01’ clause 5.4.1.2 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU

Test Name: TC_FH_MPLANE_SSH-PASSWORD-BASED_AUTHENTICATION_AUTHORIZATION

Test description and applicability

Purpose: The purpose of this test is to verify the SSH password-based authentication and authorization mechanisms on the front-haul (FH) interface between O-RU and O-DU.

Test setup and configuration

The O-RU and O-DU devices are properly configured and operational.

NACM with NETCONF is enabled and configured for authorization on the FH interface.

SSH is properly implemented and configured as defined in [2] clause 4.1.

Test procedure

Execute the test on the SSH protocol as defined in Clause 6.2.

Positive Case: Successful SSH password-based authentication and authorization.

	Test the successful SSH password-based authentication and authorization of the O-RU by the O-DU.

		Establish an SSH connection from the O-RU to the O-DU using the SSH password.

		EXAMPLE: “Command: ssh <username>@<O-DU_IP>”

			Verify that the O-DU successfully authenticates the O-RU using the SSH password.

		EXAMPLE: “Command: show ssh sessions “

			Validate that the O-RU is authorized to perform the requested operations on the FH interface.

Negative Case: Failed SSH password-based authentication.

	Test the handling of failed SSH password-based authentication attempts by the O-DU.

		Attempt to establish an SSH connection from the O-RU to the O-DU using an incorrect password.

			EXAMPLE “Command: ssh <username>@<O-DU_IP>”

			Verify that the O-DU rejects the SSH connection due to the authentication failure.

Expected Results

For step 1): Expected results in Clause 6.2.4

For step 2):

		The SSH connection is successfully established using the SSH password.

		The O-DU validates the O-RU's SSH password for authentication.

		The O-DU grants the necessary authorization to the O-RU for the requested operations.

For step 3):

		The SSH connection attempt fails due to the incorrect password.

		The O-DU identifies the authentication failure and denies access to the O-RU.

Expected format of evidence

For step 1): Logs and screenshots showing adherence to SSH protocol specifications as defined in [2] clause 4.1.

For step 2): Logs showing successful SSH authentication and authorization events.

For step 3): Logs or error messages indicating failed SSH password-based authentication attempts.

STC-11-11.1-002: FH M-Plane SSH-certificate-based authentication authorization

Requirement Name: M-Plane authorization protection over FH interface using SSH

Requirement Reference & Description: clause 5.4 in O-RAN Fronthaul Working Group Management Plane Specification [21]

Threat References: ‘T-O-RAN-05’ clause 5.4.1, ‘T-FRHAUL-01, T-FRHAUL-02, T-MPLANE-01’ clause 5.4.1.2 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU

Test Name: TC_FH_MPLANE_SSH-CERTIFICATE-BASED_AUTHENTICATION_AUTHORIZATION

Test description and applicability

Purpose: The purpose of this test is to verify the SSH-certificate-based authentication and authorization mechanisms on the front-haul (FH) interface between O-RU and O-DU.

Test setup and configuration

The O-RU and O-DU devices are properly configured and operational.

SSH keys and certificates are generated and installed on both the O-RU and O-DU devices.

NACM with NETCONF is enabled and configured for authorization on the FH interface.

SSH is properly implemented and configured as defined in [2] clause 4.1.

Test procedure

Execute the test on the SSH protocol as defined in Clause 6.2.

Positive Case: Successful SSH-certificate-based authentication and authorization.

Test the successful SSH-certificate-based authentication and authorization of the O-RU by the O-DU.

Establish an SSH connection from the O-RU to the O-DU using the SSH key and certificate.

EXAMPLE: “Command: ssh -i <path_to_private_key> -o CertificateFile=<path_to_certificate> <username>@<O-DU_IP>”

Verify that the O-DU successfully authenticates the O-RU using the SSH certificate.

EXAMPLE: “Command: show ssh sessions”

Validate that the O-RU is authorized to perform the requested operations on the FH interface.

Negative Case: Failed SSH-certificate-based authentication.

Test the handling of failed SSH-certificate-based authentication attempts by the O-DU.

Attempt to establish an SSH connection from the O-RU to the O-DU using an incorrect or invalid SSH key or certificate.

EXAMPLE: “Command: ssh -i <path_to_invalid_private_key> -o CertificateFile=<path_to_invalid_certificate> <username>@<O-DU_IP>”

Verify that the O-DU rejects the SSH connection due to the authentication failure.

Expected Results

For step 1): Expected results in Clause 6.2.4

For step 2):

	The SSH connection is successfully established using the SSH key and certificate.

	The O-DU validates the O-RU's SSH certificate for authentication.

	The O-DU grants the necessary authorization to the O-RU for the requested operations.

For step 3):

	The SSH connection attempt fails due to the incorrect or invalid SSH key or certificate.

	The O-DU identifies the authentication failure and denies access to the O-RU.

Expected format of evidence

For step 1): Logs and screenshots showing adherence to SSH protocol specifications as defined in [2] clause 4.1.

For step 2): Logs showing successful SSH authentication and authorization events.

For step 3): Logs or error messages indicating failed SSH-certificate-based authentication attempts.

STC-11-11.1-003: FH M-plane SSH Certificate-Based NACM Access Control

Requirement Name: M-Plane access control protection over FH interface using SSH

Requirement Reference & Description: clause 5.4 in O-RAN Fronthaul Working Group Management Plane Specification [21]

Threat References: ‘T-O-RAN-05’ clause 5.4.1, ‘T-FRHAUL-01, T-FRHAUL-02, T-MPLANE-01’ clause 5.4.1.2 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU

Test Name: TC_FH_MPLANE_SSH-CERTIFICATE-BASED_NACM_ACCESS_CONTROL

Test description and applicability

Purpose: The purpose of this test is to verify the SSH-certificate-based NACM access control on the FH interface between O-RU and O-DU.

Test setup and configuration

NACM with NETCONF is enabled and configured for SSH-certificate-based authorization on the FH interface.

Access control rules and permissions are defined and configured on both the O-RU and O-DU.

SSH is properly implemented and configured as defined in [2] clause 4.1.

Test procedure

Execute the test on the SSH protocol as defined in Clause 6.2.

Positive Case: Successful SSH-certificate-based NACM authorization and access control.

Test the successful enforcement of SSH-certificate-based NACM policies on the FH interface.

	Establish an SSH connection from the O-RU to the O-DU using the SSH key and certificate.

EXAMPLE: “Command: ssh -i <path_to_private_key> -o CertificateFile=<path_to_certificate> <username>@<O-DU_IP>”

	Perform an operation on the FH interface with the O-RU using the SSH connection.

	Verify that the O-DU grants or denies access based on the SSH-certificate-based NACM rules and permissions.

Negative Case: Unauthorized access denial.

Test the denial of access to unauthorized operations on the FH interface.

	Establish an SSH connection from the O-RU to the O-DU using the SSH key and certificate.

EXAMPLE “Command: ssh -i <path_to_private_key> -o CertificateFile=<path_to_certificate> <username>@<O-DU_IP>”

	Attempt to perform an unauthorized operation on the FH interface with the O-RU.

	Verify that the O-DU denies access to the unauthorized operation based on the SSH-certificate-based NACM rules.

Expected Results

For step 1): Expected results in Clause 6.2.4

For step 2):

	The SSH connection is successfully established using the SSH key and certificate.

	The O-DU evaluates the SSH certificate-based NACM rules and permissions.

	The O-DU grants or denies access to the O-RU based on the SSH-certificate-based NACM configuration.

For step 3):

	The SSH connection is successfully established using the SSH key and certificate.

	The O-DU identifies the unauthorized operation and denies access to the O-RU.

Expected format of evidence

For step 1): Logs and screenshots showing adherence to SSH protocol specifications as defined in [2] clause 4.1.

For step 2), Logs or audit records indicating successful access based on SSH-certificate-based NACM.

For step 3), Logs or error messages indicating access denial for unauthorized operations.

SSH-based M-Plane integrity, confidentiality and replay protection

The following test cases verify the M-Plane integrity, confidentiality, and replay protection over the FH interface using SSH.

STC-11-11.1-004: FH M-plane SSH Confidentiality

Requirement Name: M-Plane confidentiality protection over FH interface using SSH

Requirement Reference & Description: clause 5.4 in O-RAN Fronthaul Working Group Management Plane Specification [21]

Threat References: ‘T-O-RAN-05’ clause 5.4.1, ‘T-FRHAUL-01, T-FRHAUL-02, T-MPLANE-01’ clause 5.4.1.2 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU

Test Name: TC_FH_MPLANE_SSH_CONFIDENTIALITY

Test description and applicability

Purpose: The purpose of this test is to verify the confidentiality of M-Plane data transmitted over the front-haul (FH) interface.

Test setup and configuration

The O-RU and O-DU devices are properly configured and operational.

SSH keys and certificates are generated and installed on both the O-RU and O-DU devices.

SSH configuration is enabled to enforce confidentiality on the FH interface.

SSH is properly implemented and configured as defined in [2] clause 4.1.

Test procedure

Execute the test on the SSH protocol as defined in Clause 6.2.

Encryption and decryption of M-Plan over FH

Test the encryption and decryption of M-Plane data transmitted over the FH interface.

Establish an SSH connection from the O-RU to the O-DU using the SSH key and certificate.

EXAMPLE: “Command: ssh -i <path_to_private_key> -o CertificateFile=<path_to_certificate> <username>@<O-DU_IP>”

Transmit data from the O-RU to the O-DU over the SSH connection.

Verify that the data received by the O-DU is successfully decrypted and in the original form.

Expected Results

For step 1): Expected results in Clause 6.2.4

For step 2):

The SSH connection is successfully established using the SSH key and certificate.

The transmitted data is encrypted during transmission.

The O-DU successfully decrypts the received data. The decrypted data matches the original data transmitted by the O-RU.

Expected format of evidence

For step 1): Logs and screenshots showing adherence to SSH protocol specifications as defined in [2] clause 4.1.

For step 2): Logs or output showing successful encryption and decryption of data.

STC-11-11.1-005: FH M-plane SSH Integrity

Requirement Name: M-Plane integrity protection over FH interface using SSH

Requirement Reference & Description: clause 5.4 in O-RAN Fronthaul Working Group Management Plane Specification [21]

Threat References: ‘T-O-RAN-05’ clause 5.4.1, ‘T-FRHAUL-01, T-FRHAUL-02, T-MPLANE-01’ clause 5.4.1.2 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU

Test Name: TC_FH_MPLANE_SSH_INTEGRITY

Test description and applicability

Purpose: The purpose of this test is to verify the integrity of M-Plane data transmitted over the front-haul (FH) interface.

Test setup and configuration

The O-RU and O-DU devices are properly configured and operational.

SSH keys and certificates are generated and installed on both the O-RU and O-DU devices.

SSH configuration is enabled to enforce data integrity on the FH interface.

SSH is properly implemented and configured as defined in [2] clause 4.1.

Test procedure

Execute the test on the SSH protocol as defined in Clause 6.2.

Data integrity verification and tampering detection.

Test the successful verification of M-Plane data integrity transmitted over the FH interface and the detection of tampering by the O-DU.

	Establish an SSH connection from the O-RU to the O-DU using the SSH key and certificate.

EXAMPLE: “Command: ssh -i <path_to_private_key> -o CertificateFile=<path_to_certificate> <username>@<O-DU_IP>”

	Transmit data from the O-RU to the O-DU over the SSH connection.

	Verify the integrity of the received data on the O-DU.

	Modify the transmitted data during transmission and attempt to pass it to the O-DU.

	Verify that the O-DU detects the data tampering and rejects the tampered data.

Expected Results

For step 1): Expected results in Clause 6.2.4

For step 2):

The SSH connection is successfully established using the SSH key and certificate.

The transmitted data is protected with integrity checks.

The O-DU successfully verifies the integrity of the received data.

The O-DU detects the data tampering and rejects the tampered data.

Expected format of evidence

For step 1): Logs and screenshots showing adherence to SSH protocol specifications as defined in [2] clause 4.1.

For step 2): Logs or output indicating successful integrity verification of data and detection of data tampering.

STC-11-11.1-006: FH M-plane SSH Replay

Requirement Name: M-Plane replay protection over FH interface using SSH

Requirement Reference & Description: clause 5.4 in O-RAN Fronthaul Working Group Management Plane Specification [21]

Threat References: ‘T-O-RAN-05’ clause 5.4.1, ‘T-FRHAUL-01, T-FRHAUL-02, T-MPLANE-01’ clause 5.4.1.2 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU

Test Name: TC_FH_MPLANE_SSH_REPLAY

Test description and applicability

Purpose: The purpose of this test is to verify the replay protection mechanism on the front-haul (FH) interface.

Test setup and configuration

The O-RU and O-DU devices are properly configured and operational.

SSH keys and certificates are generated and installed on both the O-RU and O-DU devices.

SSH configuration is enabled to enforce replay protection on the FH interface.

SSH is properly implemented and configured as defined in [2] clause 4.1.

Test procedure

Execute the test on the SSH protocol as defined in Clause 6.2.

Successful detection and prevention of replayed data.

Test the successful detection and prevention of replayed data on the FH interface.

Establish an SSH connection from the O-RU to the O-DU using the SSH key and certificate.

EXAMPLE: “Command: ssh -i <path_to_private_key> -o CertificateFile=<path_to_certificate> <username>@<O-DU_IP>”

Transmit data from the O-RU to the O-DU over the SSH connection.

Attempt to replay the transmitted data to the O-DU.

Verify that the O-DU detects the replayed data and rejects it.

Expected Results

For step 1): Expected results in Clause 6.2.4

For step 2):

The SSH connection is successfully established using the SSH key and certificate.

The transmitted data is protected with a replay protection mechanism.

The O-DU detects the replayed data and rejects it to prevent unauthorized repetitions.

Expected format of evidence

For step 1): Logs and screenshots showing adherence to SSH protocol specifications as defined in [2] clause 4.1.

For step 2): Logs or output indicating successful detection and prevention of replayed data.

TLS-based M-Plane authentication, authorization and access control protection

The test cases outlined in this clause verify M-Plane authenticity, authorization, and access control protection over the FH interface using TLS.

STC-11-11.1-007: FH M-plane TLS Authentication

Requirement Name: M-Plane authenticity protection over FH interface using TLS

Requirement Reference & Description: clause 5.4 in O-RAN Fronthaul Working Group Management Plane Specification [21]

Threat References: ‘T-O-RAN-05’ clause 5.4.1, ‘T-FRHAUL-01, T-FRHAUL-02, T-MPLANE-01’ clause 5.4.1.2 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU

Test Name: TC_FH_MPLANE_TLS_AUTHENTICATION

Test description and applicability

Purpose: The purpose of this test is to verify the authentication mechanism for the O-RU and O-DU components over the TLS-based NACM with NETCONF on the FH interface for M-Plane.

Test setup and configuration

For positive case: The O-RU and O-DU components are configured with valid TLS certificates for mutual authentication.

For negative case: The O-RU and O-DU components have misconfigured or invalid TLS certificates.

The NETCONF server is configured to enforce client authentication as defined in [2] clause 4.3.

TLS is properly implemented and configured as defined in [2] clause 4.2.

Test procedure

Execute the test on the TLS protocol as defined in Clause 6.3.

Positive Case: Successful authentication.

Test the successful authentication of the O-RU and O-DU components over the TLS-based NACM with NETCONF on the FH interface.

The O-RU initiates the TLS handshake with the O-DU component, presenting its TLS certificate.

The O-DU verifies the authenticity of the O-RU's TLS certificate and presents its own TLS certificate.

The O-RU verifies the authenticity of the O-DU's TLS certificate, completing the mutual authentication.

Negative Case: Failed authentication.

Test the failure of authentication for the O-RU and O-DU components over the TLS-based NACM with NETCONF on the FH interface.

The O-RU initiates the TLS handshake with the O-DU component, presenting its TLS certificate.

The O-DU fails to verify the authenticity of the O-RU's TLS certificate due to a misconfiguration or invalid certificate.

The TLS handshake fails, and the mutual authentication is not completed.

Expected Results

For step 1): Expected results in Clause 6.3.4

For step 2), The O-RU and O-DU components successfully authenticate each other over the TLS-based NACM with NETCONF on the FH interface.

For step 3), The O-RU and O-DU components fail to authenticate each other over the TLS-based NACM with NETCONF on the FH interface.

Expected format of evidence

For step 1): Logs and screenshots showing adherence to TLS protocol specifications as defined in [2] clause 4.2.

For step 2), Logs or output indicating successful authentication.

For step 3), Logs or output indicating failed authentication.

STC-11-11.1-008: FH M-plane TLS Authorization

Requirement Name: M-Plane authorization and access control protection over FH interface using TLS

Requirement Reference & Description: clause 5.4 in O-RAN Fronthaul Working Group Management Plane Specification [21]

Threat References: ‘T-O-RAN-05’ clause 5.4.1, ‘T-FRHAUL-01, T-FRHAUL-02, T-MPLANE-01’ clause 5.4.1.2 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU

Test Name: TC_FH_MPLANE_TLS_AUTHORIZATION

Test description and applicability

Purpose: The purpose of this test is to verify the authorization mechanism for the O-RU and O-DU components over the TLS-based NACM with NETCONF on the FH interface.

Test setup and configuration

The O-RU and O-DU components are successfully authenticated and have established a secure connection with the NETCONF server.

For positive case: The NACM rules and policies are properly configured on the NETCONF server to enforce authorization.

For negative case: The NACM rules and policies are misconfigured, or the O-RU is attempting an unauthorized operation.

Test procedure

Positive Case: Successful authorization.

Test the successful authorization of the O-RU and O-DU components over the TLS-based NACM with NETCONF on the FH interface.

The O-RU sends a NETCONF request to the O-DU component to perform an authorized operation.

The NETCONF server evaluates the NACM rules and policies to determine if the O-RU is authorized to perform the requested operation.

The O-DU component executes the authorized operation and sends a response to the O-RU.

Negative Case: Failed authorization.

Test the failure of authorization for the O-RU and O-DU components over the TLS-based NACM with NETCONF on the FH interface.

The O-RU sends a NETCONF request to the O-DU component to perform an unauthorized operation.

The NETCONF server evaluates the NACM rules and policies and denies the unauthorized operation.

The O-DU component rejects the unauthorized operation and sends an error response to the O-RU.

Expected Results

For step 1) Positive case: successful authorization:

The O-RU's NETCONF request for an authorized operation is successfully received by the O-DU.

The NETCONF server, after evaluating the NACM rules and policies, grants permission for the authorized operation.

The O-DU successfully executes the authorized operation and sends a confirmation response to the O-RU.

For step 2) Negative case: failed authorization:

The O-RU's NETCONF request for an unauthorized operation is received by the O-DU.

The NETCONF server, upon evaluating the NACM rules and policies, denies the unauthorized operation.

The O-DU does not execute the unauthorized operation and sends an error response to the O-RU, indicating the rejection.

Expected format of evidence

For step 1), Logs or output indicating successful authorization.

For step 2), Logs or output indicating failed authorization.

TLS-based M-Plane integrity, confidentiality and replay protection

The following test cases verify the M-Plane integrity, confidentiality, and replay protection over the FH interface using TLS.

STC-11-11.1-009: FH M-plane TLS Confidentiality

Requirement Name: M-Plane confidentiality protection over FH interface using TLS

Requirement Reference & Description: clause 5.4 in O-RAN Fronthaul Working Group Management Plane Specification [21]

Threat References: ‘T-O-RAN-05’ clause 5.4.1, ‘T-FRHAUL-01, 02, T-MPLANE-01’ clause 5.4.1.2 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU

Test Name:  TC_FH_MPLANE_TLS_CONFIDENTIALITY

Test description and applicability

Purpose: The purpose of this test is to verify that no sensitive data is revealed at the FH M-Plane interface. It ensures that sensitive information remains protected from unauthorized access or disclosure.

Test setup and configuration

O-RU, O-DU support TLS and be connected in simulated/real network environment.

The test environment is set up with FH M-Plane interface configured.

The tester has access to the original data transported over the FH M-Plane interface.

TLS is properly implemented and configured as defined in [2] clause 4.2.

The tester has knowledge of the confidentiality algorithm and confidentiality protection keys used for encrypting the encapsulated payload.

Test procedure

The tester executes the test on the TLS protocol as defined in Clause 6.3.

The tester establishes a secure communication session over the FH M-Plane interface and verifies that all protocol versions and combinations of cryptographic algorithms for confidentiality protection that are mandated by the security profile in Clause 4.2 of O-RAN security protocols specification [2] are supported by O-RU and O-DU.

The tester establishes a secure communication session over the FH M-Plane interface and verifies that this is not possible when the O-RU and O-DU only offers a feature, including protocol version and combination of cryptographic algorithms for confidentiality protection, that is forbidden by the security profile in Clause 4.2 of O-RAN security protocols specification [2].

The tester establishes a secure communication session over the FH M-Plane interface and captures the network traffic during the communication session.

The tester analyses the captured traffic to identify any instances where information is transmitted in clear text or without appropriate encryption.

The tester verifies the captured data so that only the intended recipient can decrypt it.

The tester ensures the encryption process that does not allow the attacker to intercept the data in transit between the O-RU and O-DU except with the provision of the appropriate decryption key.

Expected results

Expected results in Clause 6.3.4

All sensitive data transmitted over the FH M-Plane interface is properly encrypted.

No instances of sensitive information being transmitted in clear text is observed.

Insecure options of protocol version and combination of cryptographic algorithms is not accepted by O-RU and O-DU.

STC-11-11.1-010: FH M-plane TLS Integrity

Requirement Name: M-Plane integrity protection over FH interface using TLS

Requirement Reference & Description: clause 5.4 in O-RAN Fronthaul Working Group Management Plane Specification [21]

Threat References: ‘T-O-RAN-05’ clause 5.4.1, ‘T-FRHAUL-01, 02, T-MPLANE-01’ clause 5.4.1.2 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU

Test Name:  TC_FH_MPLANE_TLS_INTEGRITY

Test description and applicability

Purpose: The purpose of this test is to verify the integrity of the data transmitted over the FH M-Plane interface, ensuring that no data is modified or altered during transmission (Integrity).

Test setup and configuration

O-RU and O-DU support TLS and be connected in simulated/real network environment.

The test environment is set up with FH M-Plane interface configured.

The tester has access to the original data transported over the FH M-Plane interface.

TLS is properly implemented and configured as defined in [2] clause 4.2.

The tester has knowledge of the integrity algorithm (Hash Message Authentication Code) and the protection keys.

Test procedure

Execution of the test on the TLS protocol as defined in Clause 6.3.

Setup and verification of supported protocols and algorithms:

Establish a secure communication session over the FH M-Plane interface.

Using a protocol analyzer tool, verify that all protocol versions and combinations of cryptographic algorithms for integrity protection mandated by the security profile in clause 4.2 of O-RAN security protocols specification [2] are supported by both O-RU and O-DU.

Verification of forbidden features:

Attempt to establish a secure communication session over the FH M-Plane interface using features, including protocol versions and combinations of cryptographic algorithms for integrity protection, that are forbidden by the security profile in clause 4.2 of O-RAN security protocols specification [2].

Ensure that the session establishment fails, indicating that forbidden features are not supported.

Capture and analysis of network traffic:

Using a network packet capture tool (e.g., Wireshark), establish a secure communication session over the FH M-Plane interface and capture the network traffic during the session.

Analyze the captured traffic to identify any instances where data integrity might be compromised. Look for signs of modified, tampered, or out-of-sequence packets.

Verification of MAC algorithms:

Identify the MAC algorithms used on the FH M-Plane interface, ensuring they match known secure algorithms (e.g., HMAC).

Using a cryptographic analysis tool, verify that the MAC derived at the receiving node uses the same hash function as the sending node.

Verification of MAC integrity:

Ensure that the secret key used to derive the MAC at the receiving node matches the key used to calculate the MAC at the sending node. This can be done by comparing the MAC values or using cryptographic verification tools.

Expected Results

Expected results in Clause 6.3.4

There is no modification/corruption of data between sending and receiving nodes. The MAC always matches with the calculated and derived at sending and receiving nodes respectively.

STC-11-11.1-011: FH M-plane TLS Replay

Requirement Name: M-Plane replay protection over FH interface using TLS

Requirement Reference & Description: clause 5.4 in O-RAN Fronthaul Working Group Management Plane Specification [21]

Threat References: ‘T-O-RAN-05’ clause 5.4.1, ‘T-FRHAUL-01, 02, T-MPLANE-01’ clause 5.4.1.2 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU

Test Name:  TC_FH_MPLANE_REPLAY

Test description and applicability

Purpose: The purpose of this test is to verify that no malicious capture and subsequent replay of network traffic to deceive the system or gain unauthorized access over the FH M-Plane interface. (Anti-replay).

Test setup and configuration

O-RU and O-DU support TLS and be connected in simulated/real network environment.

The test environment is set up with the FH M-Plane interface configured.

The tester has access to the original data transported over the FH M-Plane interface.

TLS is properly implemented and configured as defined in [2] clause 4.2.

The tester has knowledge of the anti-replay security controls implemented over FH M-Plane interface.

Test procedure

The tester executes the test on the TLS protocol as defined in Clause 6.3.

The tester establishes a secure communication session over the FH M-Plane interface and captures the network traffic during the communication session.

The tester identifies packets or data that are susceptible to replay attacks, such as those containing authentication credentials, session identifiers, or critical commands.

The tester attempts to replay the captured packets or data by resending them to the O-RU and O-DU.

The tester observes O-RU and O-DU behavior and response to the replayed packets.

The tester verifies each data packet assigned with a unique sequence number included in the packet header.

The tester verifies each data packet contains a timestamp.

The tester also verifies the sequence number of each received packet and compares it to the previously received packet’s sequence number and if the sequence number is too low or too high, the packet is considered a replay attack and is discarded.

Expected Results

Expected results in Clause 6.3.4

O-RU and O-DU implement countermeasures to detect and prevent replay attacks. This may include the use of sequence numbers, timestamps, or other forms of message authentication codes.

O-RU and O-DU reject or ignore replayed packets and not perform any sensitive or unauthorized actions.

U-Plane

U-Plane eCPRI Unexpected Input

The test cases in this clause focus on the O-DU's capability to recognize, handle, and respond appropriately to such anomalies in user plane packets over the eCPRI. This includes scenarios where packets are malformed or when they present unexpected payload sizes.

STC-11-11.1-012: FH U-Plane Malformed Packet

Requirement Name: Handling and rejection of malformed or invalid user plane packets

Requirement Reference & Description: clause 5.2.5.2.1 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-FRHAUL-01, T-FRHAUL-02, T-UPLANE-01’ clause 7.4.1.2 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU

Test Name: TC_FH_U-PLANE_MALFORMED_PACKET

Test description and applicability

Purpose: The purpose of this test is to verify the O-DU's ability to handle and reject malformed or invalid user plane packets.

Test setup and configuration

A valid eCPRI connection between the O-RU and O-DU.

Test procedure

Generate a user plane packet with invalid or malformed data, such as incorrect headers, corrupted payload, or unsupported formats.

Transmit the malformed packet over the eCPRI.

Monitor the O-DU's response and behaviour.

Verify that the O-DU identifies and rejects the malformed packet.

Observe the impact on the O-DU, such as error messages, logging, or abnormal behavior.

Expected Results

The O-DU detects and rejects malformed or invalid user plane packets.

It handles the rejection gracefully without affecting normal operation.

Appropriate error messages or log entries are generated.

Expected Format of Evidence:

Steps performed with detailed execution logs.

Screenshots or logs indicating the detection and rejection of the malformed packet.

STC-11-11.1-013 FH U-Plane Unexpected Payload Size

Requirement Name: Handling and rejection of malformed or invalid user plane packets

Requirement Reference & Description: clause 5.2.5.2.1 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-FRHAUL-01, T-FRHAUL-02, T-UPLANE-01’ clause 7.4.1.2 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU

Test Name: TC_FH_U-PLANE_UNEXPECTED_PAYLOAD_SIZE

Test description and applicability

Purpose: The purpose of this test is to verify the O-DU's ability to handle unexpected payload sizes in user plane packets.

Test setup and configuration

A valid eCPRI connection between the O-RU and O-DU.

Test procedure

Generate a user plane packet with an unexpected payload size, exceeding the normal or allowed range.

Transmit the packet with the unexpected payload size over the eCPRI.

Monitor the O-DU's response and behaviour.

Verify that the O-DU detects the unexpected payload size and takes appropriate action.

Observe the impact on the O-DU, such as error handling, packet drops, or performance degradation.

Expected Results

The O-DU detects and handles unexpected payload sizes in user plane packets.

It either rejects the packet or handles it with appropriate error handling mechanisms.

The O-DU maintains acceptable performance levels despite the unexpected payload size.

Expected Format of Evidence:

Steps performed with detailed execution logs.

Screenshots or logs indicating the detection and handling of the unexpected payload size.

S-Plane

DoS Attack against a Master Clock

The tests outlined in this clause evaluate the system's defense capabilities against DoS attacks targeting the master clock, especially in different LLS configurations.

STC-11-11.1-014: DOS Master Clock LLS C1 C2 C3

Requirement Name: S-Plane DoS protection

Requirement Reference & Description: ‘REQ-SEC-DOS-1’ clause 5.3.5 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-SPLANE-01’ clause 5.4.1.2 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU

Test Name: TC_DOS_MASTER_CLOCK_LLS_C1_C2_C3

Test description and applicability

Purpose: The purpose of this test is to verify the protection of the S-plane against a denial of service (DoS) attack targeting the master clock in LLS-C1, LLS-C2, LLS-C3 configurations.

Test setup and configuration

O-DU and O-RU are properly configured and connected.

For LLS-C1: The master clock functionality is enabled on the O-DU. O-DU is acting as a master and directly synchronizes O-RU.

For LLS-C2: One or more Ethernet switches are allowed in the fronthaul network. O-DU acting as master to distribute network timing toward O-RU.

For LLS-C3: One or more PRTC/T-GM are implemented in the fronthaul network to distribute network timing toward O-DU and O-RU.

A network monitoring tool is set up to capture and analyze network traffic.

Test procedure

Start monitoring the network traffic between the O-DU and O-RU.

Simulate a DoS attack by sending an excessive number of time protocol packets to the master clock using a testing tool.

EXAMPLE:

	For LLS-C1, use a command-line tool like ptp4l or pgrptp with appropriate options to flood the Master clock's IP address or hostname with an excessive number of time protocol packets.

	For LLS-C2 and LLS-C3, use a custom script or tool that supports PTP communication to generate and send a large volume of time protocol packets targeting the IP address or hostname of the Master clock.

Monitor the behavior of the master clock and the synchronization status between the O-DU and O-RU during the attack.

Observe the impact on the accuracy and availability of the master clock.

Monitor the behavior of the slave clocks at the O-RUs and their synchronization status with the master clock during the attack.

Evaluate the impact on O-RUs relying on accurate timing information:

	Measure the timing accuracy at the O-RUs before initiating the DoS attack to establish a baseline.

	During the DoS attack, continuously monitor the timing accuracy at the O-RUs at regular intervals (e.g., every 10 seconds).

	Compare the timing accuracy measurements taken during the attack to the baseline measurements.

	Identify any deviations or discrepancies in timing accuracy that exceed acceptable thresholds.

	Document any observed impact on O-RU operations that rely on precise timing, such as frame alignment, data transmission synchronization, or other time-sensitive processes.

	After the DoS attack has concluded, continue monitoring the O-RUs to determine how quickly they recover and return to their baseline timing accuracy.

Expected Results

The S-plane detects and mitigates the DoS attack against the master clock.

The master clock continues to operate with minimal impact on accuracy and availability.

The synchronization status between the O-DU and O-RU remains stable.

The slave clocks maintain synchronization with their respective master clocks, although some minor degradation may be expected.

O-RUs relying on accurate timing information should continue to function, although some degradation may be observed during the attack.

Expected Format of Evidence:

The following evidence, in one or more formats as applicable, should be provided:

Network traffic logs showing the excessive time protocol packets sent to the mater clock during the attack.

Monitoring reports indicating the behavior of the master clock and synchronization status between the O-DU and O-RU during the attack.

Analysis of the impact on the accuracy and availability of the master clock.

Evaluation of the synchronization status of the slave clocks during the attack.

STC-11-11.1-015: DOS Master Clock LLS C4

Requirement Name: S-Plane DoS protection

Requirement Reference & Description: ‘REQ-SEC-DOS-1’ clause 5.3.5 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-SPLANE-01’ clause 5.4.1.2 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU

Test Name: TC_DOS_MASTER_CLOCK_LLS_C4

Test description and applicability

Purpose: The purpose of this test is to verify the protection of the S-plane against a denial of service (DoS) attack targeting the local PRTC timing in an LLS-C4 configuration.

Test setup and configuration

The O-RU is configured with a local PRTC timing that provides time synchronization.

Local PRTC timing is enabled that provides time synchronization to the O-RU (it could be embedded in the O-RU).

A network monitoring tool is set up to capture and analyze network traffic.

Test procedure

Start monitoring the network traffic between the O-RU and the fronthaul network.

Simulate a DoS attack by sending an excessive number of time protocol packets to the O-RU's local PRTC timing using a testing tool.

Monitor the behavior of the local PRTC timing and the synchronization status between the O-RU and the fronthaul network during the attack.

Observe the impact on the accuracy and availability of the local PRTC timing.

Verify the functionality of the O-RU during the attack to ensure that it can still operate normally despite the DoS attack on the local PRTC timing.

Expected Results

The S-plane detects and mitigates the DoS attack against the local PRTC timing in the O-RU.

The local PRTC timing continues to operate with minimal impact on accuracy and availability.

The synchronization status between the O-RU and the fronthaul network should remain stable.

The O-RU should continue to function normally, even with the DoS attack targeting the local PRTC timing.

Expected Format of Evidence:

The following evidence, in one or more formats as applicable, should be provided:

Network traffic logs showing the excessive time protocol packets sent to the local PRTC timing during the attack.

Monitoring reports indicating the behavior of the local PRTC timing and synchronization status between the O-RU and the fronthaul network during the attack.

Analysis of the impact on the accuracy and availability of the local PRTC timing.

Spoofing of Master Clocks in the S-Plane

The tests presented in this clause focus on assessing the system's defenses against potential spoofing attacks on master clocks. Specifically, these tests examine scenarios where attackers may try to impersonate or manipulate the master clock's communications to disrupt accurate time synchronization.

STC-11-11.1-016: Impersonation Master Clock

Requirement Name: Spoofing Prevention for Master Clocks in the S-Plane

Requirement Reference & Description: ‘REQ-SEC-OFSP-2’ clause 5.2.5.3.2 in O-RAN Security and Controls Requirements Specifications [5]

Threat References: ‘T-SPLANE-02, T-SPLANE-03’ clause 5.4.1.2 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU

Test Name: TC_IMPERSONATION_MASTER_CLOCK

Test description and applicability

Purpose: The purpose of this test is to verify the protection of the S-plane against an impersonation attack where an attacker sends fake ANNOUNCE messages to declare itself as the best clock (Grand Master).

Test setup and configuration

For LLS-C1: The master clock functionality is enabled on the O-DU. O-DU is acting as a master and directly synchronizes O-RU.

For LLS-C2: One or more Ethernet switches are allowed in the fronthaul network. O-DU acting as master to distribute network timing toward O-RU.

For LLS-C3: One or more PRTC/T-GM are implemented in the fronthaul network to distribute network timing toward O-DU and O-RU.

For LLS-C4: Local PRTC timing is enabled that provides time synchronization to the O-RU (it could be embedded in the O-RU).

The master clock functionality of the O-DU is enabled and functioning correctly (not applicable in the LLS-C4 configuration).

A network monitoring tool is set up to capture and analyze network traffic.

Test procedure

Start monitoring the network traffic between the O-DU and O-RU.

Simulate an impersonation attack by sending a fake ANNOUNCE message declaring a different clock as the best clock in the network to the O-DU using a testing tool.

EXAMPLE:

	For LLS-C1, use a command-line tool like ptp4l or pgrptp with appropriate options to send fake ANNOUNCE messages to the IP address or hostname of the O-DU acting as the legitimate Master clock.

	For LLS-C2, use a PTP simulation tool like pysimulatedptp or ptpd to generate fake ANNOUNCE messages with the attacker's clock information, targeting the IP address or hostname of the O-DU acting as the legitimate Master clock.

	For LLS-C3, use a custom script or tool that supports PTP communication to craft and send fake ANNOUNCE messages to the IP addresses or hostnames of the PRTC/T-GM devices within the fronthaul network.

Monitor the behavior of the O-DU and O-RU upon receiving the fake ANNOUNCE message.

Observe the synchronization status between the O-DU and O-RU.

Verify that the O-DU and O-RU reject the impersonated clock and maintain the synchronization based on the legitimate master clock.

Expected Results

The S-plane detects and mitigates the impersonation attack by recognizing the fake ANNOUNCE message.

The O-DU and O-RU reject the impersonated clock and maintain synchronization with the legitimate master clock.

The synchronization status between the O-DU and O-RU remains stable and accurate.

The O-RU continues to receive accurate timing information from the legitimate master clock.

Expected Format of Evidence:

The following evidence, in one or more formats as applicable, should be provided:

Network traffic logs showing the transmission of the fake ANNOUNCE message to the O-DU.

Monitoring reports indicating the behavior of the O-DU and O-RU upon receiving the fake ANNOUNCE message.

Analysis of the synchronization status between the O-DU and O-RU.

Verification that the O-DU and O-RU reject the impersonated clock and maintain synchronization with the legitimate master clock.

STC-11-11.1-017: Rogue PTP Instance

Requirement Name: Spoofing Prevention for Master Clocks in the S-Plane

Requirement Reference & Description: ‘REQ-SEC-OFSP-2’ clause 5.2.5.3.2 in O-RAN Security and Controls Requirements Specifications [5]

Threat References: ‘T-SPLANE-02, T-SPLANE-03’ clause 5.4.1.2 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU

Test Name: TC_ROGUE_PTP_INSTANCE

Test description and applicability

Purpose: The purpose of this test is to verify the protection of the S-plane against an attacker sending manipulated or malicious ANNOUNCE messages to declare itself as the best clock (Grand Master).

Test setup and configuration

For LLS-C1: The master clock functionality is enabled on the O-DU. O-DU is acting as a master and directly synchronizes O-RU.

For LLS-C2: One or more Ethernet switches are allowed in the fronthaul network. O-DU acting as master to distribute network timing toward O-RU.

For LLS-C3: One or more PRTC/T-GM are implemented in the fronthaul network to distribute network timing toward O-DU and O-RU.

For LLS-C4: Local PRTC timing is enabled that provides time synchronization to the O-RU (it could be embedded in the O-RU).

The O-DU and O-RU are synchronized and functioning correctly.

A network monitoring tool is set up to capture and analyze network traffic.

Test procedure

Start monitoring the network traffic between the O-DU and O-RU.

Simulate an attack by injecting manipulated or malicious ANNOUNCE messages declaring the attacker as the best clock in the network by sending manipulated or malicious ANNOUNCE messages impersonating a Grand Master clock.

EXAMPLE:

For LLS-C1, use a command-line tool like ptp4l or pgrptp with appropriate options to send manipulated ANNOUNCE messages to the IP address or hostname of the O-DU acting as the legitimate Master clock.

	For LLS-C2, use a PTP simulation tool like pysimulatedptp or ptpd to generate manipulated ANNOUNCE messages with the attacker's clock information, targeting the IP address or hostname of the O-DU acting as the legitimate Master clock.

	For LLS-C3, use a custom script or tool that supports PTP communication to craft and send manipulated ANNOUNCE messages to the IP addresses or hostnames of the PRTC/T-GM devices within the fronthaul network.

	For LLS-C4, if the Master clock is embedded in the O-RU, simulate the attack by sending manipulated ANNOUNCE messages directly to the O-RU.

Monitor the behavior of the O-DU and O-RU upon receiving the manipulated or malicious ANNOUNCE messages.

Observe the synchronization status between the O-DU and O-RU.

Verify that the O-DU and O-RU detect and reject the attacker's proposed grandmaster candidate.

Expected Results

The S-plane detects and mitigates the attack by recognizing the manipulated or malicious ANNOUNCE messages.

The O-DU and O-RU reject the attacker's proposed grandmaster candidate and maintain synchronization based on the legitimate master clock.

The synchronization status between the O-DU and O-RU remains stable and accurate.

The O-RU continues to receive accurate timing information from the legitimate master clock.

Expected Format of Evidence:

The following evidence, in one or more formats as applicable, should be provided:

Network traffic logs showing the transmission of the manipulated or malicious ANNOUNCE messages.

Monitoring reports indicating the behavior of the O-DU and O-RU upon receiving the manipulated or malicious ANNOUNCE messages.

Analysis of the synchronization status between the O-DU and O-RU.

Verification that the O-DU and O-RU reject the attacker's proposed grandmaster candidate and maintain synchronization with the legitimate master clock.

Clock Accuracy Protection Against MITM Attacks

This clause delves into tests specifically designed to gauge the system's robustness when facing MITM attacks targeting clock synchronization. Such MITM attacks could manifest as the selective interception and removal of crucial PTP timing packets or the deliberate introduction of delays to these packets.

STC-11-11.1-018: Selective Interception and Removal of PTP Timing Packets

Requirement Name: Clock Accuracy Protection Against MITM Attacks

Requirement Reference & Description: ‘REQ-SEC-OFSP-3’ clause 5.2.5.3.2 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-SPLANE-04, T-SPLANE-05’ clause 5.4.1.2 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU

Test Name:  TC_SELECTIVE_INTERCEPTION_REMOVAL_PTP_TIMING_PACKETS

Test description and applicability

Purpose: The purpose of this test is to verify the resilience of the S-plane against an attack where PTP timing packets are selectively intercepted and removed.

Test setup and configuration

For LLS-C1: The master clock functionality is enabled on the O-DU. O-DU is acting as a master and directly synchronizes O-RU.

For LLS-C2: One or more Ethernet switches are allowed in the fronthaul network. O-DU acting as master to distribute network timing toward O-RU.

For LLS-C3: One or more PRTC/T-GM are implemented in the fronthaul network to distribute network timing toward O-DU and O-RU.

For LLS-C4: Local PRTC timing is enabled that provides time synchronization to the O-RU (it could be embedded in the O-RU).

The network monitoring tool is set up to capture and analyze network traffic between the O-RU and O-DU.

Test procedure

Set up the test environment with the O-RAN O-RU, O-DU, and other relevant network components.

Configure the network monitoring tool to capture PTP timing packets between the O-RU and O-DU.

Start the network monitoring tool to capture the initial state of PTP timing packets.

Simulate an attack by using a packet manipulation tool to selectively intercept and remove specific PTP timing packets.

EXAMPLE:

For LLS-C1, use a packet capture tool like Wireshark or tcpdump to capture PTP network traffic on the interface connected to the O-RU or O-DU. Modify the captured packets to selectively remove PTP timing packets using a packet editing tool like Scapy or custom scripts.

	For LLS-C2, use a network device or software with packet interception capabilities to intercept PTP timing packets between the O-RU and O-DU. Modify the intercepted packets to selectively remove PTP timing packets.

	For LLS-C3, use a network device or software capable of deep packet inspection (DPI) to intercept and analyze PTP timing packets. Modify the intercepted packets to selectively remove PTP timing packets.

	For LLS-C4, if the O-RU embeds the local PRTC timing, use a network device or software to intercept PTP timing packets between the O-RU and O-DU. Modify the intercepted packets to selectively remove PTP timing packets.

Monitor the behavior of the O-RU and O-DU during the attack simulation.

Observe the synchronization status and the impact on timing accuracy between the O-RU and O-DU.

Capture and analyze the network traffic using the network monitoring tool during the attack simulation.

NOTE: The network monitoring tool can be Wireshark or tcpdump, configured to capture packets on the interfaces between the O-RU, O-DU and to identify the intercepted and removed PTP timing packets.

Stop the network monitoring tool to finalize the captured traffic.

Expected Results

Detection of missing PTP timing packets: The S-plane is able to detect the absence of specific PTP timing packets that were selectively intercepted and removed.

Synchronization maintenance: Despite the missing PTP timing packets, the O-RU and O-DU still maintain synchronization. Any deviations from expected synchronization is minimal and within acceptable thresholds.

Corrective actions: Upon detecting the missing PTP timing packets, the O-RU and O-DU initiate predefined corrective actions to restore synchronization and mitigate the effects of the missing packets.

Network traffic analysis: The captured network traffic clearly shows the instances where specific PTP timing packets were intercepted and removed.

No system failures: The system (O-RU and O-DU) doesn’t experience any catastrophic failures or shutdowns due to the missing PTP timing packets.

Expected Format of Evidence:

The following evidence, in one or more formats as applicable, should be provided:

Recorded network traffic captured by the monitoring tool during the attack simulation.

Observations and analysis of the impact on synchronization and timing accuracy.

Any issues or anomalies encountered during the attack simulation.

STC-11-11.1-019: Delay Attack on PTP Timing Packets

Requirement Name: Clock Accuracy Protection Against MITM Attacks

Requirement Reference & Description: ‘REQ-SEC-OFSP-3’ clause 5.2.5.3.2 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-SPLANE-04, T-SPLANE-05’ clause 5.4.1.2 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-RU, O-DU

Test Name: TC_DELAY_ATTACK_PTP_TIMING_PACKETS

Test description and applicability

Purpose: The purpose of this test is to verify the S-plane's resilience against a delay attack on PTP timing packets.

Test setup and configuration

For LLS-C1: The master clock functionality is enabled on the O-DU. O-DU is acting as a master and directly synchronizes O-RU.

For LLS-C2: One or more Ethernet switches are allowed in the fronthaul network. O-DU acting as master to distribute network timing toward O-RU.

For LLS-C3: One or more PRTC/T-GM are implemented in the fronthaul network to distribute network timing toward O-DU and O-RU.

For LLS-C4: Local PRTC timing is enabled that provides time synchronization to the O-RU (it could be embedded in the O-RU).

Time synchronization is established and operational within the network.

Test procedure

Start the network monitoring tool to capture the initial state of PTP timing packets.

Simulate an attack by introducing delays in PTP timing packets using a network emulation tool.

EXAMPLE:

For LLS-C1, use a network emulator tool like WANem or NIST Net to introduce artificial delays in PTP timing packets between the O-RU and O-DU.

For LLS-C2 and LLS-C3, use a custom script or tool that supports packet manipulation and delay to introduce artificial delays in PTP timing packets between the O-RU and O-DU or between PRTC/T-GM devices.

For LLS-C4, if the O-RU embeds the local PRTC timing, use a network emulator tool or custom script to introduce delays in PTP timing packets between the O-RU and O-DU.

Monitor the behavior of the O-RU and O-DU during the delay attack on PTP timing packets.

Observe the synchronization status and timing accuracy within the LLS configuration.

Expected Results

The S-plane detects the delay attack on PTP timing packets and applies appropriate measures to mitigate the impact within all LLS configurations.

The O-RU and O-DU detects the delayed PTP timing packets, compensate for the introduced delays, and maintain synchronization.

Expected Format of Evidence:

The following evidence, in one or more formats as applicable, should be provided:

Recorded network traffic captured by the monitoring tool during the attack.

Observations and analysis of the impact on synchronization and timing accuracy within each LLS configuration.

Any issues or anomalies encountered during the attack simulation.

Y1

This clause delineates a series of test cases aimed at validating the security of the Y1 interface within the O-RAN architecture. The tests focus on five critical security facets: confidentiality, integrity, anti-replay, authenticity, and authorization. These are paramount in ensuring a robust and secure communication over the Y1 interface.

STC-11-11.2-001: Y1 Authenticity

Requirement Name: Y1 protection in terms of authenticity

Requirement Reference & Description: ‘REQ-SEC-Y1-1’, ‘REQ-SEC-Y1-5’, ‘REQ-SEC-Y1-6’ clause 5.2.7.2 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-Y1-01’, T-Y1-02’, T-Y1-03’ clause 7.4.1.13 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: Near-RT RIC, Y1 consumers

Test Name:  TC_Y1_AUTHENTICATION

Test description and applicability

Purpose: The purpose of this test is to verify the authenticity of the Y1 interface, ensuring that only legitimate and mutually authenticated Near-RT RIC, Y1 consumers can participate in the communication over the Y1 interface.

Test setup and configuration

Near-RT RIC & Y1 Consumers support mTLS and be connected in a simulated/real network environment.

The test environment is set up with the Y1 interface configured.

The tester has access to the original data transported over the Y1 interface.

mTLS is properly implemented and configured as defined in [2] clause 4.2.

Test procedure

Execute the test on the mTLS protocol as defined in Clause 6.3.

Valid Authentication Credentials and Certificates (positive case):

The tester sends a request to establish a connection with the Y1 interface using valid authentication credentials.

The tester verifies the mutual certificate verification between Near-RT RIC and Y1 consumers.

The tester captures and analyses the response received from the Y1 interface.

Invalid Authentication Credentials and Certificates (negative case):

The tester sends a request to establish a connection with the Y1 interface without providing valid or correct authentication credentials.

The tester deliberately exchanges an invalid certificate between Near-RT RIC and Y1 consumers.

The tester captures and analyses the response received from the Y1 interface.

Expected results

For 1. Expected results in Clause 6.3.4

For 2. ‘Valid Authentication Credentials and Certificates’: The Y1 interface accepts the valid credentials and responds with a successful authentication message. The mutual certificate verification process is successful.

For 3. ‘Invalid Authentication Credentials and Certificates’: The connection attempt is rejected, and an authentication failure message is received. The mutual certificate verification process fails due to the use of invalid certificates.

Expected Format of Evidence:

The following evidence, in one or more formats as applicable, should be provided:

Logs and screenshots showing adherence to mTLS protocol specifications as defined in [2] clause 4.2.

Logs of authentication requests sent to the Y1 interface.

Logs or screenshots of responses received from the Y1 interface.

Details and logs of the mutual certificate verification process.

Screenshots or logs of error messages or unusual behaviours.

Y1 Confidentiality, integrity, and replay

STC-11-11.2-002: Y1 Confidentiality

Requirement Name: Y1 protection in terms of confidentiality

Requirement Reference & Description: ‘REQ-SEC-Y1-3’, ‘REQ-SEC-Y1-4’ clause 5.2.7.2 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-Y1-01’, T-Y1-02’, T-Y1-03’ clause 7.4.1.13 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: Near-RT RIC, Y1 consumers

Test Name:  TC_Y1_CONFIDENTIALITY

Test description and applicability

Purpose: The purpose of this test is to verify that no sensitive data is exposed on the Y1 interface. It ensures that sensitive information remains protected from unauthorized access or disclosure.

Test setup and configuration

Near-RT RIC and Y1 consumers support TLS and connected within simulated or real network environments.

The test environment is set up with the Y1 interface configured.

The tester has access to the original data transported over the Y1 interface.

TLS is properly implemented and configured as defined in [2] clause 4.2.

The tester has knowledge of the confidentiality algorithm and confidentiality protection keys used for encrypting the encapsulated payload.

Test procedure

Execute the test on the TLS protocol as defined in Clause 6.3.

Support for mandated security profile:

The tester establishes a secure communication session over the Y1 interface and verifies that all protocol versions and combinations of cryptographic algorithms for confidentiality protection that are mandated by the security profile in Clause 4.2 of O-RAN security protocols specification [2] are supported by Near-RT RIC and Y1 consumers.

Rejection of forbidden security profile:

The tester establishes a secure communication session over the Y1 interface and verifies that this is not possible when the Near-RT RIC or Y1 consumers only offers a feature, including protocol version and combination of cryptographic algorithms for confidentiality protection, that is forbidden by the security profile in Clause 4.2 of O-RAN security protocols specification [2].

Traffic capture and analysis:

The tester establishes a secure communication session over the Y1 interface and captures the network traffic during the communication session.

The tester analyses the captured traffic to identify any instances where information is transmitted in clear text or without appropriate encryption.

The tester verifies the captured data so that only the intended recipient can decrypt it.

The tester ensures the encryption process that does not allow the attacker to intercept the data in transit between Near-RT RIC and Y1 consumers except with the provision of the appropriate decryption key.

Expected results

Expected results in Clause 6.3.4

Support for mandated security profile:

All sensitive data transmitted through the Y1 interface is properly encrypted in accordance with the mandated security profile. The communication session demonstrates support for the specified protocol versions and cryptographic algorithms.

Rejection of forbidden security profile:

The Y1 interface rejects attempts to establish a communication session offering forbidden protocol versions or cryptographic algorithms. The security profile's restrictions are enforced by Near-RT RIC and Y1 consumers.

Traffic capture and analysis:

No instances are observed where sensitive information is transmitted without proper encryption or in clear text. The captured traffic confirms the proper application of encryption.

The captured data remains confidential, with only the designated recipient able to decrypt it. The encryption process ensures data confidentiality and prevents unauthorized access.

Expected Format of Evidence:

The following evidence, in one or more formats as applicable, should be provided:

Logs and screenshots showing adherence to TLS protocol specifications as defined in [2] clause 4.2.

Logs of secure communication sessions established over the Y1 interface.

Details of the protocol versions and cryptographic algorithms tested.

Network traffic captures during secure communication sessions.

Analysis of captured traffic, highlighting any unencrypted data.

Verification logs or data confirming proper encryption and decryption.

Screenshots or logs showing rejection of forbidden security profiles.

STC-11-11.2-003: Y1 Integrity

Requirement Name: Y1 protection in terms of integrity

Requirement Reference & Description: ‘REQ-SEC-Y1-3’, ‘REQ-SEC-Y1-4’ clause 5.2.7.2 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-Y1-01’, T-Y1-02’, T-Y1-03’ clause 7.4.1.13 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: Near-RT RIC, Y1 consumers

Test Name:  TC_Y1_INTEGRITY

Test description and applicability

Purpose: The purpose of this test is to verify the integrity of the data transmitted over the Y1 interface, ensuring that no data is modified or altered during transmission (Integrity).

Test setup and configuration

Near-RT RIC and Y1 consumers support TLS and connected within simulated or real network environments.

The test environment is set up with the Y1 interface configured.

The tester has access to the original data transported over the Y1 interface.

TLS is properly implemented and configured as defined in [2] clause 4.2.

The tester has knowledge of the integrity algorithm (Hash Message Authentication Code) and the protection keys.

Test procedure

Execute the test on the TLS protocol as defined in Clause 6.3.

Support for mandated security profile:

The tester establishes a secure communication session over the Y1 interface and verifies that all protocol versions and combinations of cryptographic algorithms for integrity protection that are mandated by the security profile in Clause 4.2 of O-RAN security protocols specification [2] are supported by Near-RT RIC and Y1 consumers.

Rejection of forbidden security profile:

The tester establishes a secure communication session over the Y1 interface and verifies that this is not possible when Near-RT RIC or Y1 consumers only offers a feature, including protocol version and combination of cryptographic algorithms for integrity protection, that is forbidden by the security profile in Clause 4.2 of O-RAN security protocols specification [2].

Traffic capture and analysis:

The tester establishes a secure communication session over the Y1 interface and captures the network traffic during the communication session.

The tester analyses the captured traffic to identify any instances where data integrity is compromised, such as modified or tampered packets.

The tester verifies the MAC algorithms used on the Y1 interface.

EXAMPLE: MAC algorithms such as HMAC (Hash-based Message Authentication Code)

The tester ensures that the MAC is derived at the receiving node using the same hash function and that the secret key matches with MAC calculated at the sending node.

Expected Results

Expected results in Clause 6.3.4

Support for mandated security profile:

Data transmitted via the Y1 interface maintains its integrity between sending and receiving nodes. The security profile's specified protocol versions and cryptographic algorithms are upheld.

Rejection of forbidden security profile:

Near-RT RIC and Y1 consumers reject communication sessions that involve forbidden protocol versions or cryptographic algorithms. The security profile's restrictions are enforced.

Traffic capture and analysis:

Captured traffic is reviewed for any indications of compromised data integrity, such as altered or tampered packets.

No instances of compromised data integrity are observed. Data remains unaltered during transmission.

The MAC algorithms used on the Y1 interface, such as HMAC, are verified to be correctly implemented.

The integrity verification process confirms that the MAC at the receiving node is derived using the same hash function, and the secret key matches the MAC calculated at the sending node.

Expected Format of Evidence:

The following evidence, in one or more formats as applicable, should be provided:

Logs and screenshots showing adherence to TLS protocol specifications as defined in [2] clause 4.2.

Logs of secure communication sessions established over the Y1 interface.

Details of the protocol versions and cryptographic algorithms tested.

Network traffic captures during secure communication sessions.

Analysis of captured traffic, highlighting any altered or tampered packets.

Verification logs or data confirming proper MAC algorithm implementation and integrity checking.

Screenshots or logs showing rejection of forbidden security profiles.

STC-11-11.2-004: Y1 Replay

Requirement Name: Y1 protection in terms of replay

Requirement Reference & Description: ‘REQ-SEC-Y1-3’, ‘REQ-SEC-Y1-4’ clause 5.2.7.2 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-Y1-01’, T-Y1-02’, T-Y1-03’ clause 7.4.1.13 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: Near-RT RIC, Y1 consumers

Test Name:  TC_Y1_REPLAY

Test description and applicability

Purpose: The purpose of this test is to verify that no malicious capture and subsequent replay of network traffic to deceive the system or gain unauthorized access over the Y1 interface. (Anti-replay).

Test setup and configuration

Near-RT RIC and Y1 consumers support TLS and be connected in simulated/real network environments.

The test environment is set up with the Y1 interface configured.

The tester has access to the original data transported over the Y1 interface.

TLS is properly implemented and configured as defined in [2] clause 4.2.

The tester has knowledge of the anti-replay security controls implemented over the Y1 interface.

Test procedure

The tester executes the test on the TLS protocol as defined in Clause 6.3.

The tester establishes a secure communication session over the Y1 interface and captures the network traffic during the communication session.

The tester identifies packets or data that are susceptible to replay attacks, such as those containing authentication credentials, session identifiers, or critical commands.

The tester attempts to replay the captured packets or data by resending them to the O-RAN component (Near-RT RIC and Y1 consumers).

The tester observes the O-RAN component's behavior and response to the replayed packets.

The tester verifies each data packet assigned with a unique sequence number included in the packet header.

The tester verifies each data packet contains a timestamp.

The tester also verifies the sequence number of each received packet and compares it to the previously received packet’s sequence number and if the sequence number is too low or too high, the packet is considered a replay attack and is discarded.

Expected Results

Expected results in Clause 6.3.4

Near-RT RIC and Y1 consumers implement countermeasures to detect and prevent replay attacks. This may include the use of sequence numbers, timestamps, or other forms of message authentication codes.

Near-RT RIC and Y1 consumers reject or ignore replayed packets and do not perform any sensitive or unauthorized actions.

Expected Format of Evidence:

The following evidence, in one or more formats as applicable, should be provided:

Logs and screenshots showing adherence to TLS protocol specifications as defined in [2] clause 4.2.

Logs of secure communication sessions and captured network traffic over the Y1 interface.

Details of identified packets or data susceptible to replay attacks.

Logs or screenshots of the replay attack attempt and the O-RAN components' responses.

Verification logs or data confirming the use of unique sequence numbers and timestamps in packet headers.

Analysis of O-RAN components' behavior in response to replayed packets.

STC-11-11.2-005: Y1 Authorization

Requirement Name: Y1 protection in terms of mutual Authorization

Requirement Reference & Description: ‘REQ-SEC-Y1-2’, ‘REQ-SEC-Y1-6’ clause 5.2.7.2 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-Y1-01’, T-Y1-02’, T-Y1-03’ clause 7.4.1.13 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: Near-RT RIC and Y1 consumers

Test Name: TC_Y1_AUTHORIZATION

Test description and applicability

Purpose: The purpose of this test is to validate that the Y1 interface enforces an authorization mechanism to prevent unauthorized access.

Test setup and configuration

Near-RT RIC and Y1 consumers support OAuth 2.0 and are connected in simulated/real network environment.

The test environment is set up with Y1 interface configured.

The tester has access to the original data transported over the Y1 interface.

OAuth 2.0 is properly implemented and configured.

Test procedure

Execute the test on the OAuth 2.0 protocol as defined in Clause 6.6.

Valid access tokens (positive case):

The tester sends a request to access protected resources using a valid access token.

The tester captures and analyses the response from the Y1 interface.

Invalid access tokens (negative case):

The tester sends a request to access protected resources without providing valid or correct access token.

The tester captures and analyses the response from the Y1 interface.

Expected Results

For 1. Expected results in Clause 6.6.4

For 2. ‘Valid access tokens’: The Y1 interface accepts the valid access tokens and responds with a successful authorization message.

For 3. ‘Invalid access tokens’: The access is rejected, and an access failure message is received.

Expected Format of Evidence:

The following evidence, in one or more formats as applicable, should be provided:

Logs of access requests sent to the Y1 interface, including used access tokens.

Logs or screenshots of responses received from the Y1 interface.

Analysis comparing sent requests and received responses for integrity verification.

Screenshots or logs of error messages or unauthorized access attempts.

O1

This clause delineates a series of test cases aimed at validating the security of the O1 interface within the O-RAN architecture. The tests focus on five critical security facets: confidentiality, integrity, anti-replay, authenticity, and authorization. These are paramount in ensuring a robust and secure communication over the O1 interface.

STC-11-11.3-001: O1 Authenticity

Requirement Name: O1 protection in terms of authenticity

Requirement Reference & Description: ‘REQ-TLS-FUN-1’ clause 5.2.2.1 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-MPLANE-01’ clause 5.4.1.2, clause 5.4.1.1 ‘T-O-RAN-05’ in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: SMO, O-CU, O-DU, Near-RT RIC

Test Name:  TC_O1_AUTHENTICATION

Test description and applicability

Purpose: The purpose of this test is to verify the authenticity of the O1 interface, ensuring that only legitimate and authenticated O-RAN NFs can participate in the communication over the O1 interface.

Test setup and configuration

SMO, O-CU, O-DU, Near-RT RIC support mTLS and be connected in simulated/real network environment.

The test environment is set up with O1 interface configured.

The tester has access to the original data transported over the O1 interface.

mTLS is properly implemented and configured as defined in [2] clause 4.2.

Test procedure

Execute the test on the mTLS protocol as defined in Clause 6.3.

Valid Authentication Credentials and Certificates (positive case):

The tester sends a request to establish a connection with the O1 interface using valid authentication credentials.

The tester verifies the mutual certificate verification between the ORAN NFs

The tester captures and analyses the response received from the O1 interface.

Invalid Authentication Credentials and Certificates (negative case):

The tester sends a request to establish a connection with the O1 interface without providing valid or correct authentication credentials.

The tester deliberately exchanges an invalid certificate between the O-RAN NFs.

The tester captures and analyses the response received from the O1 interface.

Expected results

For 1. Expected results in Clause 6.3.4

For 2. ‘Valid Authentication Credentials and Certificates’: The O1 interface accepts the valid credentials and responds with a successful authentication message. The mutual certificate verification process is successful.

For 3. ‘Invalid Authentication Credentials and Certificates’: The connection attempt is rejected, and an authentication failure message is received. The mutual certificate verification process fails due to the use of invalid certificates.

Expected Format of Evidence:

The following evidence, in one or more formats as applicable, should be provided:

Logs and screenshots showing adherence to mTLS protocol specifications as defined in [2] clause 4.2.

Logs of authentication requests sent to the O1 interface.

Logs or screenshots of responses received from the O1 interface.

Details and logs of the mutual certificate verification process.

Screenshots or logs of error messages or unusual behaviours.

O1 Confidentiality, integrity and replay

STC-11-11.3-002: O1 Confidentiality

Requirement Name: O1 protection in terms of confidentiality

Requirement Reference & Description: ‘REQ-TLS-FUN-1’ clause 5.2.2.1 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-MPLANE-01’ clause 5.4.1.2, ‘T-O-RAN-05’ clause 5.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: SMO, O-CU, O-DU, Near-RT RIC

Test Name:  TC_O1_CONFIDENTIALITY

Test description and applicability

Purpose: The purpose of this test is to verify that no sensitive data is exposed on the O1 interface. It ensures that sensitive information remains protected from unauthorized access or disclosure.

Test setup and configuration

SMO, O-CU, O-DU, Near-RT RIC support TLS and be connected in simulated/real network environment.

The test environment is set up with O1 interface configured.

The tester has access to the original data transported over the O1 interface.

TLS is properly implemented and configured as defined in [2] clause 4.2.

The tester has knowledge of the confidentiality algorithm and confidentiality protection keys used for encrypting the encapsulated payload.

Test procedure

Execute the test on the TLS protocol as defined in Clause 6.3.

Support for mandated security profile:

The tester establishes a secure communication session over the O1 interface and verifies that all protocol versions and combinations of cryptographic algorithms for confidentiality protection that are mandated by the security profile in Clause 4.2 of O-RAN security protocols specification [2] are supported by SMO, O-CU, O-DU and Near-RT RIC.

Rejection of forbidden security profile:

The tester establishes a secure communication session over the O1 interface and verifies that this is not possible when the SMO, O-CU, O-DU or Near-RT RIC only offers a feature, including protocol version and combination of cryptographic algorithms for confidentiality protection, that is forbidden by the security profile in Clause 4.2 of O-RAN security protocols specification [2].

Traffic capture and analysis:

The tester establishes a secure communication session over the O1 interface and captures the network traffic during the communication session.

The tester analyses the captured traffic to identify any instances where information is transmitted in clear text or without appropriate encryption.

The tester verifies the captured data so that only the intended recipient can decrypt it.

The tester ensures the encryption process that does not allow the attacker to intercept the data in transit between the SMO, O-CU, O-DU and Near-RT RIC except with the provision of the appropriate decryption key.

Expected results

Expected results in Clause 6.3.4

Support for mandated security profile:

All sensitive data transmitted through the O1 interface is properly encrypted in accordance with the mandated security profile. The communication session demonstrates support for the specified protocol versions and cryptographic algorithms.

Rejection of forbidden security profile:

The O1 interface rejects attempts to establish a communication session offering forbidden protocol versions or cryptographic algorithms. The security profile's restrictions are enforced by SMO, O-CU, O-DU and Near-RT RIC.

Traffic capture and analysis:

No instances are observed where sensitive information is transmitted without proper encryption or in clear text. The captured traffic confirms the proper application of encryption.

The captured data remains confidential, with only the designated recipient able to decrypt it. The encryption process ensures data confidentiality and prevents unauthorized access.

Expected Format of Evidence:

The following evidence, in one or more formats as applicable, should be provided:

Logs and screenshots showing adherence to TLS protocol specifications as defined in [2] clause 4.2.

Logs of secure communication sessions established over the O1 interface.

Details of the protocol versions and cryptographic algorithms tested.

Network traffic captures during secure communication sessions.

Analysis of captured traffic, highlighting any unencrypted data.

Verification logs or data confirming proper encryption and decryption.

Screenshots or logs showing rejection of forbidden security profiles.

STC-11-11.3-003: O1 Integrity

Requirement Name: O1 protection in terms of integrity

Requirement Reference & Description: ‘REQ-TLS-FUN-1’ clause 5.2.2.1 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-MPLANE-01’ clause 5.4.1.2, ‘T-O-RAN-05’ clause 5.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: SMO, O-CU, O-DU, Near-RT RIC

Test Name:  TC_O1_INTEGRITY

Test description and applicability

Purpose: The purpose of this test is to verify the integrity of the data transmitted over O1 interface, ensuring that no data is modified or altered during transmission (Integrity).

Test setup and configuration

SMO, O-CU, O-DU, Near-RT RIC support TLS and be connected in simulated/real network environment.

The test environment is set up with O1 interface configured.

The tester has access to the original data transported over the O1 interface.

TLS is properly implemented and configured as defined in [2] clause 4.2.

The tester has knowledge of the integrity algorithm (Hash Message Authentication Code) and the protection keys.

Test procedure

Execute the test on the TLS protocol as defined in Clause 6.3.

Support for mandated security profile:

The tester establishes a secure communication session over the O1 interface and verifies that all protocol versions and combinations of cryptographic algorithms for integrity protection that are mandated by the security profile in Clause 4.2 of O-RAN security protocols specification [2] are supported by SMO, O-CU, O-DU and Near-RT RIC.

Rejection of forbidden security profile:

The tester establishes a secure communication session over the O1 interface and verifies that this is not possible when the SMO, O-CU, O-DU or Near-RT RIC only offers a feature, including protocol version and combination of cryptographic algorithms for integrity protection, that is forbidden by the security profile in Clause 4.2 of O-RAN security protocols specification [2].

Traffic capture and analysis:

The tester establishes a secure communication session over the O1 interface and captures the network traffic during the communication session.

The tester analyses the captured traffic to identify any instances where data integrity is compromised, such as modified or tampered packets.

The tester verifies the MAC algorithms used on the O1 interface.

EXAMPLE: MAC algorithms such as HMAC (Hash-based Message Authentication Code)

The tester ensures that the MAC is derived at the receiving node using the same hash function and that the secret key matches with MAC calculated at the sending node.

Expected Results

Expected results in Clause 6.3.4

Support for mandated security profile:

Data transmitted via the O1 interface maintains its integrity between sending and receiving nodes. The security profile's specified protocol versions and cryptographic algorithms are upheld.

Rejection of forbidden security profile:

SMO, O-CU, O-DU or Near-RT RIC reject communication sessions that involve forbidden protocol versions or cryptographic algorithms. The security profile's restrictions are enforced.

Traffic capture and analysis:

Captured traffic is reviewed for any indications of compromised data integrity, such as altered or tampered packets.

No instances of compromised data integrity are observed. Data remains unaltered during transmission.

The MAC algorithms used on the O1 interface, such as HMAC, are verified to be correctly implemented.

The integrity verification process confirms that the MAC at the receiving node is derived using the same hash function, and the secret key matches the MAC calculated at the sending node.

Expected Format of Evidence:

The following evidence, in one or more formats as applicable, should be provided:

Logs and screenshots showing adherence to TLS protocol specifications as defined in [2] clause 4.2.

Logs of secure communication sessions established over the O1 interface.

Details of the protocol versions and cryptographic algorithms tested.

Network traffic captures during secure communication sessions.

Analysis of captured traffic, highlighting any altered or tampered packets.

Verification logs or data confirming proper MAC algorithm implementation and integrity checking.

Screenshots or logs showing rejection of forbidden security profiles.

STC-11-11.3-004: O1 Replay

Requirement Name: O1 protection in terms of replay

Requirement Reference & Description: ‘REQ-TLS-FUN-1’ clause 5.2.2.1 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-MPLANE-01’ clause 5.4.1.2, ‘T-O-RAN-05’ clause 5.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: SMO, O-CU, O-DU, Near-RT RIC

Test Name:  TC_O1_REPLAY

Test description and applicability

Purpose: The purpose of this test is to verify that no malicious capture and subsequent replay of network traffic to deceive the system or gain unauthorized access over the O1 interface. (Anti-replay).

Test setup and configuration

SMO, O-CU, O-DU, Near-RT RIC support TLS and be connected in simulated/real network environment.

The test environment is set up with O1 interface configured.

The tester has access to the original data transported over the O1 interface.

TLS is properly implemented and configured as defined in [2] clause 4.2.

The tester has knowledge of the anti-replay security controls implemented over O1 interface.

Test procedure

The tester executes the tests on the TLS protocol as defined in Clause 6.3.

The tester establishes a secure communication session over the O1 interface and captures the network traffic during the communication session.

The tester identifies packets or data that are susceptible to replay attacks, such as those containing authentication credentials, session identifiers, or critical commands.

The tester attempts to replay the captured packets or data by resending them to the O-RAN component (SMO, O-CU, O-DU or Near-RT RIC).

The tester observes the O-RAN components behaviour and response to the replayed packets.

The tester verifies each data packet assigned with a unique sequence number included in the packet header.

The tester verifies each data packet contains a timestamp.

The tester also verifies the sequence number of each received packet and compares it to the previously received packet’s sequence number and if the sequence number is too low or too high, the packet is considered a replay attack and is discarded.

Expected Results

Expected results in Clause 6.3.4

SMO, O-CU, O-DU and Near-RT RIC implement countermeasures to detect and prevent replay attacks. This may include the use of sequence numbers, timestamps, or other forms of message authentication codes.

SMO, O-CU, O-DU and Near-RT RIC reject or ignore replayed packets and not perform any sensitive or unauthorized actions.

Expected Format of Evidence:

The following evidence, in one or more formats as applicable, should be provided:

Logs and screenshots showing adherence to TLS protocol specifications as defined in [2] clause 4.2.

Logs of secure communication sessions and captured network traffic over the O1 interface.

Details of identified packets or data susceptible to replay attacks.

Logs or screenshots of the replay attack attempt and the O-RAN components' responses.

Verification logs or data confirming the use of unique sequence numbers and timestamps in packet headers.

Analysis of O-RAN components' behaviour in response to replayed packets.

O1 Interface Network Configuration Access Control Model (NACM) Validation

Following zero trust principles, O-RAN O1 interface shall enforce confidentiality, integrity and authenticity through an encrypted transport, and shall support least privilege access control using the network configuration access control model. The network configuration access control model (NACM) [14] provides the means to restrict access for users to a preconfigured subset of all available NETCONF protocol operations and content.

The security test case in this clause validates the NACM enforcement on the O-RAN component O1 interface for the role-based access control.

STC-11-11.3-005: O1 Interface NACM Validation

Requirement Name: O1 Interface security requirements

Requirement Reference: ‘REQ-NAC-FUN-1 to REQ-NAC-FUN-10‘, clause 5.2.2.1 in O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: Requirements of O1 Interface Confidentiality, Integrity & Authenticity protection and Least Privilege Access Control

Threat References: ‘T-O-RAN-02, T-O-RAN-06’ clause 5.4.1.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: Non-RT RIC, Near-RT RIC, O-CU-CP, O-CU-UP, O-DU

Test Name:  TC_O1_NACM_VALIDATION

Test description and applicability

Purpose: O-RAN component(s) managed by SMO through O1 interface shall support secured NETCONF sessions over TLS and role-based least privilege access control enforced by NACM [14]. This test validates the O1 interface security requirements of the O-RAN component(s) with the focus on role-based NACM rule(s) set enforcement.

Test setup and configuration

DUT shall be the O-RAN component with:

IP enabled O1 interface, reachable from the authentication server;

Valid certificate loaded for the server and necessary certificate authorities (CAs)

Client’s root CA required to validate NETCONF client certificate

Valid TLS Client-to-NETCONF username mapping

Configure the O-RAN element with the SMO details (SMO network address and port)

Test procedure

First set up a host/device with TLS client software installed, valid client certificates, keys, root CA certificate for the server (O-RAN component), and all intermediate CA certificates required to validate the client certificate.

The following test steps shall be validated:

Initiate NETCONF call home procedure from the O-RAN element towards SMO over O1 interface.

NOTE: The O-RAN element may initiate the NETCONF call home procedure as part of its initialization automatically.

SMO connects with O-RAN element over O1 interface using TLSv1.2 or TLSv1.3 - if available with a user account from the O1_nacm_management group

Verify the session is established and mapped to the correct NETCONF user

Verify the global NACM enforcement control setting of

enable-nacm = true

read-default = permit

write-default = deny

exec-default = deny

enable-external-groups = true

Verify the NACM rule sets for the following pre-defined groups

O1_nacm_management

O1_user_management

O1_network_management

O1_network_monitoring

O1_software_management for only PNFs

Close the NETCONF session and TLS connection

Upon availability of the NETCONF operations set(s) definition per NACM group, the NACM rule set(s) enforcement by the DUT shall be validated for each of those pre-defined groups listed above.

Expected results

The O-RAN component supports the NETCONF over TLS session over its O1 interface and NACM enforcement control settings.

Expected format of evidence:

Logs or screenshots showing:

O1 interface setup.

Valid server certificate and CA details.

Client’s root CA and intermediate CA certificates.

TLS Client-to-NETCONF username mapping.

O-RAN element configured with SMO details.

Initiation of NETCONF call home procedure.

TLSv1.2 or TLSv1.3 connection establishment.

Correct NETCONF user session mapping.

O2

This clause delineates a series of test cases aimed at validating the security of the O2 interface within the O-RAN architecture. The tests focus on five critical security facets: confidentiality, integrity, anti-replay, authenticity, and authorization. These are paramount in ensuring a robust and secure communication over the O2 interface.

STC-11-11.4-001: O2 Authenticity

Requirement Name: O2 protection in terms of authenticity

Requirement Reference: ‘REQ-SEC-OCLOUD-O2dms-1, REQ-SEC-OCLOUD-O2ims-1’, clause 5.1.7.9 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O2-01’ clause 5.4.2.5.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: SMO, O-Cloud

Test Name:  TC_O2_AUTHENTICATION

Test description and applicability

Purpose: The purpose of this test is to verify the authenticity of the O2 interface, ensuring that only legitimate and authenticated O-Cloud and SMO can participate in the communication over the O2 interface.

Test setup and configuration

O-Cloud and SMO support mTLS and be connected in simulated/real network environment.

The test environment is set up with O2 interface configured.

The tester has access to the original data transported over the O2 interface.

mTLS is properly implemented and configured as defined in [2] clause 4.2.

Test procedure

Executes the tests on the mTLS protocol as defined in Clause 6.3

Valid Authentication Credentials (positive case):

The tester sends a request to establish a connection with the O2 interface using valid authentication credentials.

The tester captures and analyses the response from the O2 interface.

Invalid Authentication Credentials (negative case):

The tester sends a request to establish a connection with the O2 interface without providing valid or correct authentication credentials.

The tester captures and analyses the response from the O2 interface.

Expected results

For 1. Expected results in Clause 6.3.4

For 2. ‘Valid Authentication Credentials’: The O2 interface accepts the valid credentials and respond with a successful authentication message.

For 3. ‘Invalid Authentication Credentials’: The connection is rejected, and an authentication failure message is received.

STC-11-11.4-002: O2 Confidentiality

Requirement Name: O2 protection in terms of confidentiality

Requirement Reference: ‘REQ-SEC-OCLOUD-O2dms-2, REQ-SEC-OCLOUD-O2ims-2’ clause 5.1.7.9 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O2-01’ clause 5.4.2.5.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: SMO, O-Cloud

Test Name:  TC_O2_CONFIDENTIALITY

Test description and applicability

Purpose: The purpose of this test is to verify that no sensitive data is revealed at the O2 interface. It ensures that sensitive information remains protected from unauthorized access or disclosure.

Test setup and configuration

O-Cloud and SMO support TLS and be connected in simulated/real network environment.

The test environment is set up with O2 interface configured.

The tester has access to the original data transported over the O2 interface.

TLS is properly implemented and configured as defined in [2] clause 4.2.

The tester has knowledge of the confidentiality algorithm and confidentiality protection keys used for encrypting the encapsulated payload.

Test procedure

The tester executes the test on the TLS protocol as defined in Clause 6.3

The tester establishes a secure communication session over the O2 interface and verifies that all protocol versions and combinations of cryptographic algorithms for confidentiality protection that are mandated by the security profile in Clause 4.2 of O-RAN security protocols specification [2] are supported by both O-Cloud and SMO.

The tester establishes a secure communication session over the O2 interface and verifies that this is not possible when the O-Cloud or SMO only offers a feature, including protocol version and combination of cryptographic algorithms for confidentiality protection, that is forbidden by the security profile in Clause 4.2 of O-RAN security protocols specification [2].

The tester establishes a secure communication session over the O2 interface and captures the network traffic during the communication session.

The tester analyses the captured traffic to identify any instances where information is transmitted in clear text or without appropriate encryption.

The tester verifies the captured data so that only the intended recipient can decrypt it.

The tester ensures the encryption process that does not allow the attacker to intercept the data in transit between the O-Cloud, and SMO except with the provision of the appropriate decryption key.

Expected results

Expected results in Clause 6.3.4

All sensitive data transmitted over the O2 interface is properly encrypted.

No instances of sensitive information being transmitted in clear text is observed.

Insecure options of protocol version and combination of cryptographic algorithms is not accepted by O-RAN components.

STC-11-11.4-003: O2 Integrity

Requirement Name: O2 protection in terms of integrity

Requirement Reference: ‘REQ-SEC-OCLOUD-O2dms-2, REQ-SEC-OCLOUD-O2ims-2’ clause 5.1.7.9 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O2-01’ clause 5.4.2.5.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: SMO, O-Cloud

Test Name:  TC_O2_INTEGRITY

Test description and applicability

Purpose: The purpose of this test is to verify the integrity of the data transmitted over O2 interface, ensuring that no data is modified or altered during transmission (Integrity).

Test setup and configuration

O-Cloud and SMO support TLS and be connected in simulated/real network environment.

The test environment is set up with O2 interface configured.

The tester has access to the original data transported over the O2 interface.

TLS is properly implemented and configured as defined in [2] clause 4.2.

The tester has knowledge of the integrity algorithm (Hash Message Authentication Code) and the protection keys.

Test procedure

The tester executes the test on the TLS protocol as defined in Clause 6.3

The tester establishes a secure communication session over the O2 interface and verifies that all protocol versions and combinations of cryptographic algorithms for integrity protection that are mandated by the security profile in Clause 4.2 of O-RAN security protocols specification [2] are supported by both O-Cloud and SMO.

The tester establishes a secure communication session over the O2 interface and verifies that this is not possible when the O-Cloud or SMO only offers a feature, including protocol version and combination of cryptographic algorithms for integrity protection, that is forbidden by the security profile in Clause 4.2 of O-RAN security protocols specification [2].

The tester establishes a secure communication session over the O2 interface and captures the network traffic during the communication session.

The tester analyses the captured traffic to identify any instances where data integrity is compromised, such as modified or tampered packets.

The tester verifies the MAC algorithms used on the O2 interface.

EXAMPLE: MAC algorithms such as HMAC (Hash-based Message Authentication Code)

The tester ensures that the MAC is derived at the receiving node using the same hash function and that the secret key matches with MAC calculated at the sending node.

Expected results

Expected results in Clause 6.3.4

There is no modification/corruption of data between sending and receiving nodes. The MAC always matches with the calculated and derived at sending and receiving nodes respectively.

STC-11-11.4-004: O2 Replay

Requirement Name: O2 protection in terms of anti-replay

Requirement Reference: ‘REQ-SEC-OCLOUD-O2dms-2, REQ-SEC-OCLOUD-O2ims-2’ clause 5.1.7.9 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O2-01’ clause 5.4.2.5.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: SMO, O-Cloud

Test Name:  TC_O2_REPLAY

Test description and applicability

Purpose: The purpose of this test is to verify that no malicious capture and subsequent replay of network traffic to deceive the system or gain unauthorized access over the O2 interface. (Anti-replay).

Test setup and configuration

O-Cloud and SMO supports TLS and be connected in simulated/real network environment.

The test environment is set up with O2 interface configured.

The tester has access to the original data transported over the O2 interface.

TLS is properly implemented and configured as defined in [2] clause 4.2.

The tester has knowledge of the anti-replay security controls implemented over O2 interface.

Test procedure

The tester executes the tests on the TLS protocol as defined in Clause 6.3.

The tester establishes a secure communication session over the O2 interface and captures the network traffic during the communication session.

The tester identifies packets or data that are susceptible to replay attacks, such as those containing authentication credentials, session identifiers, or critical commands.

The tester attempts to replay the captured packets or data by resending them to the O-RAN component (O-Cloud or SMO).

The tester observes the O-RAN components behaviour and response to the replayed packets.

The tester verifies each data packet assigned with a unique sequence number included in the packet header.

The tester verifies each data packet contains a timestamp.

The tester also verifies the sequence number of each received packet and compares it to the previously received packet’s sequence number and if the sequence number is too low or too high, the packet is considered a replay attack and is discarded.

Expected results

Expected results in Clause 6.3.4

O-Cloud and SMO implements countermeasures to detect and prevent replay attacks. This may include the use of sequence numbers, timestamps, or other forms of message authentication codes.

O-Cloud and SMO reject or ignore replayed packets and not perform any sensitive or unauthorized actions.

STC-11-11.4-005: O2 Authorization

Requirement Name: O2 protection in terms of authorization

Requirement Reference: ‘REQ-SEC-OCLOUD-O2dms-3, REQ-SEC-OCLOUD-O2ims-3’ Clause 5.1.7.9 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O2-01’ Clause 5.4.2.5.1 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: SMO, O-Cloud

Test Name: TC_O2_AUTHORIZATION

Test description and applicability

Purpose: The purpose of this test is to validate that the O2 interface enforces an authorization mechanism to prevent unauthorized access.

Test setup and configuration

O-Cloud and SMO support OAuth 2.0 and are connected in simulated/real network environment.

The test environment is set up with O2 interface configured.

The tester has access to the original data transported over the O2 interface.

OAuth 2.0 is properly implemented and configured.

Test procedure

Execute the tests on the OAuth 2.0 protocol as defined in Clause 6.6

Valid access tokens (positive case):

The tester sends a request to access protected resources using a valid access token.

The tester captures and analyses the response from the O2 interface.

Invalid access tokens (negative case):

The tester sends a request to access protected resources without providing valid or correct access token.

The tester captures and analyses the response from the O2 interface.

Expected results

For 1. Expected results in Clause 6.6.4

For 2. ‘Valid access tokens’: The O2 interface accepts the valid access tokens and responds with a successful authorization message.

For 3. ‘Invalid access tokens’: The access is rejected, and an access failure message is received.

E2

This clause focuses on verifying the confidentiality, integrity, replay protection, and authenticity of data over the E2 interface. Through a series of meticulously designed tests, the E2 interface's robustness against potential threats is ascertained.

STC-11-11.5-001: E2 Confidentiality

Requirement Name: Data confidentiality protection over E2 interface

Requirement Reference & Description: ‘REQ-SEC-E2-1, SEC-CTL-E2, SEC-CTL-NEAR-RT-2, SEC-CTL-NEAR-RT-7’ clause 5.2.4 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-05’ clause 5.4.1, ‘T-NEAR-RT-01, 02, 03 & 04’ clause 5.4.1.4 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-CU, O-DU, Near-RT RIC

Test Name: TC_E2_CONFIDENTIALITY

Test description and applicability

Purpose: The purpose of this test is to verify that no sensitive data is revealed at the E2 interface between the Near-RT RIC and E2 nodes (CU & DU). It ensures that sensitive information remains protected from unauthorized access or disclosure.

Test setup and configuration

Near-RT RIC and E2 nodes support IPsec and are connected in simulated/real network environment.

The test environment is set up with E2 interface configured. Communication sessions over the E2 interface are established.

The vendor provides documentation describing how confidentiality is achieved for the data transmission over the E2 interface.

The tunnel mode IPsec ESP and IKE certificate authentication is implemented.

Tester has knowledge of the security parameters of tunnel for decrypting the ESP packets.

Tester has knowledge of the confidentiality algorithm and confidentiality protection keys used for encrypting the encapsulated payload.

IPsec is properly implemented and configured. The tester shall base the test on the profile defined in [2] clause 4.5.

Test procedure

Execute the tests on the IPsec protocol as defined in clause 6.5.

Secure communication session establishment

Establish a secure communication session over the E2 interface.

Verify that all protocol versions and combinations of cryptographic algorithms for confidentiality protection mandated by the security profile are supported by the network product.

Attempt using forbidden protocols and algorithms.

Attempt to establish a secure communication session over the E2 interface using protocol versions and cryptographic algorithms for confidentiality protection that are forbidden by the security profile.

Traffic capture

Establish a secure communication session over the E2 interface.

Captures the network traffic during the communication session.

Analyse the captured traffic to identify any instances where sensitive information is transmitted in clear text or without appropriate encryption.

Data decryption verification

Verify the captured data to ensure only the intended recipient can decrypt it.

Encryption process verification

Ensure the encryption process does not allow an attacker to intercept the data in transit between the Near-RT RIC and E2 nodes, except with the provision of the appropriate decryption key.

Expected Results

Expected results in Clause 6.5.4

The secure communication session is successfully established using the mandated protocol versions and cryptographic algorithms.

The attempts to establish a session using forbidden protocols and algorithms fail.

No instances of sensitive information being transmitted in clear text are observed.

The captured data is encrypted in such a way that only the intended recipient can decrypt it.

The encryption process is robust, preventing any unauthorized interception of data.

Expected format of evidence:

The following evidence, in one or more formats as applicable, should be provided:

Logs and screenshots showing adherence to IPsec protocol specifications as defined in [2] clause 4.5.

A screenshot containing the operational results.

Executed commands: Details of the test setup and configuration.

Captured network traffic: Sniffed packets or network captures during the test.

Analysis results: Documentation highlighting the presence or absence of encryption and clear text transmission.

Logs

STC-11-11.5-002: E2 Integrity

Requirement Name: Data integrity protection over E2 interface

Requirement Reference & Description: ‘REQ-SEC-E2-1’ clause 5.2.4 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-05’ clause 5.4.1, ‘T-NEAR-RT-01, 02, 03, 04’ clause 5.4.1.4 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-CU, O-DU, Near-RT RIC

Test Name: TC_E2_INTEGRITY

Test description and applicability

Purpose: The purpose of this test is to verify the integrity of the data transmitted over E2 interface, ensuring that no data is modified or altered during transmission.

Test setup and configuration

Near-RT RIC and E2 nodes support IPsec and are connected in simulated/real network environment.

The test environment is set up with E2 interface configured. Communication sessions over the E2 interface are established.

The vendor provides documentation describing how integrity is achieved for the data transmission over the E2 interface.

The tunnel mode IPsec ESP and IKE certificate authentication is implemented.

Tester has knowledge of the security parameters of tunnel for decrypting the ESP packets.

Tester has knowledge of the integrity algorithm (Hash Message Authentication Code) and the protection keys.

IPsec is properly implemented and configured. The tester shall base the test on the profile defined in [2] clause 4.5.

Test procedure

Execute the tests on the IPsec protocol as defined in clause 6.5.

Secure communication session establishment

Establish a secure communication session over the E2 interface.

Verify that all protocol versions and combinations of cryptographic algorithms for integrity protection mandated by the security profile are supported by the network product.

Attempt using forbidden protocols and algorithms.

Attempt to establish a secure communication session over the E2 interface using protocol versions and cryptographic algorithms for integrity protection that are forbidden by the security profile.

Traffic capture and analysis

Establish a secure communication session over the E2 interface.

Capture the network traffic during the session.

Analyze the captured traffic for any instances of compromised data integrity.

Verification of integrity protection mechanisms

Verify the integrity protection mechanisms used on the E2 interface.

Ensure that the MAC derived at the receiving node matches the MAC calculated at the sending node.

Expected Results

Expected results in Clause 6.5.4

The network product supports all mandated protocol versions and combinations of cryptographic algorithms for integrity protection. The session is established without any errors or interruptions.

The network product rejects or does not support any protocol versions and cryptographic algorithms for integrity protection that are forbidden by the security profile. No secure communication session is established using the forbidden protocols and algorithms.

The captured traffic does not show any signs of compromised data integrity. All transmitted data packets remain unaltered during transmission. No instances of tampered or modified packets are observed in the captured traffic.

The integrity algorithms and HMACs function correctly and consistently. The MAC derived at the receiving node matches the MAC calculated at the sending node, confirming the integrity of the transmitted data.

Expected format of evidence:

The following evidence, in one or more formats as applicable, should be provided:

Logs and screenshots showing adherence to IPsec protocol specifications as defined in [2] clause 4.5.

A screenshot containing the operational results.

Executed commands: Details of the test setup and configuration.

Captured network traffic: Sniffed packets or network captures during the test.

Analysis results: Documentation indicating successful verification of data integrity and absence of tampering or modifications.

Logs

STC-11-11.5-003: E2 Replay

Requirement Name: Data replay protection over E2 interface

Requirement Reference & Description: ‘REQ-SEC-E2-1’ clause 5.2.4 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-05’ clause 5.4.1, ‘T-NEAR-RT-01, 02, 03 & 04’ clause 5.4.1.4, ‘T-xAPP-01’ clause 5.4.1.6 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-CU, O-DU, Near-RT RIC

Test Name: TC_E2_REPLAY

Test description and applicability

Purpose: The purpose of this test is to verify that no malicious capture and subsequent replay of network traffic to deceive the system or gain unauthorized access over the E2 interface.

Test setup and configuration

Near-RT RIC and E2 nodes support IPsec and are connected in simulated/real network environment.

The test environment is set up with E2 interface configured. Communication sessions over the E2 interface are established.

The vendor provides documentation describing how replay protection is achieved for the data transmission over the E2 interface.

The tunnel mode IPsec ESP and IKE certificate authentication is implemented.

Tester has knowledge of the security parameters of tunnel for decrypting the ESP packets.

Tester shall have access to the original user data transported over the E2 interface.

IPsec is properly implemented and configured. The tester shall base the test on the profile defined in [2] clause 4.5.

Test procedure

Execute the tests on the IPsec protocol as defined in clause 6.5.

The tester establishes a secure communication session over the E2 interface and verifies that all protocol versions and combinations of cryptographic algorithms for replay protection that are mandated by the security profile are supported by the network product.

The tester attempts to establish a secure communication session over the E2 interface using protocol versions and cryptographic algorithms for replay protection that are forbidden by the security profile. These attempts will not succeed.

The tester establishes a secure communication session over the E2 interface and captures the network traffic during the communication session.

The tester identifies packets or data that are susceptible to replay attacks, such as those containing authentication credentials, session identifiers, or critical commands.

The tester attempts to replay the captured packets or data by resending them to the system (Near-RT RIC or E2 nodes).

The tester observes the system's behavior and response to the replayed packets.

The tester verifies each data packet assigned with a unique sequence number included in the packet header.

The tester verifies each data packet contains a timestamp.

The tester also verifies the sequence number of each received packet and compares it to the previously received packet’s sequence number and if the sequence number is too low or too high, the packet is considered a replay attack and is discarded.

Expected Results

Expected results in Clause 6.5.4

The system has implemented countermeasures to detect and prevent replay attacks. This includes the use of sequence numbers, timestamps, or other forms of message authentication codes.

The system rejects or ignores replayed packets and not performs any sensitive or unauthorized actions.

Expected format of evidence:

The following evidence, in one or more formats as applicable, should be provided:

Logs and screenshots showing adherence to IPsec protocol specifications as defined in [2] clause 4.5.

A screenshot containing the operational results.

Executed commands: Details of the test setup and configuration.

Captured network traffic: Sniffed packets or network captures during the test.

System response: Documentation of the system's behavior and response to the replayed packets.

Logs

E2 Authenticity

STC-11-11.5-004: E2 Authenticity with certificate

Requirement Name: Data Authentication over E2 interface

Requirement Reference & Description: ‘REQ-SEC-E2-1’ clause 5.2.4 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-05’ clause 5.4.1, ‘T-NEAR-RT-01, 02, 03 & 04’ clause 5.4.1.4 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-CU, O-DU, Near-RT RIC

Test Name: TC_E2_AUTHENTICATION_CERT

Test description and applicability

Purpose: The purpose of this test is to verify the authenticity of the E2 interface with valid certificates, ensuring that only legitimate and authenticated Near-RT RIC and E2 nodes can participate in the communication over the E2 interface.

Test setup and configuration

Near-RT RIC and E2 nodes support IPsec and are connected in simulated/real network environment.

Near-RT RIC and E2 nodes support IPsec and are configured to use certificate-based authentication.

The test environment is set up with E2 interface configured. Communication sessions over the E2 interface are established.

The vendor provides documentation describing how authenticity protection is achieved for the data transmission over the E2 interface.

The tunnel mode IPsec ESP and IKE certificate authentication is implemented.

Tester has knowledge of the security parameters of tunnel for decrypting the ESP packets.

Tester shall have access to the original user data transported over the E2 interface.

IPsec is properly implemented and configured. The tester shall base the test on the profile defined in [2] clause 4.5.

Test procedure

Execute the tests on the IPsec protocol as defined in clause 6.5.

Valid Authentication Credentials:

The tester sends a request to establish a connection with the E2 interface using valid certificates.

The tester shall capture and analyze the response from the E2 interface.

Invalid Authentication Credentials:

The tester sends a request to establish a connection with the E2 interface with invalid or no certificates.

The tester shall capture and analyze the response from the E2 interface.

Expected Results

For 1. Expected results in Clause 6.5.4

For 2. ‘Valid Authentication Credentials’: The E2 interface accepts the valid certificate and responds with a successful authentication message.

For 3. ‘Invalid Authentication Credentials’: The connection is rejected due to the certificate verification failure, and an authentication failure message is received.

Expected format of evidence:

Logs and screenshots showing adherence to IPsec protocol specifications as defined in [2] clause 4.5.

Capture and document the request and response messages, confirming the successful authentication with valid credentials.

Capture and document the request and response messages, confirming the rejection of invalid credentials.

11.5.4.2	STC-11-11.5-005: E2 Authenticity with PSK

Requirement Name: Data Authentication over E2 interface

Requirement Reference & Description: ‘REQ-SEC-E2-1’ clause 5.2.4 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-O-RAN-05’ clause 5.4.1, ‘T-NEAR-RT-01, 02, 03 & 04’ clause 5.4.1.4 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-CU, O-DU, Near-RT RIC

Test Name: TC_E2_AUTHENTICATION_PSK

Test description and applicability

Purpose: The purpose of this test is to verify the authenticity of the E2 interface with valid PSK, ensuring that only legitimate and authenticated Near-RT RIC and E2 nodes can participate in the communication over the E2 interface.

Test setup and configuration

Near-RT RIC and E2 nodes support IPsec and are connected in simulated/real network environment.

Near-RT RIC and E2 nodes support IPsec and are configured to use PSK-based authentication.

The test environment is set up with E2 interface configured. Communication sessions over the E2 interface are established.

The vendor provides documentation describing how authenticity protection is achieved for the data transmission over the E2 interface.

The tunnel mode IPsec ESP and IKE certificate authentication is implemented.

Tester has knowledge of the security parameters of tunnel for decrypting the ESP packets.

Tester shall have access to the original user data transported over the E2 interface.

IPsec is properly implemented and configured. The tester shall base the test on the profile defined in [2] clause 4.5.

Test procedure

Execute the tests on the IPsec protocol as defined in clause 6.5.

Valid Authentication Credentials:

The tester sends a request to establish a connection with the E2 interface using valid PSKs.

The tester shall capture and analyze the response from the E2 interface.

Invalid Authentication Credentials:

The tester sends a request to establish a connection with the E2 interface with incorrect or no PSKs.

The tester shall capture and analyze the response from the E2 interface.

Expected Results

For 1. Expected results in Clause 6.5.4

For 2. ‘Valid Authentication Credentials’: The E2 interface accepts the valid PSK and responds with a successful authentication message.

For 3. ‘Invalid Authentication Credentials’: The connection is rejected due to PSK verification failure, and an authentication failure message is received.

Expected format of evidence:

Logs and screenshots showing adherence to IPsec protocol specifications as defined in [2] clause 4.5.

Capture and document the request and response messages, confirming the successful authentication with valid credentials.

Capture and document the request and response messages, confirming the rejection of invalid credentials.

	Security test of O-RU

	Overview

This clause contains security tests to validate the security protection mechanism specific to O-RU.

STC-12-12.2-001: SSH on M-Plane interface

Introduction

Test name: TC_SSH_MPlane

Requirement Name: Network Security Protocol - SSH

Requirement Reference:  Clause 5.4, O-RAN Fronthaul Management Plane Specification [21]

Requirement Description: Robust protocol implementation with adequately strong cipher suites is being required for SSH

Threat References: T-O-RAN-05

DUT/s: O-RU

Test Description

Purpose: To verify implementation of the SSH protocol in O-RU along with validation of supported SSH version and robustness of cryptographic algorithms used for host key, symmetric encryption, key exchange, and MACs as specified in [21]

Test setup and configuration

DUT is the O-RU with SSH service enabled as server. Client is a test equipment with SSH audit tool which is used for server-side testing.

Test procedure

This test case follows the "server-side testing" procedure for SSH specified in STC-6-001: SSH Server & Client, clause 6.2 of the present document.

 Expected results

O-RU as SSH server supports only SSHv2 version with no older version supported and algorithms (for host key, symmetric encryption, key exchange, and MACs) defined in clause 5.4 of  [21].

Expected format of evidence: As defined in clause 6.2 of the present document.

STC-12-12.3-001: TLS on M-Plane interface

Introduction

Test name: TC_TLS_MPlane

Requirement Name: Network Security Protocol - TLS

Requirement Reference: Clause 5.4, O-RAN Fronthaul Management Plane Specification [21]

Requirement Description: Support TLS v1.2 and/or TLS v1.3 with protocol profiles

Threat References: T-O-RAN-05

DUT/s: O-RU

Test Description

Purpose: To verify implementation of the TLS protocol in O-RU along with validation of mandated/optional TLS versions and cipher suites specified in clause 5.4 of [21]. Since NETCONF implementations support X.509v3 certificate-based authentication using TLS 1.2, mutual authentication shall also be tested using both valid and Invalid client certificates.

Test setup and configuration

DUT is the O-RU with TLS service enabled as server equipped with CA cert for signing client certificate(s). Client is a testing equipment with TLS scanning tool with client certificate(s).

Test procedure

This test case follows the test procedure for TLS specified in STC-6-002: TLS, clause 6.3 of the present document.

 Expected results

O-RU as TLS server shall support TLS starting from version 1.2 with no older version enabled along with protocol profiles/Cipher suites defined in clause 5.4 of [21].

Expected format of evidence: As defined in clause 6.3 of the present document.

Security functional requirements and test cases

The 802.1X Supplicant Validation test cases in clause 11.2.2 of the present document apply to O-RU.

	Security test of Near-RT RIC

	Overview

This clause contains security tests to validate the security protection mechanism specific to Near-RT RIC.

	Void

Transactional APIs

Introduction

Transactional APIs in the Near-RT RIC are APIs that are based on HTTP/TLS, i.e. APIs based on REST or gRPC.

STC-13-13.3-001: TLS for transactional APIs

Introduction

Test name: TC_TLS_APIs

Requirement Name: TLS for transactional APIs

Requirement Reference: SEC-CTL-NEAR-RT-6, clause 5.1.3.2, O-RAN Security Requirements and Controls Specification [5].

Requirement Description: “Transactional APIs (REST and gRPC) shall support TLS to provide message confidentiality and integrity.”

Threat References: T-NEAR-RT-01, T-NEAR-RT-02, T-NEAR-RT-03, T-NEAR-RT-04

DUT/s: xApp, Near-RT RIC

Test description and applicability

Purpose: To verify the transactional APIs (REST and gRPC) supports TLS to provide message confidentiality and integrity.

Test setup and configuration

DUT is configured and with TLS support enabled.

The other end may be simulated or a testing equipment.

Test procedure

This test case follows the test procedure for TLS specified in TLS Test Procedure, clause 6.3.3 of the present document.

Expected results

The transaction APIs provides confidentiality and integrity protection for data in transit.

Expected format of evidence: Tool reports, log files, traffic captures and/or screenshots.

STC-13-13.3-002: mTLS for transactional APIs

Introduction

Test name: TC_mTLS_APIs

Requirement Name: mTLS for transactional APIs

Requirement Reference: REQ-SEC-NEAR-RT-3, Clause 5.1.3.2, O-RAN Security Requirements and Controls Specification [5].

Requirement Description: “The communication between xApps and Near-RT RIC platform APIs shall be mutually authenticated.”

Threat References: T-NEAR-RT-01, T-NEAR-RT-02, T-NEAR-RT-03, T-NEAR-RT-04

DUT/s: xApp, Near-RT RIC

Test description and applicability

Purpose: To verify the transactional APIs (REST and gRPC) supports mutual TLS (mTLS) authentication via X.509v3 certificates.

Applicability: DUTs that support mTLS as a mutual authentication mechanism.

Test setup and configuration

DUT is configured and with mTLS support enabled.The other end may be simulated or a testing equipment.

Test procedure

This test case follows the test procedure for TLS specified in TLS Test Procedure, clause 6.3.3 of the present document.

Expected results

The transaction APIs supports mutual TLS (mTLS) authentication.

Expected format of evidence: Tool reports, log files, traffic captures and/or screenshots.

STC-13-13.3-003: OAuth 2.0 for transactional APIs

Introduction

Test name: TC_OAuth2.0_API

Requirement Name: OAuth 2.0 for transactional APIs

Requirement Reference: REQ-SEC-NEAR-RT-4, REQ-SEC-NEAR-RT-5, Clause 5.1.3.1, O-RAN Security Requirements and Controls Specification [5].

Requirement Description: Near-RT RIC architecture provides an authorization framework.

Threat References: T-NEAR-RT-01, T-NEAR-RT-02, T-NEAR-RT-03, T-NEAR-RT-04

DUT/s: xApp, Near-RT RIC

Test description and applicability

Purpose: To verify the transactional APIs (REST and gRPC) in the DUT supports the OAuth 2.0 authorization framework.

Test setup and configuration

DUT is configured and with OAuth 2.0 support enabled.

The other end may be simulated or a testing equipment.

Test procedure

This test case follows the test procedure for OAuth2.0 specified in OAuth Test Procedure, clause 6.6.3 of the present document.

Expected results

The transaction APIs supports the use of OAuth 2.0.

Expected format of evidence: Tool reports, log files, traffic captures and/or screenshots.

	Security test of xApps

	Overview

 This chapter contains security tests to validate the security protection mechanism specific to xApps deployed on Near-RT RIC.

	xApp Signing and Verification

Security test cases “STC-9-9.5-001: Software Image/Application Package Signing” and “STC-9-9.5-002: Software Signature Verification” shall be performed.

	Security test of Non-RT RIC

	Overview

 This chapter contains security tests to validate the security protection mechanism specific to Non-RT RIC and the R1 and A1 interfaces.  Security test cases for rApps are covered in a separate sub-clause.

	Non-RT RIC

 Following zero trust principles, O-RAN Non-RT RIC shall enforce authorization using OAuth 2.0

STC-15-15.2-001: Non-RT RIC OAuth 2.0 Resource Owner/Server

Test name: TC_NonRTRIC_OAuth2.0_Server

Requirement Name: Server authorization support

Requirement Reference: REQ-SEC-NonRTRIC-1, Clause 5.1.2.1, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: Non-RT RIC supports OAuth 2.0 as a Server

Threat References: T-NONRTRIC-01, T-NONRTRIC-02, T-NONRTRIC-03

DUT/s: Non-RT RIC

Test description and applicability

Purpose: To verify the Non-RT RIC supports OAuth 2.0 resource owner/server for A1-EI.

Test setup and configuration

The DUT is acting as a Resource Owner/Server and has OAuth 2.0 support enabled.

The rest of the elements of the setup may be real or simulated.

Test procedure

This test case follows the test procedure for OAuth2.0 specified in OAuth Test Procedure, clause 6.6.3.

Expected results

The Non-RT RIC is able to authorize/deny access to resources using OAuth 2.0.

Expected format of evidence: Log files, traffic captures and/or report files.

STC-15-15.2-002: Non-RT RIC OAuth 2.0 Client

Test name: TC_NonRTRIC_OAuth2.0_Client

Requirement Name: Client authorization support

Requirement Reference: REQ-SEC-NonRTRIC-1, Clause 5.1.2.1, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: Non-RT RIC supports OAuth 2.0 as a Client

Threat References: T-NONRTRIC-01, T-NONRTRIC-02, T-NONRTRIC-03

DUT/s: Non-RT RIC

Test description and applicability

Purpose: To verify the Non-RT RIC supports OAuth 2.0 client for A1-P.

Test setup and configuration

The DUT is acting as a Client and has OAuth 2.0 support enabled.

The rest of the elements of the setup may be real or simulated.

Test procedure

This test case follows the test procedure for OAuth2.0 specified in OAuth Test Procedure, clause 6.6.3.

Expected results

The Non-RT RIC is able to request and be permitted access to resources using OAuth 2.0.

Expected format of evidence: Log files, traffic captures and/or report files.

STC-15-15.2-003: Non-RT RIC Framework OAuth 2.0

Test name: TC_NonRTRIC_OAuth2.0_Framework_Server

Requirement Name: Framework Server authorization support

Requirement Reference: REQ-SEC-NonRTRIC-2, Clause 5.1.2.1, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: Non-RT RIC Framework supports OAuth 2.0 as a Server

Threat References: T-NONRTRIC-01, T-NONRTRIC-02, T-NONRTRIC-03

DUT/s: Non-RT RIC

Test description and applicability

Purpose: To verify the Non-RT RIC Framework supports OAuth 2.0 as a resource owner/server.

Test setup and configuration

The DUT is acting as a Resource Owner and has OAuth 2.0 support enabled.

The rest of the elements of the setup may be real or simulated.

Test procedure

This test case follows the test procedure for OAuth2.0 specified in OAuth Test Procedure, clause 6.6.3.

Expected results

The Non-RT RIC Framework is able to authorize access to resources using OAuth 2.0.

Expected format of evidence: Log files, traffic captures and/or report files.

R1 interface

The R1 interface is internal to the Non-RT RIC to provide communication between the Non-RT RIC Framework and rApps.  Following zero trust principles, the R1 interface shall provide confidentiality and integrity protection of data in transit and shall support mutual authentication and authorization for access to services and resources.

STC-15-15.3-001: TLS on R1 Interface

Test name: TC_TLS_R1_Interface

Requirement Name:  Confidentiality, integrity and replay protection of R1 interface

Requirement Reference: REQ-SEC-R1-1, Clause 5.2.6.1, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: “R1 interface shall support confidentiality, integrity, and replay protection“

Threat References: T-R1-06, T-R1-07

DUT/s: Non-RT RIC, rApps

Test description and applicability

Purpose: To verify the DUT supports TLS on the R1 interface.

Test setup and configuration

The DUT has the TLS support enabled and it is properly connected.

The rest of the elements of the setup may be real or simulated.

Test procedure

This test case follows the test procedure for TLS specified in TLS Test Procedure, clause 6.3.3.

Expected results

The R1 interface provides confidentiality and integrity protection for data in transit.

Expected format of evidence: Log files, traffic captures and/or report files.

STC-15-15.3-002: mTLS on R1 Interface

Test name: TC_mTLS_R1_Interface

Requirement Name: Mutual authentication in R1 interface

Requirement Reference: REQ-SEC-R1-2, Clause 5.2.6.1, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: “R1 interface shall support mutual authentication and authorization.”

Threat References: T-R1-03

DUT/s: Non-RT RIC, rApps

Test description and applicability

Purpose: To verify the DUT supports mutual authentication on the R1 interface.

Test setup and configuration

The DUT has the mTLS support enabled.

The rest of the elements of the setup may be real or simulated.

Test procedure

This test case follows the test procedure for TLS specified in TLS Test Procedure, clause 6.3.3.

Expected results

The R1 interface supports mutual authentication using mTLS on the R1 interface.

Expected format of evidence: Log files, traffic captures and/or report files.

STC-15-15.3-003: OAuth 2.0 on R1 Interface

Test name: TC_OAuth2.0_R1_Interface

Requirement Name: Authorization on R1 interface

Requirement Reference: REQ-SEC-R1-2, Clause 5.2.6.1, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: R1 interface supports OAuth 2.0

Threat References: T-R1-01, T-R1-04, T-R1-05

DUT/s: Non-RT RIC, rApps

Test description and applicability

Purpose: To verify the R1 interface on the DUT supports OAuth 2.0.

Test setup and configuration

The DUT has the OAuth 2.0 support enabled.

The rest of the elements of the setup may be real or simulated.

Test procedure

This test case follows the test procedure for OAuth2.0 specified in OAuth Test Procedure, clause 6.6.3.

Expected results

The R1 interface supports use of OAuth 2.0.

Expected format of evidence: Log files, traffic captures and/or report files.

A1 interface

The A1 interface provides communication between the Non-RT RIC and Near-RT RIC.  Following zero trust principles, the A1 interface provides confidentiality and integrity protection of data in transit and supports mutual authentication and authorization for access to services and resources.

STC-15-15.4-001: TLS on A1 Interface

Test name: TC_TLS_A1_Interface

Requirement Name: Confidentiality, integrity and replay protection of A1 interface

Requirement Reference: REQ-SEC-A1-1, Clause 5.2.1.1, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: “A1 interface shall support confidentiality, integrity, replay protection.”

Threat References: T-A1-02, T-A1-03

DUT/s: Non-RT RIC, Near-RT RIC

Test description and applicability

Purpose: To verify the DUT supports TLS on the A1 interface.

Test setup and configuration

The DUT has TLS support enabled on the A1 interface.

The rest of the elements of the setup may be real or simulated.

Test procedure

This test case follows the test procedure for TLS specified in TLS Test Procedure, clause 6.3.3.

Expected results

The A1 interface provides confidentiality, integrity and replay protection for data in transit.

Expected format of evidence: Log files, traffic captures and/or report files.

STC-15-15.4-002: mTLS on A1 Interface

Test name: TC_mTLS_A1_Interface

Requirement Name: Mutual Authentication on A1 Interface

Requirement Reference: REQ-SEC-A1-2, Clause 5.2.1.1, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: mTLS on A1 interface

Threat References: T-A1-01

DUT/s: Non-RT RIC, Near-RT RIC

Test description and applicability

Purpose: To verify the DUT supports mutual authentication using mTLS on the A1 interface.

Test setup and configuration

The DUT has mTLS support enabled on the A1 interface.

The rest of the elements of the setup may be real or simulated.

Test procedure

This test case follows the test procedure for TLS specified in TLS Test Procedure, clause 6.3.3.

Expected results

The A1 interface of the DUT supports mutual authentication using mTLS.

Expected format of evidence: Log files, traffic captures and/or report files.

STC-15-15.4-003: OAuth 2.0 on A1 interface

Test name: TC_OAuth2.0_A1_Interface

Requirement Name: Authorization on A1 Interface

Requirement Reference: REQ-SEC-A1-2, Clause 5.2.1.1, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: A1 interface supports OAuth 2.0 security controls

Threat References: T-A1-01

DUT/s: Non-RT RIC, Near-RT RIC

Test description and applicability

Purpose: To verify the A1 interface in the DUT supports OAuth 2.0.

Test setup and configuration

The DUT has OAuth 2.0 support enabled on A1 interface.

The rest of the elements of the setup may be real or simulated.

Test procedure

This test case follows the test procedure for OAuth2.0 specified in OAuth Test Procedure, clause 6.6.3.

Expected results

The A1 interface supports the use of OAuth 2.0.

Expected format of evidence: Log files, traffic captures and/or report files.

	Security test of rApps

	Overview

This chapter contains security tests to validate the security protection mechanism specific to rApps deployed on Non-RT RIC.

	rApp Signing and Verification

Security test cases “STC-9-9.5-001: Software Image/Application Package Signing” and “STC-9-9.5-002: Software Signature Verification” shall be performed.

	rApp Authorization

STC-16-16.3-001: rApp OAuth 2.0 Client

Test name: TC_OAuth2.0_rApp

Requirement Name: rApp OAuth2.0 Client support

Requirement Reference: REQ-SEC-NonRTRIC-3, Clause 5.1.2.1, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: “rApps shall provide client authorization requests to the Non-RT RIC Framework.”

Threat References: T-rAPP-04

DUT/s: rApps

Test description and applicability

Purpose: To verify the rApp supports OAuth 2.0 client.

Test setup and configuration

The DUT is acting as an OAuth2.0 Client with OAuth 2.0 support enabled.

The rest of the elements of the setup may be real or simulated.

Test procedure

This test case follows the test procedure for OAuth2.0 specified in OAuth Test Procedure, clause 6.6.3.

Expected results

The rApp is able to request access and be permitted access to resources using OAuth 2.0.

Expected format of evidence: Log files, traffic captures and/or report files.

	Security test of SMO

	Overview

This chapter contains security tests to validate security protection mechanisms related to the SMO.	The test cases validate the security of SMO termination of O1 interfaces, SMO, SMO Services (SMOS) Communications, SMO External Interfaces, and SMO Logging are secured to zero trust principles for confidentiality, integrity, authentication, and authorization.  Definitions for the O-RAN terms SMO Service (SMOS), SMO Function (SMOF), SMO External Interfaces, and SMO External System are provided in [1].

The test cases apply to the normative security requirements specified in [5] based upon the following approved security architecture:

The SMO enforces confidentiality, integrity and authenticity through an encrypted transport for the O1 interface and supports least privilege access control using the network configuration access control model (NACM) for authorization.

The SMO supports mutual authentication and authorization of SMO Functions (SMOF) and External Interfaces.

SMO Internal Communications provide communication and services between the SMO, SMOFs, Non-RT RIC Functions, and rApps.  SMO Internal Communications shall provide confidentiality and integrity protection of data in transit and shall support mutual authentication and authorization for access to services and resources.

SMO External Interfaces provide import of AI enrichment data from external data sources to the SMO.  SMO External Interfaces shall provide confidentiality and integrity protection of data in transit and shall support mutual authentication and authorization for access to services and resources.

Void

SMO

 STC-17-17.3-001: SMO OAuth 2.0 Resource Owner/Server

Test Name: SMO OAuth 2.0 Resource Owner/Server

Requirement Name:  SEC-CTL-SMO-3

Requirement Reference: Clause 5.2.1.2.1, Security Controls, SMO, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: OAuth 2.0 security controls for SMO to authorize service requests from SMO Functions.

Threat References: T-SMO-02, T-SMO-05

DUT/s: SMO, SMO Functions

Test description and applicability

Purpose: To verify the SMO shall support OAuth 2.0 resource owner/server.

Test setup and configuration

DUT shall be the SMO with OAuth 2.0 support enabled.

Test procedure

This test case shall follow the test procedure for OAuth2.0 specified in OAuth Test Procedure, clause 6.6.3.

Expected results

The SMO shall be able to authorize/deny access requests received from SMO Functions using OAuth 2.0.

Expected format of evidence: Log entries, packet captures, and screenshots.

 STC-17-17.3-002: SMO OAuth 2.0 Client

Test Name: SMO OAuth 2.0 Client

Requirement Name:  SEC-CTL-SMO-4

Requirement Reference: Clause 5.2.1.2.1, Security Controls, SMO, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: OAuth 2.0 security controls for SMO to support client functionality for service requests to other SMO Functions

Threat References: T-SMO-02, T-SMO-05

DUT/s: SMO, SMO Functions

Test description and applicability

Purpose: To verify the SMO supports OAuth 2.0 client.

Test setup and configuration

DUT shall be the SMO with OAuth 2.0 support enabled.

Test procedure

This test case follows the test procedure for OAuth2.0 specified in OAuth Test Procedure, clause 6.6.3.

 Expected results

The SMO shall be able to request and be permitted/denied access to resources using OAuth 2.0.

Expected format of evidence: Log entries, packet captures, and screenshots.

 STC-17-17.3-003: SMO mTLS for mutual authentication

Test Name: SMO mTLS

Requirement Name:  SEC-CTL-SMO-5

Requirement Reference: Clause 5.2.1.2.1, Security Controls, SMO, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: SMO support mTLS for mutual authentication with SMO Functions.

Threat References: T-SMO-01, T-SMO-04

DUT/s: SMO, SMO Functions

Test description and applicability

Purpose: To verify the SMO supports mutual authentication with SMO Functions using mTLS, with PKI and X.509 certificates.

Test setup and configuration

DUT shall be the SMO with mTLS support enabled.  An external OAuth 2.0 Authorization Server is available and configured.

Test procedure

This test case follows the test procedure for mTLS specified in mTLS Test Procedure, clause 6.3.3.

Expected results

The SMO shall support mutual authentication of SMO Functions using mTLS.

Expected format of evidence: Log entries, packet captures, and screenshots.

SMO Internal Communications

STC-17-17.4-001: TLS for SMO Internal Communications

Test name: TLS for SMO Internal Communications

Requirement Name:  SEC-CTL-SMO-Internal-1

Requirement Reference: Clause 5.2.1.2.2, Security Controls, SMO Internal Communications, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: Data in transit protection with TLS for SMO Internal Communications

Threat References: T-SMO-09

DUT/s: SMO, SMO Functions, Non-RT RIC Functions

Test description and applicability

Purpose: To verify the SMO supports TLS on SMO Internal Communications.

Test setup and configuration

DUT shall be the SMO with TLS support enabled.

Test procedure

This test case shall follow the test procedure for TLS specified in TLS Test Procedure, clause 6.3.3.

Expected results

SMO Internal Communications shall provide confidentiality and integrity protection using TLS for data in transit.

Expected format of evidence: Log entries, packet captures, and screenshots.

STC-17-17.4-002: mTLS for SMO Internal Communications – SMO Functions

Test Name: mTLS for SMO Internal Communications

Requirement Name:  SEC-CTL-SMO-Internal-2

Requirement Reference: Clause 5.2.1.2.2, Security Controls, SMO Internal Communications, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: Mutual authentication with mTLS for SMO Internal Communications

Threat References: T-SMO-01, T-SMO-04

DUT/s: SMO Functions

Test description and applicability

Purpose: To verify SMO Functions support mutual authentication using mTLS, with PKI and X.509 certificates, for SMO Internal Communications.

Test setup and configuration

DUT shall be the SMO Function with mTLS support enabled.

Test procedure

This test case follows the test procedure for mTLS specified in mTLS Test Procedure, clause 6.3.3.

Expected results

The SMO Function shall support mutual authentication using mTLS.

Expected format of evidence: Log entries, packet captures, and screenshots.

SMO External Interfaces

 STC-17-17.5-001: TLS for SMO External Interfaces

Test Name: TLS for SMO External interfaces

Requirement Name:  SEC-CTL-SMO-External-1

Requirement Reference: Clause 5.2.1.2.3, Security Controls, SMO External Interfaces, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: Data in transit protection with TLS on SMO External Interfaces

Threat References: T-SMO-09

DUT/s: SMO

Test description and applicability

Purpose: To verify the SMO supports TLS on SMO External Interface.

Test setup and configuration

DUT shall be the SMO with TLS support enabled.

Test procedure

This test case shall follow the test procedure for TLS specified in TLS Test Procedure, clause 6.3.3.

Expected results

SMO External Interface shall provide confidentiality and integrity protection using TLS for data in transit.

Expected format of evidence: Log entries, packet captures, and screenshots.

 STC-17-17.5-002: mTLS for SMO External Interfaces

Test Name: mTLS for SMO External Interfaces

Requirement Name:  SEC-CTL-SMO-External-2

Requirement Reference: Clause 5.2.1.2.3, Security Controls, SMO External Interfaces, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: Mutual authentication with mTLS on SMO External Interfaces

Threat References: T-SMO-01, T-SMO-04

DUT/s: SMO

Test description and applicability

Purpose: To verify the SMO supports mutual authentication using mTLS, with PKI and X.509 certificates for SMO External Interfaces.

Test setup and configuration

DUT shall be the SMO with mTLS support enabled.

Test procedure

This test case follows the test procedure for mTLS specified in mTLS Test Procedure, clause 6.3.3.

Expected results

The SMO shall support mutual authentication of SMO Functions using mTLS for SMO External Interfaces.

Expected format of evidence: Log entries, packet captures, and screenshots.

 STC-17-17.5-003: SMO Framework OAuth 2.0 Resource Owner/Server for External Interface

Test name: OAuth 2.0 Resource Owner/Server for External Interface

Requirement Name:  SEC-CTL-SMO-External-3

Requirement Reference: Clause 5.2.1.2.3, Security Controls, SMO External Interfaces, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: OAuth 2.0 security controls for SMO to authorize service requests from external systems

Threat References: T-SMO-02, T-SMO-05

DUT/s: SMO

Test description and applicability

Purpose: To verify the SMO supports OAuth 2.0 resource owner/server for SMO External Interfaces.

Test setup and configuration

DUT shall be the SMO with OAuth 2.0 support enabled.  An external OAuth 2.0 Authorization Server is available and configured.

Test procedure

This test case shall follow the test procedure for OAuth2.0 specified in OAuth Test Procedure, clause 6.6.3.

Expected results

The SMO shall be able to authorize/deny access requests received from an external system using OAuth 2.0.

Expected format of evidence: Log entries, packet captures, and screenshots.

 STC-17-17.5-004: SMO Functions OAuth 2.0 Client

Test name: OAuth 2.0 Resource Owner/Server for External Interface

Requirement Name:  SEC-CTL-SMO-External-4

Requirement Reference: Clause 5.2.1.2.3, Security Controls, SMO External Interfaces, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: OAuth 2.0 security controls for SMO support client functionality for service requests to external systems

Threat References: T-SMO-02, T-SMO-05

DUT/S: SMO

Test description and applicability

Purpose: To verify the SMO shall supports OAuth 2.0 client for External Interfaces.

Test setup and configuration

DUT shall be the SMO with OAuth 2.0 support enabled.  An external OAuth 2.0 Authorization Server is available and configured.

Test procedure

This test case follows the test procedure for OAuth2.0 specified in OAuth Test Procedure, clause 6.6.3.

Expected results

The SMO shall be able to request and be permitted/denied access to external resources using OAuth 2.0.

Expected format of evidence: Log entries, packet captures, and screenshots.

SMO Logging

STC-17-17.6-001: TLS for SMO Logging Export

Test Name: TLS for SMO Logging Export

Requirement Name:  SEC-CTL-SMO-Log-1

Requirement Reference: Clause 5.2.1.2.4, Security Controls, SMO Logging, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: TLS for SMO Logging Export

Threat References: T-SMO-16

DUT/s: SMO

Test description and applicability

Purpose: To verify the SMO supports TLS for SMO logging export.

Test setup and configuration

DUT shall be the SMO with TLS support enabled.

Test procedure

This test case shall follow the test procedure for TLS specified in TLS Test Procedure, clause 6.3.3.

Expected results

SMO shall provide confidentiality and integrity protection for logging export.

Expected format of evidence: Log entries, packet captures, and screenshots.

STC-17-17.6-002: mTLS for SMO Logging Export

Test Name: mTLS for SMO Logging Export

Requirement Name:  SEC-CTL-SMO-Log-3

Requirement Reference: Clause 5.1.1.2.4, Security Controls, SMO Logging, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: mTLS on SMO Logging Export

Threat References: T-SMO-01

DUT/s: SMO

Test description and applicability

Purpose: To verify the SMO supports mutual authentication using mTLS, with PKI and X.509 certificates, for SMO logging export.

Test setup and configuration

DUT shall be the SMO with mTLS support enabled.

Test procedure

This test case follows the test procedure for mTLS specified in mTLS Test Procedure, clause 6.3.3.

Expected results

The SMO shall support mutual authentication using mTLS for SMO logging export.

Expected format of evidence: Log entries, packet captures, and screenshots.

	Security test of O-Cloud

	Overview

This clause contains security tests to validate the security protection mechanism specific to O-Cloud hosting the O-RAN components/system.

 Void

O-Cloud virtualization layer

STC-18-18.3-001: Secure authentication (positive case)

Requirement Name: Secure authentication to O-Cloud APIs

Requirement Reference: Clause 5.1.8.4.2 ‘REQ-SEC-O-CLOUD-ISO-1 to REQ-SEC-O-CLOUD-ISO-6’ in O-RAN Security Requirements Specifications [5]

Threat References: Clause 5.4.2.2 ‘T-VM-C-01 to T-VM-C-06’ in O-RAN Security Threat Modeling and Remediation Analysis [3]

DUT/s: O-Cloud

Test description and applicability

The purpose of this test is to ensure secure authentication to O-Cloud APIs.

Test setup and configuration

O-Cloud authentication mechanism are enabled.

Valid credentials are available for authentication.

Test procedure

Attempt to access O-Cloud APIs with valid authentication credentials:

Send an API request with providing valid authentication credentials.

EXAMPLE: Send an API request by executing a Kubernetes curl command or using a Kubernetes client using the valid API key or access token for authentication (e.g., valide kubeconfig file or service account token).

Capture the response received, including the status code and response body.

Verify that the API response returns a success status code.

Expected results

The API response returns a success status code.

STC-18-18.3-002: Secure authentication (negative case)

Requirement Name: Secure authentication to O-Cloud APIs

Requirement Reference: Clause 5.1.8.4.2 ‘REQ-SEC-O-CLOUD-ISO-1 to REQ-SEC-O-CLOUD-ISO-6’ in O-RAN Security Requirements Specifications [5]

Threat References: Clause 5.4.2.2 ‘T-VM-C-01 to T-VM-C-06’ in O-RAN Security Threat Modeling and Remediation Analysis [3]

DUT/s: O-Cloud

Test description and applicability

The purpose of this test is to intentionally validate the behavior of the authentication mechanism when encountering invalid or unauthorized authentication credentials.

Test setup and configuration

O-Cloud authentication mechanism is enabled.

Test procedure

Attempt to access O-Cloud APIs with invalid or expired authentication credentials:

Send an API request with providing invalid or expired authentication credentials.

EXAMPLE: Send an API request by executing a Kubernetes curl command or using a Kubernetes client using the invalid or expired API key or access token for authentication (e.g., invalid kubeconfig file, expired service account token).

Capture the response received, including the status code and response body.

Verify that the API response returns an authentication failure status code.

Expected results

The API response returns an authentication failure status code.

STC-18-18.3-003: Secure authorization (positive case)

Requirement Name: Secure authorization for accessing O-Cloud APIs

Requirement Reference: Clause 5.1.8.4.2 ‘REQ-SEC-O-CLOUD-ISO-1 to REQ-SEC-O-CLOUD-ISO-6’ in O-RAN Security Requirements Specifications [5]

Threat References: Clause 5.4.2.2 ‘T-VM-C-01 to T-VM-C-06’ in O-RAN Security Threat Modeling and Remediation Analysis [3]

DUT/s: O-Cloud

Test description and applicability

The purpose of this test is to verify that the authorization mechanism for accessing O-Cloud APIs is functioning correctly, ensuring that entities have appropriate permissions to perform specific actions on O-Cloud resources.

NOTE: Entities include Applications, SMO and O-Cloud software components.

Test setup and configuration

Valid authentication credentials.

O-Cloud access control system is enabled containing different levels of permissions assigned to entities.

EXAMPLE: Access control system such as Role-Based Access Control (RBAC), Attribute-Based Access Control (ABAC).

Test procedure

Authenticate with valid credentials:

Use valid authentication credentials to establish a connection with the O-Cloud API.

Send an API request with authorized permissions:

Construct a valid API request to perform a specific action,

EXAMPLE: specific action includes creating a pod, updating a deployment, or deleting a service.

Ensure that the requested action aligns with the entity's assigned permissions.

Send the request to the O-Cloud API endpoint.

Validate the response:

Verify that the API response returns a success status code indicating the action was successfully executed.

Expected results

The API response returns a success status code, confirming that the requested action was authorized and executed successfully.

STC-18-18.3-004: Secure authorization (negative case)

Requirement Name: Secure authorization for accessing O-Cloud APIs

Requirement Reference: Clause 5.1.8.4.2 ‘REQ-SEC-O-CLOUD-ISO-1 to REQ-SEC-O-CLOUD-ISO-6’ in O-RAN Security Requirements Specifications [5]

Threat References: Clause 5.4.2.2 ‘T-VM-C-01 to T-VM-C-06’ in O-RAN Security Threat Modeling and Remediation Analysis [3]

DUT/s: O-Cloud

Test description and applicability

The purpose of this test is to intentionally validate the behavior of the authorization mechanism when encountering unauthorized or invalid access attempts.

Test setup and configuration

Valid authentication credentials.

O-Cloud access control system is enabled containing different levels of permissions assigned to entities.

EXAMPLE: Access control system such as Role-Based Access Control (RBAC), Attribute-Based Access Control (ABAC).

Test procedure

Authenticate with valid credentials:

Use valid authentication credentials to establish a connection with the O-Cloud API.

Send an API request with unauthorized permissions:

Construct a valid API request to perform a specific action that exceeds the entity's assigned permissions,

EXAMPLE: specific action includes creating a pod, updating a deployment, or deleting a service.

Send the request to the O-Cloud API endpoint.

Validate the response:

Verify that the API response returns a failure status code indicating the action was unauthorized.

Expected results

The API response returns a failure status code, indicating that the requested action was unauthorized.

STC-18-18.3-005: Validate network connections allowed by network policies

Requirement Name: Isolation & secure communication between Applications

Requirement Reference: Clause 5.1.8.4.2 ‘REQ-SEC-O-CLOUD-ISO-1 to REQ-SEC-O-CLOUD-ISO-6’ in O-RAN Security Requirements Specifications [5]

Threat References: Clause 5.4.2.2 ‘T-VM-C-01 to T-VM-C-06’ in O-RAN Security Threat Modeling and Remediation Analysis [3]

DUT/s: O-Cloud

Test description and applicability

The purpose of this test is to ensure that network connections between VMs/Containers allowed by network policies are successfully established.

Test setup and configuration

O-Cloud with network policies is configured to allow specific VMs/Containers to VMs/Containers communication.

Test procedure

	Deploy two VMs/Containers A and B, in different zones or with different environment.

EXAMPLE: Zones such as namespaces in Kubernetes, environment such as labels in Kubernetes

	Define network policies that explicitly allow communication between the two VMs/Containers.

	Attempt to establish a network connection from VM/Container A to VM/Container B using tools.

EXAMPLE: tools such as curl or ping in Kubernetes

	Capture the response or output received.

Expected results

The network connection from VM/Container A to VM/Container B is successfully established, indicating that the network policies allow the communication between the VMs/Containers.

STC-18-18.3-006: Validate network connections not allowed by network policies

Requirement Name: Isolation & secure communication between Applications

Requirement Reference: Clause 5.1.8.4.2 ‘REQ-SEC-O-CLOUD-ISO-1 to REQ-SEC-O-CLOUD-ISO-6’ in O-RAN Security Requirements Specifications [5]

Threat References: Clause 5.4.2.2 ‘T-VM-C-01 to T-VM-C-06’ in O-RAN Security Threat Modeling and Remediation Analysis [3]

DUT/s: O-Cloud

Test description and applicability

The purpose of this test is to ensure that network connections between VMs/Containers not allowed by network policies are blocked.

Test setup and configuration

O-Cloud with network policies is configured to deny specific VM/Container to VM/Container communication.

Test procedure

Deploy two VMs/Containers A and B, in different zones or with different environment.

EXAMPLE: Zones such as namespaces in Kubernetes, environment such as labels in Kubernetes

Define network policies that explicitly deny communication between the two VMs/Containers.

Attempt to establish a network connection from VM/Container A to VM/Container B using tools.

EXAMPLE: tools such as curl or ping in Kubernetes

Capture the response or output received.

Expected results

The network connection from VM/Container A to VM/Container B is blocked, indicating that the network policies correctly deny the communication between the VMs/Containers.

STC-18-18.3-007: Validate network connections from outside the allowed network ranges

Requirement Name: Isolation & secure communication between Applications

Requirement Reference: Clause 5.1.8.4.2 ‘REQ-SEC-O-CLOUD-ISO-1 to REQ-SEC-O-CLOUD-ISO-6’ in O-RAN Security Requirements Specifications [5]

Threat References: Clause 5.4.2.2 ‘T-VM-C-01 to T-VM-C-06’ in O-RAN Security Threat Modeling and Remediation Analysis [3]

DUT/s: O-Cloud

Test description and applicability

The purpose of this test is to ensure that network connections from IP addresses outside the allowed network ranges are denied.

Test setup and configuration

O-Cloud with network policies is configured to restrict access based on IP ranges.

Test procedure

Define network policies that restrict access to certain IP ranges.

Attempt to access services or VMs/Containers from IP addresses outside the allowed ranges, either through direct IP access or using service names.

Capture the response or output received.

EXAMPLE: In this test case, the service name refers to the Kubernetes service object's name. The service acts as a load balancer and provides a stable DNS name that can be used to access the pods associated with it. For example, suppose you have a service named my-service that is associated with a set of pods. In the test case, you would attempt to access my-service from IP addresses outside the allowed ranges. This can be done using tools like curl or by making HTTP requests to http://my-service.

Expected results

Access attempts from outside the allowed IP ranges is denied, and the response or output indicates a connection failure.

STC-18-18.3-008: Exploitation of O-Cloud component vulnerabilities

Requirement Name: O-Cloud hardening and secure configuration.

Requirement Reference: Clause 5.1.8.5.1 ‘REQ-SEC-OCLOUD-SU-1’, Clause 5.3.6.1 ‘REQ-SEC-SYS-1’ Clause 5.1.8.4.2 ‘REQ-SEC-O-CLOUD-ISO-7’ in O-RAN Security Requirements Specifications [5]

Threat References: Clause 5.4.1.1 ‘T-O-RAN-02’, Clause 5.4.2.2 ‘T-VM-C-01, T-VM-C-05’ in O-RAN Security Threat Modeling and Remediation Analysis [3]

DUT/s: O-Cloud

Test description and applicability

The purpose of this test is to identify and assess the presence of vulnerabilities in O-Cloud components and evaluate the effectiveness of their mitigation measures.

Test setup and configuration

O-Cloud with various O-Cloud components deployed.

EXAMPLE: in the context of Kubernetes, components include etcd, kubelet

O-Cloud with security best practices is implemented.

Test procedure

Identify known vulnerabilities specific to the versions of used O-Cloud components using vulnerability scanning tools.

If known vulnerabilities exist, follow publicly available exploit scenarios or utilize penetration testing tools to attempt exploitation.

Monitor the O-Cloud and capture any signs of successful exploitation or vulnerabilities being triggered.

Expected results

For step 1), no known vulnerabilities exist in the O-Cloud

For step 2), mitigation measures, such as applying security patches or configuration changes are implemented to address known vulnerabilities.

For step 3), Exploit attempts fails to compromise the O-Cloud.

STC-18-18.3-009: Identification and remediation of insecure configuration settings

Requirement Name: O-Cloud hardening and secure configuration

Requirement Reference: Clause 5.1.8.5.1 ‘REQ-SEC-OCLOUD-SU-1’, Clause 5.3.6.1 REQ-SEC-SYS-1’ Clause 5.1.8.4.2 ‘REQ-SEC-O-CLOUD-ISO-7’ in O-RAN Security Requirements Specifications [5]

Threat References: Clause 5.4.1.1 ‘T-O-RAN-02’, Clause 5.4.2.2 ‘T-VM-C-01, T-VM-C-05’ in O-RAN Security Threat Modeling and Remediation Analysis [3]

DUT/s: O-Cloud

Test description and applicability

The purpose of this test is to identify insecure configuration settings in the O-Cloud and verify the effectiveness of remediation measures.

Test setup and configuration

O-Cloud with a configuration review and hardening process in place.

Test procedure

Review the O-Cloud configuration for common security misconfigurations, such as weak authentication settings, insecure defaults, or unencrypted communication.

Identify and simulate scenarios where insecure configurations can be exploited.

Monitor the O-Cloud and capture any signs of insecure configurations being successfully exploited.

Expected results

The O-Cloud configuration is hardened and securely configured to mitigate common security misconfigurations.

Insecure scenarios are identified and remediated, ensuring a hardened O-Cloud. If insecure scenarios are rectified, testing has to be repeated.

STC-18-18.3-010: Validation of logging and monitoring for security incidents

Requirement Name: logging and monitoring for security incidents

Requirement Reference: Clause 5.1.8.9.1.1 ‘REQ-SEC-OCLOUD-O2dms-4’, Clause 5.1.8.9.1.2 ‘REQ-SEC-OCLOUD-O2ims-4’ in O-RAN Security Requirements Specifications [5]

Threat References: Clause 5.4.2 in O-RAN Security Threat Modeling and Remediation Analysis [3]

DUT/s: O-Cloud

Test description and applicability

The purpose of this test is to validate logging and monitoring for security incidents.

Test setup and configuration

O-Cloud with centralized logging and monitoring systems is implemented.

Test procedure

Simulate security incidents such as unauthorized access attempts or Application compromise:

Attempt to perform unauthorized API requests or access o-Cloud resources without appropriate permissions.

Mimic a compromised Application by running malicious code or attempting privilege escalation.

Monitor the O-Cloud and capture any signs of security incidents being logged or detected.

Monitor the O-Cloud for detection and alerting of security events:

Configure the logging and monitoring systems to capture relevant security events, such as failed authentication attempts, privilege escalation, or anomalous Application behavior.

Monitor the O-Cloud in real-time or periodically to detect the simulated security incidents.

Verify that the monitoring system generates alerts or notifications for detected security events.

Expected results

For the first step, unauthorized access attempts and Application compromise attempts are captured as security events in the logs.

For the second step, the monitoring system detects and generates alerts for the simulated security incidents.

STC-18-18.3-011: O-Cloud Privilege Escalation Prevention

Test Name: TC_O-CLOUD_PRIVILEGE_ESCALATION_PREVENTION

Requirement Name: O-Cloud privilege escalation prevention

Requirement Reference & Description: Clause 5.1.8.4.2 ‘REQ-SEC-OCLOUD-ISO-1, REQ-SEC-OCLOUD-ISO-3’ [5]

Threat References: Clause 7.4.2.2 ‘T-VM-C-01’ [3]

DUT/s: O-Cloud

Test description and applicability

Purpose: To verify that privilege escalation is effectively prevented in O-Cloud by enforcing security policies (EXAMPE: PodSecurity admission (PSA).

Test setup and configuration:

O-Cloud with security policies (EXAMPLE: Kubernetes cluster with PodSecurity admission (PSA)) configured and enforced.

Test procedure:

Attempt to create a VM or Container that attempts to escalate privileges

EXAMPLE: in Kubernetes by specifying the hostPID: true or hostNetwork: true field in the pod's security context.

Monitor the API server response and logs

Expected results:

For step 1: The VM or Container creation request is denied by the O-Cloud API server.

For step 2: The O-Cloud API server logs should show a message indicating a violation of the security policies.

Expected format of evidence:

Screenshot: Displaying the API server's response to the VM or Container creation attempt.

Executed Commands: Details of the VM or Container creation parameters and security context used.

API Server Logs: Messages indicating a violation of security policies.

Conclusion Logs: Indicating whether the test passed or failed based on expected results.

Application instantiation by O-Cloud

STC-18-18.4-001: Verification of Application with valid signature by O-Cloud during Instantiation

Test Name: TC_VALID_SIGNATURE_VERIFICATION_ DURING_INSTANTIATION

Requirement Name: Verification of Application by O-Cloud during Instantiation

Requirement Reference & Description: Clause 5.1.8.2.1 ‘REQ-SEC-OCLOUD-PKG-1, REQ-SEC-OCLOUD-PKG-2’ [5]

Threat References: Clause 7.4.2.3 ‘T-IMG-01, T-IMG-04’, Clause 7.4.1.11 ‘T-AppLCM-02’ [3]

DUT/s: O-Cloud

Test description and applicability

Purpose: To verify the O-Cloud ability to check the cryptographic signature of an Application image during the process of instantiation, ensuring the integrity of Applications deployed in the O-Cloud when the signature is valid.

Test setup and configuration:

O-Cloud configured to enforce image verification (EXAMPLE: Kubernetes cluster with Kubelet using an appropriate mechanism such as the ImagePolicyWebhook admission controller).

Valid Application images with associated signatures.

Test procedure:

Valid Signature:

Prepare a valid Application image and its valid cryptographic signature.

Create a VM or Container (EXAMPLE: Kubernetes Pod) specification using the valid Application image and deploy the VM or Container.

Monitor the O-Cloud logs (EXAMPLE: Kubelet logs) for any signature verification events related to the deployment.

Verify that the O-Cloud (EXAMPLE: Kubelet) successfully verifies the cryptographic signature of the Application image.

Expected results:

Valid Signature:

Logs show successful signature verification events for the deployment.

The O-Cloud verifies the cryptographic signature of the application image, and the VM or Container is instantiated without issues.

Expected format of evidence:

Screenshot: Displaying the O-Cloud's response to the VM or Container instantiation attempt.

Executed Commands: Details of the VM or Container creation parameters, including the Application image and its cryptographic signature.

O-Cloud Logs: Messages indicating signature verification events related to the deployment.

Verification Status: Logs or screenshots indicating the O-Cloud's successful verification during the instantiation process.

STC-18-18.4-002: Verification of Application with incorrect signature by O-Cloud during Instantiation

Test Name: TC_INCORRECT_SIGNATURE_VERIFICATION_ DURING_INSTANTIATION

Requirement Name: Verification of Application by O-Cloud during Instantiation

Requirement Reference & Description: Clause 5.1.8.2.1 ‘REQ-SEC-OCLOUD-PKG-1, REQ-SEC-OCLOUD-PKG-2’ [5]

Threat References: Clause 7.4.2.3 ‘T-IMG-01, T-IMG-04’, Clause 7.4.1.11 ‘T-AppLCM-02’ [3]

DUT/s: O-Cloud

Test description and applicability

Purpose: To verify the O-Cloud ability to detect and reject an incorrect cryptographic signature of an Application image during instantiation, ensuring the integrity of Applications deployed in the O-Cloud when the signature is invalid.

Test setup and configuration:

O-Cloud configured to enforce image verification (EXAMPLE: Kubernetes cluster with Kubelet using an appropriate mechanism such as the ImagePolicyWebhook admission controller).

Application image with an incorrect associated signature.

Test procedure:

Incorrect Signature:

Prepare an Application image with an incorrect cryptographic signature.

Create a VM or Container (EXAMPLE: Kubernetes Pod) specification using the image with an incorrect signature and deploy the VM or Container.

Monitor the O-Cloud logs (EXAMPLE: Kubelet logs) for any signature verification events related to the deployment.

Verify that the O-Cloud (EXAMPLE: Kubelet) detects the incorrect cryptographic signature and denies the instantiation of the VM or Container.

Expected results:

Incorrect Signature:

Logs show signature verification events indicating a failed verification for the deployment.

O-Cloud detects the incorrect cryptographic signature, and the VM or Container instantiation is denied.

Expected format of evidence:

Screenshot: Displaying the O-Cloud's response to the VM or Container instantiation attempt.

Executed Commands: Details of the VM or Container creation parameters, including the Application image and its cryptographic signature.

O-Cloud Logs: Messages indicating failed signature verification events related to the deployment.

Verification Status: Logs or screenshots indicating the O-Cloud's denial due to incorrect signature during the instantiation process

Resource Management and enforcement in O-Cloud

STC-18-18.5-001: O-Cloud Resource Consumption Limit Enforcement

Test Name: TC_O-CLOUD_RESOURCE_CONSUMPTION_LIMIT_ENFORCEMENT

Requirement Name: Resource Management and enforcement in O-Cloud

Requirement Reference & Description: Clause 5.3.2.3.1 ‘REQ-SEC-LCM-SD-1 to REQ-SEC-LCM-SD-4’ [5]

Threat References: Clause 7.4.2.2 ‘T-VM-C-05’, Clause 7.4.1.11 ‘T-AppLCM-04, T-AppLCM-05’ [3]

DUT/s: O-Cloud

Test description and applicability

Purpose: To verify the DUT is able to ensure that resources (CPU, memory, etc.) consumed by VMs or Containers are within the defined limits, preventing any single application from monopolizing the system's resources.

Test setup and configuration:

O-Cloud environment with resource quotas and limits enforced.

A configured SMO to set and enforce resource quotas and limits.

Test procedure:

Set up resource quotas and limit ranges:

Create a dedicated isolated environment for testing.

Define a resource quota for the environment, specifying the maximum allowed CPU and memory.

Define a limit range to set default request and limit values for resources.

Attempt to deploy a VM or Container that requests resources beyond the defined limits:

Create a VM or Container configuration that requests resources exceeding the set limits.

Try to deploy the VM or Container in the test environment.

Monitor the deployment status and logs:

Check the deployment status of the VM or Container.

Expected results:

For step 1: Confirmation that a dedicated isolated environment for testing has been setup and both resource quota and limit range have been established.

For step 2: The deployment request for the VM or Container is denied or remains in a “Pending” or equivalent state.

For step 3: Logs or descriptions should show a message indicating a violation of the resource quotas or limits.

Expected format of evidence:

Configuration Details: Information on the set resource quotas and limit ranges, including the maximum allowed CPU and memory.

Executed Commands: Details of the VM or Container creation parameters, specifically the requested resources.

O-Cloud Logs: Messages indicating any violations of the resource quotas or limits during the deployment attempt.

Deployment Status: Logs or screenshots showing the status of the VM or Container deployment, especially if it’s denied or remains in a “Pending” state due to resource constraints.

EXAMPLE using Kubernetes:

Set up resource quotas and limit ranges in Kubernetes:

Create a namespace: kubectl create namespace test-limits

Apply a ResourceQuota and LimitRange as previously detailed.

Attempt to deploy a Pod in Kubernetes:

Create a pod configuration (resource-hog-pod.yaml) that requests excessive resources.

Deploy using: kubectl apply -f resource-hog-pod.yaml

Monitor the deployment status and logs in Kubernetes:

Check pod status: kubectl get pods -n test-limits

Describe the pod for details: kubectl describe pod resource-hog -n test-limits

STC-18-18.5-002: O-Cloud Storage Volume Limit Enforcement

Test Name: TC_O-CLOUD_STORAGE_VOLUME_LIMIT_ENFORCEMENT

Requirement Name: Resource Management and enforcement in O-Cloud

Requirement Reference & Description: Clause 5.3.2.3.1 ‘REQ-SEC-LCM-SD-1 to REQ-SEC-LCM-SD-4’ [5]

Threat References: Clause 7.4.2.2 ‘T-VM-C-05’, Clause 7.4.1.11 ‘T-AppLCM-04, T-AppLCM-05’ [3]

DUT/s: O-Cloud

Test description and applicability:

Purpose: To verify the DUT is able to limit the storage volume allocations for applications predefined in a O-Cloud environment.

Test setup and configuration:

O-Cloud environment with storage volume configurations.

A configured SMO to set and enforce resource quotas for storage.

Test procedure:

Set up Storage Volume Quotas:

Create a dedicated isolated environment for testing.

Define a storage volume quota for the environment, specifying the maximum allowed storage volume size.

Attempt to allocate a storage volume beyond the defined limits:

Create a configuration that requests a storage volume size exceeding the set limits.

Deploy the configuration in the test environment.

Monitor the storage allocation status and logs:

Check the status of the storage allocation.

Expected results:

For step 1: Confirmation that a dedicated isolated environment for testing has been setup and storage volume quota has been defined.

For step 2: The storage volume allocation request is denied.

For step 3: Logs or descriptions should show a message indicating a violation of the storage quotas.

Expected format of evidence:

Configuration Details: Information on the set storage volume quotas, including the maximum allowed storage volume size.

Executed Commands: Details of the storage volume allocation parameters, specifically the requested storage size.

O-Cloud Logs: Messages indicating any violations of the storage volume quotas during the allocation attempt.

Allocation Status: Logs or screenshots showing the status of the storage volume allocation, especially if it is denied due to exceeding the set limits.

EXAMPLE using Kubernetes:

Create a namespace: kubectl create namespace test-storage

Apply a ResourceQuota for storage:

apiVersion: v1

kind: ResourceQuota

metadata:

  name: storage-quota

  namespace: test-storage

spec:

  hard:

    requests.storage: 10Gi

Apply the ResourceQuota: kubectl apply -f storage-quota.yaml

Create and deploy a PersistentVolumeClaim (PVC) requesting 15Gi.

Monitor the PVC status and logs.

STC-18-18.5-003: O-Cloud CPU Overcommit Prevention

Test Name: TC_O-CLOUD_CPU_OVERCOMMIT_PREVENTION

Requirement Name: Resource Management and enforcement in O-Cloud

Requirement Reference & Description: Clause 5.3.2.3.1 ‘REQ-SEC-LCM-SD-1 to REQ-SEC-LCM-SD-4’ [5]

Threat References: Clause 7.4.2.2 ‘T-VM-C-05’, Clause 7.4.1.11 ‘T-AppLCM-04, T-AppLCM-05’ [3]

DUT/s: O-Cloud

Test description and applicability

Purpose: To verify that the O-Cloud does not overcommit CPU resources, leading to performance degradation or system instability.

Test setup and configuration:

O-Cloud with CPU allocation settings.

A configured SMO to manage CPU overcommitment.

Test procedure:

Set CPU Overcommit Ratios:

Create a dedicated isolated environment for testing.

Define CPU overcommit ratios.

Attempt to deploy multiple applications:

Sequentially deploy applications until the CPU limits are reached based on the overcommit ratios.

Monitor the CPU utilization of each deployed application.

Monitor the deployment status and CPU utilization metrics:

Check the deployment status of the applications.

Monitor CPU utilization metrics.

Expected results:

For step 1: Confirmation that a dedicated isolated environment for testing has been setup and CPU overcommit ratios has been defined.

For step 2: Applications should not be deployed beyond the capacity determined by the CPU overcommit ratios.

For step 3: CPU utilization metrics should remain stable and within acceptable thresholds.

Expected format of evidence:

Configuration Details: Information on the set CPU overcommit ratios.

Executed Commands: Details of the application deployments and their respective CPU utilization.

O-Cloud Logs: Messages indicating any violations of the CPU overcommit ratios during application deployments.

Deployment Status: Logs or screenshots showing the status of the application deployments, especially if any are denied due to reaching CPU limits.

CPU Utilization Metrics: Graphs or logs showing the CPU utilization of each deployed application, ensuring they remain within acceptable thresholds.

EXAMPLE using Kubernetes:

Set CPU Overcommit Ratios:

Manage CPU overcommitment in Kubernetes by setting CPU requests and limits on Pods.

Attempt to deploy multiple applications:

Deploy a Pod with a CPU request of ‘500m’ (half a CPU core) and a limit of ‘1’ (one full CPU core).

Monitor the deployment status and CPU utilization metrics:

Use ‘kubectl describe node <NODE_NAME>’ to view CPU allocation and utilization.

Monitor CPU metrics using tools like Prometheus.

STC-18-18.5-004: O-Cloud Memory Overcommit Prevention

Test Name: TC_O-CLOUD_MEMORY_OVERCOMMIT_PREVENTION

Requirement Name: Resource Management and enforcement in O-Cloud

Requirement Reference & Description: Clause 5.3.2.3.1 ‘REQ-SEC-LCM-SD-1 to REQ-SEC-LCM-SD-4’ [5]

Threat References: Clause 7.4.2.2 ‘T-VM-C-05’, Clause 7.4.1.11 ‘T-AppLCM-04, T-AppLCM-05’ [3]

DUT/s: O-Cloud

Test description and applicability

Purpose: To verify that the O-Cloud does not overcommit memory resources.

Test setup and configuration:

O-Cloud with memory allocation settings.

A configured SMO to manage memory overcommitment

Test procedure:

Set Memory Overcommit Ratios:

Create a dedicated isolated environment for testing.

Define memory overcommit ratios.

Attempt to deploy applications:

Sequentially deploy applications until memory limits are reached based on the overcommit ratios.

Monitor memory utilization of each deployed application.

Monitor deployment status and memory utilization metrics:

Check deployment status of the applications.

Monitor memory utilization metrics.

Expected results:

For step 1: Confirmation that a dedicated isolated environment for testing has been setup and memory overcommit ratios has been defined.

For step 2: Applications should not be deployed beyond the capacity determined by the memory overcommit ratios.

For step 3: Memory utilization should remain stable and within acceptable thresholds.

Expected format of evidence:

Configuration Details: Information on the set memory overcommit ratios.

Executed Commands: Details of the application deployments and their respective memory use.

O-Cloud Logs: Messages indicating any violations of the memory overcommit ratios during application deployments.

Deployment Status: Logs or screenshots showing the status of the application deployments, especially if any are denied due to reaching memory limits.

Memory Use Metrics: Graphs or logs showing the memory utilization of each deployed application, ensuring they remain within acceptable thresholds.

EXAMPLE using Kubernetes:

Set Memory Overcommit Ratios:

Manage memory overcommitment in Kubernetes by setting memory requests and limits on Pods.

Attempt to deploy applications:

Deploy a Pod with a memory request of ‘256Mi’ and a limit of ‘512Mi’.

Monitor deployment status and memory utilization metrics:

Use kubectl describe node <NODE_NAME> to view memory allocation and utilization.

Monitor memory metrics using tools like Prometheus.

STC-18-18.5-005: O-Cloud Network Overcommit Prevention

Test Name: TC_O-CLOUD_NETWORK_OVERCOMMIT_PREVENTION

Requirement Name: Resource Management and enforcement in O-Cloud

Requirement Reference & Description: Clause 5.1.8.4.2 ‘REQ-SEC-O-CLOUD-ISO-6’, Clause 5.3.2.3.1 ‘REQ-SEC-LCM-SD-1 to REQ-SEC-LCM-SD-4’ [5]

Threat References: Clause 7.4.2.2 ‘T-VM-C-05’, Clause 7.4.1.11 ‘T-AppLCM-04, T-AppLCM-05’ [3]

DUT/s: O-Cloud

Test description and applicability

Purpose: To verify that the O-Cloud environment does not overcommit network bandwidth.

Test setup and configuration:

O-Cloud environment with network configurations.

Tools to manage network overcommitment.

Test procedure:

Set Network Overcommit Ratios:

Define network bandwidth overcommit ratios.

Attempt to utilize network bandwidth:

Deploy applications designed to generate high network traffic.

Monitor network traffic.

Monitor network traffic metrics:

Check network traffic metrics for the applications.

Expected results:

For step 1: Confirmation that network bandwidth overcommit ratios has been defined.

For steps 2 and 3: Applications' network traffic should be throttled or limited once the bandwidth determined by the overcommit ratios is reached.

Expected format of evidence:

Configuration Details: Information on the set network bandwidth overcommit ratios.

Executed Commands: Details of the application deployments and their respective network traffic generation.

O-Cloud Logs: Messages indicating any violations of the network overcommit ratios during high network traffic.

Deployment Status: Logs or screenshots showing the status of the application deployments, especially if network traffic is throttled or limited.

Network Traffic Metrics: Graphs or logs showing the network traffic of each deployed application, ensuring they remain within the set bandwidth limits.

EXAMPLE using Kubernetes:

Set Network Overcommit Ratios:

Native Kubernetes doesn't offer direct network bandwidth controls. However, third-party plugins like ‘Calico’ or ‘Cilium’ can be used to set network policies that limit bandwidth.

Attempt to utilize network bandwidth:

Deploy a Pod and apply a network policy that limits its bandwidth.

Monitor network traffic metrics:

Use monitoring tools integrated with the network plugin (e.g., ‘calicoctl’ for Calico) to observe the network traffic metrics.

STC-18-18.5-006: O-Cloud Storage Overcommit Prevention

Test Name: TC_O-CLOUD_STORAGE_OVERCOMMIT_PREVENTION

Requirement Name: Resource Management and enforcement in O-Cloud

Requirement Reference & Description: Clause 5.3.2.3.1 ‘REQ-SEC-LCM-SD-1 to REQ-SEC-LCM-SD-4’ [5]

Threat References: Clause 7.4.2.2 ‘T-VM-C-05’, Clause 7.4.1.11 ‘T-AppLCM-04, T-AppLCM-05’ [3]

DUT/s: O-Cloud

Test description and applicability

Purpose: To verify that the O-Cloud does not overcommit storage resources.

Test setup and configuration:

O-Cloud environment with storage configurations.

A configured SMO to manage Storage overcommitment.

Test procedure:

Set Storage Overcommit Ratios:

Define storage overcommit ratios.

Attempt to allocate storage beyond defined limits:

Deploy applications that request storage space.

Monitor storage allocation and utilization.

Monitor storage allocation and utilization metrics:

Check storage metrics for the applications.

Expected results:

For step 1: Confirmation that storage overcommit ratios has been defined.

For step 2: Storage allocations should not exceed the capacity determined by the storage overcommit ratios.

For step 3: Storage usage should remain stable and within acceptable thresholds.

Expected format of evidence:

Configuration Details: Information on the set storage overcommit ratios.

Executed Commands: Details of the application deployments and their respective storage requests.

O-Cloud Logs: Messages indicating any violations of the storage overcommit ratios during storage allocation.

Deployment Status: Logs or screenshots showing the status of the application deployments, especially if storage allocations are denied or limited.

Storage usage Metrics: Graphs or logs showing the storage utilization of each deployed application, ensuring they remain within the set storage limits.

EXAMPLE using Kubernetes:

Set Storage Overcommit Ratios:

Use PersistentVolumeClaims (PVCs) with specific storage requests. Overcommitment can occur if the total storage requested by PVCs exceeds the actual available storage.

Attempt to allocate storage beyond defined limits:

Deploy a Pod that uses a PVC requesting more storage than available on the PersistentVolume (PV).

Monitor storage allocation and utilization metrics:

Use ‘kubectl get pvc’ and ‘kubectl get pv’ to monitor storage allocations.

Monitor storage metrics using tools like Prometheus.

NOTE: Below are the general guidelines to ensure effective monitoring across all test cases:

Immediate Feedback Expectation: Upon executing any test case, especially those involving security or resource constraints, immediate feedback is typically anticipated. This feedback can be in the form of API responses, system alerts, or log entries.

Monitoring Duration: While immediate feedback is expected, it's recommended to monitor for an additional 1-3 minutes post-execution to capture any delayed logs, alerts, or system responses. This ensures that asynchronous events or alerts are not missed.

Tools and Logs: Use appropriate monitoring tools, logging systems, or commands (e.g., In Kubernetes like kubectl describe or kubectl logs) to gain insights into the test execution. Ensure that these tools are set up in advance and are accessible to the testing team.

Secure Update

 STC-18-18.6-001: O-Cloud Infrastructure Software Package Integrity - Positive

Test Name: TC_O-CLOUD_SOFTWARE_PACKAGE_INTEGRITY.

Requirement Name:  O-Cloud software images authenticity and Integrity

Requirement Reference: Clause 5.1.8.5 “REQ-SEC-O-CLOUD-SU-2” in O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: Ensure Authenticity and Integrity of O-Cloud Software Images

Threat References: Clause 5.4.2.2 ‘T-GEN-01’ in O-RAN Security Threat Modeling and Remediation Analysis [3]

DUT/s: O-Cloud

Test description and applicability

Purpose: To verify the O-Cloud software image authenticity and integrity.

Test setup and configuration

Signed O-Cloud software package as per Clause 5 of O-RAN Security Protocols Specification [2]

All necessary artifacts of the O-Cloud software image (public key, digitally signed certificates, signature (Signed hash) encryption key if any for security-sensitive artifacts) are provided.

EXAMPLE: O-Cloud software includes AAL drivers, IMS, DMS, Host OS, Hypervisor, Container Engine.

Test procedure

The Tester is properly authenticated and have the required access privileges to perform the test activity.

The tester shall verify the authenticity and integrity of the list of images. The O-Cloud software package shall be verified with the provided X.509 certificate and signature provided by the O-Cloud Software Provider. The cryptographic hash of the software image is calculated and verified against the hash in the signature by the Software Provider.

 On successful validation of O-Cloud software images in Step 2, the Service Provider shall sign the verified O-cloud software image with its private key and onboard it to the SMO.

The newly signed O-Cloud images shall be onboarded to the O-cloud Image Repository.

The tester shall verify the digital signature of the O-Cloud software image bundle provided by the Software and Service Provider before deployment.

Monitor the SMO logs for signature verification events related to the upgrade.

Monitor the O-Cloud logs for any signature verification events related to the upgrade.

Expected results

Logs show that the software package integrity check has been executed for the O-Cloud software at each stage

The signature validation for the O-Cloud software image during onboarding are checked and is successful.

Expected format of evidence:

Snapshots captured in SMO logs regarding the Signature verification success.

Logs from SMO and O-Cloud (O2ims logs) to indicate the successful signature verification from the Software Provider.

 STC-18-18.6-002: O-Cloud Infrastructure Software Package Integrity Failure– Negative

Test Name: TC_O-CLOUD_SOFTWARE_PACKAGE_INTEGRITY_FAILURE

Requirement Name:  O-Cloud software images authenticity and Integrity

Requirement Reference: Clause 5.1.8.5 “REQ-SEC-O-CLOUD-SU-2” in O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: Ensure Authenticity and Integrity of O-Cloud Software Images

Threat References: Clause 5.4.2.2 ‘T-GEN-01’ in O-RAN Security Threat Modeling and Remediation Analysis [3]

DUT/s: O-Cloud

Test description and applicability

Purpose: To verify the O-Cloud software image authenticity and integrity validation failure for invalid O-cloud software image.

Test setup and configuration

O-Cloud software package obtained from the Software Provider.

All necessary artifacts of the O-Cloud software image (public key, digitally signed certificates, Signature (signed hash) encryption key if any for security-sensitive artifacts) are provided.

EXAMPLE: O-Cloud software includes AAL drivers, IMS, DMS, Host OS, Hypervisor, Container Engine.

Test procedure

The Tester is properly authenticated and has the required access privileges to perform the upgrade activity.

Attempt to validate the O-Cloud Software with the wrong public key.

Verify that the SMO detects the incorrect cryptographic signature and does not allow onboarding of the software package.

Monitor the SMO logs for any signature verification events related to the software integrity check.

Expected results

Logs show that the software package integrity check has failed.

The O-cloud software image shall not be onboarded due to the software integrity failure.

Expected format of evidence:

Snapshots captured in SMO regarding the signature verification failure.

SMO Logs:  Onboarding failure logs to indicate that integrity failure for the O-Cloud software Package.

 STC-18-18.6-003: Secure Update procedure for O-Cloud Platform -Positive

Test Name: TC_SECURE_UPDATE_OF_O-CLOUD_PLATFORM

Requirement Name:  Secure update of O-Cloud software at the infrastructure level layer.

Requirement Reference: Clause 5.1.8.5 “REQ-SEC-O-CLOUD-SU-2” in O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: Ensure secure update of O-Cloud Software Images at the Infrastructure level.

Threat References: Clause 5.4.2.2 ‘T-GEN-01’ in O-RAN Security Threat Modeling and Remediation Analysis [3]

DUT/s: O-Cloud

Test description and applicability

Purpose: To verify the secure update procedure for the O-Cloud Infrastructure using verified O-cloud software image.

Test setup and configuration

Verified O-Cloud software package obtained from Service Provider.

All necessary artifacts of the O-Cloud software image (public key, digitally signed certificates, encryption key if any for security-sensitive artifacts) shall be provided.

All necessary documents related to the Upgrade procedure of the O-Cloud components shall be available.

All necessary dependencies for O-Cloud software packages are considered prior to update.

All documents related to backward compatibility are made available by the O-Cloud Software provider.

EXAMPLE: O-Cloud software includes AAL drivers, IMS, DMS, Host OS, Hypervisor, Container Engine.

Test procedure

The Tester is properly authenticated and has the required access privileges to perform the upgrade activity.

The O-Cloud Platform to ensure image verification.

The tester performs all the necessary pre-upgrade steps on the O-Cloud Platform to ensure successful update.

 EXAMPLE:

Back up any important components, such as app-level state stored in a database, or state of critical nodes. EXAMPLE: Snapshots, Clones

As per the Upgrade documentation, the tester shall perform the upgrade of the O-Cloud Platform components.

EXAMPLE:

a.  Phased upgrades for service availability.

b.  Stage the Upgrade procedure:  upgrade control plane nodes and upgrade the worker nodes.

Monitor the O-Cloud logs (EXAMPLE: O2ims logs) for the update steps performed on the platform.

Perform a Post-Update Audit to verify the status of the O-Cloud Platform.

 Verify in the SMO that the software version for the O-Cloud platform components is updated to the required version.

Expected results

The version of the O-Cloud software components is updated to the required version.

EXAMPLE: AAL driver version, IMS version, DMS version, Host OS version, Hypervisor, Container Engine.

Expected format of evidence:

O-Cloud logs: Log captures indicating the Steps performed during the Update.

Snapshot: Executed command on CLI, GUI, API server

SMO Log: Notification on the successful upgrade of the O-Cloud components.

 STC-18-18.6-004: Secure Update failure for O-Cloud Platform-Negative

Test Name: TC_SECURE_UPDATE_FAILURE_OF_O-CLOUD_PLATFORM

Requirement Name:   Rollback to the previous version on the unsuccessful update of the O-Cloud Platform.

Requirement Reference: Clause 5.1.8.5 “REQ-SEC-O-CLOUD-SU-5, REQ-SEC-O-CLOUD-SU-6” in O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: The O-Cloud platform maintains its initial state if updates fail or incidents occur during update.

Threat References: Clause 5.4.2.2 ‘T-GEN-01’ in O-RAN Security Threat Modeling and Remediation Analysis [3]

DUT/s: O-Cloud

Test description and applicability

Purpose: To verify on failure of secure Update procedure for the O-Cloud platform, it shall remain in its initial working state.

Test setup and configuration

Verified O-Cloud platform software package obtained from Service Provider.

All necessary artifacts of the O-Cloud platform software image (public key, digitally signed certificates, encryption key if any for security-sensitive artifacts) shall be provided.

All necessary documents related to the Upgrade procedure of the O-Cloud components are made available.

EXAMPLE: O-Cloud software includes AAL drivers, IMS, DMS, Host OS, Hypervisor, Container Engine.

Test procedure

The Tester is properly authenticated and have the required access privileges to perform the upgrade activity.

The O-Cloud Platform to ensure image verification.

The tester performs all the pre-upgrade steps on the O-Cloud Platform.

 EXAMPLE:

Back up any important components, such as app-level state stored in a database, state of critical nodes.

As per the Upgrade documentation, the tester shall stage and perform the upgrade of the O-Cloud Platform

EXAMPLE:

a.  Phased upgrades for service availability.

b.  Stage the Upgrade procedure:  Upgrade control nodes and upgrade the worker nodes.

Attempt to simulate an upgrade failure scenario. EXAMPLE: Unexpected upgrade termination, Abrupt Power failure, Network disruption.

Monitor the O-Cloud logs (EXAMPLE: O2ims logs) for the upgrade steps performed on the platform.

Perform a Post-Update Audit to verify the status of the O-Cloud Platform.

The O-Cloud Platform shall automatically roll-back to its previous version.

Verify in the SMO that the software version for the O-Cloud platform components remains the same as the previous version.

Expected results

The O-Cloud Platform shall automatically roll-back to its previous version and initial working state.

SMO logs to indicate the notification of the Update failure and the version of the O-Cloud components maintains its initial state.

Expected format of evidence:

O-Cloud and SMO logs: Log captures indicating the Steps performed during the Upgrade and the version of the O-Cloud components

Snapshot: Executed command on CLI, GUI, API server

	Security test of VNF/CNF

	Overview

This chapter contains security tests to validate the security protection mechanism specific to O-RAN virtualized/containerized applications deployed on the O-Cloud.

NOTE: O-RAN Applications stand for xApps, rApps, O-CU, O-DU, Near-RT RIC.

STC-19-19.2-001: Executive environment protection

Requirement Name: secure executive environment provision

Requirement Reference & Description: ‘REQ-SEC-LCM-SD-5, REQ-SEC-LCM-SD-6’ clause 5.3.2.3.1 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-AppLCM-04, T-AppLCM-05’ clause 7.4.1.11 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-CU, O-DU, Near-RT RIC, xApps, rApps

Test Name: TC_SECURE_EXECUTIVE_ENV_PROVISION

Test description and applicability

Purpose:

1. To test whether the Application compares the owned resource state with the parsed resource state.

2. To test whether the Application send an alarm to the OAM if the two resource states are inconsistent.

Test setup and configuration

There are an Application, an O-Cloud, an OAM, a NFO-DMS, a FOCOM-IMS (or simulated O-Cloud, OAM, NFO-DMS, FOCOM-IMS) on the test environment.

Test procedure

Execute the following steps:

1. The tester utilizes the O-Cloud to change the resource state of Application (e.g. change vCPU size of the Application).

2. The tester uses the Application to query the parsed resource state from the OAM.

3. The tester uses the OAM to query the parsed resource state of the Application from the NFO and send the received resource state to the Application.

4. The tester checks whether the Application sends an alarm to the OAM when the Application receives the parsed resource state from the OAM and finds that the owned resource state and the parsed resource state are inconsistent.

Expected Results

The Application sends an alarm to the OAM when the Application receives the parsed resource state from the OAM and find that the owned resource state and the parsed resource state are inconsistent.

Expected format of evidence:

Screenshot contains the alarm on the OAM.

STC-19-19.3-001: Signature validation during App image onboarding

Requirement Name: Signature validation during App image onboarding

Requirement Reference & Description: ‘REQ-SEC-ALM-PKG-5, REQ-SEC-ALM-PKG-6’ clause 5.3.2.1.1 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-IMG-04’ clause 7.4.1.11, ‘T-AppLCM-01’ clause 5.4.2.3 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-CU, O-DU, Near-RT RIC, xApps, rApps

Test Name: TC_ SIGNATURE_VALIDATION_DURING_APP_IMAGE_ONBOARDING

Test description and applicability

Purpose: The purpose of this test is to validate the digital signature verification mechanism during the onboarding process of application images into the NFO.

Test setup and configuration

-	The Application document describes information regarding digital signature protection of Application images, including details of how the signature check is carried out, who makes the digital signature of Application image etc.

-	One Application package included two trusted Application images and the Application package carries a correct digital signature of the Application package.

-	Another Application package included untrusted Application image which carry wrong digital signature of Application image and the Application package carries a correct digital signature of the Application package.

-	There are a NFO, or a simulated NFO. A certificate or public key which is used to verify the digital signature of Application image has been pre-configured in the NFO. This certificate is trusted by the operator. It means the digital signature of the Application image is successfully verified by using the public key in the certificate trusted by the operator.

Test procedure

Execute the following steps:

1. Review the documentation provided by the vendor describing how digital signature of the Application image is verified.

2. The tester uploads an Application package included two trusted Application images into a NFO. The NFO verifies the Application images by validating each digital signature of the Application image using the pre-configured certificate or the public key according to the documentation.

3. The tester uploads another Application package included un-trusted Application image into NFO. The NFO verifies the Application image(s) by validating each digital signature of the Application image using the pre-configured certificate or the public key according to the documentation.

Expected Results

1. In the step 2, the signatures of the Application images are successfully validated, and the Application package is successfully on boarded into the NFO;

2. In the step 3, the signature of the un-trusted Application image is failed to be validated and the Application package is not on boarded into the NFO;

Expected format of evidence:

Snapshots containing the result of the Application package on boarding.

STC-19-19.4-001: Application image deployment security

Requirement Name: Application image deployment security

	Requirement Reference & Description: ‘REQ-SEC-ALM-PKG-12’ clause 5.3.2.1.1 in O-RAN Security Requirements and Controls Specifications [5]

Threat References: ‘T-IMG-04’, clause 7.4.1.11, ‘T-AppLCM-02’ clause 5.4.2.3 in O-RAN Security Threat Modeling and Risk Assessment [3]

DUT/s: O-CU, O-DU, Near-RT RIC, xApps, rApps

Test Name: TC_APP_IMAGE_VULNERABILITY_CHECK_ON_DEPLOY

Test description and applicability

Purpose: The purpose of this test is to verify that an Application image is free from known vulnerabilities.

Test setup and configuration

O-Cloud with Application image scanning tools integrated.

Test procedure

Deploy an Application image known to have vulnerabilities:

Select an Application image with known vulnerabilities, such as an image with outdated software or documented security issues.

Attempt to deploy the image to an O-Cloud using the appropriate deployment configuration.

Monitor the deployment process and capture any error messages or logs.

Deploy an Application image with outdated or unapproved software libraries:

Create a custom Application image that includes outdated or unapproved software libraries.

Attempt to deploy the custom image to an O-Cloud using the appropriate deployment configuration.

Monitor the deployment process and capture any error messages or logs.

Expected Results

For the first step, the container image with known vulnerabilities is rejected or flagged as insecure, preventing its deployment.

For the second step, the container image with outdated or unapproved software is blocked from deployment, ensuring compliance with security policies.

Expected format of evidence:

Vulnerability scan reports generated by the Application image scanning tool, indicating the detected vulnerabilities and their severity.

Rejection logs or error messages from the Application image registry or O-Cloud, indicating the rejection or blocking of insecure images.

	Security tests of Common Application Lifecycle Management

Overview

This chapter contains security tests to validate the security protection relevant to Common App LCM.

Application package

STC-20-20.2-001: Application package signature verification

Test name: TC_App_Signature_Verification

Requirement Name: Application package authenticity and integrity protection

Requirement Reference: REQ-SEC-ALM-PKG-2, clause 5.3.2.1.1, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: “The Application package shall be signed by the Application Provider prior to its delivery to the Service Provider to ensure its authenticity and integrity.”

Threat References: T-IMG-01, T-NEAR-RT-02, T-rAPP-05, T-xApp-02

DUT/s: Non-RT RIC, Near-RT RIC, O-CU, O-DU, O-RU, xApps, rApps

Test description and applicability

Purpose: To verify the application package authenticity and integrity validation during onboarding and instantiation.

Test setup and configuration

The Application package is signed by the Application Provider prior to its delivery to the Service Provider.

Test procedure

Upon reception of the Application package from the Application Provider, the Service Provider verifies the Application Provider signature using the test procedure in clause 9.5.2.

Upon verification of the Application Provider signature, the Service Provider signs the Application package prior to its onboarding onto the image’s repository using the test procedure in clause 9.5.1.

Expected Results

Validation of the Application package’s Application Provider signature is successful.

Signing of the Application package by the Service Provider is successful.

Validation of Application package signature and the Service Provider signature during instantiation of the application is successful. If verification is unsuccessful, the Service Provider may suspend the application instantiation process.

Expected format of evidence: Log files for each step of the procedure.

 Security test of O-CU-CP

Overview

The present clause contains 3GPP security test cases applicable to O-CU-CP and O-RAN specific O-CU-CP test cases.

	3GPP specific security functional requirements and test cases

Test name: As defined in clause 5.2.2 of TS 33.523 [23]

Requirement Name: 3GPP specific O-CU-CP security

Requirement Reference:  REQ-SEC-OCU-1, clause 5.1.4.1, O-RAN Security Requirements Specifications [5]

Requirement Description: “O-CU-CP and O-CU-UP shall meet the security requirements for gNB-CU-CP and gNB-CU-UP respectively”, as specified in TS 33.501 [25]

DUT/s: O-CU-CP

Purpose: To verify the O-CU-CP meet the security requirements for gNB-CU-CP

gNB-CU-CP specific security functional requirements and test cases specified in clause 5.2.2 of TS 33.523 [23] apply to O-CU-CP.

	O-RAN specific security functional requirements and test cases

The TLS test cases in clause 6.3 of the present document apply to the O1 interface of O-CU-CP.

The IPsec test cases in clause 6.4 of the present document apply to the E2 interface of O-CU-CP.

	Security test of O-CU-UP

	Overview

The present clause contains 3GPP security test cases applicable to O-CU-UP and O-RAN specific O-CU-UP test cases.

	3GPP specific security functional requirements and test cases

Test name: As defined in clause 6.2.2 of TS 33.523 [23]

Requirement Name: 3GPP specific O-CU-UP security

Requirement Reference: REQ-SEC-OCU-1, clause 5.1.4.1, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: “O-CU-CP and O-CU-UP shall meet the security requirements for gNB-CU-CP and gNB-CU-UP respectively”, as specified in TS 33.501 [25]

DUT/s: O-CU-UP

Purpose: To verify the O-CU-CP meet the security requirements for gNB-CU-UP

gNB-CU-UP specific security functional requirements and test cases specified in clause 6.2.2 of TS 33.523 [23] apply to O-CU-UP.

	O-RAN specific security functional requirements and test cases

The TLS test cases in clause 6.3 of the present document apply to the O1 interface of O-CU-UP.

The IPsec test cases in clause 6.4 of the present document apply to the E2 interface of O-CU-UP.

	Security test of O-DU

	Overview

The present clause contains 3GPP security test cases applicable to O-DU and O-RAN specific O-DU test cases.

	3GPP specific security functional requirements and test cases

Test name: As defined in clause 7.2.2 of TS 33.523 [23]

Requirement Name: 3GPP specific O-DU security

Requirement Reference: REQ-SEC-ODU-1, clause 5.1.5.1, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: “O-DU shall meet the security requirements for gNB-DU” as specified in TS 33.501 [25].

DUT/s: O-DU

gNB-DU specific security functional requirements and test cases specified in clause 7.2.2 of TS 33.523 [23] apply to O-DU.

	O-RAN specific security functional requirements and test cases

The 802.1X Authenticator Validation test cases in clause 11.2.1 applies to O-DU for the network configuration where O-DU acts as an 802.1X authenticator.

The 802.1X Supplicant Validation test cases in clause 11.2.2 apply to O-DU.

The TLS test cases in clause 6.3 of the present document apply to the O1 interface and M-Plane of O-DU.

The IPsec test cases in clause 6.4 of the present document apply to the E2 interface of O-DU.

The SSH Server & Client test cases in clause 6.2 of the present document apply to the M-Plane of O-DU.

 End-to-End security test cases

This clause describes the tests evaluating and assessing the security aspects of the E2E of a radio access network.

The whole O-RAN system (i.e. O-RU, O-DU, O-CU-CP and O-CU-UP) as defined in O-RAN Architecture Description [1] is the System under Test (SUT) and can be viewed as an integrated black box in the context of the E2E security testing.

 3GPP Security Assurance Specification (SCAS)

For NR technology, the Table 241 applies. The test cases referred in this table are 3GPP TS 33.511 [8], which are applied for O-RAN System.

For LTE technology, the Table 242 applies. The test cases referred in this table are 3GPP TS 33.216 [9], which are applied for O-RAN system.

The tables also contain the information relative to the 3GPP releases affected for each test case.

Table 241: List of SCAS Test Cases for NR and applicable technology from Clause 4.2.2 of 3GPP TS 33.511

Test Case (O-RAN Ref. #)

Test Case (3GPP Ref. #)

Requirement

Test Name

Description

Applicable Technology

3GPP Releases affected

SCAS_NR_E2E_24.1.1

4.2.2.1.1

Integrity protection of RRC-signalling

TC_CP_DATA_INT_RRC-SIGN

Verify that the RRC-signaling data sent between UE and O-RAN System over the air interface are integrity protected

NR NSA (Options 3 and 4)
NR SA

16
17
18

SCAS_NR_E2E_24.1.2

4.2.2.1.2

Integrity protection of user data

TC-UP-DATA-INT

Verify that the user data packets sent between UE and O-RAN System are integrity protected over the air interface.

NR NSA (Options 4 and 7)
NR SA

16
17
18

SCAS_NR_E2E_24.1.3

4.2.2.1.4

RRC integrity check failure

TC-CP-DATA-RRC-INT-CHECK

Verify that RRC integrity check failure is handled correctly by O-RAN System.

NR NSA
NR SA

16
17
18

SCAS_NR_E2E_24.1.4

4.2.2.1.5

UP integrity check failure

TC-UP-DATA-RRC-INT-CHECK

Verify that UP integrity check failure is handled correctly by the O-RAN System.

NR NSA
NR SA

16
17
18

SCAS_NR_E2E_24.1.5

4.2.2.1.6

Ciphering of RRC-signalling

TC-CP-DATA-CIP-RRC-SIGN

Verify that the RRC-signaling data sent between UE and O-RAN System over the air interface are confidentiality protected.

NR NSA
NR SA

16
17
18

SCAS_NR_E2E_24.1.6

4.2.2.1.7

Ciphering of user data

TC-UP-DATA-CIP

Verify that the user data packets are confidentiality protected over the air interface.

NR NSA
NR SA

16
17
18

SCAS_NR_E2E_24.1.7

4.2.2.1.8

Replay protection of user data

TC-UP-DATA-REPLAY

Verify that the user data packets are replay protected between the UE and the O-RAN System.

NR NSA
NR SA

16
17
18

SCAS_NR_E2E_24.1.8

4.2.2.1.9

Replay protection of RRC-signalling

TC-UP-DATA-RRC-REPLAY

Verify the replay protection of RRC-signaling between UE and O-RAN System over the air interface.

NR NSA
NR SA

16
17
18

SCAS_NR_E2E_24.1.9

4.2.2.1.10

Ciphering of user data based on the security policy sent by the SMF

TC-UP-DATA-CIP-SMF

Verify that the user data packets are confidentiality protected based on the security policy sent by the SMF via AMF

NR NSA (Options 4 and 7)
NR SA

16
17
18

SCAS_NR_E2E_24.1.10

4.2.2.1.11

Integrity of user data based on the security policy sent by the SMF

TC-UP-DATA-INT-SMF

Verify that the user data packets are integrity protected based on the security policy sent by the SMF.

NR NSA (Options 4 and 7)
NR SA

16
17
18

SCAS_NR_E2E_24.1.11

4.2.2.1.12

AS algorithms selection

TC-AS-alg-select

Verify that the O-RAN System selects the algorithms with the highest priority in its configured list.

NR NSA
NR SA

16
17
18

SCAS_NR_E2E_24.1.12

4.2.2.1.13

Key refresh

TC_GNB_KEY_REFRESH_DRB_ID

Key refresh at O-RAN System

NR NSA
NR SA

16
17
18

SCAS_NR_E2E_24.1.13

4.2.2.1.14

Bidding down prevention in Xn-handovers

TC-Xn-handover_bid_down

Verify that bidding down is prevented in Xn-handovers.

NR NSA
NR SA

16
17
18

SCAS_NR_E2E_24.1.14

4.2.2.1.15

AS protection algorithm selection in O-RAN System change

TC_Alg_select_change

Verify that AS protection algorithm is selected correctly

NR NSA
NR SA

16
17
18

SCAS_NR_E2E_24.1.15

4.2.2.1.16

Control plane data confidentiality protection over N2/Xn interface

TC_CP_CONF_N2_Xn

Verify the control plane data confidentiality protection over N2/Xn interface

NR NSA
NR SA

16
17
18

SCAS_NR_E2E_24.1.16

4.2.2.1.17

Control plane data integrity protection over S1/NG/Xn interface

TC_CP_INT_S1_NG_Xn

Verify the control plane data integrity protection over S1/NG/Xn interface

NR NSA
NR SA

16
17
18

SCAS_NR_E2E_24.1.17

4.2.2.1.18

Key update on dual connectivity

TC_DC_KEY_UPDATE_DRB_ID

Key update at the O-RAN System on dual connectivity – 2 test cases

NR NSA
NR SA

16
17
18

SCAS_NR_E2E_24.1.18

4.2.2.1.19

UserPlane security activation in Inactive scenario

TC_INACTIVE_TO_ACTIVE

Verify that the target O-RAN System uses the UserPlane security activation status to activate the UP security.

NR NSA
NR SA

16
17
18

SCAS_NR_E2E_24.1.19

4.2.2.1.20

User plane data confidentiality protection over N3/Xn interface

TC_UP_CONF_N3_Xn

Verify the user plane data confidentiality protection over N3/Xn interface

NR NSA
NR SA

18

SCAS_NR_E2E_24.1.20

4.2.2.1.21

User plane data integrity protection over N3/Xn interface

TC_UP_INT_N3_Xn

Verify the user plane data integrity protection over N3/Xn interface

NR NSA
NR SA

18

Table 242: List of SCAS Test Cases for LTE and applicable technology from Clause 4.2.2 of 3GPP TS 33.216

Test Case (O-RAN Ref. #)

Test Case (3GPP Ref. #)

Requirement

Test Name

Description

Applicable Technology

3GPP Releases affected

SCAS_LTE_E2E_24.1.1

4.2.2.1.1

Control plane data confidentiality protection over S1/X2

TC_CP_DATA_CONF_S1_X2

Verify the O-RAN System provide confidentiality protection for control plane packets on the S1/X2

LTE

16
17
18

SCAS_LTE_E2E_24.1.2

4.2.2.1.2

Control plane data integrity protection over S1/X2

TC_CP_DATA_INT_S1_X2

Verify the O-RAN System provides integrity protection for control plane packets on the S1/X2

LTE

16
17
18

SCAS_LTE_E2E_24.1.3

4.2.2.1.3

User plane data ciphering

TC-DATA-CIP-Uu

Verify that the user data packets are confidentiality protected over the air interface

LTE

16
17
18

SCAS_LTE_E2E_24.1.4

4.2.2.1.4

User plane data integrity protection

TC_UP_DATA_S1_X2

Verify the O-RAN System handles integrity protection for user plane packets for the S1/X2

LTE

16
17
18

SCAS_LTE_E2E_24.1.5

4.2.2.1.5

AS algorithms selection

TC-AS-alg-select

Verify that AS protection algorithm is selected correctly

LTE

16
17
18

SCAS_LTE_E2E_24.1.6

4.2.2.1.6

RRC integrity protection

TC-UP-DATA-RRC-INT-CHECK

Verify that the message is discarded in case of failed integrity check

LTE

16
17
18

SCAS_LTE_E2E_24.1.7

4.2.2.1.7

Selection of EIA0

TC_EIA0

Verify that AS NULL integrity algorithm is used correctly

LTE

16
17
18

SCAS_LTE_E2E_24.1.8

4.2.2.1.8 (1)

Key refresh (PDCP Count)

TC_KEY_REFRESH_ PDCP_COUNT

Verify that the O-RAN System performs K refresh when PDCP COUNTs are about to wrap around

LTE

16
17
18

SCAS_LTE_E2E_24.1.9

4.2.2.1.8 (2)

Key refresh (DRB ID)

TC_ KEY_REFRESH_DRB_ID

Verify that the O-RAN System performs K refresh when DRB-IDs are about to be reused

LTE

16
17
18

SCAS_LTE_E2E_24.1.10

4.2.2.1.9

AS integrity algorithm selection

TC_AS_INT_SEL

Verify that AS integrity protection algorithm is selected and applied correctly

LTE

16
17
18

SCAS_LTE_E2E_24.1.11

4.2.2.1.10

Bidding down prevention in X2-handovers

TC_BID_DOWN_X2_HO

Verify that bidding down is prevented in X2-handovers

LTE

16
17
18

SCAS_LTE_E2E_24.1.12

4.2.2.1.11

AS protection algorithm selection in O-RAN System change

TC_ AS_PROT_SEL

Verify that AS protection algorithm is selected correctly

LTE

16
17
18

SCAS_LTE_E2E_24.1.13

4.2.2.1.12

RRC and UP downlink ciphering

TC_ DL_Cipher

Verify that the O-RAN System performs RRC and UP downlink ciphering after sending the AS security mode command message

LTE

16
17
18

SCAS_LTE_E2E_24.1.14

4.2.2.1.13

Map a UE NR security capability

TC_MAP_NR_SEC_CAP

Verify that the O-RAN System creates mapped UE NR security capabilities

LTE

16
17
18

SCAS_LTE_E2E_24.1.15

4.2.2.1.14

UE NR security capability is only sent to a Secondary O-RAN System

TC_NR_SEC_CAP_SENT

Verify that the UE NR security capabilities are only sent to a O-RAN System

LTE

16
17
18

SCAS_LTE_E2E_24.1.16

4.2.2.1.15

Bidding down prevention in X2-handovers

TC_BID_DOWN_X2

Verify that bidding down is prevented in X2-handovers when target O-RAN System receives a NR security capability

LTE

16
17
18

SCAS_LTE_E2E_24.1.17

4.2.2.1.16

Integrity protection of user data

TC-UP-DATA-INT

Verify that the user data packets are integrity protected over the air interface

LTE

18

SCAS_LTE_E2E_24.1.18

4.2.2.1.17

Select the right UP integrity protection policy

TC_LOCAL_UP_INTEGRITY_PROTECTION_CONFIGURATION

Verify that the O-RAN System is locally configured with a UP integrity protection policy

LTE

18

SCAS_LTE_E2E_24.1.19

4.2.2.1.18

Select the right UP IP policy

TC_UP_IP_POLICY_Selection

Verify that the O-RAN System has a locally configured UP IP policy

LTE

18

SCAS_LTE_E2E_24.1.20

4.2.2.1.19

Select the right UP IP policy in S1 handover

TC_UP_IP_POLICY_Selection_S1_Handover

Verify that the O-RAN System has correct selection on UP IP policy in S1 handover

LTE

18

SCAS_LTE_E2E_24.1.21

4.2.2.1.20

Bidding down prevention for UP IP Policy

TC_BID_DOWN_UP_IP_Policy

Verify that bidding down for UP IP policy is prevented in X2-handovers

LTE

18

Security test of Shared O-RU

Overview

This chapter contains security tests to validate security controls related to the Shared O-RU and the Shared O-RU architecture.

 Shared O-RU test cases

STC-25-25.2-001: mTLS for mutual authentication

Test Name: mTLS for mutual authentication

Requirement Name:  SEC-CTL-SharedORU-1

Requirement Reference: Clause 5.1.9.2, Security Controls, Shared O-RU, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: mTLS support on Shared O-RU

Threat References: T-SharedORU-06

DUT/s: Shared O-RU

Test description and applicability

Purpose: To verify the Shared O-RU is able to mutually authenticate with an O-RU Controller using mTLS, with PKI-based X.509 certificates.

Test setup and configuration

DUT shall be the Shared O-RU with mTLS 1.2, or 1.3, support enabled.

Test procedure

This test case follows the test procedure for mTLS specified in mTLS Test Procedure, clause 6.3.3.

Expected results

The Shared O-RU supports mutual authentication with an O-RU Controller using mTLS.

Expected format of evidence: Log entries and packet captures.

STC-25-25.2-002: NACM Authorization

Test Name: NACM Authorization

Requirement Name: Open Fronthaul Interface security requirements

Requirement Reference: Clause 5.1.9.2, O-RAN Security Requirements Specifications [5]

Requirement Description: NACM support for Shared O-RU

Threat References: T-SharedORU-22, T-SharedORU-23

DUT/s: Shared O-RU

Test description and applicability

Purpose: To verify the Shared O-RU through is able to enforce role-based least privilege access control on the Open Fronthaul by using NACM [14].

Test setup and configuration

DUT shall be the Shared O-RU with:

IP enabled Open Fronthaul M-Plane interface, reachable from the authentication server;

Valid certificate loaded for the server and necessary certificate authorities (CAs)

Client’s root CA required to validate NETCONF client certificate

Valid TLS Client-to-NETCONF username mapping

Test procedure

First set up a host/device with TLS client software installed, valid client certificates, keys, root CA certificate for the server (Shared O-RU), and all intermediate CA certificates required to validate the client certificate.

The following test steps shall be validated:

Start the NETCONF-over-TLS session using OpenSSL s_client command to connect with DUT using TLSv1.2 or TLSv1.3

Verify the session is established and mapped to the correct NETCONF user

Verify the global NACM enforcement control setting of

enable-nacm = true

read-default = permit

write-default = deny

exec-default = deny

enable-external-groups = true

Verify the NACM rule sets for the pre-defined groups

Close the NETCONF session and TLS connection

Upon availability of the NETCONF operations set(s) definition per NACM group, the NACM rule set(s) enforcement by the DUT shall be validated for each of those pre-defined groups listed above.

Expected results

The Shared O-RU shall support the NETCONF over TLS session over its Open Fronthaul M-Plane interface and NACM enforcement control settings.

Expected format of evidence: Log entries and packet captures.

STC-25-25.2-003: TLS across Open Fronthaul

Test Name: TLS across Open Fronthaul

Requirement Name:  SEC-CTL-SharedORU-4

Requirement Reference: Clause 5.1.9.2, Security Controls, Shared O-RU, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: TLS on Shared O-RU

Threat References: T-SharedORU-27, T-SharedORU-28

DUT/s: Shared O-RU

Test description and applicability

Purpose: To verify the Shared O-RU is able to establish a TLS session with an O-RU Controller and provide confidentiality and integrity protection for messages exchanged with the O-RU Controller.

Test setup and configuration

DUT shall be the Shared O-RU with TLS support enabled.

Test procedure

This test case shall follow the test procedure for TLS specified in TLS Test Procedure, clause 6.3.3.

Expected results

Shared O-RU shall provide confidentiality and integrity protection for data in transit on the Open Fronthaul M-Plane interface.

Expected format of evidence: Log entries and packet captures.

STC-25-25.2-004: Reject Password-based authentication

Test name: Reject SSH Password-based authentication

Requirement Name:  SEC-CTL-SharedORU-2

Requirement Reference: Clause 5.1.9.2, Security Controls, Shared O-RU, O-RAN Security Requirements and Controls Specifications [5]

Requirement Description: Shared O-RU is able to reject password-based authentication on the Open Fronthaul M-Plane

Threat References: T-SharedORU-04

DUT/s: Shared O-RU

Test description and applicability

Purpose: To verify the Shared O-RU can reject a SSH session using password-based authentication on the Open Fronthaul.

Test setup and configuration

DUT shall be the Shared O-RU with password-based authentication for SSH on the Open Fronthaul disabled.

Test procedure

1. Enable SSH on the Open Fronthaul for the Shared O-RU.  Ensure password-based authentication is not enabled on the Shared O-RU for SSH on the Open Fronthaul.

2. Configure the O-RU Controller as the SSH client with password-based authentication on the Open Fronthaul M-Plane.

3. Attempt to establish the Open Fronthaul M-Plane session between the Shared O-RU and O-RU Controller.

Expected results

The Shared O-RU rejects the Open Fronthaul M-Plane session with the O-RU Controller.

Expected format of evidence: Log entries, packet captures, and/or screenshots.

Annex A (informative): 	Example of Security Testing Tools / Toolset

Testing Tool

Example(s)

DTLS scanning tool

open source “pySSLScan”: https://github.com/DinoTools/pysslscan

IPSec IKE scanning tool

open source “ike-scan”: https://github.com/royhills/ike-scan

Port scanner

open source “Nmap”: https://nmap.org/

SSH audit tool

open source “ssh-audit”: https://github.com/jtesta/ssh-audit

TLS scanning tool

open source “sslyze”: https://github.com/nabla-c0d3/sslyze

Software image signing tool

open source “Sigstore”: https://github.com/sigstore

Table Annex A1 List of sample open source security testing tools/toolset

Annex B (informative): 	Template of test report

A. GENERAL INFORMATION

A1 Name of test campaign

A2 Version of the report – reference ID

A3 Date(s) of testing

A4 Contact person (tester) – incl. Name, Organization, E-mail address

A4 Test location (lab) – incl. the address

A5 Description of test campaign, summary of test results, conclusions

List of tests - details of each test can be found in Section E.

Test No.

Test name

Test status [ PASS / FAIL / - ]

01

02

03

B. TEST AND MEASUREMENT EQUIPMENT AND TOOLS

#

Equipment or tool

Type

Manufacture

Version (HW/SW)

Notes*

01

02

03

* Specific details such as the sub-module version (such as vulnerability database version)

C. SYSTEM UNDER TEST

C1 Total number of DUTs included in SUT

C2 Deployment architecture

C3 Description of SUT – connection/block diagram

DUT 1*

C3 Type

C4 Serial Number

C5 Supplier (manufacture)

C6 SW version

C7 HW version (if applicable)

C8 Interface/IOT profile(s) if applied

C9 Description incl. parameters, setting/configuration

* If SUT contains more DUTs, please copy the table.

D. TEST CONFIGURATION

D1 Function(s) and Service(s) setting

D2 Network setting

E. TEST RESULTS

E1 Test No.

E2 Test name

E3 Date(s) of test execution

E4 Reference to test specification

E5 Utilized test and measurement equipment and tools, incl. the specific setting/configuration – reference to Section B

E6 Test setup – connection/block diagram – deployment scenario

E7 Test procedure – describe differences in comparison with the test procedure defined in test spec. – limitations

E8 Test results –including outputs of the test properties and the attachment of log file(s) and/or screenshots

E9 Notes, including observed issues with the solutions

E10 Conclusions – pass/fail – assessment of test results in comparison with the expected results – gap analysis

Revision history

Date

Revision

Description

2021.11.10

01.00

Final initial version 01.00

2022.03.23

02.00.07

Updated sections:

7.4 Network Protocol Fuzzing

9.4 Software Bill of Materials (SBOM)

11.2 Open Fronthaul Point-to-Point LAN Segment

17.2 O1 Interface Network Configuration Access Control Model (NACM) Validation

2022.07.19

03.00.01

Applied the latest O-RAN technical specifications template

Updated sections:

2.1 Normative references

3.2 Abbreviations

6.3 TLS

6.6 OAuth 2.0

9.5 Software Image Signing and Verification

13.2 Testing of IPSec on E2

14.2 Testing of TLS on A1

2022.07.25

03.00.02

Updated cross-reference section numbers of the test cases to align with latest WG11 specs

Updated table of contents

2023.03.09

04.00.00

Updated sections:

14 Security Test of xApps

15 Security test of Non-RT RIC

16 Security test of rApps

Added content to:

14.2 xApp Signing and Verification

16.2 rApp Signing and Verification

Change wording in many places to align document with ETSI PAS

2023.07.10

05.00.00

Added content to:

9.4.3 SBOM Format

9.4.4 SBOM Depth

9.5.2 Software Signature Verification

12.4 O-RU Security functional requirement and test cases

13.2 IPSec on E2 interface

13.3 Transactional APIs

18.2 O2 Interface

18.3 O-Cloud virtualization layer

20 Security tests of Common Application Lifecycle Management

21 Security test of O-CU-CP

22 Security test of O-CU-UP

23 Security test of O-DU

Alignment for ETSI PAS

Annex (informative):
Change History

Date

Revision

Description

2023.11.27

06.00.00

Published as Final version 06.00

2023.07.11

05.00.00

Published as Final version 05.00

2023.03.05

04.00.00

Published as Final version 04.00

2022.07.19

03.00.01

Published as Final version 03.00

2022.03.23

02.00.07

Published as Final version 02.00

2021.11.10

01.00

Published as Final version 01.00

	________________________________________________________________________________________________© 2024 by the O-RAN ALLIANCE e.V. Your use is subject to the copyright statement on the cover page of this specification.	52