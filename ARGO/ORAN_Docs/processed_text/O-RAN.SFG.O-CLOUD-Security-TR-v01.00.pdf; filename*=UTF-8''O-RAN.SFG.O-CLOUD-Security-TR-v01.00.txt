O-RAN.SFG.O-CLOUD-Security-TR-v01.00
Technical Report
O-RAN Security Focus Group (SFG)
Study on Security for O-CLOUD
This is a re-published version of the attached final specification.
For this re-published version, the prior versions of the IPR Policy will apply, except that the previous
requirement for Adopters (as defined in the earlier IPR Policy) to agree to an O-RAN Adopter License
Agreement to access and use Final Specifications shall no longer apply or be required for these Final
Specifications after 1st July 2022.
The copying or incorporation into any other work of part or all of the material available in this
specification in any form without the prior written permission of O-RAN ALLIANCE e.V.  is prohibited,
save that you may print or download extracts of the material on this site for your personal use, or copy
the material on this site for the purpose of sending to individual third parties for their information
provided that you acknowledge O-RAN ALLIANCE as the source of the material and that you inform the
third party that these conditions apply to them and that they must comply with them.
Copyright © 2022 by the O-RAN ALLIANCE e.V.
Your use is subject to the copyright statement on the cover page of this specification.
Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License Agreement in
Annex ZZZ
Page 1
1
O-RAN.SFG.O-CLOUD-Security-TR-v01.00
Technical Report
O-RAN Security Focus Group (SFG)
Study on Security for O-CLOUD
Copyright © 2022 by O-RAN ALLIANCE e.V.
By using, accessing or downloading any part of this O-RAN specification document, including by copying, saving, distributing, displaying
or preparing derivatives of, you agree to be and are bound to the terms of the O -RAN Adopter License Agreement contained in the
Annex ZZZ of this specification. All other rights reserved.
O-RAN ALLIANCE e.V.
Buschkauler Weg 27, 53347 Alfter, Germany
Register of Associations, Bonn VR 11238
VAT ID DE321720189
www.o-ran.org

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 2

Revision History 1
Date Revision Doc
status
Author Description
2022.01.11 V01.00.01 Draft SFG Initial draft version for review
2022.03.03 V01.00.02 Draft SFG Update according to notes from the WI core
teams. This version addresses ORA-CR009,
ORA-CR010, MTR-CR001, ORA.AO-CR011
2022.03.10 V01.00.03 Draft SFG Update according to notes from the WI core
teams. This version addresses ALT-CR001
2022.03.24 V01.00.04 Draft SFG Update after spelling check
 2
 3
 4
 5
 6
  7

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 3

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
Contents 1
Revision History ................................................................................................................................................. 2 2
1 Inroduction ............................................................................................................................................... 5 3
1.1 Scope .................................................................................................................................................................  5 4
1.2 References.......................................................................................................................................................... 5 5
1.3 Definitions and Abbreviations ........................................................................................................................... 7 6
1.3.1 Definitions .................................................................................................................................................... 7 7
1.3.2 Abbreviations and acronyms ........................................................................................................................ 8 8
1.3.3 Terms ........................................................................................................................................................... 9 9
2 O-Cloud Architecture ............................................................................................................................. 11 10
2.1 Components ..................................................................................................................................................... 11 11
2.1.1 SMO ........................................................................................................................................................... 11 12
2.1.2 Hardware resources .................................................................................................................................... 12 13
2.1.3 Operating System (OS) .............................................................................................................................. 12 14
2.1.4 Vitualization Layer ..................................................................................................................................... 12 15
2.1.5 NFs Layer ................................................................................................................................................... 12 16
2.1.6 O-Cloud images repository ........................................................................................................................ 12 17
2.2 Interfaces.......................................................................................................................................................... 12 18
2.3 Critical services ............................................................................................................................................... 13 19
2.3.1 SERV#01 SMO-O-Cloud O2 services ....................................................................................................... 13 20
2.3.2 SERV#02 O-Cloud images service ............................................................................................................ 14 21
2.3.3 SERV#03 O-Cloud monitoring service ...................................................................................................... 14 22
2.3.4 SERV#04 O-Cloud provisioning service ................................................................................................... 14 23
2.3.5 SERV#05 O-Cloud software management service .................................................................................... 15 24
2.3.6 SERV#06 O-Cloud fault management service ........................................................................................... 15 25
2.3.7 SERV#07 O-Cloud performance service ................................................................................................... 15 26
3 Cloud deployment scenarios .................................................................................................................. 17 27
3.1 Main actors ...................................................................................................................................................... 17 28
3.2 Cloud service models ....................................................................................................................................... 17 29
3.2.1 Infrastructure as a Service (IaaS) ............................................................................................................... 17 30
3.2.2 Platform as a Service (PaaS) ...................................................................................................................... 17 31
3.2.3 Software as a Service (SaaS) ...................................................................................................................... 18 32
3.3 Cloud deployment types .................................................................................................................................. 18 33
3.3.1 Private cloud............................................................................................................................................... 18 34
3.3.2 Community Cloud ...................................................................................................................................... 19 35
3.3.3 Public Cloud ............................................................................................................................................... 21 36
3.3.4 Hybrid Cloud .............................................................................................................................................. 21 37
3.4 High-Level risk assessment ............................................................................................................................. 23 38
4 Roles and responsibilities ....................................................................................................................... 26 39
5 Security Problem Definition ................................................................................................................... 28 40
5.1 Assets ............................................................................................................................................................... 28 41
5.2 Threats ............................................................................................................................................................. 32 42
5.2.1 Threat and impact types ............................................................................................................................. 32 43
5.2.2 Attack surface............................................................................................................................................. 32 44
5.2.3 Vulnerabilities ............................................................................................................................................ 33 45
5.2.4 Threat events .............................................................................................................................................. 34 46
6 Recommendations and best practices ..................................................................................................... 45 47
6.1 REC-CM Certificate management ................................................................................................................... 45 48
6.2 REC-NS Network Segmentation & Filter Network Traffic ............................................................................. 46 49
6.3 REC-IAM Identity, Authentication and Access Management ......................................................................... 46 50
6.4 REC-VHPM Vulnerability Handling and Patch Management ........................................................................ 48 51
6.5 REC-SCONF Security Configuration .............................................................................................................. 48 52
6.6 REC-SDLC Secure Development Lifecycle .................................................................................................... 49 53
6.7 REC-SNFLC Security App/VNF/CNF lifecycle ............................................................................................. 50 54
6.8 REC-IMGP Image Protection .......................................................................................................................... 50 55

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 4

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
6.9 REC-LOG Logging, Monitoring and Alerting.................................................................................................  51 1
6.10 REC-SB Secure Boot ....................................................................................................................................... 52 2
6.11 REC-ISO Strong Isolation ............................................................................................................................... 52 3
6.12 REC-AUD Security Audit ............................................................................................................................... 53 4
6.13 REC-SS Secure Storage ................................................................................................................................... 54 5
6.14 REC-PHY Physical Security Protection .......................................................................................................... 54 6
6.15 REC-RA Remote Attestation ........................................................................................................................... 55 7
7 Risk Assessment ..................................................................................................................................... 56 8
Annex A (informative):  Best practices from some of existing main security guidance .................................. 57 9
A.1 CISA/NSA Kubernetes security hardening best practices ............................................................................... 57 10
A.2 CIS Docker security best practices .................................................................................................................. 61 11
A.3 ONAP VNFs security best practices ................................................................................................................ 62 12
Annex ZZZ : O-RAN Adopter License Agreement ......................................................................................... 68 13
 14
List of Tables 15
Table 2-1 : O-Cloud interfaces ......................................................................................................................................... 13 16
Table 3-1 : High level security risk assessment of cloud deployment models.................................................................. 25 17
Table 4-1 : List of Users ................................................................................................................................................... 27 18
Table 5-1 : List of Assets .................................................................................................................................................. 31 19
 20
List of Figures 21
Figure 2-1 : O-CLOUD architecture .................................................................................................................................  11 22
Figure 2-2 : Parallel reporting & Alarm correlation [1] .................................................................................................... 15 23
Figure 3-1 : IaaS cloud service model .............................................................................................................................. 17 24
Figure 3-2 : PaaS cloud service model ............................................................................................................................. 18 25
Figure 3-3 : SaaS cloud service model ............................................................................................................................. 18 26
Figure 3-4 : On site private cloud ..................................................................................................................................... 19 27
Figure 3-5 : Outsourced private cloud .............................................................................................................................. 19 28
Figure 3-6 : On site community cloud .............................................................................................................................. 20 29
Figure 3-7 : Outsourced community cloud ....................................................................................................................... 20 30
Figure 3-8 : Public cloud .................................................................................................................................................. 21 31
Figure 3-9 : Hybrid cloud ................................................................................................................................................. 22 32
Figure 5-1 : Cartography of assets .................................................................................................................................... 28 33
Figure 5-2 : Attack vectors ............................................................................................................................................... 33 34
Figure 5-3 : Vulnerabilities within ①, ②, ③ ................................................................................................................ 34 35
Figure 5-4 : Illustration of the VM/Container escape attack ............................................................................................. 36 36
Figure 5-5 : Illustration of the migration flooding attack .................................................................................................  38 37
Figure 5-6 : Illustration of the false resource advertising attack ....................................................................................... 38 38
Figure 5-7 : Illustration of the migration MITM attack .................................................................................................... 38 39
Figure 5-8 : Illustration of the Theft-of-Service/DoS Attack ............................................................................................ 39 40
Figure 5-9 : Illustration of the VM/Container hyperjacking attack .................................................................................. 41 41
Figure 5-10 : Illustration of a cross VM/Container side channel attack ........................................................................... 43 42
 43
 44

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 5

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
1 Inroduction 1
1.1 Scope 2
This technical report is the threat model of identifying and prioritizing potential threats to the O-Cloud and determining 3
the potential mitigations to reduce those threats.  4
 5
The steps of the threat modelling process are as follows: 6
1. Identify assets: Identify the valuable assets that the O-Cloud must protect. 7
2. Identify the threats: Identify the threats that could affect O-Cloud 8
3. Document the threats: Document each threat using a common threat template that defines a core set of 9
attributes to capture for each threat. 10
4. Rate the threats: Rate the threats to prioritize and address the most significant threats first. The rating process 11
weighs the probability of the threat against damage that could result should an attack occur.  12
5. Define potential mitigations to counter the identified threats and reduce their risks. 13
 14
The structure of the document is divided into seven chapters and one annex: 15
• Chapter 2 describes the Cloud architecture in terms of components, interfaces,  and critical services. 16
• Chapter 3 explores the different deployment types and models. In addition, it provides a high-level risk 17
assessment of those cloud deployment models. 18
• Chapter 4 highlights the main actors of the O-Cloud in terms of roles and responsibilities. 19
• Chapter 5 outlines the security problem definition in terms of assets, attack vectors, vulnerabilities and threats.  20
• Chapter 6 defines recommendations and best practices to mitigate the identified threats.  21
• Chapter 7 figures out the risk assessment of the identified threats in terms of impact and likelihood.  22
• Annex A provides best practices from some of the main security guidance on cloud, virtualization and 23
containerization. 24
 25
1.2 References 26
[1] O-RAN.WG6.O2-GA&P v01.02: O-RAN O2 Interface - General Aspects and Principles  27
[2] O-RAN.WG6.ORCH-USE-CASES v03.00: Cloudification and Orchestration Use Cases and Requirements for 28
O-RAN Virtualized RAN 29
[3] CISA/NSA - Kubernetes Hardening Guidance – August 2021  30
https://media.defense.gov/2021/Aug/03/2002820425/-1/-31
1/1/CTR_KUBERNETESHARDENINGGUIDANCE.PDF 32
[4] MITRE ATT&CK containers matrix 33
https://attack.mitre.org/matrices/enterprise/containers/ 34
[5] ENISA Threat Landscape for 5G Networks: Threat assessment for the fifth generation of mobile 35
telecommunications networks (5G); November 2019 36
[6] ETSI GS NFV-SEC 025 "work in progress." Network Functions Virtualisation (NFV) Release 4; Security; 37
Secure End-to-End VNF and NS management specification 38
[7] O-RAN Working Group 6 - O-RAN O-Cloud O2 O2dms Interface Specification v02 39
[8] O-RAN Working Group 6 - O2ims Interface Specification v01.01 40
[9] IETF RFC 3647: "Internet X.509 Public Key Infrastructure Certificate Policy and Cer tification Practices 41
Framework" 42
[10] ETSI GR NFV-SEC 005 Network Functions Virtualisation (NFV); Trust; Report on Certificate Management  43
[11] IETF RFC 6749: "The OAuth 2.0 Authorization Framework". 44
[12] ETSI GS NFV-SEC 022 Network Functions Virtualisation (NFV) Release 2; Security; Access Token 45
Specification for API Access 46
[13] ETSI GR NFV-SEC 018 Network Functions Virtualisation (NFV); Security; Report on NFV Remote 47
Attestation Architecture 48
[14] Ludovic Jacquin, Antonio Lioy, Diego R. Lopez, Adrian L. Shaw, and Tao Su “The trust problem in modern 49
network infrastructures” 50

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 6

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
https://security.polito.it/doc/public/trust_modern_network_2015.pdf 1
[15] ETSI GR NFV-SEC 007 Network Functions Virtualisation (NFV); Trust; Report on Attestation Technologies 2
and Practices for Secure Deployments 3
[16] 3GPP TR 33.848 “Study on security impacts of virtualisation” 4
[17] OWASP Container Security Verification Standard 5
https://owasp.org/www-project-container-security-verification-standard/migrated_content 6
[18] CIS Docker Benchmark Securing Docker 7
https://www.cisecurity.org/benchmark/docker/ 8
[19] NIST Special Publication 800-190 Application Container Security Guide 9
[20] OWASP Docker Security Cheat Sheet 10
https://cheatsheetseries.owasp.org/cheatsheets/Docker_Security_Cheat_Sheet.html  11
[21] OWASP Kubernetes Security Cheat Sheet 12
https://cheatsheetseries.owasp.org/cheatsheets/Kubernetes_Security_Cheat_Sheet.html  13
[22] NIST SP 800-145: The NIST Definition of Cloud Computing 14
[23] NIST SP 500-322: Evaluation of Cloud Computing Services Based on NIST 800-145 15
[24] ONAP VNF Development Requirements – VNF Security 16
https://docs.onap.org/projects/onap-vnfrqts-requirements/en/latest/Chapter4/Security.html 17
[25] GSMA NG.126 - Cloud Infrastructure Reference Model 18
https://www.gsma.com/newsroom/wp-content/uploads//NG.126-v1.0-2.pdf 19
[26] Aqua Top 20 Docker Security Best Practices: Ultimate Guide 20
https://blog.aquasec.com/docker-security-best-practices 21
[27] “Security Impacts of Virtualization on a Network Testbed”, Software Security and Reliability (SERE), 2012 22
IEEE Sixth International Conference 23
https://www.researchgate.net/publication/261059755_Security_Impacts_of_Virtualization_on_a_Network_Tes24
tbed 25
[28] Beniel Dennyson W, Dr. S. Prabakaran “Detecting Hyperjacking in cloud based virtual environment” 26
https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwi92Zeznun0AhULH27
xoKHXO6AkgQFnoECAgQAQ&url=http%3A%2F%2Fsersc.org%2Fjournals%2Findex.php%2FIJAST%2Fa28
rticle%2Fdownload%2F15440%2F7789%2F&usg=AOvVaw3THwuT_S_WyKr6miOi J7GS 29
[29] Muhammad Kazim “Security Aspects of Virtualization in Cloud Computing ” 30
https://www.researchgate.net/publication/273950406_Security_Aspects_of_Virtualization_in_Cloud_Computi31
ng 32
[30] Anita Choudhary “ A critical survey of live virtual machine migration techniques “ 33
https://journalofcloudcomputing.springeropen.com/track/pdf/10.1186/s13677-017-0092-1.pdf 34
[31] Svetlana Kolesnikova, Roman Kulikov, Yuriy Gatchin, Daniil Melnik “Hypervisor Security Analyses Based 35
on Ishikawa Methodology” 36
https://www.researchgate.net/publication/323838205_Hypervisor_Security_Analyses_Based_on_Ishikawa_M37
ethodology?enrichId=rgreq-bf37d66002988b1ad9ef24fb09198313-38
XXX&enrichSource=Y292ZXJQYWdlOzMyMzgzODIwNTtBUzo2MDg0MzY3NTI0ODIzMDVAMTUyMj39
A3NDAzNDM4NQ%3D%3D&el=1_x_3&_esc=publicationCoverPdf 40
[32] Mehiar Dabbagh, Ammar Rayes “Internet of Things Security and Privacy” 41
https://www.researchgate.net/publication/309375790_Internet_of_Things_Security_and_Privacy?enrichId=rgr42
eq-69e8c33eb9fc28fccec64fbdad0a91d0-43
XXX&enrichSource=Y292ZXJQYWdlOzMwOTM3NTc5MDtBUzo1NTYxNDY2NDI2OTAwNDhAMTUw44
OTYwNzEwMDM0OA%3D%3D&el=1_x_3&_esc=publicationCoverPdf 45
[33] Changwei Liu, Anoop Singhal, Duminda Wijesekera “A Layered Graphical Model for Cloud Forensic Mission 46
Attack Impact Analysis” 47
https://www.researchgate.net/publication/327314423_A_Layered_Graphical_Model_for_Cloud_Forensic_Mis48
sion_Attack_Impact_Analysis_14th_IFIP_WG_119_International_Confer ence_New_Delhi_India_January_3-49
5_2018_Revised_Selected_Papers?enrichId=rgreq-b9ce99f09429d1a36256442e04006d0f-50

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 7

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
XXX&enrichSource=Y292ZXJQYWdlOzMyNzMxNDQyMztBUzo3NTM0MDM2Mzg1ODMzMDFAMTU11
NjYzNjgzMzI4Nw%3D%3D&el=1_x_3&_esc=publicationCoverPdf 2
[34] Docker Best practices for scanning images 3
https://docs.docker.com/develop/scan-images/ 4
[35] Shankar Lal, Tarik Taleb, and Ashutosh Dutta “NFV: Security Threats and Best Practices” 5
http://anastacia-h2020.eu/publications/NFV_Security_Threats_and_Best_Practices.pdf 6
[36] NSA/CISA Mitigating Cloud Vulnerabilities 7
https://media.defense.gov/2020/Jan/22/2002237484/-1/-1/0/CSI-MITIGATING-CLOUD-8
VULNERABILITIES_20200121.PDF 9
[37] Fraunhofer AISEC report: Threat analysis of container-as-a-service for network function virtualization 10
https://www.aisec.fraunhofer.de/content/dam/aisec/Dokumente/Publikationen/Studien_TechReports/englisch/c11
aas_threat_analysis_wp.pdf 12
[38] CSA. The treacherous 12: Cloud computing top threats in 2016. Technical report, Cloud Security Alliance, 13
2016. 12, 14, 15, 16, 17, 27 14
[39] ETSI GS NFV-SOL 013 Network Functions Virtualisation (NFV) Release 2; Protocols and Data Models;  15
Specification of common aspects for RESTful NFV MANO APIs 16
[40] CISA Cloud Security Technical Reference Architecture 17
https://www.cisa.gov/sites/default/files/publications/CISA%20Cloud%20Security%20Technical%20Reference18
%20Architecture_Version%201.pdf 19
[41] Guide ANSSI - Hardware security requirements for x86 platforms 20
https://www.ssi.gouv.fr/uploads/2019/11/anssi-guide-hardware_security_requirements.pdf 21
[42] O-RAN.SFG.Security-Requirements-Specifications-v02.00 22
[43] O-RAN.WG10.OAM-Architecture-v06.00: O-RAN Operations and Maintenance Architecture 23
[44] NSA/CISA Security Guidance for 5G Cloud Infrastructures 24
https://www.cisa.gov/news/2021/10/28/nsa-and-cisa-provide-cybersecurity-guidance-5g-cloud-infrastructures 25
[45] O-RAN.SFG.Security-Protocols-Specifications-v03.00 26
[46] ETSI GS NFV-SOL 004 Network Functions Virtualisation (NFV) Release 3; Protocols and Data Models; VNF 27
Package and PNFD Archive specification 28
[47] ETSI GS NFV-SEC 021 Network Functions Virtualisation (NFV) Release 2; Security; VNF Package Security 29
Specification 30
 31
1.3 Definitions and Abbreviations 32
1.3.1 Definitions 33
For the purposes of the present document, the terms and definitions given in 3GPP TR  21.905 and the following apply: 34
A1: Interface between non-RT RIC and Near-RT RIC to enable policy-driven guidance of Near-RT RIC 35
applications/functions, and support AI/ML workflow.  36
A1 policy: Type of declarative policies expressed using formal statements that enable the non- RT RIC function in the 37
SMO to guide the near-RT RIC function, and hence the RAN, towards better fulfilment of the RAN intent. 38
A1 Enrichment information: Information utilized by near-RT RIC that is collected or derived at SMO/non-RT RIC 39
either from non-network data sources or from network functions themselves. 40
E2:  Interface connecting the Near-RT RIC and one or more O-CU-CPs, one or more O-CU-UPs, and one or more O-41
DUs. 42
E2 Node: a logical node terminating E2 interface. In this version of the specification, O -RAN nodes terminating E2 43
interface are: 44
- for NR access: O-CU-CP, O-CU-UP, O-DU or any combination;  45
- for E-UTRA access: O-eNB. 46
FCAPS: Fault, Configuration, Accounting, Performance, Security. 47
Intents: A declarative policy to steer or guide the behavior of RAN functions, allowing the RAN function to calculate 48
the optimal result to achieve stated objective. 49

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 8

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
Near-RT RIC: O-RAN near-real-time RAN Intelligent Controller: a logical function that enables real-time control and 1
optimization of RAN elements and resources via fine-grained data collection and actions over E2 interface. 2
Non-RT RIC: O-RAN non-real-time RAN Intelligent Controller: a logical function that enables non -real-time control 3
and optimization of RAN elements and resources, AI/ML workflow including model training and updates,  and policy-4
based guidance of applications/features in Near-RT RIC. 5
O-CU: O-RAN Central Unit: a logical node hosting O-CU-CP and O-CU-UP  6
O-CU-CP: O-RAN Central Unit – Control Plane: a logical node hosting the RRC and the control plane part of the 7
PDCP protocol. 8
O-CU-UP: O-RAN Central Unit – User Plane: a logical node hosting the user plane part of the PDCP protocol and the 9
SDAP protocol. 10
O-DU: O-RAN Distributed Unit: a logical node hosting RLC/MAC/High-PHY layers based on a lower layer functional 11
split. 12
O-RU: O-RAN Radio Unit: a logical node hosting Low-PHY layer and RF processing based on a lower layer functional 13
split.  This is similar to 3GPP’s “TRP” or “RRH” but more specific in including the Low -PHY layer (FFT/iFFT, 14
PRACH extraction). 15
O1: Interface between management entities (NMS/EMS/MANO) and O-RAN managed elements, for operation and 16
management, by which FCAPS management, Software management, File management shall be achieved.  17
RAN: Generally referred as Radio Access Network. In terms of this document,  any component below Near-RT RIC per 18
O-RAN architecture, including O-CU/O-DU/O-RU. 19
NF Deployment: An O-Cloud NF Deployment is a deployment of a cloud native Network Function (all or partial), 20
resources shared within a NF Function, or resources shared across network functions. The NF Deployment configures 21
and assembles user-plane resources required for the cloud native construct used to establish the NF Deployment and 22
manage its life cycle from creation to deletion. 23
NF Deployment Descriptor: A completed data model which provides an O-Cloud the necessary information to create 24
a deployment.  25
Deployment ID: Correlation Identity created by the O-Cloud for the SMO to relate to its inventory and manage. 26
O-Cloud Node: An O-Cloud Node is exposed over O2ims as an Abstracted Resource. It is a collection of CPUs, Mem, 27
Storage, NICs, Accelerators, BIOSes, BMCs, etc., and can be thought of as a server.  28
Service Provider: A network provider who is planning to deploy applications into their network [4 3]. 29
Solution Provider: An application developer who delivers applications to Service Providers [43 ]. 30
 31
1.3.2 Abbreviations and acronyms 32
For the purposes of the present document, the abbreviations given in 3GPP TR  21.905 and the following apply: 33
AI/ML Artificial Intelligence/Machine Learning 34
CNF  Containerized Network Function 35
DMS  O-Cloud Deployment Management Services 36
eNB eNodeB (applies to LTE)  37
FOCOM  Federated O-Cloud Orchestration & Management 38
gNB gNodeB (applies to NR) 39
IMS  O-Cloud Infrastructure Management Services 40
KPI Key Performance Indicator  41
KQI Key Quality Indicator 42
LCM  Life Cycle Management 43
MIMO Multiple Input, Multiple Output 44
NF  Network Function 45
NFO  Network Function Orchestration 46

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 9

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
NFVI  Network Function Virtualization Infrastructure 1
O-CU  O-RAN Central Unit as defined by O-RAN ALLIANCE 2
O-CU-CP  O-CU Control Plane 3
O-DU-UP  O-CU User Plane 4
O-DU  O-RAN Distributed Unit (uses Lower-level Split) 5
O-RU  O-RAN Radio Unit 6
PNF  Physical Network Function 7
PRB Physical Resource Block 8
QoE Quality of Experience 9
RAN  Radio Access Network 10
RIC O-RAN RAN Intelligent Controller 11
SINR Signal-to-Interference-plus-Noise Ratio 12
UAV Unmanned Aerial Vehicle 13
V2X Vehicle to Everything 14
SMO Service Management and Orchestration 15
MNO Mobile Network Operator 16
SDN Software Defined Network 17
RBAC Role-based Access Control 18
LBT Listen Before Talk 19
NF Network Function 20
NFV Network Function Virtualisation 21
PDCP Packet Data Convergence Protocol 22
VM  Virtual machine 23
VNF Virtualised Network Function 24
LLS Lower Layer Split 25
NETCONF Network Configuration Protocol 26
SSH Secure Shell 27
IPSEC Internet Protocol Security 28
TLS Transport Layer Security 29
PTP Precision Timing Protocol 30
FTP File Transfer Protocol 31
FTPS File Transfer Protocol Secure 32
 33
1.3.3 Terms 34
In this document, the significance is following the words defined in the RFC 2119 publication by IETF. These words 35
are: 36
• "SHALL" This word, or the words "REQUIRED" and "must" mean that the process is an absolute requirement 37
of the specification. 38
• "SHOULD" This word or the adjective "RECOMMENDED" means that there may exist valid reasons in 39
particular circumstances to ignore this item, but the full implications should be understood, and the case 40
carefully weighed before choosing a different course.  41

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 10

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
• "MAY" This word or the adjective "optional" means that this item is truly optional. One vendor may choose to 1
include the process because a particular marketplace requires it or because it enhances the product, for 2
example, another vendor may omit the same item. 3

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 11

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
2 O-Cloud Architecture 1
The O-Cloud architecture is depicted in the following figure: 2
 3
 4
Figure 2-1 : O-CLOUD architecture 5
 6
2.1 Components 7
The following are a description of the functional blocks identified in the figure here above  [1], [2]: 8
2.1.1 SMO 9
The SMO components managing and orchestrating the O-Cloud software are: 10
• Federated O-Cloud Orchestration and Management (FOCOM): The FOCOM is responsible for 11
accounting and asset management of the resources in the cloud. The FOCOM is the primary consumer of  12
services provided by the IMS. The FOCOM has information about the O -Cloud resources management. 13
Specifically, the FOCOM needs to know whether the services are within the operator domain or external.  14
• Network Function Orchestrator (NFO): The NFO is responsible for orchestrating the assembly of the 15
network functions as a composition of NF Deployments in the O-Cloud. It may also utilize OAM Functions in 16
order to access the O1 interface to the NF once it is deployed. Its use of the O1 is not germane to the O2 a nd is 17
only mentioned here for completeness. The NFO is the primary consumer of the DMS.  18
• Infrastructure Management Services (IMS): The IMS is responsible for management of the O-Cloud 19
resources and the software which is used to manage those resources. The I MS generally provides services for 20
consumption by the FOCOM. 21

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 12

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
• Deployment Management Services (DMS): The DMS is responsible for management of NF Deployments 1
into the O-Cloud. It provides the ability to instantiate, monitor, and terminate NF Deployments. The DMS 2
generally provides services for consumption by the NFO. 3
2.1.2 Hardware resources 4
• A Computer System is defined to be a physical or composed system capable of perform computations that is 5
Underlay-Network connected. A Computer System can run any major Operating System with or without 6
Virtualization and/or Container support functionality. Note: A computer system in the context of a cloudified 7
network and usage in cluster requires a network connectivity. For example, a server in a data center connected 8
to an underlay network. 9
• An underlay network is a physically connected network enabling Computer Systems to communicate with 10
each other and with the gateway(s) connected to networks outside of the data center.  11
• Hardware accelerator manager: It is an acceleration management function, that provides management 12
capabilities for the HW Accelerator(s) in the O-Cloud Node. Management capabilities include but not limited 13
to lifecycle management, configuration, updates/upgrades and failure handling. Hardware Accelerators include 14
ASIC, FPGA, DSP and GPU. 15
2.1.3 Operating System (OS) 16
An Operating system is a software platform that manages and abstracts the Computer System hardware and software 17
resources as well as provides common services for NFs such as scheduling and network connectivity. 18
2.1.4 Vitualization Layer 19
• Hypervisor (VMs): An hypervisor is an OS that includes the ability to offer multiple Virtual Machines, each 20
acting as a well-separated Computer System. 21
• Container Engine: A Container Engine is an OS that include the ability to offer multiple separated name 22
spaces, quotas, and management for Containers. 23
2.1.5 NFs Layer 24
The following are three deployment scenarios of a NF: 25
1. Bare Metal Container Cluster – A Bare Metal Container Cluster is a set of network-connected computer 26
systems with their individual operating system instances that supports containers in a cluster configuration.  27
2. VM-based Container Cluster – A VM-based Container Cluster is a set of network-connected Virtual 28
Machines with their individual guest operating system instance that supports containers in a clustered 29
configuration. 30
3. VM Cluster – A VM Cluster is a set of network-connected Computer Systems with their individual operating 31
instance that supports virtual machines in a cluster configuration. 32
2.1.6 O-Cloud images repository 33
The repository containing the Software Images of O-RAN Network Functions. 34
2.2 Interfaces 35
O-Cloud interfaces are illustrated in the following table: 36
 37
Interfaces Interface between Exposure Description Security
protection
O2dms
SMO and O-Cloud
Deployment Management
Services (DMS)
External
It is responsible for the deployment management services of
the NF Deployment. It offers the following services APIs
[7]:
• O2dms_DeploymentInventory Services
• O2dms_DeploymentProvisioning Services
• O2dms_DeploymentFault Services
• O2dms_DeploymentPerformance Services
• O2dms_DeploymentLifecycle Services
TLS 1.2/1.3
O2ims
SMO and O-Cloud
Infrastructure
Management Services
(IMS)
External
It is responsible for infrastructure management services for
O-Cloud Nodes. It offers the following services APIs [8]:
• O2ims_InfrastuctureInventory Services: Service for
querying the O-Cloud resources and management
services.
• O2ims_InfrastructureMonitoring Services: Service for
configuring telemetry reporting of O-Cloud
infrastructure resources.
• O2ims_InfrastructureProvisioning Services: Service
for configuring the O-Cloud infrastructure resources
and management services.
TLS 1.2/1.3

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 13

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
• O2ims_InfrastructureSoftwareManagement Services:
Services for software inventory and updating the
software used for O-Cloud infrastructure resources and
management services.
• O2ims_InfrastructureLifecycleManagement Services:
Services related to O-Cloud infrastructure lifecycle
management and events.
O1 SMO and the RAN
managed functions External
SMO performs relevant configuration updates in RAN over
O1 interface for each network function.
SMO on operator request can perform recover (reset) of an
application (in case of failures) within a NF through the O1
interface.
SMO is notified of configuration events, fault events and
performance measurements from an O-RAN NF instantiated
on an O-Cloud, using the O1 interface.
SMO reterives configuration data from NFs through O1.
TLS 1.2/1.3
O-Cloud
APIs
O-Cloud infrastructure
and VNFs/CNFs Internal
The interface is used to specify interactions between the
VNFs/CNFs and O-Cloud. The interfaces can be used by the
VNFs/CNFs to register/deregister for receiving events from
the O-Cloud.
Security-by-
design, as the
communication is
restricted within
the same POD.
AAL APIs O-Cloud infrastructure
and VNFs/CNFs Internal For allocation, usage, release, and querying of acceleration
resources.
Work on initial
security
requirements for
the AAL is
ongoing. How to
fulfill these
requirements is
FFS.
Management
(Tenant
level APIs)
External interfaces are use
case specific interfaces
that are not standardized
in O-RAN.  Security of
these interfaces is outside
the scope of this work
item and recommended to
be outside the scope of the
O-RAN Alliance.
External
APIs for the management (creation, deletion, and operation)
of the Tenant, software flavours, Operating System and
workload images, Identity and Authorization, virtual
resources, security, and the workload application.
HTTPS
Enable
Services
Interfaces
External interfaces are use
case specific interfaces
that are not standardized
in O-RAN.  Security of
these interfaces is outside
the scope of this work
item and recommended to
be outside the scope of the
O-RAN Alliance.
External
An operational O-Cloud needs a set of standard services to
function. Services such as NTP for time synchronization,
DHCP f r or IP address allocation, DNS for obtaining IP
addresses for domain names, and LBaaS to distribute
incoming requests amongst a pool of designated resources.
HTTPS
Table 2-1 : O-Cloud interfaces 1
2.3 Critical services 2
The following main critical services are provided by the O-Cloud components [1], [2] which need to be highly protected 3
and securely maintained. They are identified in this report to assess the negative impact that the identified threats may 4
cause on them. 5
 6
2.3.1 SERV#01 SMO-O-Cloud O2 services 7
 8
Using the O2 interface, the SMO can perform the following operations: 9
• Provide a boot image for a remote node 10
• Send a cloud descriptor, (i.e., cloudbdeployment and configuration files) for initial cloud startup  11
• Query the O-Cloud for attributes such as SW inventory 12
• Send a request to O-Cloud to download software sent to it from the SMO, such as request for download of an 13
xAPP deployment. 14
• Subscribe to notification of configuration events, fault events and performance measurements from the O -15
Cloud 16
• Query the O-Cloud for the DMS end points it supports 17
• Query the O-Cloud for attributes such as capabilities and capacities 18
• Request the O-Cloud to create a Network Function deployment using cloud resources 19

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 14

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
• Request the O-Cloud to terminate Network Function deployment(s) 1
• Request the O-Cloud to reset NF Deployment(s) 2
• Request the O-Cloud to reset O-Cloud Node(s) 3
• Issue a subscription to the O-Cloud to receive alarm event notifications 4
• Query the O-Cloud for alarms on O-Cloud resources with query criteria which define the alarm characteristics 5
that the SMO is interested in 6
• Query the O-Cloud for state and status information 7
• Perform an Alarm Subscription query towards the IMS 8
• Perform a NF deployment (that releases an NF instance) resest through the O2dms interface  9
• Perform an O-Cloud Node (recovery of the resources within the O-Cloud) resest through the O2ims interface 10
 11
Using the O2 interface, the O-Cloud can perform the following operations: 12
• Send asynchronous events to the SMO when available capabilities or capacities are changed, including when 13
new hardware is added 14
• Asynchronously notify the SMO when a software upgrade completes 15
• Asynchronously notify the endpoint specified by the SMO (alarm subscriber) of alarm notifications related to 16
O-Cloud resources 17
• Return alarms in response to the SMO alarm query that match the alarm query criteria 18
 19
2.3.2 SERV#02 O-Cloud images service 20
 21
It provides Add/Delete/Update/Query functions of O-RAN Cloudified Network Functions images with their related 22
information (e.g. SoftwareImageId, Vendor, and Version) from O-Cloud repository. 23
 24
2.3.3 SERV#03 O-Cloud monitoring service 25
 26
When the O-Cloud Infrastructure or the ORAN cloudified NFs fails, it needs to be fixed immediately, and preferably 27
automatically, to prevent end users from experiencing service disruptions. To avoid this service disruption Network 28
Operations must consider the telemetry information of O-Cloud deployments in the network. The telemetry information 29
serves as a vital resource for analysing the O-Cloud’s state and health, and for delivering on service monitoring goals. 30
The O-Cloud Monitoring Service uses telemetry data to provide monitoring of O-Cloud infrastructures. O-Cloud 31
telemetry shall minimally consist of Fault, Performance, and Configuration Data. There are different types of telemetry:  32
• Managed Element Telemetry to monitor the NFs behavior through O1. 33
• Deployment Telemetry to monitor the number of deployment instances an O-Cloud has at that moment and 34
how many were expected, how the on-progress deployment is going, and health checks. Additional 35
Deployment Telemetry metrics like CPU, network, and memory usage can also be collected. This will be 36
performed through the O2dms interface. 37
• Infrastructure Telemetry to monitor the health of the O-Cloud Infrastructure components. Network 38
Operations are interested in discovering if all the components in the O-Cloud Infrastructure are working 39
properly and at what capacity, how many deployments are running on each node, and the resource utilization 40
of the O-Cloud Infrastructure. This will be perofmed through the O2ims interface. 41
 42
The SMO shall be able to collect and correlate telemetries to aggregate problems to a root cause.  43
 44
The O-Cloud shall be able to report telemetries and make all Configuration Data and any external changes to it 45
available to the SMO. 46
 47
2.3.4 SERV#04 O-Cloud provisioning service 48
 49
O-Cloud Provisioning is the allocation of O-Cloud’s resources and services to an O-RAN Cloudified Network Function. 50
This is one of the key functionalities of the O-Cloud, relating to how an O-RAN Cloudified Network Function procures 51
O-Cloud services and resources. O-Cloud Provisioning shall provide: 52
• Create/Read/Update/Delete rules for Affinity, Anti-Affinity, and Quorum Diversity 53
• Query of O-Cloud Capacity & Availability 54
 55

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 15

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
2.3.5 SERV#05 O-Cloud software management service 1
 2
Software management will manage the O-Cloud software. The software management should be a priority as without 3
proper management unnecessary risks may be taken. The software management ensures security, cost management and 4
software support. There are many benefits to software management, of which the main benefits are: 5
• Prevents unauthorized software from being installed  6
• Maintains a catalog of authorized software and its versions 7
• Provides visibility into what software and version is being used 8
• Provides a better view of which software products and versions are vendor supported 9
 10
In O-RAN from an O-Cloud perspective there are two types of software which needs to be managed on the O2 11
Interface: 12
• The O-Cloud Infrastructure Software 13
• The O-RAN Cloudified Network Function Software is the software implementation of O-RAN NFs which can 14
run over the O-Cloud 15
2.3.6 SERV#06 O-Cloud fault management service 16
 17
It is related to IMS & DMS fault management. There are three types of fault notifications originate from O-Cloud and 18
collected by SMO through O1, O2dms and O2ims. 19
• Fault notifications originate from the O-cloud infrastructure when a condition occurs within IMS on an O-20
Cloud resource. An event is issued towards the SMO for analysis. The SMO can issue a specific fault query 21
towards to IMS related to the O-Cloud resources and resource pool through O2ims. 22
• DMS resource faults are associated with a workload. The SMO can issue a specific query related to xApp/NF 23
deployments (e.g. workloads) from the DMS through O2dms. 24
• NFs faults are reported through O1 (application level). 25
 26
Figure 2-2 : Parallel reporting & Alarm correlation [1] 27
 28
It is possible that multiple resources can associate with a workload, whereby one fault might trigger a fault notification 29
on IMS, DMS and O1. 30
For example, it is conceivable that a O-DU application might report a fault on O1, and a related physical server 31
allocated to a workload of a O-DU would raise a DMS fault which might also have an infrastructure fault raised on 32
IMS. 33
For example, the SMO may receive a fault with a root cause of a network issue among the O-Cloud resources which 34
manifests itself in a deployment and application fault as well. Thus, the SMO might receive three notifications over 35
O2ims, O2dms and O1. It might correlate these faults to a common root cause.  36
Note: Faults issued by the O-Cloud could be stored at the O-Cloud resource for a configured amount of time. 37
2.3.7 SERV#07 O-Cloud performance service 38
 39
The purpose of performance is to report operational information related to O -cloud resources. Typically, performance 40
information allows an operator or administrator of the O-cloud a sense of how well the system is operating. It is distinct 41

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 16

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
from faults in that it is not about failures in the system but about how well the overall system is performing. Though, 1
faults or alarms may negatively impact performance of the O-Cloud which might be observable in performance 2
measurements. 3
Performance measurements are typically captured periodically through time. They are collected and stored at regular 4
intervals by the system in order to gauge the performance of a system over a period of time. This allows for analytical 5
operations to be performed on the collected data and statistics to be built over time. This can tell an operator or system 6
analyst whether they have sufficient capacity in a network based on the demands of the network. This can be vital for 7
making business operational decisions such as scaling a network. 8

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 17

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
3 Cloud deployment scenarios 1
3.1 Main actors 2
1. Operator 3
2. CSP (Cloud Service Provider) 4
3. Vendors 5
4. Third parties (e.g. service providers, verticals) 6
3.2 Cloud service models 7
Different levels of abstraction constitute the platform of the cloud architecture. These abstractions are grouped into the 8
different service levels, depending on what resources are offered as a service for a given  abstraction level. According to 9
NIST SP 800-145 the three standard cloud service models are Platform as a Service (PaaS), Software as a Service 10
(SaaS), and Infrastructure as a Service (IaaS). 11
3.2.1 Infrastructure as a Service (IaaS) 12
The capability provided to the Operator is to provision processing, storage, networks, and other fundamental computing 13
resources where the Operators or Vendors are able to deploy and run arbitrary software, which can include Host OS 14
(Operator or Vendor), virtualization platforms (Operator or Vendor) and VNFs/CNFs (Operator). Operators and 15
Vendors do not manage or control the underlying cloud infrastructure but have control over Host OS (Operator or 16
Vendor), virtualization platforms (Operator or Vendor) and VNFs/CNFs (Operator). 17
 18
 19
Figure 3-1 : IaaS cloud service model 20
 21
3.2.2 Platform as a Service (PaaS) 22
The capability provided to the Operator is to deploy onto the cloud infrastructure VNFs/CNFs created using 23
programming created using programming languages, libraries, services, and tools supported by the cloud provider. The 24
Operator does not manage or control the underlying cloud infrastructure including network, servers, operating systems, 25
or storage, but has control over the deployed VNFs/CNFs and possibly configuration settings for the application-hosting 26
environment. PaaS provides this platform from the cloud, hence allowing operators to develop and run VNFs/CNFs 27
without the overhead cost (CAPEX) of building and maintaining separate platforms.  28
 29

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 18

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
 1
Figure 3-2 : PaaS cloud service model 2
3.2.3 Software as a Service (SaaS) 3
SaaS as defined by NIST is the capability provided to the Cloud Consumer to use the Cloud Provider’s applications 4
running on a cloud infrastructure. Applications are accessible through web browser or program interface. The operator 5
does not manage or control the underlying cloud infrastructure including network, servers, operating systems, storage, 6
or even Applications. 7
 8
Figure 3-3 : SaaS cloud service model 9
 10
This service model introduces risk for the Operator, acting as the Cloud Consumer, due to shared resources, reduced 11
control, lack of transparency for data security, secure access configuration, limited visibility to logging at lower layers, 12
malicious insiders, regulatory drift, and lack of due diligence. It is not expected that 5G operators will deploy with the 13
SaaS service model. 14
 15
The Cloud Provider may offer 5G private networks directly to its customers in a SaaS service model.  In this service 16
model the Cloud Provider’s customer is the Cloud Consumer, which has responsibility for securing its data and access 17
to the applications.  18
3.3 Cloud deployment types 19
In NIST SP 800-145, cloud deployment models describe how the cloud is operated and who has access to the cloud 20
service resources. The four deployment models are defined in NIST SP 800-145 as follows:  21
3.3.1 Private cloud 22
A private cloud gives a single Operator the exclusive access to and usage of the cloud service and related infrastructure 23
and computational resources. It may be managed either by the Operator or by a third party Cloud Provider and may be 24
hosted on the Operator’s premises (i.e., on-site private clouds) or outsourced to a hosting company (i.e., outsourced 25
private clouds). The following figures present an on-site private cloud and an outsourced private cloud, respectively. 26
 27

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 19

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
 1
Figure 3-4 : On site private cloud 2
 3
 4
 5
Figure 3-5 : Outsourced private cloud 6
 7
On site private cloud 8
Cloud type Cloud model Hardware Host OS Container Engine or
Hypervisor VNFs/CNFs
On-site private SaaS On-
Premise Operator Operator Operator Operator
On-site private IaaS Operator,
CSP CSP, Operator Operator, Vendors Operator
On-site private PaaS Operator,
CSP CSP, Operator CSP, Operator Operator
 9
Outsourced private cloud 10
Cloud type Cloud model Hardware Host OS Container Engine or
Hypervisor VNFs/CNFs
Outsourced private SaaS On-
Premise NA NA NA NA
Outsourced private IaaS Operator,
CSP CSP, Operator Operator, Vendors Operator
Outsourced private PaaS Operator,
CSP CSP, Operator CSP, Operator Operator
 11
3.3.2 Community Cloud 12
A community cloud serves a group of Operators that have shared concerns such as mission objectives, security, privacy 13
and compliance policy, rather than serving a single Operator (e.g., a private cloud). Similar to private clouds, a 14

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 20

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
community cloud may be managed by the Operators or by a third party Cloud Provider and may be implemented on the 1
Operator’s premise (i.e., on-site community cloud) or outsourced to a hosting company (i.e., outsourced community 2
cloud). Figure 3-7 depicts an on-site community cloud comprised of a number of participant Operators. An Operator 3
can access the local cloud resources, and also the resources of other Operators through the connections between the 4
associated Operators. Figure 3-8 shows an outsourced community cloud, where the server side is outsourced to a 5
hosting company. In this case, an outsourced community cloud builds its infrastructure off premise, and serves a set of 6
Operators that request and consume cloud services. 7
 8
Figure 3-6 : On site community cloud 9
 10
 11
Figure 3-7 : Outsourced community cloud 12
 13
On-site Community Cloud  14
Cloud type Cloud model Hardware Host OS Container Engine or
Hypervisor VNFs/CNFs
On-site Community Cloud On-Premise Operators Operators Operators Operators
On-site Community Cloud IaaS CSP,
Operators
CSP, Operators,
Vendors CSP, Operators, Vendors Operators
On-site Community Cloud PaaS CSP,
Operators
CSP, Operators,
Vendors CSP, Operators, Vendors Operators
 15
Outsourced community cloud 16
Cloud type Cloud model Hardware Host OS Container Engine or
Hypervisor VNFs/CNFs
Outsourced community On-Premise NA NA NA NA

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 21

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
Outsourced community IaaS CSP CSP, Operators,
Vendors CSP, Operators, Vendors Operators
Outsourced community PaaS CSP CSP, Operators,
Vendors CSP, Operators, Vendors Operators
 1
3.3.3 Public Cloud 2
A public cloud is one in which the cloud infrastructure and computing resources are made available to the general 3
public over a public network. A public cloud is owned by an organization providing cloud services, and serves a diverse 4
pool of clients (e.g. Operators, Third parties service providers).  5
 6
Figure 3-9 presents a simple view of a public cloud and its actors. 7
 8
 9
Figure 3-8 : Public cloud 10
 11
Cloud type Cloud model Hardware Host OS Container Engine or
Hypervisor VNFs/CNFs
Public On-Premise NA NA NA NA
Public IaaS NA NA NA Operators
Public PaaS CSP CSP CSP Operators
 12
3.3.4 Hybrid Cloud 13
A hybrid cloud is a composition of two or more clouds (on-site private, on-site community, off-site private, off-site 14
community or public) that remain as distinct entities but are bound together by standardized or proprietary technology 15
that enables data and application portability. Figure 7 presents a simple view of a hybrid cloud that could be built with a 16
set of clouds in the five deployment model variants. 17
The idea is to combine the benefits of multiple deployment models. The deployment in hybrid clouds could be either a 18
combination of private, public or community clouds. One of the popular use cases of hybrid clouds is in enhancing 19
security and privacy on the cloud without incurring the overhead costs (CAPEX) of building a private cloud. In this 20
case, non-critical resources like test workloads can be hosted in the public cloud, while critical resources like user data 21
and workloads are hosted internally. 22
 23

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 22

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
 1
 2
Figure 3-9 : Hybrid cloud 3
 4
 5
 6
 7
 8
 9
 10
 11
  12
 13

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License Agreement in Annex ZZZ
Page 23
O-RAN.SFG.O-CLOUD-
Security-TR-v01.00
3.4 High-Level risk assessment 1
The following table illustrates the high-level security risk assessment of the cloud deployment models (Private, Community, Public and Hyb rid). Colors red, yellow, and green 2
are used on the security risk assessment to indicate high, medium, and low levels of risk. The Cloud Consumer (operator) is accountable for the security posture of the 3
deployment for all cloud deployment models [44]. 4
 5
Risks Private Cloud Community Cloud Public Cloud Hybrid Cloud
Regulatory
Compliance: Risk of
non-compliance with
regulations on data
ownership, geographic
location and privacy.
Regulatory drift.

Data security and
regulatory risk can be
associated with loss,
leakage, or
unavailability of data.
This can cause business
interruption, loss of
revenue, loss of
reputation, or regulatory
incompliance (e.g.
GDPR, HIPAA).

The Cloud Consumer
(operator) is
accountable for data,
regulatory compliance,
and configuration of
security controls.
Low Risk:  Similar to traditional computing, as operators
have better control and understanding on how various
government rules, laws, and regulations apply to them.  The
Cloud Consumer (operator) has control of data and regulatory
compliance.
Moderate Risk: Cloud Consumer (operator) has
better control and understanding on how various
government rules, laws, and regulations apply to
them.  Data leakage or data access risks due to
multitenancy/shared infrastructure between different
operators.
High Risk: Lack of flexibility over
data protections mechanisms, such as
encryption and implementation of
specific controls by data type.
Different operators or service
providers might have different
encryption and control requirements,
and a public cloud provider may not
be able to customize their
infrastructure or provide customers
the control over encryption keys.

In some situations, it may be
determined that a Cloud Service
Provider's cybersecurity tools,
processes and methods are
insufficient for protecting highly
sensitive data.  The Cloud Consumer
(operator) is responsible for the
security configuration of CSP
provided applications, tools and
services.

The Cloud Consumer (operator) must
practice due diligence to assess the
regulatory compliance of the Cloud
Service Provider's environment.
Moderate Risk: Cloud
Consumer (operator) has
better control and
understanding on how
various government
rules, laws, and
regulations apply to
them.

Administrators have
more control and
flexibility when
implementing security.
The Cloud Consumer
can architect the Hybrid
Cloud deployment to
ensure regulatory
compliance of most
sensitive data, while less
sensitive data is
accessed, stored, and
processed in the Public
Cloud.

The Cloud Consumer
(operator) must practice
due diligence to assess
the regulatory
compliance of the Cloud
Service Provider's
environment.
Multi-Tenancy: Risk
due to Multi-Tenancy
with shared resources.
Risks include data
leakage, VM Escape,
Host Escape, and
Hyperjacking.
Low Risk: Private Networks avoid shared resources.
High Risk: Data leakage or access risks due to
multitenancy/shared resources for multiple Cloud
Consumers (operators) that may be competitors.
Cloud Consumer (operator) must ensure security
configurations to protect access to network functions,
confidentiality and integrity of data in motion, and
confidentiality, integrity, and access controls for data
at rest.
High Risk: Data leakage or access
risks due to multitenancy/shared
resources.  Cloud Consumer
(operator) must ensure security
configurations to protect access to
network functions, confidentiality
and integrity of data in motion, and
confidentiality, integrity, and access
controls for data at rest.
High Risk: Data leakage
or access risks due to
multitenancy/shared
infrastructure.  Cloud
Consumer (operator)
must ensure security
configurations to protect
access to network
functions, confidentiality
and integrity of data in
motion, and

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License Agreement in Annex ZZZ
Page 24

O-RAN.SFG.O-CLOUD-
Security-TR-v01.00
O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
confidentiality, integrity,
and access controls for
data at rest.
Third-Party
Administration:
Operational risk can be
associated with O-RAN
network services, lack
of control, visibility,
etc.
Low Risk: With private cloud, the operator gains full control
and visibility over its cybersecurity posture and can customize
it to fit its specific needs.

Operator has complete visibility, monitoring and control,
analyze logs, alerts and other data down to the packet level.
Moderate Risk:  Security administrators may deal
with differing methods and tools to monitor and act
on threats depending on where vulnerable resources
reside.

Lack of customized security and service level for
different ORAN network services, which might
require the operator to choose a proximate acceptable
security and service level, including those related to
availability and disaster recovery.
High Risk: Lack of customized
security and service level for different
ORAN network services, which
might require the operator to choose a
compensating security control and
security baseline.

The underlying infrastructure is not
managed by the operator, security
information may be not accessible.

Reduced control on critical network
services can impact availability and
disaster recovery.  Disaster Recovery
with a second CSP, which may not
have the same security posture due to
use of different security tools and
configurations.
High Risk:  Varying
security tools and
configurations may not
prevent a consistent
security baseline across
the Hybrid Cloud
deployment.  The Cloud
Consumer may have
reduced visibility with
the CSP controlled part
of the service.

Disaster Recovery
should be provided with
a second CSP, which
may not have the same
security posture due to
use of different security
tools and configurations.

Security roles and
responsibilities must be
clearly defined and
assigned to the Cloud
Consumer (operator) and
Cloud Service Provider
(CSP).   The Cloud
Consumer (operator)
must practice due
diligence to ensure a
consistent security
posture across the
Hybrid Cloud
deployment.

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License Agreement in Annex ZZZ
Page 25

O-RAN.SFG.O-CLOUD-
Security-TR-v01.00
O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
Technology Evolution:
Technology risk can be
associated with
constantly evolving
technologies and lack of
standardization in how
they integrate or
interoperate.
Technology risks could
lead to costly
rearchitecture efforts for
adoption or integration
with new technology.
High Risk: A constantly evolving technology landscape that
might require the operator to upgrade or rearchitect its
computing resources and retrain its technology support staff.

A potential for human error due to the number of configurable
points and frequency of deployments.

Lack of qualified talent.
Moderate Risk: Operators share a common set of
security tools, for which each is responsible for
properly configuring the security of its tenancy.

Operators can share cloud complexity to manage
constantly evolving technology landscape that might
require operators to upgrade or rearchitect its
computing resources and retrain its technology
support staff.
Low Risk: Larger CSPs often invest
heavily in top-end cybersecurity
tools, as well as staff who are highly
knowledgeable in their field. This
makes offloading cybersecurity tools
and tasks from in-house to a third
party highly appealing.

Operators can transfer cloud
complexity to the CSP, which already
has the necessary cloud expertise,
infrastructure and systems. For
example, faster time-to-market and
improved operations efficiency are
achieved by taking advantage of
CSP-trained talent and their existing
CI/CD DevOps, automation,
orchestration and analytics
capabilities. Operators can then focus
on service differentiation, not the
underlying cloud platforms.
Moderate Risk: Hybrid
Cloud deployments
provide flexible
management of legacy
and proprietary
applications while
enabling use of
technologies associated
with cloud-based
services and
applications.

A potential for human
error due to the number
of configurable points
and frequency of
deployments.  The
operator is responsible
for properly configuring
the security across the
Hybrid Cloud.  The
Cloud Consumer
(operator) must practice
due diligence to ensure a
consistent security
posture across the
Hybrid Cloud
deployment.
Financial costs &
operation
High Risk: Operating private clouds is often a more
expensive endeavor than public cloud options. Businesses pay
a premium for granular cloud control and visibility.

Designing and maintaining cybersecurity tools inside private
clouds dramatically increase management responsibilities.

Lack of Operator-trained administrators.
Moderate Risk: Designing and maintaining
cybersecurity tools inside community clouds increase
management responsibilities.

Lack of Operator-trained administrators.

Operators can share financial cost and the operation
of community cloud.
Low Risk: Operating public clouds is
often a less expensive endeavor than
private and community cloud options.

Operators can transfer cloud
operation to the CSP, which already
has the necessary cloud expertise,
infrastructure, and systems.
Moderate Risk:
Designing and
maintaining
cybersecurity tools
inside hybrid clouds
increase management
responsibilities.

Operators can transfer
part of the cloud
operation to the CSP,
which already has the
necessary cloud
expertise, infrastructure,
and systems.
 1
Risk levels: High, Moderate, Low 2
 3
Table 3-1 : High level security risk assessment of cloud deployment models4

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 26

4 Roles and responsibilities 1
The list of users likely to interact with the O-CLOUD as well as their roles are presented in the table below. The last 2
column distinguishes between stakeholders acting:  3
• Under the direct responsibility of an operator or  4
• Under the responsibility of a third party (e.g. equipment supplier) acting through a contract with the operator.  5
 6
The table shows many roles in which the operator and cloud service provider are both stakeholders.   This highlights the 7
need to have: 8
• Clearly defined and agreed upon roles and responsibilities in the cloud service agreement.    9
• Separation of Duties enforced by the cloud service provider to limit insider threats. 10
• Principles of least privilege access control configured and enforced by the operator.  11
 12
Roles Responsibilities Stakeholders
O-Cloud Planner  Operator planning O-Cloud instance. Operator, CSP
O-Cloud Installation Manager Operator designing each O-Cloud instance.
Cloud Installation Manager issues a “service request” to the SMO to update
its Inventory, i.e., indicate that a new O-Cloud is to be inventoried. The
Cloud Installation Project Manager also registers to the SMO the basic
software for the O-Cloud.
Operator, CSP
Network Function Install
Manager
Operator designing each Network Function instance. Operator,
Vendor
O-Cloud Installer  Operator installing O-Cloud Node. He notifies SMO of the new O-Cloud
Build
Note: Cloud Installer must provide SMO with information to connect with
the new O-Cloud Build, including the target O-Cloud Node in the O-Cloud
and identity of the basic software for O-Cloud to be loaded on the O-Cloud
Operator, CSP
O-Cloud Maintainer  Operator that operates and manages O-Cloud Nodes Operator
Security administrator
They manage component security configuration: configuration of access
rights, password and cryptographic key storage system, IPSec parameters,
configuring remote access systems, etc.
They hold the root password and the secret encryption root key.
Operator
System administrator They manage “system” components (e.g. back-up, update, configuring
system logs, etc.). Operator
O-RAN NF Administrator
They can manage and configure one or more VNFs/CNFs (e.g. Near RT
RIC, O-CU, O-DU). They can perform the daily operational tasks (notably
provisioning) of NFs.
Operator
IMS Administrator
They manage IMS activities. They can perform the daily operational tasks
and configure the IMS. They control functions providing access to the IMS.
They are responsible for VNFs/CNFs hardware configuration.
Operator, CSP
DMS Administrator
They manage DMS activities. They can perform the daily operational tasks
(notably provisioning) and configure the DMS. They control functions
providing access to DMS.
Operator CSP
Virtualization layer
administrator
(Hypervisor/Container Engine)
They manage the virtualization/containerization layer (Hypervisor/Container
Engine). They can perform the daily operational tasks (notably provisioning)
and configuration of the virtualization layer. They control functions
providing access to this layer.
Operator, CSP
Compute nodes administrator
(physical servers)
They manage compute nodes (physical servers) They can access the node’s
graphic console, start, stop, restart the node. They can activate/deactivate the
node network interfaces and check its status. They manage local storage in
compute nodes.
Operator, CSP
Storage administrator They manage shared storage (e.g. images repository) Operator, CSP
Maintainer (equipment
supplier or third party)
They can remotely (e.g. via VPN) or locally access equipment to update,
configure, remove or add network applications. They have access to
compute node configuration interfaces to update firmware and configure
BIOS, CPU, MMU, etc.
The maintainer works on the O-Cloud platform under the control of the
operator who (e.g. via IAM: Identity Access Management) creates specific
accounts for a limited period.
Vendor, Third
Party
Internal validation laboratory They are responsible for vulnerability scanning, testing, qualifications,
security/compliance of network applications before their deployment.
Operator,
Vendor, CSP
Security Incident Response
Team
Setup a vulnerability management process of monitoring, identifying,
evaluating, treating, and reporting on security vulnerabilities and incidents.
Operator,
Vendor, CSP

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 27

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04

Maintenance of the O-Cloud components that includes monitoring for use of
open source software with known vulnerabilities and patching for
vulnerabilities.

Provide a process for users, including security researchers, to submit bug
reports (e.g., using an issue tracker or a mailing list).
Table 4-1 : List of Users 1
 2

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 28

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
5 Security Problem Definition 1
Before analyzing the way to protect the O-Cloud, it is important to identify the threats affecting the different O-Cloud 2
components and data. 3
For this identification of threats, it is essential first to know the critical assets, consisting of anything that has value for 4
within O-Cloud and needs to be protected, and secondly to identify the threat agents, the entities that can adversely act 5
on the asset. 6
 7
5.1 Assets 8
The services offered by the O-Cloud must be available and non-corrupted and must protect the assets highlighted in the 9
following cartography. 10
 11
Figure 5-1 : Cartography of assets 12
 13
For each asset, a description, the owner, and its security protection properties are given in the table below.14

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License Agreement in Annex ZZZ
Page 29
O-RAN.SFG.O-CLOUD-
Security-TR-v01.00
Asset
ID Asset Tilte Asset Description Compo
nent Interface
When Protection Level
At rest In transit Confidentiality Integrit
y Availability Replay Authentic
ity
A-
OC-1
O-Cloud Inventory
information of
NFVI hardware
resources and
software resources
It consists of
• The Physical Infrastructure (O-Cloud Node Identifier, Pool Identifier,
Pool Location Identifier, and Use Identifier) used to create the O -
Cloud
• The logical Clouds which it provides as interfaces for deployments,
and the inventory of deployments (deployment ID and descriptor) on
the cloud
• O-Cloud ID, IP address, IMS address, the IP address endpoint or url
of the SMO and any necessary security keys or passwords for
communication using O2
• DMS capabilities
• O-Cloud (IMS): List of All Resource Pools in the O -Cloud, Attributes
of a specific O-Cloud, List of all resources of an O-Cloud Pool,
Attributes of each O-Cloud Resource, List of all DMS
• O-Cloud (DMS): List of Locations Supported For a given location the
Capabilities supported (e.g. Descriptor types, Technology types,
Accelerator types), For a given location the Capacity of the location,
For a given location the Availability of the location
SMO,
O-
CLOUD
O2, O-
CLOUD
internal
interfaces
x x x x x x x
A-
OC-2
Functional
telemetry:
deployment,
infrastructure
It includes:
• Telemetry information of O-Cloud deployments in the network for
analyzing the O-Cloud’s state and health, and for delivering on
service monitoring goals. It consists of fault, performance and
configuration data.
• Deployment Telemetry to monitor the number of deployment
instances an O-Cloud has at that moment and how many were
expected, how the on-progress deployment is going, and health
checks.  Additional Deployment Telemetry metrics like CPU,
network, and memory usage can also be collected.
• Infrastructure Telemetry to monitor the health of the O-Cloud
Infrastructure components. Network Operations are interested in
discovering if all the components in the O-Cloud Infrastructure are
working properly and at what capacity, how many deployments are
running on each node, and the resource utilization of the O -Cloud
Infrastructure.
SMO,
O-
CLOUD
O2, O-
CLOUD
internal
interfaces
x x x x x x x
A-
OC-3
O-Cloud
Provisioning
information
O-Cloud Provisioning information (Affinity, Anti-Affinity, Quorum
Diversity Rules, capabilities, capacity and availability)
SMO,
O-
CLOUD
O2, O-
CLOUD
 x x x  x x

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License Agreement in Annex ZZZ
Page 30

O-RAN.SFG.O-CLOUD-
Security-TR-v01.00
O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
Asset
ID Asset Tilte Asset Description Compo
nent Interface
When Protection Level
At rest In transit Confidentiality Integrit
y Availability Replay Authentic
ity
internal
interfaces
A-
OC-4
O-Cloud software
management
information
O-Cloud software management information: catalog of authorized software
and its version, list of authorized VNF/CNF, VNF/CNF description files
SMO,
O-
CLOUD
O2, O-
CLOUD
internal
interfaces
 x x x x x x
A-
OC-5
O-RAN Cloudified
Network Function
Package: O-RAN Cloudified Network Function Software Image including
the underlying software executable image, image properties/metadata such
as descriptors, image signature(s), LCM scripts, data files, SoftwareImageId,
Vendor, and version, secrets, configuration files.
Application data: Subscriber data, Policy data, UE context, etc.
NF location, time clock
NF instance: Application software, guest OS, host OS, Libs, instance
identity, crypto keys, namespaces, virtual resources instance states, physical
hardware, etc.
O-
CLOUD - x  x x x
A-
OC-6 Certificates
X.509 certificates in O-RAN network such as those used for SMO, O -CU-
CP, O-CU-UP, O-DU, O-RU, Near-RT RIC, Non-RT RIC, O-CLOUD,
NetCONF (O1, Fronthaul)
All
O2, O-
CLOUD
internal
interfaces
x x  x x  x
A-
OC-7 Private keys
Security private keys in O-RAN network such as those used by SMO, O-
CU-CP, O-CU-UP, O-DU, O-RU, Near-RT RIC, Non-RT RIC, O-CLOUD,
NetCONF (O1, Fronthaul) for authentication, encryption, signing (e.g. for
TLS and similar protocols, image signing)
All
O2, O-
CLOUD
internal
interfaces
x  x x x
A-
OC-8 Credentials
Credentials (Administrators): account information and passwords on SMO,
O-CU-CP, O-CU-UP, O-DU, O-RU, Near-RT RIC, Non-RT RIC, O-Cloud
used in O-RAN network
All - x  x x x
A-
OC-9
Software
components at
runtime and their
associated data
O-Cloud components associated and configuration data, such as:
• Software version information, identifier, IP address, port number,
network layer parameters, time of request, previous behavior, etc.
• The security related parameters (such audit records, lists of algorithms
which are allowed for usage, file management, hash values, etc.).
All
O2, O-
CLOUD
internal
interfaces
x  x x x
A-
OC-
10
Security event logs Security event log files generated by O-Cloud components All - x x x x x x x

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License Agreement in Annex ZZZ
Page 31

O-RAN.SFG.O-CLOUD-
Security-TR-v01.00
O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
Asset
ID Asset Tilte Asset Description Compo
nent Interface
When Protection Level
At rest In transit Confidentiality Integrit
y Availability Replay Authentic
ity
A-
OC-
11
Security telemetry Security telemetry from the NFV system for detecting threats and anomalies  All
O2, O-
CLOUD
internal
interfaces
x x x x x x x
A-
OC-
12
Other Crypto
materials Cryptographic keys used during secure boot, for encryption/decryption, etc.  All - x  x x x
 Table 5-1 : List of Assets 1
 2

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 32

5.2 Threats 1
The complexity and the extension of attack surface of a virtualized environment increase the difficulty to list, in an 2
exhaustive manner, the security threats to which the O-Cloud assets are exposed. For this activity of threat analysis, 3
some reports have been used to help the identification of a largest number  of these threats: 4
• CISA/NSA - Kubernetes Hardening Guidance [3] 5
• MITRE ATT&CK containers matrix [4] 6
• ENISA Threat Landscape for 5G Networks: Threat assessment for the fifth generation of mobile 7
telecommunications networks (5G) [5] 8
• ETSI Secure End-to-End VNF and NS management specification Secure End-to-End VNF and NS management 9
specification [6] 10
 11
The following table is the template used to present the threat characteristics: 12
 13
Threat ID Unique identification per Threat (e.g. T-XX-01)
Threat title Title of the threat
Threat description Description of the Threat
Threat type Spoofing
Tampering
Repudiation
Information disclosure
Denial of Service
Elevation of Privilege
Vulnerabilities What vulnerabilities can the threat exploits?
Impact type Authenticity
Integrity
Non-repudiability
Confidentiality
Availability
Authorization
Threatened Assets Impacted Asset(s) (Data & Component)
Affected Services What services (from section 2.3) could be affected by this Threat
Potential mitigations Mitigation measures to address the threat
 14
5.2.1 Threat and impact types 15
For identifying threats, we are using STRIDE: 16
1. S - Spoofing identity. An application or program can masquerade as another to gain advantages not typically 17
allowed for that program. 18
2. T - Tampering with data. This involves the malicious modification of data, including making unauthorized 19
changes to a database and alteration of data as it flows between computers. 20
3. R - Repudiation. A user or program refuses the authenticity of a good or reasonable command or action.  21
4. I - Information disclosure. This involves the exposure of information to individuals with unauthorized access 22
to it. For example, users gain the ability to read a file that they normally would not have been granted access 23
to, or an intruder can read data in transit between computers. 24
5. D - Denial of service. These attacks deny service to valid users, such as making a website unavailable or 25
unusable by flooding it with illegitimate requests to keep legitimate users without access. 26
6. E - Elevation of privileges. An unauthorized user gains privileged rights to access previously no granted to 27
compromise or destroy the system, such as a change in membership. 28
 29
Threat types Impact types
Spoofing Authenticity
Tampering Integrity
Repudiation Non-repudiability
Information disclosure Confidentiality
Denial of Service Availability
Elevation of Privilege Authorization
 30
5.2.2 Attack surface 31
An attack surface of a system refers to the set of various entry points that can be exploited. The various components that 32
compose the attack surface of the O-Cloud are depicted in the following figure. They are as follows: 33

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 33

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
1) VNFs/CNFs: O-DU, O-CU, O-RU, Near RT-RIC/xApps 1
2) Images repository with its interface to O-Cloud 2
3) Virtualization layer: Hypervisor and/or Container Engine, Host OS 3
4) Hardware resources including compute, storage, network, and hardware accelerator manager 4
5) O-Cloud API 5
6) O2dms and O2ims interfaces 6
7) NFO and Federated O-Cloud O&M (FOCOM) within the SMO 7
8) AAL 8
 9
The attack vectors for exploiting vulnerabilities of these components are discussed in detail in the threat events sections. 10
 11
 12
Figure 5-2 : Attack vectors 13
 14
5.2.3 Vulnerabilities 15
 16
The following figure highlights the main vulnerabilities that may emerge within  the attack vectors ①, ②, ③ (see 17
Figure 5-2).  18
 19

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 34

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
 1
Figure 5-3 : Vulnerabilities within ①, ②, ③ 2
 3
The illustration of vulnerabilities within the other attack vectors will be provided in a future version. 4
5.2.4 Threat events 5
 6
Threats with the attack vectors ④, ⑥, ⑦ ⑧ will be developed in a future version. 7
5.2.4.1 Generic Threats 8
 9
Threat ID T-GEN-01
Threat title Software flaw attack
Threat description
Code of host OS, Hypervisor/Container Engine and VNF/CNF can include flaws that an attacker can exploit if they are
present.
As O-RAN software components relies on opensource software, opensource libraries, 3rd party components.
Vulnerability in any of these software components likely to allow attacker to exploit O-CLOUD environment. This
could lead attacker to carry out to malicious activities, such as:
• Compromise of the underlying VM/Container
• Exploit host access via Escape to Host
• Take advantage of weak identity and access management policies to attempt to elevate privileges
• Execute adversary-controlled code
• Enable an adversary to move from a virtualized environment, such as within a virtual machine or container, onto
the underlying host
Threat type Spoofing, Tampering, Information disclosure, Elevation of Privilege
Vulnerabilities Vulnerable code exploits, Design Weakness
Impact type Authenticity, Integrity, Confidentiality, Authorization
Threatened Assets Host OS, Hypervisor/Container Engine and VNFs/CNFs (Near RT RIC, O-CU, O-DU)
Affected Services All services
Potential mitigations
REC-IMGP Image protection
REC-VHPM Vulnerability Handling and Patch Management
REC-SDLC Secure Development Lifecycle
REC-LOG Logging, Monitoring and Alerting
REC-ISO Strong Isolation
REC-AUD Security Audit
 10
Threat ID T-GEN-02
Threat title Malicious access to exposed services using valid accounts
Threat description
Access to valid accounts to use the O-Cloud services is often a requirement, which could be obtained through credential
pharming or by obtaining the credentials from users after compromising the network.
Adversaries may obtain and abuse credentials of existing accounts as a means of gaining initial access, persistence,
privilege escalation, or defense evasion. Compromised credentials may be used to bypass access controls placed on
various resources on O-Cloud.
Compromised credentials may also grant an adversary increased privilege to specific O-Cloud services or access to
restricted areas of the O-Cloud network.
Access may be also gained through an exposed service that doesn’t require authentication. In containerized
environments, this may include an exposed Docker API, Kubernetes API server, kubelet, or web application such as the
Kubernetes dashboard.
Threat type Spoofing, Tampering, Information disclosure, Elevation of Privilege
Vulnerabilities Lack of authentication
Impact type Authenticity, Integrity, Confidentiality, Authorization

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 35

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
Threatened Assets Host OS, Hypervisor/Container Engine and VNFs/CNFs (Near RT RIC, O-CU, O-DU)
Affected Services All services
Potential mitigations
REC-IAM Identity, Authentication, and Access Management
REC-CM Certificate management
REC-LOG Logging, Monitoring and Alerting
REC-NS Network Segmentation & Filter Network Traffic
REC-AUD Security Audit
 1
Threat ID T-GEN-03
Threat title Untrust binding between the different O-Cloud layers
Threat description
One major challenge in virtualized architectures and especially in O-Cloud is to prove that a particular VM/Container
runs on top of a specific Hypervisor/Container Engine. More specifically, it is necessary to assure that a trusted
VM/Container is executed on a particular trusted Hypervisor/Container Engine, whereas the Hypervisor/Container
Engine's trust state relies on an attestation that considers the entire corresponding hard and software stack. More
precisely, this includes all hardware chips, firmware, OS and Hypervisor/Container Engine components that are relevant
for the Hypervisor/Container Engine's trust state determination.
If it is not possible to establish a correlation between VM/Container and Hypervisor/Container Engine, an attacker is
able to make use of a trusted VM/Container that runs on top of an untrusted Hypervisor/Container Engine and it would
be impossible to detect any interference made by the malicious Hypervisor/Container Engine, e.g. intercepting
communication, replacing strong or using weak cryptographic keys, etc. Similarly, trustworthiness in the service-layer
might only be established if there is a mechanism to determine that only trusted VNFs/CNFs, w.r.t trusted
VM/Container's, are running on specific trusted Hypervisors/Container Engines that are part of the service-
provisioning-chain.
Threat type Tampering, Information disclosure
Vulnerabilities Lack of integrity verification during boot or runtime
Impact type Integrity, Confidentiality
Threatened Assets Host OS, Hypervisor/Container Engine and VNFs/CNFs (Near RT RIC, O-CU, O-DU)
Affected Services All services
Potential mitigations
REC-IMGP Image protection
REC-LOG Logging, Monitoring and Alerting
REC-RA Remote Attestation
REC-SB Secure Boot
REC-SNFLC Security VNF/CNF lifecycle
 2
Threat ID T-GEN-04
Threat title Lack of Authentication & Authorization in interfaces between O-Cloud components
Threat description
O-Cloud deploys CNF applications as containers in a cluster of physical nodes which may be spanned across
geographical locations. Owing to the Service Based Architecture of CNFs, this introduces several service endpoints
communicating across each other over the network (container to container, container to cloud infrastructure component)
and it is difficult to distinguish between a service terminating an external interface and a service exposing only an
internal interface.

Multi-tenant deployments and deployments in public cloud also require the CNF applications to run alongside unknown
entities. In such deployment scenarios, CNF service endpoints with no authentication/weak authentication expose risk
of attack that can impact the availability of service and the CNF.

Lack of proper authentication in interfaces exposed by CNF services, introduces threats of lateral movement where a
compromised container/rogue container:
• Can compromise the availability of internal service by bringing down the internal service and perform lateral
movement of attack by exploiting the availability of other such services
• Can compromise the confidentiality of the internal service by extracting critical application data
Threat type Information disclosure, Denial of Service
Vulnerabilities Lack of authentication, Insecure interfaces
Impact type Availability, Confidentiality
Threatened Assets Host OS, Hypervisor/Container Engine and VNFs/CNFs (Near RT RIC, O-CU, O-DU)
Affected Services All services
Potential mitigations REC-IAM Identity, Authentication, and Access Management
REC-CM Certificate management
 3
5.2.4.2 Threats concerning VMs/Containers 4
 5
Threat ID T-VM-C-01
Threat title Abuse of a privileged VM/Container
Threat description
It’s possible to run VMs/Containers with unintended configurations. Such misconfigurations can help the adversaries to
compromise even strongest of VM/Container isolation measures.

Such misconfigurations scenarios include:
• A VMs/Containers can be configured to have more privileges than what is actually required (e.g. settings that give
it unnecessary, and perhaps unplanned, privileges). For example, an attacker with access to such a container, can
use it to gain higher privileges on host, perform un-authorized operations and get to anything that the host, or any
of the containers running on that host, can reach.
• A VMs/Containers have unintended read/write access to a directory on host filesystem. This could allow an
attacker to perform unauthorized modifications to the contents, create symbolic links to any directories or files not

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 36

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
directly exposed by the hostPath, install SSH keys, read secrets mounted to the host, and take other malicious
actions.
Threat type Spoofing, Tampering, Information disclosure, Denial of Service and Elevation of privilege
Vulnerabilities Misconfiguration or Insecure VM/Container configurations
Impact type Authenticity, Integrity, Confidentiality, Availability and Authorization
Threatened Assets Host OS, Hypervisor/Container Engine and VNFs/CNFs (Near RT RIC, O-CU, O-DU)
Affected Services SERV#01, SERV#03, SERV#04, SERV#05, SERV#06, SERV#07
Potential mitigations
REC-SCONF Security Configuration
REC-IAM Identity, Authentication, and Access Management
REC-CM Certificate management
REC-ISO Strong Isolation
REC-SNFLC Security VNF/CNF lifecycle
REC-NS Network Segmentation & Filter Network Traffic
REC-SS Secure Storage
 1
Threat ID T-VM-C-02
Threat title VM/Container escape attack
Threat description
VNF/CNF deployed on the same physical machine as tenants share the same host kernel and host OS resources. Lack of
strong isolation between the VMs/Containers and the host allows for a potential risk of a rogue VM/Container escaping
the VM/Container confinement and impacting other co-hosted VMs/Containers. In others, an attacker may deploy a
new malicious VM/Container configured without network rules, user limitations, etc. to bypass existing defenses within
O-Cloud infrastructure.

Attacker deploys malicious VM/Container to escapes the host (Hypervisor/Container Engine/Host OS) and reaches the
server’s hardware, then the malicious VM/Container can gain root access to the whole server where it resides. This
gives the malicious VM/Container full control on all the VMs/Containers hosted on the same hacked server. This could
allow an attacker to undermine the confidentiality, integrity and/or availability of VNFs/CNFs resources.

Containers can be deployed by various means, such as via Docker's create and start APIs or via a web application such
as the Kubernetes dashboard or Kubeflow. Adversaries may deploy containers based on retrieved or built malicious
images or from benign images that download and execute malicious payloads at runtime.

When a malicious VM/Container escapes isolation, it can gain full control over the underlying host and cause any of the
below serious threats:
• Attacker would gain the ability to mount attacks on the host or compromise the host functionalities
• Compromise the confidentiality & integrity of co-hosted VMs/Containers and tenants
• Launch DDOS attacks on co-hosted VMs/Containers and host services thereby degrading their performance
• Introduce new vulnerabilities in host to be used for future attacks
• Lack of network segmentation could potentially expose other VMs/Containers in the environment to attack. An
example of this could be reconnaissance, exploitation and subsequent lateral movement to another host within the
cluster.
Threat type Spoofing, Tampering, Information disclosure, Denial of Service and Elevation of privilege
Vulnerabilities Shared tenancy vulnerabilities (multitenant environment), Lack of strong VM/Container isolation, lack of
authentication, Insecure networking, Unrestricted communication between VMs/Containers
Impact type Authenticity, Integrity, Confidentiality, Availability and Authorization
Threatened Assets Host OS, Hypervisor/Container Engine and VNFs/CNFs (Near RT RIC, O-CU, O-DU)
Affected Services SERV#01, SERV#03, SERV#04, SERV#05, SERV#06, SERV#07
Potential mitigations
REC-ISO Strong Isolation
REC-IAM Identity, Authentication, and Access Management
REC-CM Certificate management
REC-NS Network Segmentation & Filter Network Traffic
REC-LOG Logging, Monitoring and Alerting
REC-SCONF Security Configuration
REC-SNFLC Security VNF/CNF lifecycle
REC-SS Secure Storage
 2
 3
Figure 5-4 : Illustration of the VM/Container escape attack 4
 5
Threat ID T-VM-C-03

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 37

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
Threat title VM/Container data theft
Threat description
The VNF/CNF remotely stores sensitive data (e.g. passwords, private keys, subscription data, logs) on the logical
volume that the IMS/DMS allocates to the VNF/CNF. An attacker can retrieve/manipulate these data if they have been
stored in an insecure way (e.g. clear text, unsalted hashes) or a malware is installed on the logical volume that the VIM
allocates to the VNF/CNF.

Container example: Adversaries may attempt to discover containers and other resources that are available locally within
O-Cloud. Other resources may include images, deployments, pods, nodes, and other information such as the status of a
cluster. These resources can be viewed within web applications such as the Kubernetes dashboard or can be queried via
the Docker and Kubernetes APIs. In Docker, logs may leak information about the environment, such as the
environment’s configuration, which services are available, and what cloud provider the victim may be utilizing. The
discovery of these resources may inform an adversary’s next steps in the environment, such as how to perform lateral
movement and which methods to utilize for execution.
Threat type Tampering, Information disclosure
Vulnerabilities Lack of authentication, insecure data storage
Impact type Integrity, Confidentiality
Threatened Assets Images, environment’s configuration, and other information such as the status of a cluster
Affected Services SERV#01, SERV#02
Potential mitigations
REC-IAM Identity, Authentication, and Access Management
REC-CM Certificate management
REC-NS Network Segmentation & Filter Network Traffic
REC-LOG Logging, Monitoring and Alerting
REC-PHY Physical Security Protection
REC-SS Secure Storage
 1
Threat ID T-VM-C-04
Threat title VM/Container migration attacks
Threat description
The attacks that exploit VM/Container migration can be divided into two subcategories based on the target plane:
1. Control Plane Attacks: These attacks target the module that is responsible for handling the migration process on
a server which is called the migration module that is found in the host. By exploiting a bug in the migration
module software, the attacker can hack the server and take full control over the migration module. This gives the
attacker the ability to launch malicious activities including the following:
a. Migration Flooding: The attacker moves all the VMs/Containers that are hosted on the hacked server
to a victim server that does not have enough resource capacity to host all the moved VMs/Containers.
This causes a denial of service for the VNFs/CNFs running in the VMs/Containers of the victim server
as there will not be enough resources to satisfy the demands of all the hosted VMs/Containers leading
into VM/Container performance degradation and VM/Container crashes.
b. False Resource Advertising: The hacked server claims that it has a large resource slack (a large
amount of free resources). This attracts other servers to off-load some of their VMs/Containers to the
hacked server so that the O-Cloud workload gets distributed over the O-Cloud servers. After moving
VMs/Containers from other servers to the hacked server, the attacker can exploit other vulnerabilities
to break into the offloaded VMs/Containers as now these VMs/Containers are placed on a server that is
under the control of the attacker.
2. Data Plane Attacks: These constitute the second type of VM/Container migration attacks and those attacks target
the network links over which the VM/Container is moved from a server to another. Such data plane attacks
include the MitM where an attacker sniffs the packets that are exchanged between the source and destination
servers and reads the migrated memory pages. The attacker can monitor and/or modify the received packets while
continuing to forward them to victim VM/Container resides so that the victim does not detect that any malicious
activity is going on.
Threat type Tampering, Information disclosure, Denial of Service
Vulnerabilities Host misconfiguration, lack of authentication, memory pages copied in clear, vulnerable code exploits
Impact type Integrity, Confidentiality, Availability
Threatened Assets VNFs/CNFs (Near RT RIC, O-CU, O-DU)
Affected Services SERV#03, SERV#04, SERV#05, SERV#06, SERV#07
Potential mitigations
REC-CM Certificate management
REC-NS Network Segmentation & Filter Network Traffic
REC-IAM Identity, Authentication and Access Management
REC-SNFLC Security VNF/CNF lifecycle
REC-LOG Logging, Monitoring and Alerting
REC-RA Remote Attestation
 2

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 38

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
 1
Figure 5-5 : Illustration of the migration flooding attack 2
 3
 4
Figure 5-6 : Illustration of the false resource advertising attack 5
 6
 7
Figure 5-7 : Illustration of the migration MITM attack 8
 9
Threat ID T-VM-C-05
Threat title Changing virtualization resource without authorization
Threat description
IMS/DMS which manage the Virtualization layer is responsible for assigning virtualized resource as requested.

There are several ways to cause a DoS attack for the VNFs/CNFs:

• If IMS/DMS are compromised or the O2 interface is not securely protected, an attacker who compromised the
IMS/DMS or breached the O2 interface can change the virtualized resource used by a VNF/CNF by manipulating
the allocation of virtualized resource. For example, when an instantiated VNF/CNF is running, adversaries having
access to a compromised IMS/DMS or adversaries breaching the insecure O2 interface can misguide the
Virtualization layer to reduce the resource of or delete a VM/Container on which a VNF/CNF is running. This can
result in the reliability, availability or even illegal termination of a VNF/CNF and hence the denial of service.
• Hardware resource configuration and state information (e.g. events) exchange is performed through O2 interface.
If the IMS is compromised or the O2 interface is not securely protected, an attacker who compromised the IMS or
breached the O2 interface can tamper the hardware configuration and state information so that the virtualized
resource supported by the hardware layer becomes unreliable. For example, adversaries having access to a
compromised IMS or adversaries breaching the insecure O2 interface can misguide the O-Cloud platform to
detach a hardware accelerator from a VNF/CNF.

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 39

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
• Adversaries having access to a compromised virtualization layer can change the virtualization resource used by
the instantiated VNF/CNF without authorization,
• A malicious VM/Container deployed for one instance of a VNF/CNF on a host can illegally occupy the resources
of the instantiated VNF/CNF deployed on the same host, resulting in resource limitation of the instantiated
VNF/CNF

In this type of attacks, the extra allocation of resources for the malicious VM/Container comes at the expense of the
other VMs/Containers that share the same server as the malicious VM/Container, where these victim VMs/Containers
get allocated less share of resources than what they should actually obtain, which in turn degrades their performance.
Threat type Denial of Service
Vulnerabilities Insecure O1/O2 interfaces, Lack of authentication/access control on IMS/DMS
Impact type Availability
Threatened Assets Host OS, Hypervisor/Container Engine and VNFs/CNFs (Near RT RIC, O-CU, O-DU)
Affected Services SERV#01
Potential mitigations
REC-LOG Logging, Monitoring and Alerting
REC-CM Certificate management
REC-IAM Identity, Authentication and Access Management
REC-ISO Strong Isolation
REC-PHY Physical Security Protection
REC-AUD Security Audit
 1
 2
Figure 5-8 : Illustration of the Theft-of-Service/DoS Attack 3
 4
Threat ID T-VM-C-06
Threat title Failed or incomplete VNF/CNF termination or releasing of resources
Threat description
A malicious VNF/CNF is instantiated in the O-Cloud infrastructure to access to data not erased from a terminated
VNF/CNF or any VNF/CNF that has released resources. Data could include application data, cryptographic keys...
Abuse of resources allocation in the O-Cloud infrastructure to allocate to a malicious VNF/CNF the virtual resources
released from a terminated VNF/CNF or from a VNF/CNF that has released resources after a move or a scaling process.
Inclusion of concealed software in the O-Cloud infrastructure to prevent the deletion/erasure of data and states of the
VNF/CNF that has been terminated.
Threat type Information disclosure
Vulnerabilities Lack of authentication, misconfigurations (VNF/CNF, Host OS, Hypervisor/Container Engine)
Impact type Confidentiality
Threatened Assets Sensitive data (e.g. passwords, private keys, subscription data, logs), VNFs/CNFs (Near RT RIC, O-CU, O-DU)
software and data
Affected Services No affected services
Potential mitigations
REC-SNFLC Security VNF/CNF lifecycle
REC-LOG Logging, Monitoring and Alerting
REC-SS Secure Storage
REC-SCONF Security Configuration
 5
5.2.4.3 Threats concerning VM/Container images 6
 7
Threat ID T-IMG-01
Threat title VM/Container images tampering
Threat description
An attacker can inject malicious code or tamper the information inside the unprotected image during on boarding. Then
after the instantiation of the VNF/CNF, the tampered code can cause DoS, information stealing, frauds and so on. There
are several attacks categories belonging to this threat. Such attacks include:
• Build machine attacks: If an attacker can modify or influence the way a VM/Container image is built, they could
insert malicious code that will subsequently get run in the production environment.
• Supply chain attacks: Once the VM/Container image is built, it gets stored in a registry, and it gets retrieved or
“pulled” from the registry at the point where it’s going to be run. An attacker who can replace an image or modify
an image between build and deployment could run arbitrary code on your deployment.

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 40

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
Threat type Tampering, Information disclosure
Vulnerabilities Compromised VM/Container images (Build machine attacks, Supply chain attacks) at rest, lack of authentication,
misconfiguration or Insecure VM/Container images configurations
Impact type Integrity, Confidentiality
Threatened Assets VM/Container images
Affected Services SERV#02
Potential mitigations
REC-AUD Security Audit
REC-LOG Logging, Monitoring and Alerting
REC-IMGP Image Protection
REC-VHPM Vulnerability Handling and Patch Management
REC-IAM Identity, Authentication, and Access Management
REC-CM Certificate management
REC-SDLC Secure Development Lifecycle
 1
Threat ID T-IMG-02
Threat title Insecure channels with images repository
Threat description
Images often contain sensitive components like an organization’s proprietary software, and embedded secrets and
administrator credentials. If connections to registries are performed over insecure channels, man-in-the-middle attacks
could intercept network traffic and therefore the contents integrity and confidentiality of images may be compromised.
There is also an increased risk of man-in-the-middle attacks that could intercept network traffic intended for registries
and steal developer or administrator credentials within that traffic. Thus, could be used to provide fraudulent or outdated
images to orchestrators, etc.
Threat type Tampering, Information disclosure
Vulnerabilities Compromised VM/Container images in transit
Impact type Integrity, Confidentiality
Threatened Assets VMs/Containers images
Affected Services SERV#02
Potential mitigations
REC-NS Network Segmentation & Filter Network Traffic
REC-IAM Identity, Authentication, and Access Management
REC-CM Certificate management
REC-IMGP Image Protection
REC-LOG Logging, Monitoring and Alerting
 2
Threat ID T-IMG-03
Threat title Secrets disclosure in VM/Container images
Threat description
There are scenarios which benefit from including configuration and secrets, such as passwords or credentials in
VNFs/CNFs images. For e.g. VMs/Containers require to be able to connect to other VMs/Containers within the
deployment as well as with external entities. All these connections need to be authenticated and secured. One way of
achieving this is to provide the requisite secrets or keys to the VMs/Containers which allow them to authenticate, be
authenticated, secure the communication channel and signature.  A common but in-secure means of providing secrets to
the VMs/Containers is by packaging the secrets or the keys with the image itself. There is the risk that the same can be
extracted, read or manipulated before the VM/Container is deployed and the secret used.

With a long supply chain, VM/Container images are vulnerable to outside scrutiny. With VM/Container images
containing secrets or keys, this becomes a serious threat vector. Adversaries can extract them by obtaining a copy of the
image and they can be potentially shared with third parties for illicit gain.
• Secrets embedded within a VM/Container image can be stolen.
• Secrets embedded within a VM/Container image can be modified

Compromised private keys and algorithms used for image signing due to poor key protection/management/design could
undermine the security of image signing process.
Threat type Spoofing, Tampering, Information disclosure
Vulnerabilities Secret exposure in VNF/CNF images
Impact type Authenticity, Integrity, Confidentiality
Threatened Assets VM/Container images
Affected Services SERV#02
Potential mitigations
REC-AUD Security Audit
REC-IMGP Image Protection
REC-SS Secure Storage
REC-SDLC Secure Development Lifecycle
 3
Threat ID T-IMG-04
Threat title Build image on VL
Threat description
Adversaries may build a VM/Container image directly on the VL to bypass defenses that monitor for the retrieval of
malicious images from a registry.

Container example: A remote build request may be sent to the Docker API that includes a Dockerfile that pulls a vanilla
base image, such as alpine, from a public or local registry and then builds a custom image upon it.

An adversary may take advantage of that build API to build a custom image on the host that includes malware
downloaded from their C2 server, and they then may deploy container using that custom image. If the base image is
pulled from a public registry, defenses will likely not detect the image as malicious since it’s a vanilla image. If the base
image already resides in a local registry, the pull may be considered even less suspicious since the image is already in
the environment.

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 41

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
Threat type Spoofing, Tampering, Information disclosure, Denial of Service and Elevation of privilege
Vulnerabilities Host misconfiguration, lack of authentication
Impact type Authenticity, Integrity, Confidentiality, Availability and Authorization
Threatened Assets VM/Container images
Affected Services SERV#02, SERV#05
Potential mitigations
REC-AUD Security Audit
REC-IAM Identity, Authentication, and Access Management
REC-CM Certificate management
REC-LOG Logging, Monitoring and Alerting
REC-IMGP Image Protection
REC-SB Secure Boot
REC-SS Secure Storage
REC-RA Remote Attestation
 1
5.2.4.4 Threats concerning the virtualization layer (Host OS-Hypervisor/Container engine) 2
 3
Threat ID T-VL-01
Threat title VM/Container hyperjacking attack
Threat description
VMs/Containers run on host machines, and it is needed to ensure that those hosts (Hypervisor/Container Engine/Host
OS- are not running vulnerable code (for example, old versions of components with known vulnerabilities).

Hyperjacking is an attack in which adversaries gain control over the host of a server or install a malicious
Hypervisor/Container Engine/Host OS and exploit that to run malicious applications on the VM/Container that run on
top of the host. This would enable the attacker to control all the VMs/Containers running on the host.

Hyperjacking involves installing a malicious, fake the Hypervisor/Container Engine/Host OS that can manage the entire
server system. If the attacker gains access to the Hypervisor/Container Engine/Host OS, everything that is connected to
that server can be manipulated. The Hypervisor/Container Engine/Host OS represents a single point of failure when it
comes to the security and protection of sensitive information.

For a hyperjacking attack to succeed, an attacker would have to take control of the Hypervisor/Container Engine/Host
OS by the following methods:
• Injecting a rogue Hypervisor/Container Engine or Host OS beneath the original hypervisor or on top of an existing
Hypervisor/Container Engine/Host OS
• Directly obtaining control of the original Hypervisor/Container Engine or Host OS
• Running a rogue hypervisor on top of an existing hypervisor
Threat type Spoofing, Tampering, Information disclosure, Denial of Service and Elevation of privilege
Vulnerabilities Host misconfiguration, lack of authentication
Impact type Authenticity, Integrity, Confidentiality, Availability and Authorization
Threatened Assets Host OS, Hypervisor/Container Engine and VNFs/CNFs (Near RT RIC, O-CU, O-DU)
Affected Services SERV#01, SERV#03, SERV#04, SERV#05, SERV#06, SERV#07
Potential mitigations
REC-SCONF Security Configuration
REC-SB Secure Boot
REC-VHPM Vulnerability Handling and Patch Management
REC-NS Network Segmentation & Filter Network Traffic
REC-IAM Identity, Authentication, and Access Management
REC-CM Certificate management
REC-ISO Strong Isolation
REC-SS Secure Storage
 4
 5
Figure 5-9 : Illustration of the VM/Container hyperjacking attack 6
 7
Threat ID T-VL-02
Threat title Boot tampering
Threat description
The bootloader of the virtualization layer (Host OS, Hypervisor, Container Engine) for VNF/CNF may be maliciously
tampered by an attacker, e.g. the attacker compromises hypervisor or host OS to tamper the bootloader of guest OS (in
case of VM) or Container.

In a O-Cloud environment any failure during the boot sequence can result in a number of situations that need to be
handled by the NFO/FOCOM:

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 42

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
• failure of the physical machine to start at all
• physical machine entering a safe-mode
• physical machine continuing boot regardless of the integrity measurements
Threat type Tampering
Vulnerabilities Host misconfigurations, lack of authentication
Impact type Integrity
Threatened Assets Host OS, Hypervisor/Container Engine and VNFs/CNFs (Near RT RIC, O-CU, O-DU)
Affected Services SERV#01, SERV#03, SERV#04, SERV#05, SERV#06, SERV#07
Potential mitigations
REC-SB Secure Boot
REC-PHY Physical Security Protection
REC-RA Remote Attestation
REC-LOG Logging, Monitoring and Alerting
 1
5.2.4.5 Threats concerning O-Cloud interfaces 2
5.2.4.5.1 O2 interface 3
 4
Two main interfaces are defined in O-RAN WG6 specification and identified as critical assets of O-Cloud, i.e. 5
interfaces O2 between O-Cloud and SMO. The threats on these interfaces are as follows. 6
 7
Threat ID T-O2-01
Threat title MitM attacks on O2 interface between O-Cloud and SMO
Threat description
If the interface O2 interface is not protected, an attacker can attack all the requests/responses sent between the O-Cloud
and the SMO (FOCOM and NFO).
For example, the attacker can tamper/alter/disclose requests and services (See ‘Critical services’ in 2.3) sent over O2
between O-Cloud and SMO, hence the virtualized resource or relevant status information is not as requested. This
affects the normal operation of the O-Cloud, and even causes DoS attacks, information leakage.
An attacker can tamper the specific assignment of virtualized resources to cause resource assignment errors or an
attacker can intercept virtualized resources state information leading to information disclosure.
An attacker can compromise IMS to tamper with the hardware state information (e.g. deleting hardware alarm
information) to affect the hardware's operation or to result in information disclosure (e.g. an attacker can get the
hardware configuration from the compromised IMS. Then, the attacker can attack the hardware according to the
configuration such as CPU type, memory size etc.). An attacker can also tamper or intercept the hardware resource
configuration and state information if the configuration and state information are transmitted using an insecure protocol
on the O2 interface.
Threat type Tampering, Information disclosure, Denial of Service
Vulnerabilities Insecure O2 interface, lack authentication
Impact type Integrity, Confidentiality, Availability
Threatened Assets Telemetry, provisioning, logs, software management, performance information
Affected Services SERV#01
Potential mitigations
REC-NS Network Segmentation & Filter Network Traffic
REC-IAM Identity, Authentication, and Access Management
REC-CM Certificate management
REC-SCONF Security Configuration
 8
5.2.4.5.2 O-Cloud API 9
 10
Threat ID T-OCAPI-01
Threat title MitM attacks on O-Cloud interface between VNFs/CNFs and the virtualization layer
Threat description
An attacker can attack an instantiated VNF/CNF through a compromised virtualization layer. For example,
cryptographic keys or other security critical data of an instantiated VNF/CNF could be stolen by an attacker with access
to the virtualization layer, or the virtualized resource provided by the Virtualization layer to the instantiated VNF/CNF
can be manipulated or the bootloader of Guest OS (in case of VM) or Container of an instantiated VNF/CNF can be
tampered by an attacker via a compromised virtualization layer.
Threat type Tampering, Information disclosure, Denial of Service
Vulnerabilities Insecure O-Cloud APIs, lack of authentication
Impact type Integrity, Confidentiality, Availability
Threatened Assets Host OS, Hypervisor/Container Engine and VNFs/CNFs (Near RT RIC, O-CU, O-DU)
Affected Services SERV#01, SERV#03, SERV#04, SERV#05, SERV#06, SERV#07
Potential mitigations
REC-NS Network Segmentation & Filter Network Traffic
REC-IAM Identity, Authentication, and Access Management
REC-CM Certificate management
REC-SCONF Security Configuration
REC-SS Secure Storage
REC-PHY Physical Security Protection
 11
5.2.4.6 Threats concerning hardware resources 12
 13
Threat ID T-HW-01

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 43

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
Threat title Cross VM/Container side channel attacks
Threat description
In a typical cross-VM/Container side channel attack scenario, an adversary places a malicious VM/Container co-
resident to the target VM/Container so that they share the same hardware resources. Then, the attacker extracts useful
information such as cryptographic keys from the target VM/Container to use them for traffic eavesdropping and man-in-
the-middle attacks. Through the side channel attack, an attacker sharing the same cache as the victim can monitor the
cache access behavior of the victim. For example, the attacker is able to monitor cache timing information by measuring
the execution of different operations on the victim’s VM/Container. Generally, the attacker exploits timings in the
shared high-level cache memory. However, power consumption or electromagnetic leaks can also be used as a vector to
launch side channel attacks.

In the virtual environment, prior to the cross-VM/Container side channel attack, the attacker needs to identify the target
VM/Container’s location and place a malicious VM/Container co-resident with the target. Later, that attacker may use
the maliciously placed VM/Container to extract information from the target VM/Container with the side channel attack.

Hardware vulnerabilities in processors can also have a large impact on O-Cloud security. Flaws in chip design can
result in the compromise of tenant information in the cloud through side-channel attacks1.
Threat type Tampering, Information disclosure, Denial of Service
Vulnerabilities Flaws in chip design, use of shared hardware, Lack of isolation, lack of authentication
Impact type Integrity, Confidentiality, Availability
Threatened Assets Sensitive data (e.g. passwords, private keys, subscription data, logs), VNFs/CNFs (Near RT RIC, O-CU, O-DU) related
data
Affected Services SERV#01, SERV#03, SERV#04, SERV#05, SERV#06, SERV#07
Potential mitigations
REC-ISO Strong Isolation
REC-PHY Physical Security Protection
REC-IAM Identity, Authentication, and Access Management
REC-CM Certificate management
REC-SS Secure Storage
 1
 2
Figure 5-10 : Illustration of a cross VM/Container side channel attack 3
 4
Threat ID T-HW-02
Threat title MitM attacks on the interface between virtualization layer and hardware
Threat description An attacker can utilize the vulnerabilities of hardware (e.g. Meltdown and Specter of CPU in host) to attack
virtualization layer and/or VNFs/CNFs through this interface, resulting in tampering, information disclosure or DoS.
Threat type Tampering, Information disclosure, Denial of Service
Vulnerabilities Insecure interfaces between HW and VL layers, lack of authentication, misconfiguration
Impact type Integrity, Confidentiality, Availability
Threatened Assets All assets
Affected Services All services
Potential mitigations
REC-PHY Physical Security Protection
REC-NS Network Segmentation & Filter Network Traffic
REC-IAM Identity, Authentication, and Access Management
REC-CM Certificate management
 5
5.2.4.7 Threats concerning O-Cloud management (SMO, NFO, FOCOM) 6
 7
Threat ID T-ADMIN-01
Threat title Denial of service against NFO/FOCOM
Threat description A denial-of-service attack against the NFO/FOCOM can interfere with the ability of operators to control and maintain
their deployments. This can lead to the inability to react to changing resource requirements. In addition, the
NFO/FOCOM is the external API to interact with the O-Cloud platform. Thus, other services may become inaccessible

1 Graz University of Technology (2018), Meltdown and Specter. [Online] Available at: https://meltdownattack.com

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 44

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
as well. For example, operators may be unable to retrieve logs, telemetry data. An attacker could use this opportunity to
hide additional attacks on VM/Container instances.
In addition, an attacker on the NFO/FOCOM could prevents the O-Cloud software update (VNFs/CNFs, VL) to exploit
a known security flaw in the O-Cloud software.
Threat type Denial of Service
Vulnerabilities Lack of authentication, vulnerable code exploits, design weakness, insecure O2 interface
Impact type Availability
Threatened Assets VM/Container images, VNF/CNF, host OS, Hypervisor/Container Engine software
Affected Services SERV#02, SERV#05
Potential mitigations REC-IAM Identity, Authentication and Access Management
REC-CM Certificate management
REC-AUD Security Audit
REC-SCONF Security Configuration
 1
Threat ID T-ADMIN-02
Threat title Abuse a O-Cloud administration service
Threat description
Usually, the SMO including NFO/FOCOM is exposed to the tenant in a web front-end or REST API. In case these
interfaces contain software vulnerabilities or implement authentication and authorization insufficiently, an adversary
would be able to gain access to the VM/Container management and pose as a tenant. It is also possible that an adversary
gains the ability to submit requests without prior authentication and authorization.

The NFO/FOCOM interfaces encompasses a great deal of privileges because anyone gaining sufficient access is able to
deploy new instances and disrupt existing O-Cloud services. It may also be possible for an adversary to submit
compromised VM/Container images that unsuspecting tenants then use to initiate O-Cloud services. Moreover,
adversaries can use the same access to extract business data, configuration data, user data and possibly credentials. For
example, they may be able to create backups of VM/Container instances or they can export VM/Container images. The
impact of compromised credentials is exacerbated by the fact that weak and insufficient safeguarding of credentials is
recognized as one of the top threats in cloud computing [38].

Container example: Adversaries may abuse a container administration service to execute commands within a container.
A container administration service such as the Docker daemon, the Kubernetes API server, or the kubelet may allow
remote management of containers within an environment.

Container example: In Docker, adversaries may specify an entrypoint during container deployment that executes a script
or command, or they may use a command such as docker exec to execute a command within a running container. In
Kubernetes, if an adversary has sufficient permissions, they may gain remote execution in a container in the cluster via
interaction with the Kubernetes API server, the kubelet, or by running a command such as kubectl exec.
Threat type Tampering, Information disclosure, Denial of Service and Elevation of privilege
Vulnerabilities Lack of authentication, secret exposure (insufficient safeguarding of credentials), vulnerable code exploits, design
weakness
Impact type Integrity, Confidentiality, Authorization
Threatened Assets VNF/CNF, host OS, Hypervisor/Container Engine software and related information
Affected Services SERV#03, SERV#04, SERV#06, SERV#07
Potential mitigations
REC-NS Network Segmentation & Filter Network Traffic
REC-IAM Identity, Authentication, and Access Management
REC-CM Certificate management
REC-AUD Security Audit
REC-SCONF Security Configuration
REC-VHPM Vulnerability Handling and Patch Management

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 45

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
6 Recommendations and best practices 1
A large number of useful and relevant security guidelines and best practices exist that are relevant for VM/Container-2
based virtualization and cloud computing in general. Therefore, we provide them here collectively and highly 3
recommend that readers consult them for additional references: 4
• 3GPP TS 33.848 Study on security impacts of virtualisation 5
• MITRE containers matrix 6
• CIS Critical Security Controls 7
• CIS Docker Benchmark  8
• CIS VMWARE Benchmark 9
• ONAP master documentation 10
• CISA/NSA Kubernetes security guidance 11
• OpenStack security guide 12
• Cloud native wiki by aqua 13
• ANSSI “Recommandations de sécurité relatives aux déploiements de conteneur docker “ 14
• CISA/NSA “Security guidance for 5g cloud infrastructures” parts 1 to 4 15
• GSMA NG.126 “Cloud Infrastructure Reference Model” 16
• Docker best practices 17
• FFTelecoms “Référentiel d'objectifs de sécurité en matière de fonctions réseau virtualisées “ 18
• Fraunhofer AISEC Threat analysis of container-as-a-service for network function virtualization 19
6.1 REC-CM Certificate management 20
Recommendation: O-Cloud should support Public Key Cryptography for the purpose of distributing Public Key 21
Certificates (PKC) for authenticating, authorizing, and encrypting links between components in O -Cloud. Each operator 22
should develop Certificate Policy in accordance with their regional and national requirements. In addition, Operators 23
should setup a renewal procedure (preferably automatically) of certificates prior to their expiration.  24
In O-Cloud, the components to be issued certificates include: 25
• O-Cloud and VNFs/CNFs should employ certificates which can be used for images signing and verification 26
during onboarding and registration. 27
• SMO and VNF/CNF should employ certificates which can be used in order to establish secure connections 28
between them. 29
• SMO employs certificates in order to establish secure management connections with NFO and FOCOM.  30
• O-Cloud infrastructure employs certificate(s) in order to establish secure connections with NFO and FOCOM 31
through O2 interface. 32
 33
Best practices to fulfill this recommendation: 34
 35
BP ID Description
REC-CM-BP-1 The certificate policy should be consistent with the Internet X.509 Certificate Policy and Certification Practices Framework as defined
in IETF RFC 3647 [9].
REC-CM-BP-2
In order to eliminate or mitigate risks against attacks such as spoofing, tampering and information disclosure, secure connection can be
established on all the interfaces within O-Cloud. IPsec and TLS mechanisms are widely deployed to protect the communication
between O-Cloud components using certificates.
REC-CM-BP-3 Certificate management in O-Cloud should be automated and manual operations should be avoided as much as possible. Automated
certificate lifecycle management should be supported, i.e. creation, update and revocation of certificate.
REC-CM-BP-4
It’s important to continuously monitor and audit certificates that are issued and active, with the ability to generate audits and keep on
top of expirations and renewals to avoid any disruption in O-Cloud services. Unknown, rogue or non-complaint certificates can result
in an unexpected outage, or worse, misuse that allows unintended access to O-Cloud components.
REC-CM-BP-5
Securing the CAs that issue the certificates is critical. If a CA is compromised, attackers can issue their own identities that will be
trusted by default across O-Cloud, and this can be extremely costly to remediate, as it effectively invalidates every identity issued by
that CA. Hardware devices such as HSMs should be used to secure CA certificates and keys, ensure robust protection and complete
visibility, policy enforcement, and automation for all certificates.
 36
For more details see ETSI GR NFV-SEC 005 [10]. 37
 38
This recommendation can help to mitigate: T-GEN-02, T-GEN-04, T-VM-C-01, T-VM-C-02, T-VM-C-03, T-VM-39
C-04, T-VM-C-05, T-IMG-01, T-IMG-02, T-IMG-04, T-VL-01, T-O2-01, T-OCAPI-01, T-HW-01, T-HW-02, T-40
ADMIN-01, T-ADMIN-02 41
 42

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 46

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
6.2 REC-NS Network Segmentation & Filter Network Traffic 1
Recommendation: Physical and logical segmentation to prevent access to potentially sensitive O-Cloud components 2
and information should be implemented. In addition, network policies should be defined to ensure a secure 3
communication between VMs/Containers and limit the communication between VMs/Containers as much as possible t o 4
limit potential damage if a VM/Container is compromised. 5
 6
Best practices to fulfill this recommendation: 7
 8
BP ID Description
REC-NS-BP-1 Isolate O-Cloud infrastructure components that do not require broad network access.
REC-NS-BP-2
Configure access controls, network proxies, gateways, and firewalls to limit access to:
• Critical O-Cloud components. Most cloud environments support separate virtual private cloud (VPC) instances that enable
further segmentation of cloud systems.
• Systems used to create and manage accounts.
REC-NS-BP-3 Follow best practices for network firewall and proxies configurations to allow only necessary ports and legitimate traffic to enter and
exit the network.
REC-NS-BP-4 Operate intrusion detection, analysis, and response systems on a separate network from the production environment to lessen the
chances that an adversary can see and interfere with critical response functions.
REC-NS-BP-5 Consider filtering DNS requests to unknown, untrusted, or known bad domains and resources. Resolving DNS requests with on-
premise/proxy servers may also disrupt adversary attempts to conceal data within DNS packets.
REC-NS-BP-6 Enforce proxies and use dedicated servers for services such as DNS and only allow those systems to communicate over respective
ports/protocols, instead of all systems within a network.
REC-NS-BP-7 Consider using IP allowlisting along with user account management to ensure that data access is restricted not only to valid users but
only from expected IP ranges to mitigate the use of stolen credentials to access data.
REC-NS-BP-8 Apply extended ACLs to block unauthorized protocols outside the trusted network.
REC-NS-BP-9
Upon identifying a compromised network device being used to bridge a network boundary, block the malicious packets using an
unaffected network device in path, such as a firewall or a router that has not been compromised. Continue to monitor for additional
activity and to ensure that the blocks are indeed effective.
REC-NS-BP-10
When flood volumes exceed the capacity of the network connection being targeted, it is typically necessary to intercept the incoming
traffic upstream to filter out the attack traffic from the legitimate traffic. Such defenses can be provided by the hosting Internet Service
Provider (ISP) or by a 3rd party such as a Content Delivery Network (CDN) or providers specializing in DoS mitigations.
REC-NS-BP-11 Filter network traffic to prevent use of protocols across the network boundary that are unnecessary.
REC-NS-BP-12
Use of network intrusion detection and prevention systems that can
• Identify traffic patterns and use network signatures to identify traffic for specific adversary malware, can be used to mitigate
malicious activity at the network level.
• Detect and prevent remote service scans.
 9
This recommendation can help to mitigate: T-GEN-02, T-VM-C-01, T-VM-C-02, T-VM-C-03, T-VM-C-04, T-IMG-10
02, T-VL-01, T-O2-01, T-OCAPI-01, T-HW-02, T-ADMIN-02 11
6.3 REC-IAM Identity, Authentication and Access Management 12
Recommendation: A strong IAM framework should be in place to ensure authentication, authorization, accounting and 13
access control. It should be used to initiate, capture, record and manage user identities and their related access 14
permissions to O-Cloud assets in an automated way.  15
 16
The IAM framework should be set up to manage and secure access to NFO/FOCOM, VNFs/CNFs, Host OS, 17
Hypervisor, Container Engine, data and services that reside in the O-Cloud. This framework should protect credentials 18
and accounts associated with O-Cloud platforms. Specifically, IAM protects root accounts for servers in the O-Cloud, 19
limits privileged access to the O-Cloud control panel and governs ongoing access to privileged resources in the O-20
Cloud. 21
 22
IAM should be based on Authentication, Authorization, and Accounting (AAA) systems and least privileges approach 23
to limit actions administrators, perform and provide a history of user actions to detect unauthorized use and abuse.  24
 25
Protocols without encryption/authentication mechanisms should ne be used. Access to administrative and management 26
interfaces from untrusted network sources should be limited. 27
 28
Best practices to fulfill this recommendation: 29
 30
Req ID Description

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 47

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
REC-IAM-BP-1
OAuth2.0 with access token defined by IETF RFC 6749 [11] should be used for the authorization of API request and notifications.
There are several existing Access Token solutions. Such solutions are Openstack Keystone2, OpenID Connect3, 3GPP authorization
framework ETSI TS 133 5014, IETF TLS-Based AccessToken Binding5 6.
For more details see ETSI GR NFV-SEC 022 [12].
REC-IAM-BP-2 O-Cloud components must support authenticated and secure access to API, GUI and command line interfaces. In addition, they must
support Traffic Filtering (for example, FireWall, IDS/IPS).
REC-IAM-BP-3 O-Cloud interfaces should support secure and encrypted communications, and confidentiality and integrity of network traffic on all
channels. All APIs access must use TLS protocol, including back-end APIs [45].
REC-IAM-BP-4
O-Cloud components should implement controls enforcing separation of duties and privileges, least privilege use and least common
mechanism (e.g. Role-Based Access Control).
Communication between different trust domains is not allowed, by default.
The O-Cloud infrastructure must not allow the effect of an attack on one trust domain to impact the other domains either directly or
indirectly.
REC-IAM-BP-5
The O-Cloud should not reuse the same authentication credential (e.g., key-pair) on different components (e.g., on different hosts, or
different services).
The O-Cloud should protect all secrets by using strong encryption techniques and storing the protected secrets externally from the
component.
The O-Cloud should provide secrets dynamically as and when needed.
REC-IAM-BP-6 Data Centre Operations staff and O-Cloud components should use management protocols that limit security risk. Management
protocols such as SNMPv3, SSH v2, ICMP, NTP, syslog, and TLS v1.2 or higher.
REC-IAM-BP-7
Remotely available services that may be unnecessary should be disabled or blocked. Remote access to internal O-Cloud systems
should be controlled using centrally managed concentrators such as VPNs and other managed remote access systems of network,
proxies, gateways, and firewalls.
Strong two-factor or multi-factor authentication for remote service accounts to mitigate an adversary's ability to leverage stolen
credentials should be used.
REC-IAM-BP-8 Ensure VM/Containers are not running as root by default.
REC-IAM-BP-9
Do not allow domain administrator accounts to be used for day-to-day operations that may expose them to potential adversaries on
unprivileged systems.
Consider using temporary credentials for accounts that are only valid for a certain period of time to reduce the effectiveness of
compromised accounts.
REC-IAM-BP-10 Limit access to the root account and prevent users from loading kernel modules and extensions through proper privilege separation
and limiting Privilege Escalation opportunities.
REC-IAM-BP-11
Container: Run the microservice with the least privilege possible; First, never use the --privileged flag. It gives all so-called
capabilities to the container, and it can access host devices (/dev) including disks, and also has access to the /sys and /proc
filesystem. And with a little work the container can even load kernel modules on the host7. The good thing is that containers are per
default unprivileged. You would have to configure them explicitly to run privileged.
REC-IAM-BP-12 When PowerShell is necessary, restrict PowerShell execution policy to administrators. Be aware that there are methods of bypassing
the PowerShell execution policy, depending on environment configuration.
REC-IAM-BP-13
Least of privilege principles:
• Use the principal of least privilege and protect administrative access to domain trusts such as the service account in
Kubernetes, Openstacks, etc. to limit impact of exploitation.
• Restrict administrator accounts to as few individuals as possible, following least privilege principles.
• Limit permissions associated with creating and modifying images or VMs/Containers based on the principle of least privilege.
REC-IAM-BP-14 Prevent credential overlap across systems of administrator and privileged accounts.
REC-IAM-BP-15 Ensure critical system files as well as those known to be abused by adversaries have restrictive permissions and are owned by an
appropriately privileged account, especially if access is not required by users nor will inhibit system functionality.
REC-IAM-BP-16
Audit domain and local accounts as well as their permission levels routinely to look for situations that could allow an adversary to
gain wide access by obtaining credentials of a privileged account. These audits should also include if default accounts have been
enabled, or if new local accounts are created that have not been authorized.
REC-IAM-BP-17 Do not put user or admin domain accounts in the local administrator groups across systems unless they are tightly controlled, as this
is often equivalent to having a local administrator account with the same password on all systems.
REC-IAM-BP-18 Do not allow remote access to services as a privileged account unless necessary.
REC-IAM-BP-19 Do not allow remote access via SSH as root or other privileged accounts.
REC-IAM-BP-20 Restrict execution of particularly vulnerable binaries to privileged accounts or groups that need to use it to lessen the opportunities
for malicious usage.
REC-IAM-BP-21
Ensure that any accounts used by third-party providers to access these systems are traceable to the third-party and are not used
throughout the network or used by other third-party providers in the same environment. Ensure there are regular reviews of accounts
provisioned to these systems to verify continued business need and ensure there is governance to trace de-provisioning of access that
is no longer required. Ensure proper system and access isolation for critical network systems through use of account privilege
separation.

2 https://docs.openstack.org/keystone/latest/admin/tokens.html
3 https://openid.net/specs/openid-connect-core-1_0.html
4 TSI TS 133 501: "5G; Security architecture and procedures for 5G System (3GPP TS 33.501)"
5 draft-ietf-oauth-token-binding-08: "OAuth 2.0 Token Binding", Work in progress
6 IETF RFC 8705: "OAuth 2.0 Mutual-TLS Client Authentication and Certificate-Bound Access Tokens"
7 https://www.cyberark.com/threat-research-blog/how-i-hacked-play-with-docker-and-remotely-ran-code-on-the-host/

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 48

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
REC-IAM-BP-22 A Cloud Access Security Broker (CASB) can be used to set usage policies and manage user permissions on cloud applications to
prevent access to application access tokens.
REC-IAM-BP-23
Password policy
• O-Cloud components that utilize default username and password should be changed immediately after the installation, and
before deployment to a production environment. When possible, passwords should be updated periodically and properly
secured. (Refer to NIST guidelines when creating password policies NIST Special Publication 800-63B8, CIS Password Policy
Guide9).
• Use strong passwords to increase the difficulty of credential hashes from being cracked if they are obtained.
• Do not reuse local administrator account passwords across systems. Ensure password complexity and uniqueness such that the
passwords cannot be cracked or guessed.
• In case SSH is used with password (not recommended), Ensure SSH key pairs have strong passwords and refrain from using
key-store technologies such as ssh-agent unless they are properly protected.
• Consider rotating access keys within a certain number of days to reduce the effectiveness of stolen credentials.
• Use strong passphrases for private keys to make cracking difficult. Do not store credentials within the Registry. Establish an
organizational policy that prohibits password storage in files.
• Ensure that cloud accounts, particularly privileged accounts, have complex, unique passwords across all systems on the
network. Passwords and access keys should be rotated regularly. This limits the amount of time credentials can be used to
access resources if a credential is compromised without your knowledge. Cloud service providers may track access key age to
help audit and identify keys that may need to be rotated.
 1
This recommendation can help to mitigate: T-GEN-02, T-GEN-04, T-VM-C-01, T-VM-C-02, T-VM-C-03, T-VM-2
C-04, T-VM-C-05, T-IMG-01, T-IMG-02, T-IMG-04, T-VL-01, T-O2-01, T-OCAPI-01, T-HW-01, T-HW-02, T-3
ADMIN-01, T-ADMIN-02 4
 5
6.4 REC-VHPM Vulnerability Handling and Patch Management 6
Recommendation: A vulnerability handling process should be in place to find potentially exploitable software 7
vulnerabilities, to determine what types and levels of threat may use software exploits and 0- days against O-Cloud and 8
to remediate them. 9
A patch management process should be implemented to check unused dependencies, unmaintained and/or previously 10
vulnerable dependencies, unnecessary features, components, files, and documentation.  11
 12
Best practices to fulfill this recommendation: 13
 14
BP ID Description
REC-VHPM-BP-1 Regularly scan O-Cloud software components for vulnerabilities and establish procedures to rapidly patch systems when critical
vulnerabilities are discovered through scanning and through public disclosure.
REC-VHPM-BP-2 Regularly scan the internal network for available services to identify new and potentially vulnerable services.
REC-VHPM-BP-3 Continuous monitoring of vulnerability sources and the use of automatic and manual code review tools should also be implemented
as well.
REC-VHPM-BP-3
Patch strategy shall be applied for each component to maintain the O-Cloud software infrastructure.
The patch strategy should handle regular and emergency patches. It is also needed to be prepared for testing patches and rollback
procedures. The patch strategy should be automated. It's also recommended to make use of plugins for monitoring software and
notifying of pending patches.
Keep in mind that some patches require a restart of their service, a new deployment (VM/Container image) or even a reboot (host) to
become effective. If this won't be done, patching otherwise could be as effective as just not to patch. Technical details when to
restart a service, a host or initiate a new deployment need to be defined in the patch strategy too.
There are four different patch domains:
• Images: the VM/Container distribution
• Hypervisor/Container Engine software: e.g. VMWARE, Docker
• Orchestration software (Kubernetes, Mesos, OpenShift, ...)
• Host operating system
REC-VHPM-BP-4
Maintain SBOMs for O-RAN software components in a centralized repository. This will make possible to quickly scan and search
the SBOM for any Zero-Day vulnerability when get disclosed, which allows O-Cloud operator to respond quickly to the Zero-day
vulnerability to mitigate potential attacks. For more details about SBOM see Chapter 4 ‘SBOM Guidelines for O-RAN’ in [42].
 15
This recommendation can help to mitigate: T-GEN-01, T-IMG-01, T-VL-01, T-ADMIN-02, T-O2-01, T-OCAPI-01 16
 17
6.5 REC-SCONF Security Configuration 18
Recommendation: The O-Cloud virtualization layer shall 19
• Be configured to ensure conformance to industry standard benchmarks and requirements with respect to 20
security configurations. 21

8 https://pages.nist.gov/800-63-3/sp800-63b.html
9 https://www.cisecurity.org/white-papers/cis-password-policy-guide

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 49

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
• Use automated or manual mechanisms to detect configuration drifts/misconfigurations from industry standard 1
benchmarks and requirements. 2
 3
Best practices to fulfill this recommendation: 4
 5
BP ID Description
REC-SCONF-BP-1
O-Cloud virtualization layer should be configured to adhere/conform to industry standard benchmarks and guidelines for securing
the virtualization layer. For example, the CIS benchmark guidelines enforce many security configurations related to the container
deployment like:
• Avoid running containers as privileged, apply the principle of least privilege access controls for privileged containers, and
restrict functionality of privileged containers.
• Restrict containers from using hostPath volume mounts write permissions from within container.
• Enforce non-root default user in containers (using Kubernetes pod spec parameters or USER directive in Dockerfile).
REC-SCONF-BP-2
O-Cloud operator & vendor should perform automated or manual scans to check security posture adherence to industry standard
benchmarks. For example, Cloud Security Posture Management tools can be used to check conformance to industry standard
benchmarks like CIS, NIST, etc.
REC-SCONF-BP-3
O-Cloud CNF vendors should define the CPU and Memory requirements of their CNF applications, ie, the CPU and Memory
requirements for the CNF applications to perform its functions under normal operating scenarios and the threshold limit value of
CPU & Memory requirements beyond which the CNF should not be allowed to use. O-Cloud virtualization platform should consider
the CPU & Memory resource requirements & limits associated to each CNF provided by O-Cloud CNF vendors during onboarding
of the CNFs.
REC-SCONF-BP-4
O-Cloud virtualization platform should consider enforcing the O-Cloud CNF vendors to specify the CPU & Memory resource
requirements & limits using suitable admission controller solutions. Setting CPU & memory limits will help OCloud virtualization
platform to avoid a rogue CNF container using up all resources thereby starving off other co-located CNF containers.
 6
This recommendation can help to mitigate: T-VM-C-01, T-VM-C-02, T-VM-C-06, T-VL-01, T-ADMIN-01, T-7
ADMIN-02 8
6.6 REC-SDLC Secure Development Lifecycle 9
Recommendation: Software providers should assume that their VNFs/CNFs and VL software contain flaws and have 10
appropriate processes in place to mitigate these cases. To this end, they should adopt a secure software development 11
life-cycle (S-SDLC). A S-SDLC integrates security considerations into the normal software development life-cycle. 12
This ensures that risks, threats, and security mechanisms are formalized alongside the development of VNFs/CNFs and 13
VL. 14
 15
Best practices to fulfill this recommendation: 16
 17
Req ID Description
REC-SDLC-BP-1
Define and implement good coding practices. This includes writing documentation, adopting secure programming guidelines,
enforcing code quality metrics and perform software tests. In particular, code quality and adherence to coding standards can be
checked automatically with tools, such as SonarQube10. With this approach, the chance of introducing easily exploitable
vulnerabilities into the code is reduced.
REC-SDLC-BP-2
Modern continuous integration (CI) and continuous delivery (CD) systems can be used to build new container images from code
repositories, such as Git711 automatically. Thus, every commit can be used to generate a new container image that is immediately
deployed for testing in a development environment. Once a new software version passes all tests, it can be deployed automatically to
the O-Cloud platform. This step should be safeguarded by an internal approval process. For example, operators can configure their
CI/CD pipeline to only start deployment in production after quality assurance, security testing and operations have approved the new
version.
REC-SDLC-BP-3
During development, developers may include private keys and configuration files with passwords into their VM/Container images
for convenience and testing reasons. However, this information should never be published in a production VM/Container image.
Thus, one of important step before actually deploying any VM/Container image to the O-Cloud platform is to verify that no sensitive
information is included. In case of Docker, recent versions allow to specify these image differences between development and
operations by using multiple FROM commands, i.e., one for development and one production in the respective Dockerfile.
REC-SDLC-BP-4
Define mechanisms and processes that ensure that VM/Container image metadata is signed and verified. Thus, if operators download
an image from a party they trust, they can verify the signature and the cryptographic hashes of the image files.
Example: use of Docker Notary and Content Trust12
 18
This recommendation can help to mitigate: T-GEN-01, T-IMG-01, T-IMG-03 19

10 http://sonarqube.org
11 https://git-scm.com
12 https://docs.docker.com/engine/security/trust/content_trust/

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 50

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
6.7 REC-SNFLC Security App/VNF/CNF lifecycle 1
Recommendation: Security into the life cycle management of Apps/VNFs/CNFs should be integrated during 2
development, onboarding, instantiation, scaling, migration, and termination. Security lifecycle management must be 3
adapted to work in a more dynamic environment with fast-changing network topology, data flow paths, and network 4
addresses. 5
 6
Best practices to fulfill this recommendation: 7
 8
Req ID Description
REC-SNFLC-BP-1
Before an App/VNF/CNF is deployed, the NFO/FOCOM system should verify compliance with its build-configuration standards. A
check can include but is not limited to:
• Security of the configuration
• Whether the package contains only trusted and expected components
• Whether trusted components have been altered (integrity)
REC-SNFLC-BP-2
Apps/VNFs/CNFs can easily be cloned and instantiated. As a result, a security framework must address the following elements:
• Depending on the migration technique, certificates, accounts, media access control addresses, or hardware IDs will look
identical after cloning.
• Trusted platform modules (e.g., TPM, HSM, Intel’s Trusted Execution Technology, or TXT) may be required to ensure that
virtual components can provide attestation or a true status of the security of the underlying hardware and physical location.
 9
This recommendation can help to mitigate: T-GEN-03, T-VM-C-01, T-VM-C-02, T-VM-C-04, T-VM-C-06 10
6.8 REC-IMGP Image Protection 11
Recommendation: Only images from secure and trusted sources should be used. These images should be scanned to 12
ensure that images not contain vulnerable software. 13
The App/VNF/CNF images shall not be packaged with embedded secrets such as passwords or credentials, or any other 14
critical configuration data. 15
During the onboarding, the authenticity and integrity of the VNF Package should be verified against the signature 16
provided by the VNF provider. Furthermore, Operators should undertake additional se curity validation of the VNF 17
Package during the onboarding process and operator's signing should be used to certify the VNF as authorized to 18
onboard into the operator's network [46], [47]. 19
 20
Best practices to fulfill this recommendation: 21
 22
Image Scanning 23
Scanning process needs to identify when Apps/VNFs/CNFs are running with out-of-date packages that need to be 24
updated for security patches. Further, it should identify malware that has been built into an image. The O-Cloud VL 25
should enforce image scans to check and flag the presence of secrets in images. 26
 27
(1) VM/Container images need to be frequently scanned throughout the lifecycle of the App/ VNF/CNF 28
 29
During Development Within the registry Before Deployment During Runtime
Perform frequent scanning
for known vulnerability or
misconfiguration on
App/VNF/CNF image during
build phase. E.g., Check for
malware, secrets stored in
image.
Ideal to automate with CI
pipeline.

Responsible: O-RAN
Solution Provider/Vendor
Regular scan for
App/VNF/CNF image
known vulnerability or
misconfiguration stored in
the registry. E.g., scan for
new vulnerabilities after
built.

Responsible: O-RAN
Solution
Provider/Vendor/Operator
Perform frequent scanning for known
vulnerability or misconfiguration on
App/VNF/CNF image before deployment
using admission control techniques.
Admission controller could block
deployments if the image doesn’t comply
with the operator security policies e.g., To
check the images used to create CNF pods
are secure by checking for malware.
Ideal to automate with CD pipeline.

Responsible: O-RAN Solution
Provider/Vendor/Operator
Perform continuous
scanning/monitoring for known
vulnerability or
misconfiguration on runtime
workloads, check for any open
ports, VM/Container escape.

Responsible: Operator/O-Cloud
Operator
 30
(2) As part of O-RAN App/VNF/CNF development, O-RAN Solution Provider/Vendor is recommended to choose 31
base images and packages used in the O-RAN App/VNF/CNF from a trusted publisher or create in-house base 32
images. Choosing trusted signed images helps to mitigate MITM attacks that can introduce vulnerabilities into 33
the base images available in public registries.  34
(3) As part of O-RAN App/VNF/CNF development, O-RAN Solution Provider/Vendor is recommended to choose 35
minimal base images that bundle only the necessary system tools and libraries required by O -RAN 36
App/VNF/CNF, to limit the attack surface of O-RAN App/VNF/CNF. 37
 38

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 51

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
App/VNF/CNF Image Signing 1
Responsible: App/VNF/CNF Solution Provider/Vendor and/or Operator  2
(1) App/VNF/CNF Solution Provider creates public/private key pair for code signing.  3
(2) CA verifies public key belong to the owner and issue CA certificate with attached public key.  4
(3) Hash function on App/VNF/CNF Image returns image Digest.  5
(4) Image Digest is encrypted with private key.  6
(5) Signed App/VNF/CNF Image contains CA Certificate, Digest, Hash function.  7
 8
App/VNF/CNF Image Verification 9
Responsible: Operator or O-Cloud Operator  10
(1) Verify CA certificate for authenticity.  11
(2) Decrypt digest with public key 12
(3) Compare Decrypted digest with Digest computed as result of Hash function on App/ VNF/CNF Image.  13
(4) Verification is successful if both digest matches.  14
 15
Proposed Signing/Verification Models  16
1. Software signing by Solution Provider/Vendor, Software verification at runtime by O-Cloud Operator 17
2. Software signing by Solution Provider/Vendor, Software verification by operator before onboarding vendor 18
images to the operator registry 19
3. Software signing by Operator, Software verification at runtime by O-Cloud Operator 20
4. Software signing by Solution Provider/Vendor, Software verification at runtime by O-Cloud Operator and/or 21
Operator. 22
5. Software signing by solution provider/vendor, Software verification by Operator and software re -signing by 23
Operator before onboarding vendor images to the operator registry, software verification at instantiation. 24
 25
Other best practices: 26
• Least privilege access that limits and controls access to the images’ repository and the repository of source code, 27
secure storage, and automation for verifying the configuration of images before loading. 28
• Utilize a trust model such as Docker Content Trust with digital signatures to ensure runtime verif ication of the 29
integrity and publisher of specific image tags. 30
• Implement only digitally signed host images to validate the integrity of the software used on the O -Cloud platform. 31
Make use of this feature where possible in order to prevent and/or detect attempts by adversaries to compromise the 32
host image. 33
• The registry is most sensitive part of the system and should be run in an HSM. 34
• The App/VNF/CNF images shall not be packaged with embedded secrets such as passwords or credentials, or any 35
other critical configuration data. Secrets have to be stored outside the App/VNF/CNF images. For example, K8s 36
secrets or external secrets managers (like Vault) can be used to store secret and sensitive information hence 37
preventing the threat of packaging secrets in CNF container images. Secrets required by containerized applications 38
can be injected into the CNF container from the External Secrets Manager as required . 39
• encryPtInG Vnf Volume/sWAP AreAs Virtual volume disks associated with VNFs may contain sensitive da ta. 40
Therefore, they need to be protected. The best practice to secure the VNF volume is by encrypting them and storing 41
the cryptographic keys at safe locations. The TPM module can also be used to securely store these keys. In 42
addition, the hypervisor should be configured to securely wipe out the virtual volume disks in the event a VNF is 43
crashed or intentionally destroyed to prevent it from unauthorized access. VM swapping is a memory management 44
technique used to move memory segments from the main memory to disk, which is used as a secondary memory in 45
order to increase system performance in case the system runs out of memory. These transferred memory segments 46
can contain sensitive information such as passwords and certificates. They can be stored on the disk and remain 47
persistent even after system reboot. This enables an attack scenario whereby a VM swap is copied and investigated 48
to retrieve any useful information. One way to avoid this kind of attack is to encrypt VM swap areas. Linux based 49
tools such as dm-crypt can be used for this purpose. 50
 51
This recommendation can help to mitigate: T-GEN-01, T-GEN-03, T-IMG-01, T-IMG-02, T-IMG-03, T-IMG-04 52
6.9 REC-LOG Logging, Monitoring and Alerting 53
Recommendation: The continuous security of O-Cloud software (running VNFs/CNFs, Hypervisor/Container Engine, 54
Host OS, NFO/FOCOM) depends on the ability to identify attacks and reconstruct them. The earlier operators identify 55
suspicious behavior and possible attacks, the faster they can initiate countermeasures. In the best case, they are able to 56
stop attacks severe before harm is done. In the worst case, they at least are able to reduce the attacks severity and collect  57
important details on the attack itself. This knowledge is important to find and fix flaws and vulnerabilities to prevent 58
similar attacks in the future. Therefore, a key activity is to perform logging, monitoring and alerting.  59

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 52

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
The importance increases because of the dynamic VM/Container deployment. VMs/Containers may be started when 1
demand arises and then quickly be terminated once they are no longer required. Furthermore, the focused nature of 2
VMs/Containers and the application of a microservice architecture means that there are more systems to monitor. As a 3
result, monitoring and logging must handle this dynamic landscape and be able to collect data from many systems at 4
once. 5
 6
Best practices to fulfill this recommendation: 7
 8
Req ID Description
REC-LOG-BP-1 Any change to the O-Cloud components must be logged as a security event, and the logged event must include the identity of the
entity making the change, the change, the date and the time of the change.
REC-LOG-BP-2 Security logs should be time synchronized and regularly scanned for events of interest.
REC-LOG-BP-3 Consider monitoring for the presence or loading of known vulnerable software that adversaries may drop and exploit to execute code
in kernel mode.
REC-LOG-BP-4
Monitor for the deployment of suspicious or unknown container images and pods in your environment, particularly containers
running as root. Additionally, monitor for unexpected usage of syscalls such as mount (as well as resulting process activity) that may
indicate an attempt to escape from a privileged container to host. In Kubernetes, monitor for cluster-level events associated with
changing containers' volume configurations.
REC-LOG-BP-5
Establish centralized logging for the activity of container and Kubernetes cluster components. This can be done by deploying
logging agents on Kubernetes nodes and retrieving logs from sidecar proxies for application pods to detect malicious activity at the
cluster level.
REC-LOG-BP-6
Monitor logs for actions that could be taken to gather information about container infrastructure, including the use of discovery API
calls by new or unexpected users. Monitor account activity logs to see actions performed and activity associated with the Kubernetes
dashboard and other web applications.
REC-LOG-BP-7
Consider monitoring process resource usage to determine anomalous activity associated with malicious hijacking of resources such
as CPU, memory, and graphics processing resources. Monitor for suspicious use of network resources associated with
cryptocurrency mining software. Monitor for common cryptomining software process names and files on local systems that may
indicate compromise and resource usage.
REC-LOG-BP-8
Container administration service activities and executed commands can be captured through logging of process execution with
command-line arguments on the container and the underlying host. In Docker, the daemon log provides insight into events at the
daemon and container service level. Kubernetes system component logs may also detect activities running in and out of containers in
the cluster.
REC-LOG-BP-9
Monitor interactions with images and containers by users to identify ones that are added or modified anomalously. In containerized
environments, changes may be detectable by monitoring the Docker daemon logs or setting up and monitoring Kubernetes audit logs
depending on registry configuration.
REC-LOG-BP-10
Monitor for suspicious or unknown container images and pods in your environment. Deploy logging agents on Kubernetes nodes
and retrieve logs from sidecar proxies for application pods to detect malicious activity at the cluster level. In Docker, the daemon log
provides insight into remote API calls, including those that deploy containers. Logs for management services or applications used to
deploy containers other than the native technologies themselves should also be monitored.
REC-LOG-BP-11
Monitor for unexpected Docker image build requests to the Docker daemon on hosts in the environment. Additionally monitor for
subsequent network communication with anomalous IPs that have never been seen before in the environment that indicate the
download of malicious code.
 9
This recommendation can help to mitigate: T-GEN-01, T-GEN-02, T-GEN-03, T-VM-C-02, T-VM-C-03, T-VM-C-10
04, T-VM-C-05, T-VM-C-06, T-IMG-01, T-IMG-02, T-IMG-04, T-VL-02 11
6.10 REC-SB Secure Boot 12
Recommendation: All servers part of O-Cloud Infrastructure should support a root of trust and secure boot to trust that 13
the running host OS, Hypervisor/Container Engine and VNFs/CNFs code were loaded. 14
 15
Best practices to fulfill this recommendation: 16
 17
Req ID Description
REC-SB-BP-1
Using trusted platform module (TPM) as a hardware root of trust, the measurement of system sensitive components such as platform
firmware, BIOS, bootloader, OS kernel, and other system components can be securely stored and verified. The platform
measurement can only be taken when the system is reset or rebooted; there is no way to write the new platform measurement in
TPM during the system run-time. The validation of the platform measurements can be performed by TPM’s launch control policy
(LCP) or through the remote attestation server.
 18
For more details see ETSI GR NFV-SEC 007 [15]. 19
 20
This recommendation can help to mitigate: T-GEN-03, T-IMG-04, T-VL-01, T-VL-02 21
6.11 REC-ISO Strong Isolation 22
Recommendation: Strengthen VNFs/CNFs sandboxing, isolation and segmentation should be enforced to make 23
difficult for adversaries to advance their operation through exploitation of undiscovered or unpatched vulnerabilities . O-24
Cloud virtualization layer shall adopt measures to ensure strong VM/Container isolation among VM/Container 25
workloads to limit the impact of rogue/misbehaving VM/Container on other co-hosted VMs/Containers 26

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 53

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
 1
Best practices to fulfill this recommendation: 2
 3
Req ID Description
REC-ISO-BP-1
In order to prevent privilege escalations, Operators shall ensure that CNFs shall:
• Avoid using binaries with SUID or SGID bit. Instead. specific capabilities required by the files/binaries should be provided
using Linux Capabilities set
• Avoid root user and sudo privileges within container
REC-ISO-BP-2
Restrict the damage attackers can do once they successfully escaped a container. Again, the Linux kernel provides a couple of
security features that can be used to restrict user actions. Among them are Linux security modules providing mandatory access
control and user namespaces themselves.
REC-ISO-BP-3
Restrict the large system call interface is to use seccomp. The seccomp (’Secure Computing’) integrates a BPF-like filter mechanism
for system calls into the Linux kernel. This can be used to reduce the number of system calls that a container can effectively use.
Moreover, the parameters to system calls can be sanitized. Thus, seccomp reduces one attack surface by reducing the number of
exploitable system calls.
REC-ISO-BP-4
Linux kernel allows to restrict users’ capabilities to perform specific operations. In particular, root users have a vast set of
permissions. Linux capabilities permit a fine-grained partition of the capabilities bundled into the root user. Thus, instead of being
root, different capabilities can be restricted. For example, a user can be root without having the permissions to change network
settings. Currently, the Linux kernel has 37 capabilities. Unfortunately, not all capabilities have a specific, well-defined scope. For
example, CAP_SYS_PTRACE permits the use of ptrace(), while CAP_SYS_ADMIN comprises many permissions such as changing
the host and domain name, using mount() and umount(), or performing various configurations of storage and memory devices.
Restricting capabilities assigned to container processes limits the operations an adversary can use on the host system.
REC-ISO-BP-5
Namespaces and cgroups are the two features that enable container-based virtualization in the Linux kernel. They provide isolation
and separation of processes. However, their default configuration is often not as restrictive as possible to support many use cases.
Thus, it is important to employ many namespaces and cgroups and tighten their configuration.
For example, the user namespace separates the user IDs on the host system from the user IDs of a container. A user within the
container can be root, while on the host system the same user is unprivileged. As another example, the devices control group can
restrict what device nodes can be created and be accessed. Other control groups limit the maximum resources a container can use.
Thus, they prevent degradation or denial of services in a shared environment.
REC-ISO-BP-6
Linux security modules (LSM) are are software components that use a well-defined kernel interface to control and decline certain
operations. In particular, LSMs providing mandatory access control (MAC) define rules that further restrict what files a process can
access. Two well-known LSM MACs are AppArmor and SELinux. These MACs define policy rules about what a process can and
cannot access. The resulting policies are then enforced by the kernel. Thus, adversaries are on the one side further limited on the
resources that are exploitable. On the other hand, they have to invest additional time and resources to circumvent and disable the
LSMs.
So far, these security mechanisms mostly protect the host from containers. If a container is compromised, an adversary still has to
put in the additional effort to compromise the host. However, these protections may not circumvent exploits across containers on the
same host. For example, containers on the Docker engine share a common user namespace and storage space for the container
images. Thus, an adversary escaping one container may have access to the container images of another container. This can be used to
manipulate images and introduce persistent threats or steal information. One safeguard against these cross-container exploitations are
extended features of LSM MACs known as multi category security. Using MCS, every container gets a unique identity when it is
initialized. Based on this unique identity, the kernel can perform more fine-grained access decisions because two process executing
the same binary that would usually have the same policy are now distinguishable.
As a result, access to container specific resources can be restrict for each container.
REC-ISO-BP-7
It is important to secure remote access to the host and containers themselves. While not going into the details of full network security
in a cloud environment, each container and host must be protected as part of the security-in-depth approach. On Linux systems,
netfilter/iptables and ebtables can be used to create packet firewalls. They limit network access to exposed ports on the host and in
the containers. Similar to virtual switches in hypervisors, containers can be connected by a Linux bridge device. Platforms such as
Docker use a default bridge device for all container if no separate network is specified during container initiation. As a result,
containers may share a common network segment, which can be exploited. Therefore, ebtables is recommended as an additional
firewall configured for the bridge device.
REC-ISO-BP-8
Stronger isolation mechanisms to keep application code constrained within a VM/Container. Such solutions include the private
cloud, physical separation.
For containers, many security solutions13 are used for ensuring strong isolation of resources, such as LXC, LXD, Singularity, Docker
(runc), Kata-containers (kata-runtime), and gVisor (runsc).
REC-ISO-BP-9 Shared cache memory partitioning or isolation and assigning of a separate portion of cache memory to each VM can reduce or
eliminate successful side channel attacks in a virtualized environment14.
 4
This recommendation can help to mitigate: T-GEN-01, T-VM-C-01, T-VM-C-02, T-VM-C-05, T-VL-01, T-HW-01 5
6.12 REC-AUD Security Audit 6
Recommendation: Periodic audit and scan should be conducted of: 7
• The integrity of images and VM/Containers used in O-Cloud deployments to ensure they have not been 8
modified to include malicious software. 9
• Accounts and privileges for images repositories. 10

13 Olivier Flauzac, Fabien Mauhourat, Florent Nolot, A review of native container security for running applications, Procedia Computer Science,
Volume 175, 2020, Pages 157-164, ISSN 1877-0509, https://doi.org/10.1016/j.procs.2020.07.025. “A review of native container security for running
applications “
14 https://arxiv.org/pdf/1606.01356.pdf

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 54

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
• All accounts, access lists and the privileges they have been granted to access O -Cloud components and images 1
repositories. 2
 3
Best practices to fulfill this recommendation: 4
 5
Req ID Description
REC-AUD-BP-1 Scan code repositories for exposed credentials or other sensitive information. Preemptively search for files containing passwords or
other credentials and take actions to reduce the exposure risk when found.
REC-AUD-BP-2 Suspicious accounts/credentials should be investigated and removed.
REC-AUD-BP-3 Routinely check account role permissions to ensure only expected users and roles have permission to modify cloud firewalls, to
modify cloud compute infrastructure components, create snapshots and backups, and to create/delete new instances.
 6
This recommendation can help to mitigate: T-GEN-01, T-GEN-02, T-VM-C-05, T-IMG-01, T-IMG-03, T-IMG-04, 7
T-ADMIN-01, T-ADMIN-02 8
6.13 REC-SS Secure Storage 9
Recommendation: The O-Cloud infrastructure should support encrypted storage, for example, block, object , file 10
storage, credentials, and secrets with access to encryption keys restricted based on a need to know. 11
 12
Best practices to fulfill this recommendation: 13
 14
Req ID Description
REC-SS-BP-1 Controlled Access Based on the Need to Know should be implemented15.
REC-SS-BP-2 When possible, store keys on separate cryptographic hardware (e.g. HSM, TPM) instead of on the local system.
REC-SS-BP-3 Use best practices for authentication protocols, such as OAuth 2.0,, and ensure traffic that may contain credentials is protected by
TLS.
 15
This recommendation can help to mitigate: T-VM-C-01, T-VM-C-02, T-VM-C-03, T-VM-C-06, T-IMG-03, T-IMG-16
03, T-VL-01, T-OCAPI-01, T-HW-01 17
6.14 REC-PHY Physical Security Protection 18
Recommendation: Physical security protection measures should be considered to deny unauthorized access to O-Cloud 19
facilities, equipment and resources. 20
 21
Best practices to fulfill this recommendation: 22
 23
Req ID Description
REC-PHY-BP-1
Reduce the hardware platform (computing platform based for example on the x86 hardware architecture (32bit or 64bit)), like
servers) attack surface by removing unneeded interfaces.
Example: Wireless interfaces (e.g., WiFi, 4G), if present, should remain optional for the platform REC-PHY-BP-1 [41].
REC-PHY-BP-2
Enforce protection of the main memory against untrusted peripherals.
Example: The hardware platform exposes an input/output memory management unit, such as VT-x (Intel) or AMD-V (AMD). This
feature needs to be enabled by default and can only be disabled by the owner of the hardware platform (not the user) [41].
REC-PHY-BP-3
Ensure the security hardware component quality.
Example: In case the platform embeds a TPM, the latter is certified (e.f. from a Common Criteria perspective according to the
Protection Profile TCG Protection Profile PC Client Specific TPM Family 2.0) [41].
Only the owner of the hardware platform (not the user) can enable and disable the TPM.
REC-PHY-BP-4
Ensure the hardening of the platform against persistent compromises.
Example: hardware platform firmwares are expected to ensure their integrity by means of state-of-the-art security mechanisms. This
notably includes protecting integrity of the code and data stored on the Flash Memory. The modification of firmware code should
only be the result of a legitimate, signed update using robust cryptographic protocols. The installation of a signed update older than
the version currently installed on the hardware platform shall be considered illegitimate by default. However, for the latter case, the
firmware configuration interface shall allow the platform owner to disable this protection.
REC-PHY-BP-5
Ensure the presence of minimal security features within the firmware (Low-level software components shipped with the hardware
platform, including UEFI and legacy BIOSes or hardware components embedded software).
Example: The firmware configuration interface provides the following features [41]:
• Protecting the access to the firmware configuration interface thanks to a dedicated password
• Locking the boot sequence of the platform thanks to a dedicated password
• Enabling and disabling input/output interfaces (e.g. USB)
• Configuring the boot order (the ordering of the list of devices checked by the BIOS to boot an operating system)
• Replacing default Secure Boot keys with custom keys generated by the owner
REC-PHY-BP-6 Allow for inspecting and auditing firmware code.
Example: Mechanisms which prevent firmware code inspection shall be absent or disabled by default.
REC-PHY-BP-7 Data centre physical security protections based on its location and such risk assessments, to determinate the structures, and data
centre support systems (sensors, video camera, alarms to a Security Operation Centre…)

15 https://www.cisecurity.org/controls/cis-controls-list/

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 55

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
REC-PHY-BP-8 Backup system in other area if needed.
REC-PHY-BP-9 Enforcing Multi-Factor Authentication for privileged users could be a mitigation.
REC-PHY-BP-10 Server cabinets fitted with an electronic lock.
REC-PHY-BP-11 Physical Access Control based system with video and entry logs system.
REC-PHY-BP-12 Sensors on the room or the cabinet to generate alarms to the Network / Security Operation Centre.
REC-PHY-BP-13 Limited number of physical interfaces on the on-board NIC of the server and remotely control NIC.
REC-PHY-BP-14 Secure All Endpoints (terminal, physical connectivity…).
REC-PHY-BP-15 Zero trust architecture with security layers including physical access and redundancies, with regular security audit if needed.
 1
This recommendation can help to mitigate: T-VM-C-03, T-VM-C-05, T-VL-02, T-OCAPI-01, T-HW-01, T-HW-02 2
 3
6.15 REC-RA Remote Attestation 4
Recommendation: A remote attestation (RA) approach should be used to determine the trustworthiness of O-Cloud 5
components. It is a defensive measure that address the malicious software execution. In O-Cloud it is obvious the need 6
for applying procedures to verify the integrity of the whole O-Cloud service deployment by the appropriate attestation 7
of the O-Cloud architectural elements, including software and firmware images and associated supporting security sub -8
systems that will run to instantiate individual VNFs/CNFs and their composition into a O -Cloud service. 9
 10
The remote attestation requires identifying the root(s) of trust, establishing a chain of trust for the  O-Cloud 11
infrastructure, the VL, VNFs/CNFs, and the NFO/FOCOM sub-systems, and verification of the trust chain, so the 12
NFO/FOCOM components can verifiably establish a sufficient level of assurance in the different software elements 13
constituting the VNFs/CNFs and the service(s) that use them. 14
 15
The remote attestation (RA) capabilities should be used to realize trust establishment in the following use case 16
scenarios: 17
1. Measurement of VM/Container during launch. 18
2. Protected VM/Container launch on a trusted O-Cloud platform 19
3. Measurement of VM/Container during launch and while in use 20
4. Remote attestation of secret storage 21
5. Secure VM/Container migration between two trusted O-Cloud platform 22
 23
Best practices to fulfill this recommendation: 24
 25
Req ID Description
REC-RA-BP-1 ETSI GR NFV-SEC 018 [13], [14], ETSI GR NFV-SEC 007 [15] could be used as a security guidance of the remote attestation
(RA) approach.
REC-RA-BP-2 All servers part of O-Cloud infrastructure should support measured boot and an attestation server that monitors the measurements of
the servers.
 26
Example: Operators might use RA to assess if the overall O-Cloud infrastructure is trustworthy, datacenters might use 27
RA to assess trustworthiness of subsystems they use, and management entities might use RA to assess the 28
trustworthiness of individual infrastructural components. Hence, there are numerous use-cases and scenarios that might 29
be considered where attestation is a fundamental step of creating an overall trustworthy system.  30
A trustworthy element is the entity which has a component that provides a unique identifier, certification (e.g. through 31
cryptographic signing) and which is able to store measurements and data about the state of that element (including 32
related sub-elements or dependent elements if necessary) in a tamperproof and verifiable form. For exam ple, the 33
TPM2.0 quoting mechanism using the TPMS_ATTEST data structure is an example of this.  34
 35
This recommendation can help to mitigate: T-GEN-03, T-VM-C-04, T-IMG-04, T-VL-02 36
 37

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 56

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
7 Risk Assessment 1
It will be provided in a future version of the report 2

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 57

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
Annex A (informative):  Best practices from some of existing 1
main security guidance 2
Operators, O-Cloud vendors and Cloud providers should ensure that O-Cloud components and interfaces are secure 3
under very strict set of security best practices. Such security guidance include: 4
• A.1  CISA/NSA Kubernetes security hardening best practices 5
• A.2  CIS Docker security best practices 6
• A.3  ONAP VNFs security best practices 7
A.1  CISA/NSA Kubernetes security hardening best practices 8
This section summarizes recommendations and best practices from the CISA/NSA Kubernetes Hardening Guidance. 9
The report details recommendations to harden Kubernetes systems. Primary actions include the scanning of containers 10
and Pods for vulnerabilities or misconfigurations, running containers and Pods with the least privileges possible, and 11
using network separation, firewalls, strong authentication, and log auditing. To ensure the security of applications, 12
system administrators should keep up to date with patches, updates, and upgrades to minimize risk. NSA and CISA also 13
recommend periodic reviews of Kubernetes settings and vulnerability scans to ensure appropriate risks are accounted 14
for and security patches are applied. 15
 16
Download the full Kubernetes Hardening Guidance: https://media.defense.gov/2021/Aug/03/2002820425/-1/-17
1/1/CTR_KUBERNETES%20HARDENING%20GUIDANCE.PDF 18
 19
Kubernetes Pod security 20
 21
Pods are the smallest deployable Kubernetes unit and consist of one or more containers. Pods are often a cyber actor’s 22
initial execution environment upon exploiting a container. For this reason, Pods should be hardened to make 23
exploitation more difficult and to limit the impact of a successful compromise.  24
 25
“Non-root” containers: Preventing root execution by using non-root containers limits the impact of a container 26
compromise. container engines allow containers to run applications as a non- root user with non-root group membership. 27
Typically, this non-default setting is configured when the container image is built. Having non-root execution integrated 28
at build time provides better assurance that applications will function correctly without root privileges. (See Appendix 29
A in [3]). 30
 31
Immutable container file systems: By default, containers are permitted mostly unrestricted execution within their own 32
context. A cyber actor who has gained execution in a container can create files, download scripts, and modify the 33
application within the container. Kubernetes can lock down a container’s file system, thereby preventing many post -34
exploitation activities. However, these limitations also affect legitimate container applications and can potentially result 35
in crashes or anomalous behavior. To prevent damaging legitimate applications, K ubernetes administrators can mount 36
secondary read/write file systems for specific directories where applications require write access. (See Appendix B in 37
[3]). 38
 39
Building secure container images: Container images are usually created by either building a container from scratch or 40
by building on top of an existing image pulled from a repository. In addition to using trusted repositories to build 41
containers, image scanning is key to ensuring deployed containers are secure. Throughout the container build workflow, 42
images should be scanned to identify outdated libraries, known vulnerabilities, or misconfigurations, such as insecure 43
ports or permissions. One approach to implementing image scanning is by using an admission controller [3]. This 44
admission controller could block deployments if the image doesn’t comply with the organization’s security policies 45
defined in the webhook configuration16. 46
 47
Hardening container engines: Some platforms and container engines provide additional options to harden the 48
containerized environments. A powerful example is the use of hypervisors to provide container isolation. Hypervisors 49
rely on hardware to enforce the virtualization boundary rather than the operating system. Hypervisor isolation is more 50
secure than traditional container isolation. Container engines running on the Windows operating system can be 51
configured to use the built-in Windows hypervisor, Hyper-V, to enhance security. Additionally, some security focused 52

16 The Linux Foundation, "11 Ways (Not) to Get Hacked," 18 07 2018 https://kubernetes.io/blog/2018/07/18/11-ways-not-to-get-hacked/#10- scan-
images-and-run-ids.

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 58

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
container engines natively deploy each container within a lightweight hypervisor for defense-in-depth. Hypervisor-1
backed containers mitigate container breakouts. 2
 3
Network separation and hardening 4
 5
Cluster networking is a central concept of Kubernetes. Communication between containers, Pods, services, and external 6
services must be taken into consideration. Resource separation and encryption can be an effective way to limit a cyber 7
actor’s movement and escalation within a cluster. 8
 9
Namespaces: Kubernetes namespaces are one way to partition cluster resources among multiple individuals, teams, or 10
applications within the same cluster (See [3] for more details). 11
 12
Network policies: Network policies control traffic flow between Pods, namespaces, and external IP addresses. By 13
default, no network policies are applied to Pods or namespaces, resulting in unrestricted ingress and egress traffic within 14
the Pod network. Pods become isolated through a network policy that applies to the Pod or the Pod’s namespace. Once 15
a Pod is selected in a network policy, it rejects any connections that are not specifically allowed by any applicable 16
policy object. (See Appendix E in [3] for more details). 17
 18
Resource policies: In addition to network policies, LimitRange and ResourceQuota are two policies that can limit 19
resource usage for namespaces or nodes. A LimitRange policy constrains individual resources per Pod or container 20
within a particular namespace, e.g., by enforcing maximum compute and storage resources. ResourceQuotas are 21
restrictions placed on the aggregate resource usage for an entire namespace, such as limits placed on total CPU and 22
memory usage. If a user tries to create a Pod that violates a LimitRange or ResourceQuota policy, the Pod creation fails. 23
(See Appendixes F and G in [3] for more details). 24
 25
Control plane hardening: The control plane is the core of Kubernetes and gives users the ability to view containers, 26
schedule new Pods, read Secrets, and execute commands in the cluster. Because of these sensitive capabilities, the 27
control plane should be highly protected. In addition to secure configurations such as TLS encryption, RBAC, and a 28
strong authentication method, network separation can help prevent unauthorized users from accessing the control plane. 29
The Kubernetes API server should be protected (e.g. by firewall, TLS encryption) and not be exposed to the Internet or 30
an untrusted network. 31
 32
Worker node segmentation: A worker node can be a virtual or physical machine, depending on the cluster’s 33
implementation. Because nodes run the microservices and host the web applications for the cluster, they are often the 34
target of exploits. If a node becomes compromised, an administrator should proactively limit the attack surface by 35
separating the worker nodes from other network segments that do not need to communicate with the worker nodes or 36
Kubernetes services. A firewall can be used to separate internal network segments from the external facing worker 37
nodes or the entire Kubernetes service depending on the network. Examples of services that may need to be separated 38
from the possible attack surface of the worker nodes are confidential databases or internal services that would not need 39
to be internet accessible. 40
 41
Encryption: Administrators should configure all traffic in the Kubernetes cluster—including between components, 42
nodes, and the control plane—to use TLS 1.2 or 1.3 encryption. Encryption can be set up during installation or 43
afterward using TLS bootstrapping, detailed in the Kubernetes documentation 17, to create and distribute certificates to 44
nodes. For all methods, certificates must be distributed amongst nodes to communicate securely. 45
Secrets: Kubernetes Secrets maintain sensitive information, such as passwords, OAuth tokens, SSH and TLS keys. 46
Secrets can be encrypted by configuring data-at-rest encryption on the API server or by using an external Key 47
Management Service (KMS), which may be available through a cloud provider. (See Appendixes H and I in [3] for 48
more details). 49
 50
Protecting sensitive cloud infrastructure: Kubernetes is often deployed on virtual machines in a cloud environment. As 51
such, administrators should carefully consider the attack surface of the virtual machines on which the Kubernetes 52
worker nodes are running. In many cases, Pods running on these virtual machines have access to sensitive cloud 53
metadata services on a non-routable address. These metadata services provide cyber actors with information about the 54
cloud infrastructure and possibly even short-lived credentials for cloud resources. Cyber actors abuse these metadata 55
services for privilege escalation. Kubernetes administrators should prevent Pods from accessing cloud metadata services 56
by using network policies or through the cloud configuration policy. Because these services vary based on the cloud 57
provider, administrators should follow vendor guidance to harden these access vectors.  58

17 https://kubernetes.io/docs/tasks/administer-cluster/securing-a-cluster/

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 59

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
 1
Authentication and authorization 2
 3
Authentication and authorization are the primary mechanisms to restrict access to cluster resources. Cyber actors can 4
scan for well-known Kubernetes ports and access the cluster’s database or make API calls without being authenticated 5
if the cluster is misconfigured. User authentication is not a built-in feature of Kubernetes. However, several methods 6
exist for administrators to add authentication to a cluster. 7
 8
Authentication: Kubernetes clusters have two types of users: service accounts and normal user accounts. Service 9
accounts handle API requests on behalf of Pods. Authentication is typically managed automatically by Kubernetes 10
through the ServiceAccount Admission Controller using bearer tokens. The bearer tokens are mounted into Pods at 11
well-known locations and can be used from outside the cluster if the tokens are left unsecured. Because of this, access 12
to Pod Secrets should be restricted to those with a need to view them using K ubernetes RBAC. For normal users and 13
admin accounts, there is no automatic authentication method for users. Administrators must add an authentication 14
method to the cluster to implement authentication and authorization mechanisms. The Kubernetes documentati on18 lists 15
several ways to implement user authentication including client certificates, bearer tokens, authentication plugins, and 16
other authentication protocols. At least one user authentication method should be implemented. Administrators should 17
not use weak methods such as static password files. Weak authentication methods could allow cyber actors to 18
authenticate as legitimate users.  19
 20
Role-based access control: RBAC is one method to control access to cluster resources based on the roles of individuals 21
within an organization. RBAC is enabled by default in Kubernetes version 1.6 and newer. Privileges assigned to users, 22
groups, and service accounts should follow the principle of least privilege, giving only required permissions to 23
resources. Users or user groups can be limited to particular namespaces where required resources reside. By default, a 24
service account is created for each namespace for Pods to access the Kubernetes API. RBAC policies can be used to 25
specify allowed actions from the service accounts in each namespace. Access to the Kubernetes API is limited by 26
creating an RBAC Role or ClusterRole with the appropriate API request verb and desired resource on which the action 27
can be applied. Tools exist that can help audit RBAC policies by printing use rs, groups, and service accounts with their 28
associated assigned Roles and ClusterRoles. (See Appendixes J and K in [3] for more details).  29
 30
Log auditing 31
Logs capture activity in the cluster. Auditing logs is necessary, not only for ensuring that services ar e operating and 32
configured as intended, but also for ensuring the security of the system. Systematic audit requirements mandate 33
consistent and thorough checks of security settings to help identify compromises. Kubernetes is capable of capturing 34
audit logs for cluster actions and monitoring basic CPU and memory usage information; however, it does not natively 35
provide in-depth monitoring or alerting services. 36
 37
Logging: System administrators running applications within Kubernetes should establish an effective logging, 38
monitoring, and alerting system for their environment. Logging Kubernetes events alone is not enough to provide a full 39
picture of the actions occurring on the system. Logging should also be performed at the host level, application level,  and 40
on the cloud if applicable. These logs can then be correlated with any external authentication and system logs as 41
applicable to provide a full view of the actions taken throughout the environment for use by security auditors and 42
incident responders. Within the Kubernetes environment, administrators should monitor/log the following:  43
• API request history 44
• Performance metrics 45
• Deployments 46
• Resource consumption 47
• Operating system calls 48
• Protocols, permission changes 49
• Network traffic 50
• Pod scaling 51
When a Pod is created or updated, administrators should capture detailed logs of the network communications, response 52
times, requests, resource consumption, and any other relevant metrics to establish a baseline.  53
RBAC policy configurations should be audited periodically and whenever changes occur to the organization’s system 54
administrators. 55
Audits of internal and external traffic logs should be conducted to ensure all intended security constraints on 56
connections have been configured properly and are working as intended. 57

18 https://kubernetes.io/docs/reference/access-authn-authz/authentication

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 60

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
Logs can be streamed to an external logging service to ensure availability to security professionals outside of the 1
cluster, identify abnormalities as close to real time as possible, and protect logs from being deleted if a compromise 2
occurs. If using this method, logs should be encrypted during transit with TLS 1.2 or 1.3 to ensure cyber actors cannot 3
access the logs in transit and gain valuable information about the environment. (See Appendixes L and M in [3] for 4
more details). 5
 6
SIEM platforms: Security Information and Event Management (SIEM) software collects logs from across an 7
organization’s network. SIEM software brings together firewall logs, application logs, and more; parsing them out to 8
provide a centralized platform from which analysts can monitor system security. SIEM tools have variations in their 9
capabilities. Generally, these platforms provide log collection, threat detection, and alerting capabilities. Some include 10
machine learning capabilities, which can better predict system behavior and help to reduce false alerts. Organizations 11
using these platforms in their environment can integrate them with Kubernetes to better monitor and secure clusters. 12
Open-source platforms for managing logs from a Kubernetes environment exist as an alternative to SIEM pl atforms. 13
 14
Alerting: Kubernetes does not natively support alerting; however, several monitoring tools with alerting capabilities are 15
compatible with Kubernetes. If Kubernetes administrators choose to configure an alerting tool to work within a 16
Kubernetes environment, there are several metrics for which administrators should monitor and configure alerts. 17
Examples of cases that could trigger alerts include but are not limited to: 18
• Low disk space on any of the machines in the environment, 19
• Available storage space on a logging volume running low, 20
• External logging service going offline, 21
• A Pod or application running with root permissions, 22
• An anonymous account being used or gaining privileges, 23
• Unusual system calls or failed API calls,  24
• user/admin behavior that is abnormal (i.e. at unusual times or from an unusual location), and  25
• Significant deviations from the standard operation metrics baseline.  26
 27
Service meshes: Service meshes are platforms that streamline microservice communications within an application by 28
allowing for the logic of these communications to be coded into the service mesh rather than within each microservice. 29
Coding this communication logic into individual microservices is difficult to scale, difficult to debug as failures occur, 30
and difficult to secure. Using a service mesh can simplify this for developers. The mesh can:  31
• Redirect traffic when a service is down, 32
• Gather performance metrics for optimizing communications, 33
• Allow management of service-to-service communication encryption, 34
• Collect logs for service-to-service communication, 35
• Collect logs from each service, and 36
• Help developers diagnose problems and failures of microservices or communication mechanisms.  37
 38
Fault tolerance: Fault tolerance policies should be put in place to ensure logging service availability. One policy that 39
can be put in place is to allow new logs to overwrite the oldest log files if absolutely necessary in the event of storage 40
capacity being exceeded. If logs are being sent to an external service, a mechanism sho uld be in place for logs to be 41
stored locally if a communication loss or external service failure occurs. Once communication to the external service is 42
restored, a policy should be in place for the locally stored logs to be pushed up to the external server . 43
 44
Tools: Kubernetes does not include extensive auditing capabilities. However, the system is built to be extensible, 45
allowing users the freedom to develop their own custom solution or to choose an existing add- on that suits their needs. 46
One of the most common solutions is to add additional audit backend services, which can use the information logged by 47
Kubernetes and perform additional functions for users, such as extended search parameters, data mapping features, and 48
alerting functionality. Organizations that already use SIEM platforms can integrate Kubernetes with these existing 49
capabilities. Open-source monitoring tools—such as the Cloud Native Computing Foundation’s Prometheus, Grafana 50
Labs’ Grafana, and Elasticsearch’s Elastic Stack (ELK) —are available to conduct event monitoring, run threat 51
analytics, manage alerting, and collect resource isolation parameters, historical usage, and network statistics on running 52
containers. Scanning tools can be useful when auditing the access control and permission configurations by assisting in 53
identifying risky permission configurations in RBAC. NSA and CISA encourage organizations utilizing Intrusion 54
Detection Systems (IDSs) on their existing environment to consider integrating that service into their Kubernetes 55
environment as well. This integration would allow an organization to monitor for—and potentially kill containers 56
showing signs of—unusual behavior so the containers can be restarted from the initial clean image. Many cloud service 57
providers also provide container monitoring services for those wanting more managed and scalable solutions. 58
 59
Upgrading and application security practices 60

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 61

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
 1
Security of applications running on Kubernetes orchestrated containers is an ongoing process, and it is vital to keep up 2
with patches, updates, and upgrades. The specific software components vary depending on the individual configuration, 3
but each piece of the overall system should be kept as secure as possible. This includes updating: Kubernetes, 4
hypervisors, virtualization software, plugins, operating systems on which the environment is running, applications 5
running on the servers, and any other software hosted in the Kubernetes environment.  6
The Center for Internet Security (CIS) publishes benchmarks for securing software. Administ rators should adhere to the 7
CIS benchmarks for Kubernetes and any other relevant system components. Administrators should check periodically to 8
ensure their system's security is compliant with the current security experts’ consensus on best practices. Peri odic 9
vulnerability scans and penetration tests should be performed on the various system components to proactively look for 10
insecure configurations and zero-day vulnerabilities. Any discoveries should be promptly remediated before potential 11
cyber actors can discover and exploit them. 12
As updates are deployed, administrators should also keep up with removing any old components that are no longer 13
needed from the environment. Using a managed Kubernetes service can help to automate upgrades and patches for 14
Kubernetes, operating systems, and networking protocols. However, administrators must still patch and upgrade their 15
containerized applications. 16
A.2  CIS Docker security best practices  17
CIS Benchmarks are universal security best practices developed by cybersecurity p rofessionals and experts. Each CIS 18
Benchmark provides guidelines for creating a secure system configuration. The following table summarizes 19
recommendations from the CIS Docker Community Edition Benchmark, specifying how to set up a safe docker 20
configuration. 21
 22
Download the full CIS Docker Benchmark: https://www.cisecurity.org/benchmark/docker/  23
 24
Host Configuration 25
 26
Create a separate partition for containers 27
• Harden the container host 28
• Update your Docker software on a regular basis 29
• Manage Docker daemon access authorization wisely 30
• Configure your Docker files directories, and 31
• Audit all Docker daemon activity. 32
 33
Docker Daemon Configuration 34
 35
• Restrict network traffic between default bridge containers and access to new privileges from containers.  36
• Enable user namespace support to provide additional, Docker client commands authorization, live r estore, and 37
default cgroup usage 38
• Disable legacy registry operations and Userland Proxy 39
• Avoid networking misconfiguration by allowing Docker to make changes to iptables, and avoid experimental 40
features during production. 41
• Configure TLS authentication for Docker daemon and centralized and remote logging. 42
• Set the logging level to 'info', and set an appropriate default ulimit 43
• Don’t use insecure registries and aufs storage drivers 44
• Apply base device size for containers and a daemon-wide custom SECCOMP profile to limit calls. 45
 46
Container Images and Build File 47
 48
• Create a user for the container 49
• Ensure containers use only trusted images 50
• Ensure unnecessary packages are not installed in the container 51
• Include security patches during scans and rebuilding processes 52
• Enable content trust for Docker 53
• Add HEALTHCHECK instructions to the container image 54
• Remove setuid and setgid permissions from the images 55
• Use COPY is instead of ADD in Dockerfile 56
• Install only verified packages 57

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 62

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
• Don’t use update instructions in a single line or alone in the Dockerfile 1
• Don’t store secrets in Dockerfiles 2
 3
Container Runtime 4
 5
• Restrict containers from acquiring additional privileges and restrict Linux Kernel Capabilities.  6
• Enable AppArmor Profile. 7
• Avoid use of privileged containers during runtime, running ssh within containers, mapping privileged ports 8
within containers. 9
• Ensure sensitive host system directories aren’t mounted on containers, the container's root filesystem is 10
mounted as read-only, the Docker socket is not mounted inside any containers. 11
• Set appropriate CPU priority for the container, set 'on-failure' container restart policy to '5', and open only 12
necessary ports on the container. 13
• Apply per need SELinux security options, and overwrite the default ulimit at runtime.  14
• Don’t share the host's network namespace and the host's process namespace, the host's IPC namespace, mount 15
propagation mode, the host's UTS namespace, the host's user namespaces. 16
• Limit memory usage for container and bind incoming container traffic to a specific host interface.  17
• Don’t expose host devices directly to containers, don’t disable the default SECCOMP profile, don’t use docker 18
exec commands with privileged and user option, and don’t use Docker's default bridge docker0.  19
• Confirm cgroup usage and use PIDs cgroup limit, check container health at runtime, and always update docker 20
commands with the latest version of the image. 21
 22
Docker Security Operations 23
 24
• Avoid image sprawl and container sprawl. 25
 26
Docker Swarm Configuration 27
 28
• Enable swarm mode only if needed 29
• Create a minimum number of manager nodes in a swarm 30
• Bind swarm services are bound to a specific host interface 31
• Encrypt containers data exchange on different overlay network nodes 32
• Manage secrets in a Swarm cluster with Docker's secret management commands 33
• Run swarm manager in auto-lock mode 34
• Rotate swarm manager auto-lock key periodically 35
• Rotate node and CA certificates as needed 36
• Separate management plane traffic from data plane traffic 37
 38
A.3  ONAP VNFs security best practices 39
ONAP provides details on the VNF general security requirements on various security areas such as user access control, 40
network security, ACLs, infrastructure security, and vulnerability management. These requirements cover topics 41
associated with compliance, security patching, logging/accounting, authentication, encryption, role -based access 42
control, least privilege access/authorization. This section summarizes requirements from ONAP, specifying how to 43
integrate and operateVNFs within a robust security environment. 44
 45
For more details see the full documentation: https://docs.onap.org/projects/onap-vnfrqts-46
requirements/en/latest/index.html 47
 48
VNF General Security Requirements 49
 50
This section provides details on the VNF general security requirements on various security areas such as user access 51
control, network security, ACLs, infrastructure security, and vulnerability management. These requirements cover 52
topics associated with compliance, security patching, logging/accounting, authentication, encryption, role -based access 53
control, least privilege access/authorization. The following security requirements need to be met by the O -RAN NFs in 54
a virtual environment: 55
1. The VNF must implement and enforce the principle of least privilege on all protected interfaces. 56
2. The VNF must provide a mechanism (e.g., access control list) to permit and/or restrict access to services on the 57
VNF by source, destination, protocol, and/or port. 58

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 63

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
3. The VNF should provide a mechanism that enables the operators to perform automated system configuration 1
auditing at configurable time intervals. 2
4. The VNF provider must follow GSMA vendor practices and SEI CERT Coding Standards when developing 3
the VNF in order to minimize the risk of vulnerabilities. See GSMA NESAS Network Equipment Security 4
Assurance Scheme – Development and Lifecycle Security Requirements Version 1.0 (https://www.gsma.com/ 5
security/wp-content/uploads/2019/11/FS.16-NESAS-Development-and-Lifecycle-Security- Requirements-6
v1.0.pdf) and SEI CERT Coding Standards (https://wiki.sei.cmu.edu/ 7
confluence/display/seccode/SEI+CERT+Coding+Standards). 8
5. The VNF must have all code (e.g., QCOW2) and configuration files (e.g., HEAT template, Ansible playbook, 9
script) hardened, or with documented recommended configurations for hardening and interfaces that allow the 10
Operator to harden the VNF. Actions taken to harden a system include disabling all unnecessary services, and 11
changing default values such as default credentials and community strings. 12
6. The VNF should support the separation of (1) signaling and payload traffic (i.e., customer facing traffic), (2) 13
operations, administration and management traffic, and (3) internal VNF traffic (i.e., east -west traffic such as 14
storage access) using technologies such as VPN and VLAN. 15
7. The VNF Provider must have patches available for vulnerabilities in the VNF as soon as possible. Patching 16
shall be controlled via change control process with vulnerabilities disclosed along with mitigati on 17
recommendations. 18
8. The VNF must support only encrypted access protocols, e.g., TLS 1.2/1.3. 19
9. The VNF must store authentication credentials used to authenticate to other systems encrypted except where 20
there is a technical need to store the password unencrypted in which case it must be protected using other 21
security techniques that include the use of file and directory permissions. Ideally, credentials should rely on a 22
HW Root of Trust, such as a TPM or HSM. 23
10. VNFs that are subject to regulatory requirements must provide functionality that enables the Operator to 24
comply with ETSI TC LI requirements, and, optionally, other relevant national equivalents.  25
11. The VNF must be able to authenticate and authorize all remote access. 26
12. The VNF must log any security event required by the VNF Requirements to Syslog using LOG_AUTHPRIV 27
for any event that would contain sensitive information and LOG_AUTH for all other relevant events.  28
13. If SNMP is utilized, the VNF must support at least SNMPv3 with message authentication.  29
14. The VNF application processes should not run as root. If a VNF application process must run as root, the 30
technical reason must be documented. 31
15. Login access (e.g., shell access) to the virtualization layer, whether interactive or as part of an automated 32
process, must be through an encrypted protocol such as TLS 1.2/1.3. 33
16. The VNF must include a configuration (e.g. a template) that specifies the targeted parameters (e.g. a limited set 34
of ports) over which the VNF will communicate; including internal, external and management communication.  35
17. Containerized components of VNFs should follow the recommendations for Container Base Images and Build 36
File Configuration in the latest available version of the CIS Docker Community Edition Benchmarks to ensure 37
that containerized VNFs are secure. All non-compliances with the benchmarks must be documented. 38
18. Containerized components of VNFs should execute in a Docker run-time environment that follows the 39
Container Runtime Configuration in the latest available version of the CIS Docker Community Edition 40
Benchmarks to ensure that containerized VNFs are secure. All non-compliances with the benchmarks must be 41
documented. 42
 43
VNF Identity and Access Management Requirements 44
 45
The following security requirements for logging, identity, and access management need to be met by the O -RAN NFs in 46
a virtual environment: 47
1. The VNF must, if not integrated with the Operator’s Identity and Access Management system, support the 48
creation of multiple IDs so that individual accountability can be supported. 49
2. The VNF must, if not integrated with the operator’s IAM system, provide a mechanism for assigning roles 50
and/or permissions to an identity. 51
3. The VNF must, if not integrated with the Operator’s Identity and Access Management system, support 52
multifactor authentication on all protected interfaces exposed by the VNF for use by human users. 53
4. The VNF must support account names that contain at least A-Z, a-z, and 0–9-character sets and be at least 6 54
characters in length. 55
5. The VNF must, if not integrated with the Operator’s Identity and Access Management system, comply with 56
“password complexity” policy and support configurable password expiration. When passwords are used, they 57
shall be complex and shall at least meet the following password construction requirements: (1) be a m inimum 58
configurable number of characters in length, (2) include 3 of the 4 following types of characters: upper -case 59
alphabetic, lower-case alphabetic, numeric, and special, (3) not be the same as the UserID with which they are 60
associated or other common strings as specified by the environment, (4) not contain repeating or sequential 61

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 64

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
characters or numbers, (5) not to use special characters that may have command functions, and (6) new 1
passwords must not contain sequences of three or more characters from the previous password. 2
6. The VNF must allow the Operator to restrict access to protected resources based on the assigned permissions 3
associated with an ID in order to support Least Privilege (no more privilege than required to perform job 4
functions). 5
7. The VNF must set the default settings for user access to deny authorization, except for a super user type of 6
account. 7
8. The VNF must not store authentication credentials to itself in clear text or any reversible form and must use 8
salting. 9
9. The VNF must, if not integrated with the Operator’s Identity and Access Management system, support the 10
ability to lock out the userID after a configurable number of consecutive unsuccessful authentication attempts 11
using the same userID. The locking mechanism must be reversible by an administrator and should be 12
reversible after a configurable time period. 13
10. The VNF must, if not integrated with the Operator’s identity and access management system, authenticate all 14
access to protected resources. 15
11. The VNF must support LDAP in order to integrate with an external identity and access manage system. It 16
MAY support other identity and access management protocols. 17
12. The VNF must not identify the reason for a failed authentication, only that the authentication failed.  18
13. The VNF must provide a means to explicitly logout, thus ending that session. 19
14. The VNF must provide explicit confirmation of a session termination such as a message, new page, or 20
rerouting to a login page. 21
15. The VNF must, if not integrated with the Operator’s Identity and Access Management syste m, enforce a 22
configurable “terminate idle sessions” policy by terminating the session after a configurable period of 23
inactivity. 24
 25
VNF API Security Requirements 26
 27
This section covers API security requirements when these are used by the VNFs. Key security are as covered in API 28
security are Access Control, Authentication, Passwords, PKI Authentication Alarming, Anomaly Detection, Lawful 29
Intercept, Monitoring and Logging, Input Validation, Cryptography, Business continuity, Biometric Authentication, 30
Identification, Confidentiality and Integrity, and Denial of Service. 31
 32
The O-RAN NFs in a virtual environment needs to meet the following API security requirements:  33
1. The VNF should integrate with the Operator’s authentication and authorization services (e.g., IDAM).  34
2. The VNF must implement the following input validation control: Check the size (length) of all input. Do not 35
permit an amount of input so great that it would cause the VNF to fail. Where the input may be a file, the VNF 36
API must enforce a size limit. 37
3. The VNF must implement the following input validation controls: Do not permit input that contains content or 38
characters inappropriate to the input expected by the design. Inappropriate input, such as SQL expressions, 39
may cause the system to execute undesirable and unauthorized transactions against the database or allow other 40
inappropriate access to the internal network (injection attacks). 41
4. The VNF must implement the following input validation control on APIs: Validate that any input file has a 42
correct and valid Multipurpose Internet Mail Extensions (MIME) type. Input files should be tested for spoofed 43
MIME types. 44
 45
VNF Security Analytics Requirements 46
 47
This section covers VNF security analytics requirements that are mostly applicable to security monitoring. The VN F 48
Security Analytics cover the collection and analysis of data following key areas of security monitoring:  49
 50
• Anti-virus software 51
• Logging 52
• Data capture 53
• Tasking 54
• DPI 55
• API based monitoring 56
• Detection and notification 57
• Resource exhaustion detection 58
• Proactive and scalable monitoring 59
• Mobility and guest VNF monitoring 60

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 65

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
• Closed loop monitoring 1
• Interfaces to management and orchestration 2
• Malformed packet detections 3
• Service chaining 4
• Dynamic security control 5
• Dynamic load balancing 6
• Connection attempts to inactive ports (malicious port scanning) 7
 8
The following requirements of security monitoring need to be met by the O -RAN NFs in a virtual environment. 9
1. The VNF must support Real-time detection and notification of security events. 10
2. The VNF must support API-based monitoring to take care of the scenarios where the control interfaces are not 11
exposed or are optimized and proprietary in nature. 12
3. The VNF must support detection of malformed packets due to software misconfiguration or softwar e 13
vulnerability and generate an error to the syslog console facility. 14
4. The VNF must support proactive monitoring to detect and report the attacks on resources so that the VNFs and 15
associated VMs can be isolated, such as detection techniques for resource exh austion, namely OS resource 16
attacks, CPU attacks, consumption of kernel memory, local storage attacks. 17
5. The VNF should operate with anti-virus software which produces alarms every time a virus is detected. 18
6. The VNF must protect all security audit logs (including API, OS and application-generated logs), security 19
audit software, data, and associated documentation from modification, or unauthorized viewing, by standard 20
OS access control mechanisms, by sending to a remote system, or by encryption.  21
7. The VNF must log successful and unsuccessful authentication attempts, e.g., authentication associated with a 22
transaction, authentication to create a session, authentication to assume elevated privilege.  23
8. The VNF must log logoffs. 24
9. The VNF must log starting and stopping of security logging. 25
10. The VNF must log success and unsuccessful creation, removal, or change to the inherent privilege level of 26
users. 27
11. The VNF must log connections to the network listeners of the resource. 28
12. he VNF must log the field “event type” in the security audit logs. 29
13. The VNF must log the field “date/time” in the security audit logs. 30
14. The VNF must log the field “protocol” in the security audit logs. 31
15. The VNF must log the field “service or program used for access” in the security audit logs.  32
16. The VNF must log the field “success/failure” in the security audit logs. 33
17. The VNF must log the field “Login ID” in the security audit logs. 34
18. The VNF must not include an authentication credential, e.g., password, in the security audit logs, even if 35
encrypted. 36
19. The VNF must detect when its security audit log storage medium is approaching capacity (configurable) and 37
issue an alarm. 38
20. The VNF must support the capability of online storage of security audit logs. 39
21. The VNF must activate security alarms automatically when a configurable n umber of consecutive unsuccessful 40
login attempts is reached. 41
22. The VNF must activate security alarms automatically when it detects the successful modification of a critical 42
system or application file. 43
23. The VNF must activate security alarms automatically when it detects an unsuccessful attempt to gain 44
permissions or assume the identity of another user. 45
24. The VNF must include the field “date” in the Security alarms (where applicable and technically feasible).  46
25. The VNF must include the field “time” in the Security alarms (where applicable and technically feasible). 47
26. The VNF must include the field “service or program used for access” in the Security alarms (where applicable 48
and technically feasible). 49
27. The VNF must include the field “success/failure” in the Security alarms (where applicable and technically 50
feasible). 51
28. The VNF must include the field “Login ID” in the Security alarms (where applicable and technically feasible).  52
29. The VNF must restrict changing the criticality level of a system security alarm to users with administrative 53
privileges. 54
30. The VNF must monitor API invocation patterns to detect anomalous access patterns that may represent 55
fraudulent access or other types of attacks or integrate with tools that implement anomaly and abuse detection. 56
31. The VNF must generate security audit logs that can be sent to Security Analytics Tools for analysis. 57
32. The VNF must log successful and unsuccessful access to VNF resources, including data.  58
33. The VNF must support the storage of security audit logs for a configurable period of t ime. 59

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 66

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
34. The VNF must have security logging for VNFs and their OSs be active from initialization. Audit logging 1
includes automatic routines to maintain activity records and cleanup programs to ensure the integrity of the 2
audit/logging systems. 3
35. The VNF must be implemented so that it is not vulnerable to OWASP Top 10 web application security risks.  4
36. The VNF must protect against all denial-of-service attacks, both volumetric and non-volumetric, or integrate 5
with external denial of service protection tools. 6
37. The VNF must be capable of automatically synchronizing the system clock daily with the Operator’s trusted 7
time source, to assure accurate time reporting in log files. It is recommended that Coordinated Universal Time 8
(UTC) be used where possible, so as to eliminate ambiguity owing to daylight savings time.  9
38. The VNF must log the Source IP address in the security audit logs. 10
39. The VNF must have the capability to securely transmit the security logs and security events to a remote system 11
before they are purged from the system. 12
40. The VNF should provide the capability of maintaining the integrity of its static files using a cryptographic 13
method. 14
41. The VNF must log automated remote activities performed with elevated privileges. 15
 16
VNF Data Protection Requirements 17
 18
This section covers VNF data protection requirements that are mostly applicable to security monitoring.  19
1. The VNF MUST provide the capability to restrict read and write access to data handled by the VNF. 20
2. The VNF MUST Provide the capability to encrypt data in transit on a physical or virtual network.  21
3. The VNF MUST provide the capability to encrypt data on non-volatile memory. Non-volative memory is 22
storage that is capable of retaining data without electrical power, e.g. Complementary metal -oxide-23
semiconductor (CMOS) or hard drives. 24
4. The VNF SHOULD disable the paging of the data requiring encryption, if possible, where the encryption of 25
non-transient data is required on a device for which the operating system performs paging to virtual memory. 26
If not possible to disable the paging of the data requiring encryption, the virtual memory should be encrypted.  27
5. The VNF MUST use NIST and industry standard cryptographic algori thms and standard modes of operations 28
when implementing cryptography. 29
6. The VNF MUST NOT use compromised encryption algorithms. For example, SHA, DSS, MD5, SHA -1 and 30
Skipjack algorithms. Acceptable algorithms can be found in the NIST FIPS publications 31
(https://csrc.nist.gov/publications/fips) and in the NIST Special Publications 32
(https://csrc.nist.gov/publications/sp). 33
7. The VNF MUST use, whenever possible, standard implementations of security applications, protocols, and 34
formats, e.g., S/MIME, TLS, SSH, IPSec, X.509 digital certificates for cryptographic implementations. These 35
implementations must be purchased from reputable vendors or obtained from reputable open source 36
communities and must not be developed in-house. 37
8. The VNF MUST provide the ability to migrate to newer versions of cryptographic algorithms and protocols 38
with minimal impact. 39
9. The VNF MUST support digital certificates that comply with X.509 standards. 40
10. The VNF MUST NOT use keys generated or derived from predictable functions or values, e.g., values 41
considered predictable include user identity information, time of day, stored/transmitted data.  42
11. The VNF MUST provide the capability of using X.509 certificates issued by an external Certificate Authority.  43
12. The VNF MUST be capable of protecting the confidentiality and integrity of data at rest and in transit from 44
unauthorized access and modification. 45
 46
VNF Cryptography Requirements 47
 48
This section covers VNF cryptography requirements that are mostly applicable to encryption or protocol methods.  49
1. The VNF SHOULD support an automated certificate management protocol such as CMPv2, Simple Certificate 50
Enrollment Protocol (SCEP) or Automated Certificate Management Environment (ACME).  51
2. The VNF SHOULD provide the capability to integrate with an external encryption service.  52
3. The VNF MUST use symmetric keys of at least 112 bits in length. 53
4. The VNF MUST use asymmetric keys of at least 2048 bits in length. 54
5. The VNF MUST provide the capability to configure encryption algorithms or devices so that they comply with 55
the laws of the jurisdiction in which there are plans to use data encryption. 56
6. The VNF MUST provide the capability of allowing certificate renewal and revocation.  57
7. The VNF MUST provide the capability of testing the validity of a digital certificate by validating the CA 58
signature on the certificate. 59
8. The VNF MUST provide the capability of testing the validity of a digital certificate by validating the date the 60
certificate is being used is within the validity period for the certificate. 61

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 67

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
9. The VNF MUST provide the capability of testing the validity of a digital certificate by checking the Certificate 1
Revocation List (CRL) for the certificates of that type to ensure that the certificate has not been revoked.  2
10. The VNF MUST provide the capability of testing the validity of a digital certificate by recognizing the identity 3
represented by the certificate - the “distinguished name”. 4
11. The VNF MUST support HTTPS using TLS v1.2 or higher with strong cryptographic ciphers.  5
12. The VNF MUST support the use of X.509 certificates issued from any Certificate Authority (CA) that is 6
compliant with RFC5280, e.g., a public CA such as DigiCert or Let’s Encrypt, or an RFC5280 compliant 7
Operator CA. 8
 9
Note: The VNF provider cannot require the use of self-signed certificates in an Operator’s run time environment. 10
 11

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 68

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
Annex ZZZ : O-RAN Adopter License Agreement 1
BY DOWNLOADING, USING OR OTHERWISE ACCESSING ANY O- RAN SPECIFICATION, ADOPTER 2
AGREES TO THE TERMS OF THIS AGREEMENT. 3
This O-RAN Adopter License Agreement (the “Agreement”) is made by and between the O -RAN Alliance and the 4
entity that downloads, uses or otherwise accesses any O-RAN Specification, including its Affiliates (the “Adopter”). 5
This is a license agreement for entities who wish to adopt any O-RAN Specification. 6
Section 1: DEFINITIONS 7
1.1 “Affiliate” means an entity that directly or indirectly controls, is controlled by, or is under common control with 8
another entity, so long as such control exists. For the purpose of this Section, “Control” means beneficial ownership of 9
fifty (50%) percent or more of the voting stock or equity in an entity. 10
1.2 “Compliant Implementation” means any system, device, method or operation (whether implemented in hardware, 11
software or combinations thereof) that fully conforms to a Final Specification. 12
1.3 “Adopter(s)” means all entities, who are not Members, Contributors or Academic Contributors, including their 13
Affiliates, who wish to download, use or otherwise access O-RAN Specifications. 14
1.4 “Minor Update” means an update or revision to an O-RAN Specification published by O-RAN Alliance that does 15
not add any significant new features or functionality and remains interoperable with the prior version of an O-RAN 16
Specification. The term “O-RAN Specifications” includes Minor Updates. 17
1.5 “Necessary Claims” means those claims of all present and future patents and patent applications, other than design 18
patents and design registrations, throughout the world, which (i) are owned or otherwise licensable by a Member, 19
Contributor or Academic Contributor during the term of its Member, Contributor or Academic Contributorship; (ii) 20
such Member, Contributor or Academic Contributor has the right to grant a license without the payment of 21
consideration to a third party; and (iii) are necessarily infringed by a Compliant Implementation (without considering 22
any Contributions not included in the Final Specification). A claim is necessarily infringed only when it is not possible 23
on technical (but not commercial) grounds, taking into account normal technical practice and the state of the art 24
generally available at the date any Final Specification was published by the O -RAN Alliance or the date the patent 25
claim first came into existence, whichever last occurred, to make, sell, lease, otherwise dispose of, repair, use or operate 26
a Compliant Implementation without infringing that claim. For the avoidance of doubt in exceptional cases where a 27
Final Specification can only be implemented by technical solutions, all of which infringe patent claims, all such patent 28
claims shall be considered Necessary Claims. 29
1.6 “Defensive Suspension” means for the purposes of any license grant pursuant to Section 3, Member, Contributor, 30
Academic Contributor, Adopter, or any of their Affiliates, may have the discretion to include in their license a term 31
allowing the licensor to suspend the license against a licensee who brings a patent infringeme nt suit against the 32
licensing Member, Contributor, Academic Contributor, Adopter, or any of their Affiliates.  33
Section 2: COPYRIGHT LICENSE 34
2.1 Subject to the terms and conditions of this Agreement, O-RAN Alliance hereby grants to Adopter a nonexclusive, 35
nontransferable, irrevocable, non-sublicensable, worldwide copyright license to obtain, use and modify O-RAN 36
Specifications, but not to further distribute such O-RAN Specification in any modified or unmodified way, solely in 37
furtherance of implementations of an O-RAN 38
Specification. 39
2.2 Adopter shall not use O-RAN Specifications except as expressly set forth in this Agreement or in a separate written 40
agreement with O-RAN Alliance. 41

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 69

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
Section 3: FRAND LICENSE 1
3.1 Members, Contributors and Academic Contributors and their Affiliates are prepared to grant based on a separate 2
Patent License Agreement to each Adopter under Fair Reasonable And Non - Discriminatory (FRAND) terms and 3
conditions with or without compensation (royalties) a nonexclusive, non-transferable, irrevocable (but subject to 4
Defensive Suspension), non-sublicensable, worldwide patent license under their Necessary Claims to make, have made, 5
use, import, offer to sell, lease, sell and otherwise distribute Compliant Implementations; provided, however, that s uch 6
license shall not extend: (a) to any part or function of a product in which a Compliant Implementation is incorporated 7
that is not itself part of the Compliant Implementation; or (b) to any Adopter if that Adopter is not making a reciprocal 8
grant to Members, Contributors and Academic Contributors, as set forth in Section 3.3. For the avoidance of doubt, the 9
foregoing licensing commitment includes the distribution by the Adopter’s distributors and the use by the Adopter’s 10
customers of such licensed Compliant Implementations. 11
3.2 Notwithstanding the above, if any Member, Contributor or Academic Contributor, Adopter or their Affiliates has 12
reserved the right to charge a FRAND royalty or other fee for its license of Necessary Claims to Adopter, then Adopter 13
is entitled to charge a FRAND royalty or other fee to such Member, Contributor or Academic Contributor, Adopter and 14
its Affiliates for its license of Necessary Claims to its licensees. 15
3.3 Adopter, on behalf of itself and its Affiliates, shall be prepared to grant based on a separate Patent License 16
Agreement to each Members, Contributors, Academic Contributors, Adopters and their Affiliates under Fair 17
Reasonable And Non-Discriminatory (FRAND) terms and conditions with or without compensation (royalties) a 18
nonexclusive, non-transferable, irrevocable (but subject to Defensive Suspension), non-sublicensable, worldwide patent 19
license under their Necessary Claims to make, have made, use, import, offer to sell, lease, sell and otherwise distribute 20
Compliant Implementations; provided, however, that such license will not extend: (a) to any part or function of a 21
product in which a Compliant Implementation is incorporated that is not itself part of the Compliant Implementation; or 22
(b) to any Members, Contributors, Academic Contributors, Adopters and their Affiliates that is not making a reciprocal 23
grant to Adopter, as set forth in Section 3.1. For the avoidance of doubt, the foregoing licensing commitment includes 24
the distribution by the Members’, Contributors’, Academic Contributors’, Adopters’ and their Affiliates’ distributors 25
and the use by the Members’, Contributors’, Academic Contributors’, Adopters’ and their Affiliates’ customers of such 26
licensed Compliant Implementations. 27
Section 4: TERM AND TERMINATION 28
4.1 This Agreement shall remain in force, unless early terminated according to this Section 4.  29
4.2 O-RAN Alliance on behalf of its Members, Contributors and Academic Contributors may terminate this Agreement 30
if Adopter materially breaches this Agreement and does not cure or is not capable of curing such breach within thirty 31
(30) days after being given notice specifying the breach. 32
4.3 Sections 1, 3, 5 - 11 of this Agreement shall survive any termination of this Agreement. Under surviving Section 3, 33
after termination of this Agreement, Adopter will continue to grant licenses (a) to entities who become Adopters after 34
the date of termination; and (b) for future versions of O-RAN Specifications that are backwards compatible with the 35
version that was current as of the date of termination. 36
Section 5: CONFIDENTIALITY 37
Adopter will use the same care and discretion to avoid disclosure, publication, and dissemination of O -RAN 38
Specifications to third parties, as Adopter employs with its own confidential information, but no less than reasonable 39
care. Any disclosure by Adopter to its Affiliates, contractors and consultants should be subject to an obligation of 40
confidentiality at least as restrictive as those contained in this Section. The foregoing obligation shall not apply to any 41
information which is: (1) rightfully known by Adopter without any limitation on use or disclosure prior to disclosure; 42
(2) publicly available through no fault of Adopter; (3) rightfully received without a duty of confidentiality; (4) disclosed 43
by O-RAN Alliance or a Member, Contributor or Academic Contributor to a third party without a duty of 44
confidentiality on such third party; (5) independently developed by Adopter; (6) disclosed pursuant to the order of a 45
court or other authorized governmental body, or as required by law, provided that Adopter provides reasonable prior 46
written notice to O-RAN Alliance, and cooperates with O-RAN Alliance and/or the applicable Member, Contributor or 47

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 70

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
Academic Contributor to have the opportunity to oppose any such order; or  (7) disclosed by Adopter with O-RAN 1
Alliance’s prior written approval. 2
Section 6: INDEMNIFICATION 3
Adopter shall indemnify, defend, and hold harmless the O-RAN Alliance, its Members, Contributors or Academic 4
Contributors, and their employees, and agents and their respective successors, heirs and assigns (the “Indemnitees”), 5
against any liability, damage, loss, or expense (including reasonable attorneys’ fees and expenses) incurred by or 6
imposed upon any of the Indemnitees in connection with any claims, suits, investigations, actions, demands or 7
judgments arising out of Adopter’s use of the licensed O-RAN Specifications or Adopter’s commercialization of 8
products that comply with O-RAN Specifications. 9
Section 7: LIMITATIONS ON LIABILITY; NO WARRANTY 10
EXCEPT FOR BREACH OF CONFIDENTIALITY, ADOPTER’S BREACH OF SECTION 3, AND ADOPTER’S 11
INDEMNIFICATION OBLIGATIONS, IN NO EVENT SHALL ANY PARTY BE LIABLE TO ANY OTHER 12
PARTY OR THIRD PARTY FOR ANY INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE OR CONSEQUENTIAL 13
DAMAGES RESULTING FROM ITS PERFORMANCE OR NON-PERFORMANCE UNDER THIS AGREEMENT, 14
IN EACH CASE WHETHER UNDER CONTRACT, TORT, WARRANTY, OR OTHERWISE, AND WHETHER OR 15
NOT SUCH PARTY HAD ADVANCE NOTICE OF THE POSSIBILITY OF SUCH DAMAGES. O- RAN 16
SPECIFICATIONS ARE PROVIDED “AS IS” WITH NO WARRANTIES OR CONDITIONS WHATSOEVER, 17
WHETHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE. THE O-RAN ALLIANCE AND THE 18
MEMBERS, CONTRIBUTORS OR ACADEMIC CONTRIBUTORS EXPRESSLY DISCLAIM ANY WARRANTY 19
OR CONDITION OF MERCHANTABILITY, SECURITY, SATISFACTO RY QUALITY, NONINFRINGEMENT, 20
FITNESS FOR ANY PARTICULAR PURPOSE, ERROR-FREE OPERATION, OR ANY WARRANTY OR 21
CONDITION FOR O-RAN SPECIFICATIONS. 22
Section 8: ASSIGNMENT 23
Adopter may not assign the Agreement or any of its rights or obligations under this Agreement or make any grants or 24
other sublicenses to this Agreement, except as expressly authorized hereunder, without having first received the prior, 25
written consent of the O-RAN Alliance, which consent may be withheld in O-RAN Alliance’s sole discretion. O-RAN 26
Alliance may freely assign this Agreement. 27
Section 9: THIRD-PARTY BENEFICIARY RIGHTS 28
Adopter acknowledges and agrees that Members, Contributors and Academic Contributors (including future Members, 29
Contributors and Academic Contributors) are entitled to rights as a third-party beneficiary under this Agreement, 30
including as licensees under Section 3. 31
Section 10: BINDING ON AFFILIATES 32
Execution of this Agreement by Adopter in its capacity as a legal entity or association constitutes that legal entity’s  or 33
association’s agreement that its Affiliates are likewise bound to the obligations that are applicable to Adopter hereunder 34
and are also entitled to the benefits of the rights of Adopter hereunder. 35
Section 11: GENERAL 36
This Agreement is governed by the laws of Germany without regard to its conflict or choice of law provisions.  37
This Agreement constitutes the entire agreement between the parties as to its express subject matter and expressly 38
supersedes and replaces any prior or contemporaneous agreements between the parties, whether written or oral, relating 39
to the subject matter of this Agreement.  40

Copyright © 2022 by the O-RAN Alliance e.V.  Your use is subject to the terms of the O-RAN Adopter License
Agreement in Annex ZZZ
Page 71

O-RAN.SFG.O-CLOUD-Security-TR-v01.00.04
Adopter, on behalf of itself and its Affiliates, agrees to comply at all times with all applicable laws, rules and 1
regulations with respect to its and its Affiliates’ performance under this Agreement, including without limitation, export 2
control and antitrust laws. Without limiting the generality of the foregoing, Adopter acknowledges that this Agreement 3
prohibits any communication that would violate the antitrust laws. 4
By execution hereof, no form of any partnership, joint venture or other special relationship is created between Adopter, 5
or O-RAN Alliance or its Members, Contributors or Academic Contributors. Except as expressly set forth in this 6
Agreement, no party is authorized to make any commitment on behalf of Adopter, or O-RAN Alliance or its Members, 7
Contributors or Academic Contributors. 8
In the event that any provision of this Agreement conflicts with governing law or if any provision is held to be null, 9
void or otherwise ineffective or invalid by a court of competent jurisdiction, (i) such provisions will be deemed stricken 10
from the contract, and (ii) the remaining terms, provisions, covenants and restrictions of this Agreement will remain in 11
full force and effect.  Any failure by a party or third party beneficiary to insist upon or enforce performance by another 12
party of any of the provisions of this Agreement or to exercise any rights or remedies under this Agreement or 13
otherwise by law shall not be construed as a waiver or relinquishment to any extent of the other parties’ or third party 14
beneficiary’s right to assert or rely upon any such provision, right or remedy in that or any other instance; rather the 15
same shall be and remain in full force and effect. 16
 17