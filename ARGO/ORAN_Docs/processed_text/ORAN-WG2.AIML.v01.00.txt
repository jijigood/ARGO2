O
-RAN Working Group 2
AI/ML workflow description and requirements
ORAN-WG2.AIML.v01.00
Technical Report 
This is a re-published version of the attached final specification. 
For this re-published version, the prior versions of the IPR Policy will apply, except that the 
previous requirement for Adopters (as defined in the earlier IPR Policy) to agree to an O-RAN 
Adopter License Agreement to access and use Final Specifications shall no longer apply or be 
required for these Final Specifications after 1st July 2022.
The copying or incorporation into any other work of part or all of the material available in this 
specification in any form without the prior written permission of O-RAN ALLIANCE e.V.  is 
prohibited, save that you may print or download extracts of the material on this site for your 
personal use, or copy the material on this site for the purpose of sending to individual third parties 
for their information provided that you acknowledge O-RAN ALLIANCE as the source of the 
material and that you inform the third party that these conditions apply to them and that they must 
comply with them.

 
O-RAN Working Group 2 
AI/ML workflow description and requirements 
                                  
ORAN-WG2.AIML.v01.00
Technical Report  
 
 
Prepared by the O-RAN Alliance e.V. Copyright © 2019 by the O-RAN Alliance e.V. By using, accessing or downloading any part of this O-
RAN specification 
document, including by copying, saving, distributing, displaying or preparing derivatives of, you agree to be and are bound to the terms of the O-RAN Adopter 
License Agreement contained in the Annex Z of this specification. All other rights reserved. 
© 2019 O-RAN Alliance  All Rights Reserved                       1 


 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
2 
 
ORAN-WG2.AIML.v01.00 
Revision History  1 

 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
3 
 
ORAN-WG2.AIML.v01.00 
Date Revision Author Description 
2019.03.12 01.00.01 Rittwik Jana, 
Reuben Klein, 
Dhruv Gupta, Qi 
Sun 
Draft for template 
2019.03.15 01.00.02 Rittwik Jana, 
Reuben Klein 
First draft with Scope, references, acronyms 
2019.03.22 01.00.03 C. Santori, 
RaviKanth 
Common terminology 
Comments/clarifications 
2019.04.01 01.00.04 R. Jana, C. 
Santori, Yang 
Jiaolong 
Edited common terminology, added pipeline definitions, 
modified ML lifecycle figure 
2019.04.05 01.00.05 All Addressed comments from tea m call 
2019.04.08 01.00.06 AT&T, Nokia, 
Orange, Aricent 
Updated scope, figures and comments 
2019.04.22 01.00.07 RaviKanth Moved AL/ML terminolo gy to S2, updated fig in S5.2 
and added details for figures in S3 
updated figure-2 based on updated fig uploaded by 
Nokia 
2019.04.23 01.00.08 R. Jana Merged inputs, generate  clean version for approval 
2019.05.03 01.01.00 R. Jana Approved version, final  formatting 
2019.06.02 01.01.02 AT&T, CMCC, 
Nokia, Altran 
Updating draft with Approved CR 2019.05.27-WG2-C-
AI_ML Procedure_Interface and Requirements_v12 
2019.07.05 01.01.03 CMCC, AT&T Updating draft as pe r WG2 f2f meeting comments 
2019.07.12 01.01.03 Manoop Talasila Updated ML mode l resource discovery requirements 
and ML based xApp design details 
2019.07.20 01.01.04 R. Jana, D Gupta, 
Q Sun  
Updated draft 01.01.04 with corrections suggested by 
CR matrix in CMCC-ATT-WG2-ML Spec-v01.01.03-
review-comments.xls 
2019.08.03 01.01.05 R. Jana, D. Gupta Updated to dr aft 01.01.05 reflecting changes suggested 
in WG2-ML Spec-v01.01.04-review-comments, 2019-
07-30-ATT-CR -AIMLv01.01.04-Phases_description, 
new figures from WG2_2019.07.20_Nokia-O-RAN ML 
Workflow INTERFACES_v8.pptx, AIML_07_20_19-
draftspec-figures_v2.pptx 
2019.08.09 01.01.06 R. Jana, D. Gupta, 
Q. Sun 
Updated sequence figure as per 2019-07-30-ATT-CR -
AIMLv01.01.04-PlantUML_figure; cleaned up 
extraneous text 
2019.08.19 01.01.07 J. Power, R.Jana, 
D Gupta, Q. Sun 
Incorporating comments from John Power 
2019.09.01 01.01.08 R.Jana, D.Gupta, 
Q. Sun, J. Power 
O-RAN Adopter license agreement, final edits  
2019.09.11 01.01.09 R.Jana Final edits, removed com ments resolved 

 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
4 
 
ORAN-WG2.AIML.v01.00 
2019. 
09.14 
01.01. 
10 
Q.Sun, 
R.Jana 
Final edits, removed all the comments, capture the 
unresolved comments for the next version. 
2019. 
10.08 
01.00 R. Jana Spec renamed to 01.00 for publishing (as per O-RAN 
guidelines) 
  1 

 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
5 
 
ORAN-WG2.AIML.v01.00 
 1 
Contents  2 
Revision History ................................................................................................................................................. 2 3 
Chapter 1 Introduction ........................................................................................................................................ 6 4 
1.1 Scope 6 5 
1.2  References......................................... ................................................... ................................................... ........... 6 6 
1.3  Definitions and Abbreviations ........................................................................ ...................................................  7 7 
1.3.1  Abbreviations ........................................................................................ ................................................... .... 7 8 
1.3.2  Abbreviations ........................................................................................ ................................................... .... 8 9 
Chapter 2 Machine Learning ............................................................................................................................ 10  10 
2.1 Common terminology and Definitions ............................................................... ................................................... ..... 10  11 
2.2 General principles ............................................................................... ................................................... ..................... 12  12 
Chapter 3 Types of Machine Learning algorithms ........................................................................................... 13  13 
3.1 Supervised learning .............................................................................. ................................................... ................... 13  14 
3.2 Unsupervised learning ............................................................................ ................................................... ................. 13  15 
3.3 Reinforcement learning............................................................................ ................................................... ................ 14  16 
3.4 Mapping AI/ML functionalities into O-RAN control loops ....................................................................................... 14  17 
Chapter 4 Procedure/Interface framework, Data/Evaluation pipelines ............................................................ 16  18 
4.1 AI/ML General Procedure and Interface Framework ................................................................................................. 16  19 
4.2 Model Design and Composition ..................................................................... ................................................... ......... 19  20 
4.3 Data, Model Training and Model Evaluation pipeline ................................................................................................ 19  21 
4.4 ML Model Lifecycle Implementation Example ........................................................ .................................................. 20  22 
Chapter 5 Deployment Scenarios ..................................................................................................................... 22  23 
5.1 Sequence Diagram for Deployment Scenarios 1.1 and 1.2 ......................................................................................... 23  24 
Chapter 6 Requirements ................................................................................................................................... 26  25 
6.1 Functional Requirements .......................................................................... ................................................... ............... 26  26 
6.2 Non-Functional Requirements ...................................................................... ................................................... ........... 27  27 
Annex A (Informative) ..................................................................................................................................... 27  28 
A.1 Discussion on A1/O1 clarification ................................................................ ................................................... .......... 27  29 
A.2 Examples of ML model capabilities/descriptors .................................................... ................................................... . 28  30 
Annex Z ............................................................................................................................................................ 29  31 
  32 

 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
6 
 
ORAN-WG2.AIML.v01.00 
Chapter 1 Introduction 1 
1.1 Scope 2 
This Technical Specification has been produced by O-RAN Alliance. 3 
The contents of the present document are subject to continuing work within O-RAN WG2 and may change following formal 4 
O-RAN approval. In the event that O-RAN Alliance de cides to modify the contents of the present documen t, it will be re-5 
released by O-RAN Alliance with an identifying change of release date and an increase in version number as follows: 6 
Release x.y.z 7 
where: 8 
x the first digit is incremented for all changes of  substance, i.e. technical enhancements, correction s, updates, etc. 9 
(the initial approved document will have x=01). 10 
y the second digit is incremented when editorial on ly changes have been incorporated in the document. 11 
z the third digit included only in working versions  of the document indicating incremental changes during the editing 12 
process. 13 
The current document addresses the overall architec ture and solution for AI/ML related requirements fo r the use-cases 14 
described in O-RAN WG2 UCR doc [ORAN-WG2.UCR.01.01.00]. The document provides the terminology, workflow, and 15 
requirements, related to AI/ML model training, and its distribution and deployment in the Radio Access Network (RAN).  16 
 17 
 18 
1.2 References 19 
The following documents contain provisions which, t hrough reference in this text, constitute provision s of the present 20 
document. 21 
- References are either specific (identified by dat e of publication, edition number, version number, etc.) or non-specific. 22 
- For a specific reference, subsequent revisions do  not apply. 23 
- For a non-specific reference, the latest version applies. In the case of a reference to a 3GPP docum ent (including a 24 
GSM document), a non-specific reference implicitly refers to the latest version of that document in Release 15. 25 
[1] 3GPP TR 21.905: “Vocabulary for 3GPP Specificat ions” 26 
[2] 3GPP TS 38.401: "NG-RAN; Architecture descripti on". 27 
[3]  "O-RAN: towards an Open and smart RAN", O-RAN white paper, https://www.o-ran.org/s/O-RAN-28 
WP-FInal-181017.pdf  29 
[4] ORAN-WG2.UCR.01.01.00, ORAN WG2 use case requir ements 30 
 31 
 32 

 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
7 
 
ORAN-WG2.AIML.v01.00 
 1 
Informative references 2 
 3 
[i.x1]  ETSI GR NFV IFA 023: “Network Functions Virtualisat ion (NFV); Management and Orchestration; 4 
Report on Policy Management in MANO; Release 3”. 5 
[i.x2] ETSI GS ZSM 001: “Zero-touch Network and Ser vice Management (ZSM); Requirements based on 6 
documented scenarios”. 7 
[i.x3] OPNFV Wiki, copper project, https://wiki.opnfv.org/display/copper  8 
[i.x4] OpenStack Wiki, congress project, https://wiki.openstack.org/wiki/Congress  9 
[i.x5] ONAP Wiki, Policy Framework, https://wiki.onap.org/display/DW/The+ONAP+Policy+Framework  10 
[i.x6] B. Moore, E. Ellesson, J. Strassner, A. West erinen, “Policy Core Information Model,” RFC 3060 , 11 
IETF, February 2001 12 
[i.x7] A. Westerinen et.al. “Terminology for Policy -Based Management”, RFC 3198, IETF, November 2001 13 
[i.x8] Morris Sloman, “ Policy driven management for distributed systems ” in Journal of Network and 14 
Systems Management, Plenum Press, Vol. 2, No. 4, 1994, pp. 333-360 15 
[i.x9] Acumos ML model schema -  16 
[i.x10]  Acumos ML model signature -  17 
http://acumosr.research.att.com/#/marketSolutions?solutionId=cdb34d2d-f46a-4658-97e8-18 
8b30efb9451c&revisionId=d3bb02db-3079-4b00-9114-0f0693bbc635&parentUrl=marketplace#md-19 
model-detail-template  20 
[i.x11] O-RAN WG1.OAM Architecture -v01.00 - ACC-2019.07.02-oRAN.WG1.OAM Draft Arch Spec-21 
v01.00.015.docx  22 
 23 
1.3 Definitions and Abbreviations 24 
1.3.1 Abbreviations 25 
For the purposes of the present document, the terms and definitions given in 3GPP TR 21.905 [1] and the following apply. 26 
A term defined in the present document takes precedence over the definition of the same term, if any, in 3GPP 27 
TR 21.905 [1]. 28 
NMS: A Network Management System  29 
O-DU : O-RAN Distributed Unit: a logical node hosting RLC/MAC/High-PHY layers based on the 7-2x fronthaul split defined 30 
by O-RAN. 31 
O-RU : O-RAN Radio Unit: a logical node hosting Low-PHY layer and RF processing based on the 7-2x fronthaul  split 32 
defined by O-RAN. 33 

 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
8 
 
ORAN-WG2.AIML.v01.00 
Non-RT RIC: O-RAN non-real-time RAN Intelligent Controller: a l ogical function that enables non-real-time control and 1 
optimization of RAN elements and resources, AI/ML w orkflow including model training and updates, and p olicy-based 2 
guidance of applications/features in Near-RT RIC. 3 
Near-RT RIC: O-RAN near-real-time RAN Intelligent Controller: a logical function that enables near-real-time control and 4 
optimization of RAN elements and resources via fine-grained data collection and actions over E2 interface.  5 
O1 : Interface between orchestration & management enti ties (Orchestration/NMS) and O-RAN managed elements , for 6 
operation and management, by which FCAPS management , Software management, File management and other si milar 7 
functions shall be achieved.  8 
A1 : Interface between Non-RT RIC and Near-RT RIC to e nable policy-driven guidance of Near-RT RIC 9 
applications/functions, and support AI/ML workflow.  10 
E2 : Interface between Near-RT RIC and underlying RAN functions (CU-CP, CU-UP, and DU).  11 
1.3.2 Abbreviations 12 
For the purposes of the present document, the abbreviations given in 3GPP TR 21.905 [1] and the following apply. An 13 
abbreviation defined in the present document takes precedence over the definition of the same abbreviation, if any, in 3GPP 14 
TR 21.905 [1].  15 
eNB eNodeB (applies to LTE)  16 
gNB gNodeB (applies to NR)  17 
O-DU O-RAN Distributed Unit  18 
O-RU O-RAN Radio Unit  19 
O-CU O-RAN Central Unit 20 
RIC [O-RAN] RAN Intelligent Controller 21 
Non-RT RIC Non-real-time RIC 22 
Near-RT RIC Near-RT RIC 23 
QoE Quality of Experience 24 
KQI Key Quality Indicator 25 
KPI Key performance indicator 26 
CNN Convolutional neural network 27 
PCA  principal components analysis 28 
RL  reinforcement learning 29 
DRL  deep reinforcement learning 30 
GPU  graphics processing unit 31 
KNN  k nearest neighbors 32 
LSTM  long short-term memory 33 
ML  machine learning 34 

 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
9 
 
ORAN-WG2.AIML.v01.00 
NN neural network 1 
RL  reinforcement learning 2 
RNN  recurrent neural network 3 
SMO service management and orchestration 4 
SVM  support vector machine 5 
 6 
  7 

 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
10 
 
ORAN-WG2.AIML.v01.00 
Chapter 2 Machine Learning  1 
Machine learning is a field of study that provides computers the ability to learn without being explicitly programmed. The 2 
ability to learn useful information from input data can help improve RAN or network performance. For example, 3 
convolutional neural networks and recurrent neural networks can extract spatial features and sequential features from time-4 
varying signal strength indicators (e.g., RSSI).  5 
This chapter introduces some of the common terminology related to AI/ML based use-cases development in context of O-6 
RAN architecture. 7 
2.1 Common terminology and Definitions 8 
Table 1 - Common terminology 9 
Definitions  Note/example  
Application: An application is a complete and deployable 
package, environment to achieve a certain function in an 
operational environment. An AI/ML application is one that 
contains some AI/ML models.  
Generally, an AI/ML application should 
contain a logically top-level AI/ML 
model and application-level descriptions 
ML-assisted solution: A solution which addresses a specific 
use case using Machine-Learning algorithms during operation.  
As an example, video optimization using 
ML is an ML-assisted solution. 
ML model: The ML methods and concepts used by the ML-
assisted solution.  
Depending on the implementation a specific ML model could 
have many sub-models as components and the ML model 
should train all sub-models together.  
ML models include supervised learning, 
unsupervised learning, reinforcement 
learning, deep neural network, and 
depending on use-case, appropriate ML 
model has to be chosen. Separately 
trained ML models can also be chained 
together in a ML pipeline during 
inference. 
ML workflow: A ML workflow is the process consisting of 
data collection and preparation, model building, model 
training, model deployment, model execution, model 
validation, continuous model self-monitoring and self-
learning/retraining related to ML-assisted solutions  
Based on ML model chosen, some or all 
of the phases of workflow will be 
included.  
ML (model) life-cycle: The life-cycle of the ML model 
includes deployment, instantiation and termination of ML 
model components.  
These are operational phases: the initial 
training, inference, possible re-training  
 

 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
11 
 
ORAN-WG2.AIML.v01.00 
ML pipeline: The set of functionalities, functions, or functional 
entities specific for an ML-assisted solution.  
a ML pipeline may consist of one or 
several data sources in a data pipeline, a 
model training pipeline, a model 
evaluation pipeline and an actor. 
ML training host: The network function which hosts the 
training of the model  
Non-RT RIC can also be a training host. 
ML training can be performed offline 
using data collected from the RIC, O-
DU and O-RU. 
ML inference host: The network function which hosts the ML 
model during inference mode (which includes both the model 
execution as well as any online learning if applicable).  
The ML inference host often coincides 
with the Actor. The ML-host informs the 
actor about the output of the ML 
algorithm, and the Actor takes a decision 
for an action. 
Actor: The entity which hosts an ML assisted solution using 
the output of ML model inference.  
 
Action: An action performed by an actor as a result of the 
output of an ML assisted solution.  
 
Subject of action: The entity or function which is configured, 
controlled, or informed as result of the action.  
 
Model training information: Information needed for training 
the ML model.  
This is the data of the ML model 
including the input plus optional labels 
for supervised training 
Model inference information: Information needed as input for 
the ML model for inference.  
The data needed by an ML model for 
training and inference may largely 
overlap, however they are logically 
different.  
 1 
Figure 1 depicts the use of the ML components and terminologies as described in Table 1. 2 
 3 

 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
12 
 
ORAN-WG2.AIML.v01.00 
 1 
 2 
  3 
Figure 1 - ML modeling terminology 4 
 5 
2.2 General principles 6 
Principle 1: In O-RAN we will always have some offline learning as a proposed best practice (even for reinforcement learning 7 
type of scenarios). In the current document, offline training means a model is first trained with offline data, and trained model 8 
is deployed in the network for inference. Online tr aining refers to scenarios such as reinforcement le arning, where the model 9 
‘learns’ as it is executing in the network. However , even in the latter scenario, it is possible that some offline training may 10 
happen.  11 
Principle 2: A model needs to be trained and tested before deploying in the network. A completely untrained model will not 12 
be deployed in the network. 13 
 14 
 15 
 16 
 17 
 18 
 19 


 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
13 
 
ORAN-WG2.AIML.v01.00 
Chapter 3 Types of Machine Learning algorithms 1 
This section provides a view of how the different ML algorithms can be deployed and realized in O-RAN architecture. It 2 
does not detail or recommend the various machine learning algorithms available or recommend specific M L algorithms that 3 
should be applied to the use-cases realized in O-RAN architecture. 4 
3.1 Supervised learning 5 
Input data is called training data and has a known label or result. Supervised learning is a machine learning task that aims to 6 
learn a mapping function from the input to the output, given a labeled data set. 7 
1.  Regression: Linear Regression, Logistic Regression 8 
2.  Instance-based Algorithms: k-Nearest Neighbor (KNN)  9 
3.  Decision Tree Algorithms: CART 10 
4.  Support Vector Machines: SVM 11 
5.  Bayesian Algorithms: Naive Bayes 12 
6.  Ensemble Algorithms: Extreme Gradient Boosting, Bag ging: Random Forest 13 
 14 
Supervised learning can be further grouped into Regression and Classification problems. Classification  is about predicting a 15 
label whereas Regression is about predicting a quantity. 16 
 17 
Figure 2 - Supervised learning model training and a ctor locations 18 
In supervised learning (see Figure 2), Non-RT RIC is part of the SMO and thus is part of the management layer. ML 19 
training host and ML model host/actor can be part o f Non-RT RIC or Near-RT RIC.  20 
3.2 Unsupervised learning 21 
Input data is not labeled and does not have a known result. Unsupervised learning is a machine learnin g task that aims to 22 
learn a function to describe a hidden structure fro m unlabeled data. Some examples of unsupervised learning are K-means 23 
clustering and principal component analysis (PCA). 24 


 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
14 
 
ORAN-WG2.AIML.v01.00 
 1 
Figure 3 - Unsupervised learning model training and actor locations 2 
In unsupervised learning (see Figure 3), ML trainin g host and ML model host/actor can be part of Non-RT RIC or Near-RT 3 
RIC.  4 
3.3 Reinforcement learning  5 
A goal-oriented learning based on interaction with environment. In reinforcement learning (RL), the agent aims to optimize 6 
a long-term objective by interacting with the environment based on a trial and error process. There ar e several RL 7 
algorithms 8 
•  Q-learning 9 
•  Multi-armed bandit learning 10 
•  Deep RL 11 
 12 
Figure 4- Reinforcement learning model training and actor locations 13 
In reinforcement learning (see Figure 4), ML traini ng host and ML model host/actor shall be co-located  as part of Non-RT 14 
RIC or Near-RT RIC. 15 
3.4 Mapping AI/ML functionalities into O-RAN control loops 16 
There are three types of control loops defined in O-RAN. ML assisted solutions fall into the three control loops.  Time scale 17 
of O-RAN control loops depend on what is being controlled, e.g. system parameters, resources or radio resource 18 
management (RRM) algorithm parameters. For example, if O-RAN control loop adapts the parameters of RRM algorithms, 19 
its time scale is slower than that of the RRM algorithm. 20 
Loop 1 deals with per TTI msec level scheduling and operates at a time scale of the TTI or above. Loop  2 operates in the 21 
near RT RIC operating within the range of 10-500 msec and above (resource optimization). Loop 3 operat es in the Non-RT 22 
RIC at greater than 500 msec (policies, orchestration). It is not expected that these loops are hierarchical but can instead run 23 
in parallel.  24 


 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
15 
 
ORAN-WG2.AIML.v01.00 
 1 
Figure 5 - Control loops in O-RAN 2 
Figure 5 shows the three control loops in O-RAN arc hitecture. AI/ML related functionalities can be map ped into the three 3 
loops. The location of the ML model training and th e ML model inference for a use case depends on the computation 4 
complexity, on the availability and the quantity of  data to be exchanged, on the response time require ments and on the type 5 
of ML model. For example, online ML model for confi guring RRM algorithms operating at the TTI time sca le could run in 6 
O-DU, while the configuration of system parameters such as beamforming configurations requiring a larg e amount of data 7 
with no response time constraints can be performed in the Non-RT RIC and Orchestration and management layer where 8 
intensive computation means can be made available.  9 
In the first phase of O-RAN, ML model training will  be considered in the Non-RT RIC and ML model infer ence will be 10 
considered in loops 2 and 3. For loop2, the ML infe rence is typically running in Near-RT RIC For Loop 1, the ML model 11 
inference is typically running in an O-DU. ML workflow on loop 1 is FFS. While ML model implementation  in O-RU could 12 
be envisaged, it is presently not supported in O-RAN. 13 
 14 
  15 
Service management & Orchestration 
Non -RT RIC  
Near -RT RAN Intelligent Controller (RIC)  
O-CU -CP  
O-CU-
 
O-DU  
O-RU  
A1 
F1 -c F1-u 
E1  
Infrastr 
ucture 
Manag 
ement 
Frame 
work  
Open Fronthaul 
 
 
Infrastructure-COST / White Box / Peripheral Hardware & 
Virtualization Layer  
~NFVI  
O1*  
O1  
 Loop1 : per TTI/msec resource 
 Loop2 : 10~500 msec (resource optimization)  
 Loop3 : > 500 msec 
(policies, 
management and 
orchestration)  

 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
16 
 
ORAN-WG2.AIML.v01.00 
Chapter 4 Procedure/Interface framework, Data/Evaluation 1 
pipelines 2 
4.1 AI/ML General Procedure and Interface Framework  3 
This chapter first provides the general framework o f AI/ML procedure and interfaces, which addresses t he ML components 4 
rather than network functions (non/Near-RT RIC, etc.). The potential mapping relationship between the ML components and 5 
network functions, interfaces defined in O-RAN are also illustrated in Figure 6.  6 
 7 
Figure 6 - ML training host and inference locations  8 
Note:  ML capabilities shall be stored in the management system (FFS). Query and Discovery of ML capabilities are 9 
terminated in the management system but not shown. ML inference host often coincides with the actor 10 
The deployment scenarios that are considered for ML  architecture/framework in O-RAN architecture are 11 
1.  Deployment Scenario 1.1: Non-RT RIC acts as both the ML training and inference host 12 
2.  Deployment Scenario 1.2: Non-RT RIC acts as the ML training host and the Near-RT RIC as the ML inference host 13 
3.  Deployment Scenario 1.3: Non-RT RIC acts as the ML training host and the O-CU/O-DU as the ML inference  host 14 
(for FFS) 15 
In addition, for reinforcement learning based ML model-based deployment, both ML training and ML inter ference host 16 
shall be co-located on same MF. 17 
 18 
 19 
 20 


 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
17 
 
ORAN-WG2.AIML.v01.00 
 1 
Table 2 shows the various deployment scenarios and interfaces. 2 
Table 2 - AI/ML deployment scenarios 3 
Deployment 
Scenario 
ML 
Training 
Host  
ML 
Inference 
Host 
Interface for 
ML model 
deployment / 
update 
Subject 
of 
Action 
Action from inference host 
to subject 
Enrichment 
data for 
inference 
Config 
Mgmt. 
(CM) 
Policy / Control 
  Scenario 1.1 SMO/Non-
RT RIC 
Non-RT 
RIC 
SMO internal Near-RT 
RIC 
O1 A1  
(policy) 
SMO internal 
O-CU, 
O-DU, 
O-RU 
O1 N/A SMO internal 
  Scenario 1.2 SMO/Non-
RT RIC 
Near-RT 
RIC 
O1, O1* Near-RT 
RIC 
near-RT 
RIC 
internal 
near-RT RIC 
internal 
A1 
O-CU, 
O-DU, 
O-RU 
N/A E2 
(control/policy) 
E2 (if 
applicable) 
Scenario 1.3 
(FFS) 
SMO/Non-
RT RIC 
 
O-CU / O-
DU 
O1, O1* O-CU, 
O-DU, 
O-RU 
FFS FFS FFS 
 4 
Note: Configuration management for scenario 1.2 via E2 is FFS;  5 
O1^ - Non-RT RIC can use SMO internal interfaces to trigger configuration changes over O1 6 
Based on the framework, some key phases of machine learning are expected to be applied to any ML-assisted solution 7 
planned in O-RAN architecture. Any use case defined for ML-assisted solution shall have one or more phases (as 8 
applicable) and the phases are defined below: 9 
1. ML model capability query/discovery  10 
This procedure shall be executed whenever AI/ML model is to be used for ML-assisted solution. This procedure can be 11 
executed at start-up or run-time (when a new ML model is to be executed or existing ML model is to be updated). The SMO 12 
will discover various capabilities and properties of the ML inference host, such as: 13 
a) Processing capability of HW where ML model is go ing to be executed (for example: resources available such as 14 
CPU/GPU, memory etc. that can be allocated for ML model inference). 15 
b) Properties such as supported ML model formats an d ML engines (for example: Protobuf, JSON, or any ONAP specific 16 
VES data formats). 17 
c) NFVI based architecture support in MF to run ML model(s) 18 

 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
18 
 
ORAN-WG2.AIML.v01.00 
d) Data-sources available to run ML-pipeline (for e xample: support for data streams, data lake, or any specific database 1 
access) 2 
This discovery of the capabilities shall be used to check if a ML model can be executed in the target ML inference host 3 
(MF), and what number and type of ML models can be executed in the MF.  4 
Note: Exact mechanism and contents of capabilities discovery is FFS.  5 
2. ML model Selection and Training  6 
This procedure corresponds to design time selection and training of a ML model in relation with a specific ML-assisted 7 
solution (use case) to be executed. The ML designer will select and onboard the ML model and relevant meta data into the 8 
SMO environment. Utilizing on the ML training data collection, the ML training host will initiate the model training. Once 9 
the model is trained and validated, it is published back in the SMO catalogue.  10 
At this stage, the ML designer can check whether the trained model can be deployed in the ML inference host, by mapping 11 
the ML model requirements to HW and performance properties discovered from Step 1. Upon successful validation, ML 12 
designer will inform the SMO to initiate model deployment. 13 
3. ML model Deployment and Inference  14 
The AI/ML model that is selected for the use case can be deployed via containerized image to MF where ML model shall be 15 
executing. This also includes configuration of ML inference host with AI/ML model description file.  16 
Note: The O1 interface mechanism for ML model deployment is being specified by WG1. 17 
Once the ML model is deployed and activated, ML online data shall be used for inference in ML-assisted solutions, which 18 
includes:  19 
a)  3GPP specific events/counters (across all different Managed Elements) over O1/E2 interface  20 
a.  Events: 3GPP 32.423 21 
b.  Counters: 3GPP 32.425  22 
b) Non-3GPP specific events/counters (across all di fferent Managed Elements) over O1/E2 interface (to be defined in 23 
ORAN WGs) 24 
c) Enrichment information from non-RT RIC over A1 i nterface (to be defined in ORAN WGs) 25 
Based on the output of the ML model, the ML-assisted solution will inform the Actor to take the necessary actions towards 26 
the Subject. These could include CM changes over O1 interface, policy management over A1 interface, or control actions or 27 
policies over E2 interface, depending on the location of ML inference host and Actor.  28 
4. ML model performance monitoring  29 
The ML inference host is expected to feedback or report the performance of the ML model to the ML training host so that 30 
the ML training host can monitor the performance of the ML model and potentially update the model. Based on the use-31 
case, specific set of data as applicable for use-case shall be used for ML model re-training. Based on the performance 32 
evaluation, either some guidance can be provided to use a different model in the ML inference host, or a notification can be 33 
sent indicating the need for retraining the model. 34 
Note: Feedback mechanism and how the ML model switching can occur at runtime is FFS. 35 
5. ML model redeploy/update 36 

 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
19 
 
ORAN-WG2.AIML.v01.00 
Based on the feedback and data received from various MFs, the ML performance evaluation module can inform the ML 1 
designer that an update is required to the current model. The ML designer will initiate the model selection and training step, 2 
but with the existing trained model. Once a new model has been trained, it will be deployed as described in Step 3, and the 3 
updated model will be used for ML inference.  4 
4.2 Model Design and Composition 5 
ML model design is the first step to conceiving the initial model. This requires connecting to data so urces, parsing messages 6 
and tokenizing to create and select features. This activity is offline and requires data exploration mechanisms to help the 7 
model designer.  8 
4.3 Data, Model Training and Model Evaluation pipeline 9 
This section describes the data, model training and evaluation pipelines.   10 
 11 
Figure 7 - Data pipeline 12 
Figure 77 defines the data pipelines. The “extract- transform-load” (ETL) process describes how data ca n be extracted from 13 
storage, transformed and loaded into training and testing sets. Additional data quality and validation stages can be inserted 14 
into the ETL pipeline. Data cleaning can also be part of the Transform block. This is outside the scope of WG2.  15 


 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
20 
 
ORAN-WG2.AIML.v01.00 
 1 
Figure 8 - Model training and evaluation pipelines 2 
Figure 88 shows the model training and evaluation pipelines. Model training pipeline may change with model types. Model 3 
evaluation pipeline, however, is a more generic pro cess. Model evaluation can be used to evaluate a single model or 4 
extended to select the best model from a range of models.  5 
The end-to-end training process includes the following 6 
• Fulfills the data requirements of the model (format, sample distribution, extent) 7 
• Connects with requisite data via Data Pipeline (simplest ex: a data broker) 8 
• Partitions data into appropriate sets (training, validation, testing, sample) 9 
• Keeps Training data cached for error recovery and subsequent usage 10 
• Manages model training though all phases 11 
• Implements training by invoking a Model Training Pipeline  12 
• Training Client tunes model parameters during training phases 13 
• Scoring client monitors performance in order to dec lare training phase complete 14 
• Communicates with license manager for usage and ver sioning 15 
4.4 ML Model Lifecycle Implementation Example 16 
The section provides an example (see Figure 9) of M L model lifecycle implementation example and key phases involved in 17 
the design and deployment in O-RAN architecture.  18 


 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
21 
 
ORAN-WG2.AIML.v01.00 
 1 
Figure 9 - ML model lifecycle (an implementation example) 2 
Note: ML Model capability query and discovery can occur in ML designer and Non-RT RIC.  3 
The typical steps involved in AL/ML based use-case application in O-RAN architecture is shown in Figure 910 considering 4 
supervised/unsupervised learning ML models. The steps for reinforcement model could vary with respect to ML training 5 
host and the related interaction flows. 6 
1.  ML Modeler uses a designer environment along with M L toolkits (e.g., scikit-learn, R, H2O, Keras, TensorFlow) 7 
to create the initial ML model 8 
2.  The initial model is sent to training hosts for training 9 
3.  The appropriate data sets are collected from the Near-RT RIC, O-CU and O-DU to a data lake and passed to the 10 
ML training hosts. 11 
4.  The trained model/sub models are uploaded to the ML designer catalog (one such open source catalog pla tform is 12 
AcumosAI ). The final ML model is composed.  13 
5.  The ML model is published to Non-RT RIC along with the associated license and metadata. 14 
6.  Non-RT RIC creates a containerized ML application c ontaining the necessary model artifacts (when using 15 
AcumosAI, the ML model’s container is created in Ac umos catalog itself).  16 
7.  Non-RT RIC deploys the ML application to the Near-RT RIC, O-DU and O-RU using the O1 interface. Polici es 17 
are also set using the A1 interface.  18 
8.  PM data is sent back to ML training hosts from Near-RT RIC, O-DU and O-RU for retraining.  19 
 20 
Note that Near-RT RIC can also update ML model para meters at runtime (e.g., gradient descent) without going through 21 
extensive retraining. Training hosts and ML designers can also be part of Non-RT RIC.  22 
  23 


 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
22 
 
ORAN-WG2.AIML.v01.00 
Chapter 5 Deployment Scenarios 1 
This chapter describes the high-level architecture of deployment scenarios defined in Section 5.1 and also captures the 2 
sequence diagrams to show end-to-end flows.  3 
The current version captures the deployment scenarios 1.1 (see Figure 10) and 1.2 (see Figure 11) only, and scenario 1.3 is 4 
not in current scope of document and are FFS. 5 
 6 
Figure 10 – Deployment scenario 1.1 - ML training a nd inference host locations 7 
 8 
 9 
Figure 11 - Deployment scenario 1.2 - ML training a nd inference host locations 10 


 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
23 
 
ORAN-WG2.AIML.v01.00 
5.1 Sequence Diagram for Deployment Scenarios 1.1 and 1.2 1 
The sequence diagram (see Figure 12) for Deployment Scenario-1.1 (SMO/Non-RT RIC for model training, Non-RT RIC 2 
for model inference host) and Deployment Scenario-1.2 (SMO/Non-RT RIC for model training, Near-RT RIC as model 3 
inference host) is captured below 4 

 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
24 
 
ORAN-WG2.AIML.v01.00 
 1 


 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
25 
 
ORAN-WG2.AIML.v01.00 
Figure 12 - Non-RT RIC as ML training host, Non-RT RIC or Near-RT RIC as ML inference host (Note that the 1 
SMO components are defined in WG1 OAM architecture, Appendix B [i.x11])  2 

 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
26 
 
ORAN-WG2.AIML.v01.00 
Chapter 6 Requirements 1 
6.1 Functional Requirements 2 
 3 
[Editor notes]: This section describes the functional requirements for A1 interface and Non-RT RIC. 4 
[REQ-Non-RT RIC-FUN1] Non-RT RIC may request/trigge r ML model training in training hosts. 
Notes: Regardless of where the model is deployed and executed, non-RT RIC should request/trigger ML model training. 5 
Note that ML models may be trained and not currently deployed. Implicitly, model re-training and model 6 
performance/evaluation. 7 
 [REQ-Non-RT RIC-
FUN2]     
Non-RT RIC shall provide a query able catalog for  ML designer to 
publish/install trained ML models (executable software components) and 
Non-RT RIC will provide discovery mechanism if a particular ML model 
can be executed in the target ML inference host (MF), and what number 
(and type) of ML models can be executed in the MF. 
Notes: Non-RT RIC is a component of the SMO framework, i.e., one component of the NMS.  The catalogue is not only for 8 
external ML market place or platform to publish the models, but also the source for any internal models as well. Non-RT 9 
RIC can also connect to external ML catalogues via SMO specific interfaces (interface specification is not in scope of 10 
document). There are three types of catalogs namely (design-time catalog (outside non-RT RIC in other ML platforms), 11 
training/deployment-time catalog (inside non-RT RIC), and run-time catalog (inside near-RT RIC for scenario 1.2)). In 12 
scenario 1.1 where ML models are trained, deployed and executed in non-RT RIC.  13 
[REQ-Non-RT RIC-
FUN3]     
Non-RT RIC shall support necessary capabilities (enable executable 
software to be installed, e.g., containers) for ML model inference in 
support of ML assisted solutions running in non-RT RIC 
  
Notes: ML engines are packaged s/w executable libraries that provide the necessary routines to run the model.  14 
Note: As an example, policies to switch and activate ML model instances under different operating conditions (busy hour vs 15 
non-busy hour or seasonal changes, etc.) 16 
[REQ-Non-RT RIC-FUN5] Non-RT RIC shall be able to access feedback data over O1 interface on 
ML model performance and perform necessary evaluation. 
Note: PM and FM stats for ML model are relayed over O1. If the ML model fails during runtime an alarm can be generated 17 
as feedback to non-RT RIC. How well the ML model is performing in terms of accuracy of prediction or other operating 18 
statistics it produces can be sent to non-RT RIC over O1.  19 
Table 4.1.0-1 20 
 21 
 22 

 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
27 
 
ORAN-WG2.AIML.v01.00 
 1 
REQ  Description  
 [REQ-O1-FUN1]     O1 interface shall support deployment and update of the ML models as a 
packaged s/w executable (e.g., in a container). 
[REQ-O1-FUN2] O1 interface shall support PM and FM data collection for ML models, including 
fine-grained events/counters needed for ML training and inference. 
[REQ-O1-FUN3] O1 interface shall support collection of ML relevant capabilities of the managed 
function where the model is to be deployed for inference. 
 2 
6.2 Non-Functional Requirements 3 
[Editor notes]: This section describes the non-functional requirements for A1 interface and Non-RT RIC, e.g., security. 4 
REQ  Description  
[REQ-O1-
NONFUN1] 
O1 interface shall support scaling ML model instances running in target ML 
inference host (MF) by observing resource utilization in MF. 
 5 
Note: The environment where the ML model instance is running will monitor resource utilization (e.g., in ORAN-SC there 6 
is a component call ResourceMonitor in near-RT RIC; similarly, in non-RT RIC there needs to be a ResourceMonitor that 7 
continuously monitors resource utilization). If resources are low or fall below a certain threshold, the runtime environment 8 
in near-RT RIC and non-RT RIC needs to provide a scaling mechanism to add more ML instances. K8s runtime 9 
environments typically provide auto-scaling feature.  10 
 11 
REQ  Description  
[REQ-O1-
NONFUN2] 
ML model instances running in target ML inference hosts shall be automatically 
scaled by observing resource utilization in MF. 
 12 
 13 
Annex A (Informative) 14 
A.1 Discussion on A1/O1 clarification 15 
The following table tries to summarize WG2 involved information exchange over O1 and A1 interface based on the UCR 16 
doc and AI/ML workflow discussion. 17 
Table 3 - A1 vs O1 information exchange 18 
Informat ion  Interface  Management Services  Remarks  

 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
28 
 
ORAN-WG2.AIML.v01.00 
Policy  A1    
Enrichment information  A1    
Policy feedback  A1   Feedback for model state  
Non-RT RIC performance 
data collection  
O1 Performance 
measurement  
SMO internal interface to 
access O1 data  
Non-RT RIC Fault data 
collection  
O1 Fault measurement SMO internal interface to 
access O1 data  
Network parameter 
configuration  
O1  Provisioning management  O1 -CM  
AI/ML model 
deployment  
O1 Software management  
AI/ML model update O1   Software management Contain erized, same for 
xApp update/revision 
control as per OAM  
AI/ML model 
performance monitoring 
O1  Enhancement is needed. 
How to model the AI/ML 
in the information model 
needs further study. 
 1 
A.2 Examples of ML model capabilities/descriptors 2 
- ML capabilities may include performance aspects of the target network function (e.g. CPU, memory, etc.), support 3 
for ML engines, supported libraries, [i.x10, i.x9]. 4 
- These capabilities need to be matched against an ML model descriptor to decide whether a model can be deployed 5 
in the target network function. 6 

 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
29 
 
ORAN-WG2.AIML.v01.00 
-  1 
Figure 13 - Example ML model descriptor schema 2 
Figure 14 provides an example schema for ML models and an illustration for a face_privacy_detection use case. It shows 3 
the input/output mapping and a set of ML model runtime dependencies. 4 
 5 
Annex Z 6 
O-RAN ADOPTER LICENSE AGREEMENT  7 
BY DOWNLOADING, USING OR OTHERWISE ACCESSING ANY O- RAN SPECIFICATION, ADOPTER AGREES TO THE 8 
TERMS OF THIS AGREEMENT.   9 
 10 
This O-RAN Adopter License Agreement (the “Agreement”) is made by and between the O-RAN Alliance and the 11 
entity that downloads, uses or otherwise accesses a ny O-RAN Specification, including its Affiliates (t he 12 
“Adopter”). 13 
 14 
This is a license agreement for entities who wish to adopt any O-RAN Specification. 15 
 16 
SECTION 1:  DEFINITIONS 17 


 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
30 
 
ORAN-WG2.AIML.v01.00 
 1 
1.1  “Affiliate” means an entity that directly or indire ctly controls, is controlled by, or is under common 2 
control with another entity, so long as such control  exists.  For the purpose of this Section, “Control”  means 3 
beneficial ownership of fifty (50%) percent or more of the voting stock or equity in an entity. 4 
 5 
1.2  “Compliant Portion” means only those specific porti ons of products (hardware, software or 6 
combinations thereof) that implement any O-RAN Specification.  7 
 8 
1.3   “Adopter(s)” means all entities, who are not Member s, Contributors or Academic Contributors, 9 
including their Affiliates, who wish to download, use or otherwise access O-RAN Specifications. 10 
 11 
1.4  “Minor Update” means an update or revision to an O- RAN Specification published by O-RAN Alliance 12 
that does not add any significant new features or f unctionality and remains interoperable with the pri or 13 
version of an O-RAN Specification.  The term “O-RAN Specifications” includes Minor Updates. 14 
 15 
1.5  “Necessary Claims” means those claims of all present and future patents and patent applications, other 16 
than design patents and design registrations, throu ghout the world, which (i) are owned or otherwise 17 
licensable by a Member, Contributor or Academic Contributor during the term of its Member, Contributor or 18 
Academic Contributorship; (ii) such Member, Contribu tor or Academic Contributor has the right to grant a 19 
license without the payment of consideration to a t hird party; and (iii) are necessarily infringed by 20 
implementation of a Final Specification (without co nsidering any Contributions not included in the Fin al 21 
Specification). A claim is necessarily infringed on ly when it is not possible on technical (but not co mmercial) 22 
grounds, taking into account normal technical practice and the state of the art generally available at the date 23 
any Final Specification was published by the O-RAN Alliance or the date the patent claim first came in to 24 
existence, whichever last occurred, to make, sell, leas e, otherwise dispose of, repair, use or operate an 25 
implementation which complies with a Final Specification without infringing that claim. For the avoidance of 26 
doubt in exceptional cases where a Final Specification can only be implemented by technical solutions, all of 27 
which infringe patent claims, all such patent claims shall be considered Necessary Claims. 28 
1.6  “Defensive Suspension” means for the purposes of an y license grant pursuant to Section 3, Member, 29 
Contributor, Academic Contributor, Adopter, or any of their Affiliates, may have the discretion to include  in 30 
their license a term allowing the licensor to suspe nd the license against a licensee who brings a pate nt 31 
infringement suit against the licensing Member, Contributor, Academic Contributor, Adopter, or any of their 32 
Affiliates. 33 
 34 
SECTION 2: COPYRIGHT LICENSE 35 
 36 

 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
31 
 
ORAN-WG2.AIML.v01.00 
2.1  Subject to the terms and conditions of this Agreement, O-RAN Alliance hereby grants to Adopter a non-1 
exclusive, non-transferable, irrevocable, non-sublic ensable, worldwide copyright license to obtain, use and 2 
modify O-RAN Specifications, but not to further dist ribute such O-RAN Specification in any modified or 3 
unmodified way, solely in furtherance of implementations of an O-RAN Specification 4 
2.2  Adopter shall not use O-RAN Specifications except a s expressly set forth in this Agreement or in a 5 
separate written agreement with O-RAN Alliance. 6 
 7 
SECTION 3: FRAND LICENSE 8 
 9 
3.1  Members, Contributors and Academic Contributors and their Affiliates are prepared to grant based on a 10 
separate Patent License Agreement to each Adopter under Fair, Reasonable And Non-Discriminatory (FRAND) 11 
terms and conditions with or without compensation (royalties) a nonexclusive, non-transferable, irrevocable 12 
(but subject to Defensive Suspension), non-sublicensable,  worldwide license under their Necessary Claims to 13 
make, have made, use, import, offer to sell, lease, sell and otherwise distribute Compliant Portions; provided, 14 
however, that such license shall not extend: (a) to  any part or function of a product in which a Compl iant 15 
Portion is incorporated that is not itself part of the Compliant Portion; or (b) to any Adopter if that Adopter is 16 
not making a reciprocal grant to Members, Contributo rs and Academic Contributors, as set forth in Sectio n 17 
3.3.  For the avoidance of doubt, the foregoing license includes the distribution by the Adopter’s distributors 18 
and the use by the Adopter’s customers of such licensed Compliant Portions. 19 
 20 
3.2  Notwithstanding the above, if any Member, Contri butor or Academic Contributor, Adopter or their 21 
Affiliates has reserved the right to charge a FRAND royalty or other fee for its license of Necessary Claims to 22 
Adopter, then Adopter is entitled to charge a FRAND royalty or other fee to such Member, Contributor or  23 
Academic Contributor, Adopter and its Affiliates for its license of Necessary Claims to its licensees. 24 
 25 
3.3 Adopter, on behalf of itself and its Affiliates, shall be prepared to grant based on a separate Pate nt 26 
License Agreement to each Members, Contributors, Aca demic Contributors, Adopters and their Affiliates 27 
under FRAND terms and conditions with or without co mpensation (royalties) a nonexclusive, non-28 
transferable, irrevocable (but subject to Defensive Suspension), non-sublicensable,  worldwide license under 29 
their Necessary Claims to make, have made, use, impo rt, offer to sell, lease, sell and otherwise distrib ute 30 
Compliant Portions; provided, however, that such lice nse will not extend: (a) to any part or function of  a 31 
product in which a Compliant Portion is incorporated that is not itself part of the Compliant Portion; or (b) to 32 
any Members, Contributors, Academic Contributors, Adop ters and their Affiliates that is not making a 33 
reciprocal grant to Adopter, as set forth in Section  3.1.  For the avoidance of doubt, the foregoing lic ense 34 
includes the distribution by the Members’, Contributo rs’, Academic Contributors’, Adopters’ and their 35 
Affiliates’ distributors and the use by the Members’, Contributors’, Academic Contributors’, Adopters’ and 36 
their Affiliates’ customers of such licensed Compliant Portions. 37 
 38 
SECTION 4:  TERM AND TERMINATION 39 

 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
32 
 
ORAN-WG2.AIML.v01.00 
 1 
4.1  This Agreement shall remain in force, unless early terminated according to this Section 4. 2 
 3 
4.2  O-RAN Alliance on behalf of its Members, Contributors and Academic Contributors may terminate this 4 
Agreement if Adopter materially breaches this Agreement and does not cure or is not capable of curing such 5 
breach within thirty (30) days after being given notice specifying the breach. 6 
 7 
4.3  Sections 1, 3, 5 - 11 of this Agreement shall survive any termination of this Agreement.  Under surviving 8 
Section 3, after termination of this Agreement, Adopt er will continue to grant licenses (a) to entities who 9 
become Adopters after the date of termination; and (b) for future versions of O-RAN Specifications tha t are 10 
backwards compatible with the version that was current as of the date of termination. 11 
 12 
SECTION 5: CONFIDENTIALITY 13 
 14 
Adopter will use the same care and discretion to av oid disclosure, publication, and dissemination of O- RAN 15 
Specifications to third parties, as Adopter employs with its own confidential information, but no less than 16 
reasonable care.  Any disclosure by Adopter to its Affiliates, contractors and consultants should be subject to 17 
an obligation of confidentiality at least as restri ctive as those contained in this Section.  The fore going 18 
obligation shall not apply to any information which is: (1) rightfully known by Adopter without any limitation 19 
on use or disclosure prior to disclosure; (2) publi cly available through no fault of Adopter; (3) righ tfully 20 
received without a duty of confidentiality; (4) dis closed by O-RAN Alliance or a Member, Contributor or  21 
Academic Contributor to a third party without a duty of confidentiality on such third party; (5) independently 22 
developed by Adopter; (6) disclosed pursuant to the order of a court or other authorized governmental body, 23 
or as required by law, provided that Adopter provides reasonable prior written notice to O-RAN Alliance, and 24 
cooperates with O-RAN Alliance and/or the applicable Member, Contributor or Academic Contributor to have 25 
the opportunity to oppose any such order; or (7) di sclosed by Adopter with O-RAN Alliance’s prior writt en 26 
approval.  27 
 28 
SECTION 6:  INDEMNIFICATION 29 
 30 
Adopter shall indemnify, defend, and hold harmless th e O-RAN Alliance, its Members, Contributors or 31 
Academic Contributors, and their employees, and agent s and their respective successors, heirs and assigns  32 
(the “Indemnitees”), against any liability, damage, loss, or expense (including reasonable attorneys’ fees and 33 
expenses) incurred by or imposed upon any of the In demnitees in connection with any claims, suits, 34 
investigations, actions, demands or judgments arisi ng out of Adopter’s use of the licensed O-RAN 35 
Specifications or Adopter’s commercialization of products that comply with O-RAN Specifications. 36 
 37 

 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
33 
 
ORAN-WG2.AIML.v01.00 
SECTION 7:  LIMITATIONS ON LIABILITY; NO WARRANTY 1 
 2 
EXCEPT FOR BREACH OF CONFIDENTIALITY, ADOPTER’S BREAC H OF SECTION 3, AND ADOPTER’S 3 
INDEMNIFICATION OBLIGATIONS, IN NO EVENT SHALL ANY PARTY BE LIABLE TO ANY OTHER PARTY OR THIRD 4 
PARTY FOR ANY INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE OR CONSEQUENTIAL DAMAGES RESULTING FROM 5 
ITS PERFORMANCE OR NON-PERFORMANCE UNDER THIS AGREE MENT, IN EACH CASE WHETHER UNDER 6 
CONTRACT, TORT, WARRANTY, OR OTHERWISE, AND WHETHER OR NOT SUCH PARTY HAD ADVANCE NOTICE 7 
OF THE POSSIBILITY OF SUCH DAMAGES. 8 
 9 
O-RAN SPECIFICATIONS ARE PROVIDED “AS IS” WITH NO W ARRANTIES OR CONDITIONS WHATSOEVER, 10 
WHETHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE.  THE O-RAN ALLIANCE AND THE MEMBERS, 11 
CONTRIBUTORS OR ACADEMIC CONTRIBUTORS EXPRESSLY DIS CLAIM ANY WARRANTY OR CONDITION OF 12 
MERCHANTABILITY, SECURITY, SATISFACTORY QUALITY, NONINFRINGEMENT, FITNESS FOR ANY PARTICULAR 13 
PURPOSE, ERROR-FREE OPERATION, OR ANY WARRANTY OR CONDITION FOR O-RAN SPECIFICATIONS. 14 
 15 
SECTION 8:  ASSIGNMENT 16 
 17 
Adopter may not assign the Agreement or any of its rights or obligations under this Agreement or make any 18 
grants or other sublicenses to this Agreement, except as expressly authorized hereunder, without having first 19 
received the prior, written consent of the O-RAN Alliance, which consent may be withheld in O-RAN Alliance’s 20 
sole discretion.  O-RAN Alliance may freely assign this Agreement. 21 
 22 
 23 
 24 
SECTION 9:  THIRD-PARTY BENEFICIARY RIGHTS 25 
 26 
Adopter acknowledges and agrees that Members, Contributors and Academic Contributors (including future 27 
Members, Contributors and Academic Contributors) are entitled to rights as a third-party beneficiary un der 28 
this Agreement, including as licensees under Section 3. 29 
 30 
SECTION 10:  BINDING ON AFFILIATES 31 
 32 
Execution of this Agreement by Adopter in its capac ity as a legal entity or association constitutes th at legal 33 
entity’s or association’s agreement that its Affiliates are likewise bound to the obligations that are applicable 34 
to Adopter hereunder and are also entitled to the benefits of the rights of Adopter hereunder. 35 
 36 
SECTION 11:  GENERAL 37 

 
Copyright © 2019 by the O-RAN Alliance e.V. Your use is subject to the terms of the O-RAN Adopter License 
Agreement in the Annex Z.  
34 
 
ORAN-WG2.AIML.v01.00 
 1 
This Agreement is governed by the laws of Germany without regard to its conflict or choice of law provisions.   2 
 3 
This Agreement constitutes the entire agreement bet ween the parties as to its express subject matter a nd 4 
expressly supersedes and replaces any prior or contemporaneous agreements between the parties, whether 5 
written or oral, relating to the subject matter of this Agreement. 6 
 7 
Adopter, on behalf of itself and its Affiliates, agre es to comply at all times with all applicable laws, rules and 8 
regulations with respect to its and its Affiliates’ performance under this Agreement, including without 9 
limitation, export control and antitrust laws.  With out limiting the generality of the foregoing, Adopte r 10 
acknowledges that this Agreement prohibits any communication that would violate the antitrust laws. 11 
 12 
By execution hereof, no form of any partnership, joint venture or other special relationship is created between 13 
Adopter, or O-RAN Alliance or its Members, Contributors or Academic Contributors.  Except as expressly set 14 
forth in this Agreement, no party is authorized to make any commitment on behalf of Adopter, or O-RAN 15 
Alliance or its Members, Contributors or Academic Contributors. 16 
 17 
In the event that any provision of this Agreement conflicts with governing law or if any provision is held to be 18 
null, void or otherwise ineffective or invalid by a court of competent jurisdiction, (i) such provisions  will be 19 
deemed stricken from the contract, and (ii) the remaining terms, provisions, covenants and restrictions of this 20 
Agreement will remain in full force and effect. 21 
 22 
Any failure by a party or third party beneficiary to insist upon or enforce performance by another party of any 23 
of the provisions of this Agreement or to exercise any rights or remedies under this Agreement or otherwise 24 
by law shall not be construed as a waiver or relinquishment to any extent of the other parties’ or third party 25 
beneficiary’s right to assert or rely upon any such  provision, right or remedy in that or any other ins tance; 26 
rather the same shall be and remain in full force and effect. 27 